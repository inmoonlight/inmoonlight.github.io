{"pages":[{"title":"Hello,  ì•ˆë…•í•˜ì„¸ìš”  ğŸ‘‹","text":"Iâ€™m Jihyung Moon, a co-founder / CTO of SoftlyAI My current interests are Building a great AI product Effective and efficient AI product development Leading at scale Work and Education [JAN 2022 ~ ] CTO / Co-founder, SoftlyAI [OCT 2020 ~ DEC 2021] NLP Research Engineer, Upstage [DEC 2018 ~ OCT 2020] NLP Research Engineer, Papago, NAVER Corporation [FEB 2018 ~ DEC 2018] ML Research Engineer, Search Modeling, Search &amp; Clova, NAVER Corporation [MAR 2016 ~ FEB 2018] M.S., Datamining Lab, Seoul National University [MAR 2011 ~ FEB 2016] B.S., Major in Chemical and Biological Engineering and minor in Industrial Engineering, Seoul National University Publications Analyzing Norm Violations in Real-Time Live-Streaming Chat. NLP+CSS@EMNLP 2022 [paper] Jihyung Moon*, Dong-Ho Lee*, Hyundong J. Cho, Woojeong Jin, Chan Young Park, Minwoo Kim, Jay Pujara and Sungjoon Park KOLD: Korean Offensive Language Dataset. EMNLP 2022 [paper] Younghoon Jeong, Juhyun Oh, Jaimeen Ahn, Jongwon Lee, Jihyung Moon, Sungjoon Park, and Alice Oh KLUE: Korean Language Understanding Evaluation. NeurIPS 2021 Datasets and Benchmarks Track [paper] [github] Sungjoon Park*, Jihyung Moon *, Sungdong Kim*, Won Ik Cho*, Jiyoon Han, Jangwon Park, Chisung Song, Junseong Kim, Yongsook Song, Taehwan Oh, Joohong Lee, Juhyun Oh, Sungwon Lyu, Younghoon Jeong, Inkwon Lee, Sangwoo Seo, Dongjun Lee, Hyunwoo Kim, Myeonghwa Lee, Seongbo Jang, Seungwon Do, Sunkyoung Kim, Kyungtae Lim, Jongwon Lee, Kyumin Park, Jamin Shin, Seonghyun Kim, Lucy Park, Alice Oh, Jung-Woo Ha, and Kyunghyun Cho PATQUEST: Papago Translation Quality Estimation. Proceedings of the Fifth Conference on Machine Translation [paper] Yujin Baek*, Zae Myung Kim*, Jihyung Moon, Hyunjoong Kim, and Eunjeong L. Park BEEP! Korean Corpus of Online News Comments for Toxic Speech Detection. SocialNLP@ACL 2020 [paper] [github] [slide] Jihyung Moon *, Won Ik Cho*, and Junbum Lee Revisiting Round-Trip Translation for Quality Estimation. EAMT 2020 [paper] Jihyung Moon, Hyunchang Cho, and Eunjeong L. Park Talks AI and Marginarlized Language. July 2023. ICML Panel Discussion. KLUE and XTREME. Sep 2021. XTREME Talks (Google Internal Seminar Series). KLUE: Korean Language Understanding Evaluation. Sep 2021. BigScience Episode #2. [youtube] [AIì™€ ì €ì‘ê¶Œë²•] ë‚´ê°€ ë§Œë“  AI ëª¨ë¸ì€ í•©ë²•ì¼ê¹Œ, ë¶ˆë²•ì¼ê¹Œ?. Feb 2021. Boostcamp AI Tech. ì„œë¹„ìŠ¤ ê´€ì ì—ì„œì˜ AI ëª¨ë¸ ê°œë°œ. Nov 2020. ë©‹ìŸì´ ì‚¬ìì²˜ëŸ¼. ì´ ì„  ë„˜ìœ¼ë©´ ì¹¨ë²”ì´ì•¼, BEEP!. Sep 2020. PyCon. [slide] [youtube] BEEP! Korean Corpus of Online News Comments for Toxic Speech Detection. July 2020. ì¹´ì¹´ì˜¤ë¸Œë ˆì¸. [slide] íŒŒíŒŒê³ ê°€ ì–¸ì–´ë¥¼ ë°°ìš°ëŠ” ë°©ë²•. June 2020. ì¸ë¬¸í•™ë„ë¥¼ ìœ„í•œ ì–¸ì–´ê³¼í•™ ì½œë¡œí‚¤ì›€, ì„œìš¸ëŒ€í•™êµ ë™ì•„ë¬¸í™”ì—°êµ¬ì†Œ. [slide] ì˜¨ë¼ì¸ ë‰´ìŠ¤ ëŒ“ê¸€ ìƒíƒœê³„ë¥¼ íë¦¬ëŠ” ì–´ë·°ì € ë¶„ì„ê¸°. Oct 2019. ë°ì´í„°ì•¼ë†€ì. [slide] Academic Services Reviewer for EMNLP 2021, EMNLP 2022, and ACL 2023 Patents í™œë™ ë°ì´í„° ë¶„ì„ì„ í†µí•´ ë¹„ì •ìƒ ì‚¬ìš©ì ê·¸ë£¹ì„ íƒì§€í•˜ëŠ” ë°©ë²• ë° ì‹œìŠ¤í…œ (METHOD AND SYSTEM FOR DETECTING ABUSER USING LOG DATA ANALYSIS), KR 1022091000000, filed 5 Sep 2018, issued 22 Jan 2021. [kipris] ê¹€íƒœìš±, ë¬¸ì§€í˜•, ìµœì¸ì‹, ë°•íš¨ê·  Projects [NOV 2018] PyTorchTutorial for Beginners [github] [JUL 2017] Tensorflow Implementation of Relation Network (RN) [github] [JAN 2017 ~ FEB 2017] êµ¬ê¸€ ì—¬ì„± ì†Œí”„íŠ¸ì›¨ì–´ ìº í”„ (Develop with Google) 1ê¸° Things you donâ€™t need to know Cafephile, especially drip and dutch coffee â˜•ï¸ Fan of figure skating â›¸ Emoticon creator, debuted with â€œDaily life of SOTA, an ML Research Engineerâ€","link":"/about/index.html"}],"posts":[{"title":"2020ë…„ì„ ì •ë¦¬í•˜ê³ , 2021ë…„ì„ ë§ì´í•˜ëŠ” ê¸€","text":"2020ë…„ì˜ ì—°ë§ì€ ê·¸ ì–´ëŠ ë•Œë³´ë‹¤ë„ ì—°ë§ê°™ì§€ ì•Šì•˜ë‹¤. ì¼ ë…„ì„ ì£¼ê¸°ë¡œ ì›€ì§ì˜€ë˜ í•™ìƒ ë•Œë‚˜ íšŒì‚¬ì˜ ê·¼ë¡œìì¼ ë•Œì™€ëŠ” ì²˜í•œ ìƒí™©ì´ ë‹¤ë¥´ê¸°ë„ í–ˆê³ , ì½”ë¡œë‚˜ë¡œ ì¸í•œ ê³ ìš”í•¨ë„ í•œ ëª«í–ˆë˜ ê²ƒ ê°™ë‹¤. ìƒˆë¡­ê²Œ íšŒì‚¬ë¥¼ ë§Œë“¤ê³  ë©¤ë²„ë“¤ê³¼ alignë˜ì–´ ë‹¬ë ¤ë‚˜ê°ˆ ì¤€ë¹„ë¥¼ ë§ˆì¹œ ì‹œì ì´ 11ì›” ì •ë„ì˜€ê³ , í•œì°½ KLUE í”„ë¡œì íŠ¸ê°€ ë‹¬ë¦¬ê³  ìˆë˜ ì‹œê¸°ê°€ 12ì›”ì´ì—ˆìœ¼ë‹ˆ 12ì›” ë§ì´ ì—°ë§ë³´ë‹¤ëŠ” ì›”ë§ì˜ ëŠë‚Œì´ì—ˆë‹¤. ê²Œë‹¤ê°€ ì½”ë¡œë‚˜ë¡œ ì‚¬íšŒì  ê±°ë¦¬ë‘ê¸° ë‹¨ê³„ê°€ ê²©ìƒë˜ë©´ì„œ ì—°ë§íŒŒí‹°ë¥¼ í•˜ë©° ì‚¬ëŒë“¤ê³¼ ê°•ì œë¡œë¼ë„ ì¼ë…„ì„ íšŒê³ í•˜ê³  ë§ˆë¬´ë¦¬í•˜ëŠ” ê²ƒì¡°ì°¨ ì–´ë ¤ì› ë‹¤. ë”°ë¡œ ì‹œê°„ì„ ë‚´ì„œ ë§ˆë¬´ë¦¬í•˜ê¸°ì—ëŠ” ì²´ë ¥ì ìœ¼ë¡œë„, ì •ì‹ ì ìœ¼ë¡œë„ íœ´ì‹ì´ ë” í•„ìš”í–ˆê¸° ë•Œë¬¸ì— &quot;ë‚˜ì˜ ì—°ë§ì€ ì´ í”„ë¡œì íŠ¸ê°€ ë§ˆë¬´ë¦¬ë˜ëŠ” ì‹œì ìœ¼ë¡œ ìœ ì˜ˆí•œë‹¤!&quot;ê³  ìê¸° í•©ë¦¬í™”ë¥¼ í•˜ë©° ì—°ë§ê³¼ ì—°ì´ˆë¥¼ ë³´ëƒˆë‹¤. ê·¸ëŸ°ë° ë–¡í•˜ë‹ˆ íšŒê³ ì˜ ë‹¤ì§ì˜ ì£¼ì œë¥¼ ë‹´ì„ ë²•í•œ ì´ ê¸€ì€ ëŒ€ì²´ ë¬´ì—‡ì´ëƒ. ì‘ë…„ ìƒë°˜ê¸°ì˜ í”„ë¡œì íŠ¸ê°€ ì™„ë£Œë˜ê³  í•œ í…œí¬ ì‰¬ì–´ê°€ë˜ 4ì›”ì„ ì œì™¸í•˜ê³  í•˜ë°˜ê¸°ë¥¼ ìì˜ë°˜ íƒ€ì˜ë°˜ìœ¼ë¡œ ì‰´í‹ˆì—†ì´ ë‹¬ë ¤ì™”ë˜ì§€ë¼ ë²ˆì•„ì›ƒìœ¼ë¡œ ì¸í•œ ìŠ¬ëŸ¼í”„ê°€ ì˜¤ê¸° ì‹œì‘í–ˆë‹¤. ë‚˜ì˜ ë²ˆì•„ì›ƒ ê·¹ë³µ ë…¸í•˜ìš° ì¤‘ì˜ í•˜ë‚˜ë¡œ ë‹¹ì¥ í•´ì•¼í•  ê²ƒ ê°™ì€ ì¼ì„ ë¨¸ë¦¬ì—ì„œ ì§€ìš°ê³ , ê·¸ ì¼ì„ í•´ì•¼í•˜ëŠ” ì´ìœ ë¥¼ ì •ë¦¬í•˜ëŠ” ê²ƒì´ ìˆë‹¤. ì™œ ë‚˜ëŠ” ì´ ì‹œê°„ì— ì´ ì¼ì„ í•˜ê³  ìˆëŠ”ì§€ ìŠ¤ìŠ¤ë¡œë¥¼ ì´í•´ì‹œí‚¤ê³  ì •ë§ í•´ì•¼í•˜ëŠ” ì¼ê³¼ í•˜ë©´ ì¢‹ì„ ì¼ì„ êµ¬ë¶„í•˜ë©´ í˜„ì¬ì˜ ë‚´ê°€ ì§Šì–´ì§„ ë¬´ê²Œë¥¼ ëœì–´ë‚¼ ìˆ˜ ìˆê³ , ê¼­ ì§Šì–´ì ¸ì•¼ í•  ë¬´ê²Œë¥¼ ê°ë‹¹í•  ì˜ì§€ë¥¼ ë‹¤ì¡ì„ ìˆ˜ ìˆì–´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ìŠ¬ëŸ¼í”„ê°€ ê·¹ë³µëœë‹¤. ì§€ê¸ˆ ì •ë¦¬í•˜ëŠ” ê¸€ì€, ê·¸ë˜ì„œ ìƒˆí•´ë¶€í„° ì°¾ì•„ì˜¨ ë²ˆì•„ì›ƒ ê·¹ë³µì˜ ì¼í™˜ì´ë‹¤. ìµœê·¼ì— ì‚¬ëŒë“¤ì„ ë§Œë‚  ë•Œë§ˆë‹¤ ê°€ì¥ ìì£¼ ë“¤ì—ˆë˜ ì§ˆë¬¸ì€, â€œê·¸ë˜ì„œ ì–´ì©Œë‹¤ê°€ ì—…ìŠ¤í…Œì´ì§€ì— í•©ë¥˜í•˜ê²Œ ëœê±°ì•¼?â€ ì´ë‹¤. ë¬¼ì–´ë³´ëŠ” ì‚¬ëŒì— ë”°ë¼ ì—¬ëŸ¬ ë²„ì „ìœ¼ë¡œ ëŒ€ë‹µì„ í–ˆë˜ ê²ƒ ê°™ë‹¤. ì‚¬ì‹¤ì´ ì•„ë‹Œ ë‹µë³€ì€ ì—†ì—ˆì§€ë§Œ, ì§„ì§œ ë‚˜ì˜ ìƒê°ì„ ê¾¹ê¾¹ ë‹´ì•„ ì „ë‹¬í•´ë³¸ ì ë„ ì—†ë˜ ê²ƒ ê°™ë‹¤. ë‚˜ëŠ” ì‚¬ëŒë“¤ì˜ ì‚¶ì— ë¹„ë¡ ë¯¸ì•½í• ì§€ë¼ë„, ê¸ì •ì ì¸ ë³€í™”ë¥¼ ë¶ˆì–´ë„£ê³  ì‹¶ë‹¤. ê·¸ë¦¬ê³  ê·¸ ë³€í™”ëŠ” ë‚´ê°€ ì‚´ì•„ì˜¤ë©´ì„œ ëŠê¼ˆë˜ ë¶ˆë§Œì¡±ìŠ¤ëŸ¬ì›€ì˜ ì˜ì—­ì„ ë§Œì¡±ìŠ¤ëŸ¬ì›€ì˜ ì˜ì—­ìœ¼ë¡œ ë§Œë“œëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. ë‚˜ëŠ” ì‚¬ëŒë“¤ ê°œê°œì¸ì˜ ë…ì°½ì„±ì´ ì¡´ì¤‘ë°›ëŠ” ì‚¬íšŒë¥¼ ì›í•œë‹¤. ì´ ë•Œë¬¸ì— ë˜‘ë˜‘í•¨ì„ íŒë‹¨í•˜ëŠ” ê¸°ì¤€ì„ ì‹œí—˜ì„ ì˜ ë³´ëŠ” ê²ƒ ì •ë„ë¡œ ê·œì •í•˜ëŠ” ìš°ë¦¬ë‚˜ë¼ì˜ êµìœ¡ì œë„ì™€ ê°œì¸ì— ëŒ€í•œ ì œëŒ€ë¡œ ëœ ì´í•´ì—†ì´ ì¼ë¶€ì˜ íŠ¹ì„±ë§Œìœ¼ë¡œ ê°œì¸ì„ ê·œì •í•˜ê³  íŒë‹¨í•˜ëŠ” ì‚¬íšŒì  í¸ê²¬ê³¼ í˜ì˜¤ë¥¼ ê°œì„ ì‹œí‚¤ê³  ì‹¶ì—ˆë‹¤. ìš°ë¦¬ë‚˜ë¼ì˜ êµìœ¡ì œë„ë¥¼ ê°œì„ ì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ë¬´ì—‡ì„ í•´ì•¼í• ê¹Œ? ë‚´ê°€ êµìœ¡ì— ìˆì–´ ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ì „ë‹¬í•˜ê³  ì‹¶ì€ ë©”ì‹œì§€ëŠ”, &quot;ë˜‘ë˜‘í•˜ê³  ì§€í˜œë¡œìš´ ì‚¬ëŒì€ ìë¦¬ì— ì•‰ì•„ì„œ ì±…ì— ì íŒ ê°œë…ì„ ì™¸ìš°ê±°ë‚˜ ì´í•´í•´ì„œ ì‹œí—˜ë¬¸ì œë¥¼ ì‹¤ìˆ˜ì—†ì´ ì˜ í’€ê³  ë§ì¶”ëŠ” ì‚¬ëŒ&quot;ì´ ì•„ë‹ˆë¼ëŠ” ê²ƒì´ë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— í•˜ë£¨ì˜ ëŒ€ë¶€ë¶„ì„ í•™ì›ì´ë‚˜ í•™êµì—ì„œ ë³´ë‚´ê³  ì •ì‘ ì¸ìƒì—ì„œ ì¤‘ìš”í•œ &quot;ë‚˜ë¼ëŠ” ì‚¬ëŒì„ ë‹¤ê°ë„ì—ì„œ ì´í•´í•˜ê¸° ìœ„í•´ ì„¸ìƒì„ ê²½í—˜í•˜ëŠ” ì‹œê°„&quot;ì„ ê°€ì§€ì§€ ëª»í•˜ëŠ” ê²ƒì´ ì•ˆíƒ€ê¹Œì› ë‹¤. ì™œ ë‹¤ë“¤ í•™ì›ê³¼ í•™êµì—ì„œ ì˜¤ëœ ì‹œê°„ì„ ë³´ë‚¼ê¹Œ? ê·¸ ê²ƒì€ ì…ì‹œì—ì„œ ë’¤ì³ì§€ë©´ ë§í•  ê²ƒì´ë¼ëŠ” ì–´ë¥¸ë“¤ì˜ ê³¼ë„í•œ ë‘ë ¤ì›€ê³¼ ì–‘ê·¹í™”ë¡œ ì¸í•œ ë¶ˆê³µì •í•œ ì‚¬íšŒë¼ëŠ” ì‚¬ì‹¤ í˜¹ì€ ì¸ì‹ ë•Œë¬¸ì´ë‹¤. ê°œì¸ì˜ ë…¸ë ¥ìœ¼ë¡œëŠ” ë” ì´ìƒ ì¢‹ì€ ì¡°ê±´ì˜ í™˜ê²½ì„ ê·¹ë³µí•  ìˆ˜ ì—†ëŠ” ì‚¬íšŒë¼ëŠ” ìƒê°ì´ ê°•í•´ì§ˆìˆ˜ë¡, ê³µì •í•´ë³´ì´ëŠ” ìˆ˜ëŠ¥ì„ í†µí•œ í•™ë²Œ ì‚¬ë‹¤ë¦¬ë¥¼ íƒ€ê¸° ìœ„í•´ ì‚¬êµìœ¡ì‹œì¥ì€ ë”ìš± ì¹˜ì—´í•˜ê²Œ ë¶ˆíƒ€ì˜¤ë¥¼ ê²ƒì´ë‹¤. ë‹¤í–‰ì¸ì§€ ë¶ˆí–‰ì¸ì§€, ë‚˜ëŠ” ê·¸ë ‡ê²Œ ì¢‹ì€ ìˆ˜ì €ë¥¼ ë¬¼ê³  íƒœì–´ë‚œ í¸ì€ ì•„ë‹ˆë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ì´ ì‚¬íšŒê°€ ì–¼ë§Œí¼ ë¶ˆê³µì •í•œì§€, ë¶€ëª¨ë‹˜ë“¤ì´ ëŠë¼ëŠ” ë‘ë ¤ì›€ì€ ì •ë‹¹í•œ ê²ƒì¸ì§€ ì§ì ‘ ê²½í—˜í•˜ê³  ë‚˜ì˜ ì¸ìƒì´ ì €ë¬¼ì–´ê°ˆ ë•Œì¯¤ì—ì•¼ ë‚´ê°€ í•œêµ­ êµìœ¡ì—ì„œ ë¬¸ì œë¼ê³  ëŠë¼ëŠ” ê°€ì„¤ì— ëŒ€í•œ ë‹µì„ ì°¾ì„ ìˆ˜ ìˆì„ ê²ƒì´ë¼ê³  ìƒê°í–ˆë‹¤. ë‹µì„ ì°¾ëŠ”ë‹¤ë©´, ì£¼ì €ì—†ì´ í•™êµë¥¼ ì„¸ì›Œì„œ ë‚˜ì˜ ê²½í—˜ í˜¹ì€ ìœ ì‚¬í•œ ê²½í—˜ì„ í–ˆë˜ ë¶„ë“¤ì˜ ì´ì•¼ê¸°ë¥¼ ì „ë‹¬í•˜ê³  ì‹¶ë‹¤. ì‚¬íšŒì  í¸ê²¬ê³¼ í˜ì˜¤ëŠ” ì™œ ë¬¸ì œì´ê³  ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆì„ê¹Œ? í¸ê²¬ê³¼ í˜ì˜¤ì˜ ê·¼ê±°ê°€ ë˜ëŠ” ì†ì„±ì´ &quot;ë‚˜&quot;ë¥¼ êµ¬ì„±í•˜ëŠ” íŠ¹ì§•ì´ê³  ì´ëŠ” ë‚˜ì˜ ë…¸ë ¥ìœ¼ë¡œ ì–´ì°Œí•  ìˆ˜ ì—†ëŠ” ì˜ì—­ì´ê±°ë‚˜ ì¡´ì¤‘ë°›ì•„ì•¼ ë§ˆë•…í•  ì„ íƒì´ê¸° ë•Œë¬¸ì´ë‹¤. ë‚˜ì˜ ì„±ë³„ì€ ì—¬ìë‹¤. ì´ ì†ì„±ì€ ë‚˜ì˜ ì˜ì§€ë¡œ ê·¸ë ‡ê²Œ ëœ ê²ƒì´ ì•„ë‹ˆë‹¤ (ë†€ëê²Œë„ 500ì—¬ë…„ ì „ì—ëŠ” ì–´ì°Œí•  ìˆ˜ ìˆëŠ” ì˜ì—­ì´ë¼ê³  ìƒê°í–ˆì—ˆë‹¤). ì„±ì ì§€í–¥ì„±, ì¥ì• ë„ ë§ˆì°¬ê°€ì§€ë¼ê³  ìƒê°í•œë‹¤. ì´ë¯¼ í˜¹ì€ ì •ì¹˜ì  ì„±í–¥ì€ ë‚˜ì˜ ì„ íƒê³¼ ìƒê°ì˜ ì˜ì—­ì´ì§€ ë‚¨ì—ê²Œ ë¹„ë‚œë°›ì•„ì•¼í•  ì†ì„±ì€ ì•„ë‹ˆë‹¤. ì–´ë–»ê²Œ í•œ ì‚¬ëŒì„ ê²‰ìœ¼ë¡œ ë“œëŸ¬ë‚  ë¿ì¸ ì–•ì€ íŠ¹ì„±ë§Œìœ¼ë¡œ ë§ì€ ë¶€ë¶„ì„ ê·œì •ì§“ê³  í˜¸ì™€ ë¶ˆí˜¸ë¥¼ ê°€ë³ê²Œ íŒë‹¨í•´ë²„ë¦´ ìˆ˜ ìˆëŠ”ê±¸ê¹Œ. êµìœ¡ê³¼ëŠ” ë‹¤ë¥´ê²Œ ì‚¬íšŒì  í¸ê²¬ê³¼ í˜ì˜¤ëŠ” ë‚´ê°€ ê°€ì§„ ëŠ¥ë ¥ìœ¼ë¡œ í•´ê²°í•˜ê¸° ìœ„í•´ ë” ë¹ ë¥¸ ì‹œì ì— ë„ì „í•´ë³¼ ê°€ì¹˜ê°€ ìˆëŠ” ë¬¸ì œë¼ê³  ì—¬ê²¨ì¡Œë‹¤. í‘œí˜„ì„ í•˜ëŠ” í–‰ìœ„ ìì²´ëŠ” ì–´ì°Œí•  ìˆ˜ ì—†ë”ë¼ë„ (ì¼ì •ë¶€ë¶„ í‘œí˜„ì˜ ììœ ì™€ë„ ë§ë¬¼ë ¤ ìˆëŠ” ì˜ì—­ì´ê¸°ë„ í•˜ê³ ) ì ì–´ë„ ê·¸ í”¼í•´ê°€ í”¼í•´ìì—ê²Œê¹Œì§€ëŠ” ë‹¿ì§€ ì•Šì•˜ìœ¼ë©´ í•˜ëŠ” ë§ˆìŒì´ ìˆì—ˆë‹¤. ê·¸ë˜ì„œ ì¡°ê·¸ë§£ê²Œë‚˜ë§ˆ ë‚´ê°€ í•  ìˆ˜ ìˆëŠ” ì¼ë¶€í„° ì‹œì‘í–ˆê³ , ê·¸ ì¼ì´ ê³„ê¸°ê°€ ë˜ì–´ ë‹¤ì–‘í•œ ì‚¬ëŒë“¤ê³¼ ê¸°íšŒë¥¼ ë§ˆì£¼í•˜ê²Œ ë˜ì—ˆë‹¤. ì²˜ìŒì—ëŠ” ì•„ë¬´ ê²ƒë„ ì—†ì—ˆê¸° ë•Œë¬¸ì— ë°ì´í„°ì…‹ì„ ë§Œë“¤ê³  ì—°êµ¬ë¡œì„œì˜ ê°€ì¹˜ë¥¼ ë§Œë“œëŠ” ê²ƒìœ¼ë¡œ ì‹œì‘í–ˆì§€ë§Œ ë” í° ë³€í™”ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ë” ë§ì€ ì‚¬ëŒë“¤ê³¼ í•¨ê»˜ í•´ì•¼í•œë‹¤ê³  ìƒê°í–ˆë‹¤. ì‚¬ëŒì„ ëª¨ìœ¼ëŠ” ê²ƒì´ ë‚´ê°€ ì•„ë‹ˆë”ë¼ë„ ìƒê´€ì—†ì—ˆê³ , ê·¸ì € ë‚˜ì™€ ë°©í–¥ì´ ê°™ì€ ì‚¬ëŒë“¤ê³¼ ë¬´ì—ì„œ ìœ ë¥¼ ì°½ì¡°í•˜ê³  ì‹¶ì—ˆë‹¤. ê·¸ ë§ˆìŒì´ ì›ìµë‹˜, ì¤€ë²”ë‹˜, ì„±ì¤€ë‹˜ì„ ê±°ì³ ë£¨ì‹œ, í™œì„ë‹˜, ê·¸ë¦¬ê³  ì„±í‚´ê¹Œì§€ ë§Œë‚˜ê²Œ í•´ì£¼ì—ˆê³  ì—…ìŠ¤í…Œì´ì§€ì˜ í•©ë¥˜ë¥¼ ê²°ì •í•˜ê²Œ í•´ì£¼ì—ˆë‹¤. ê²°ê³¼ì ìœ¼ë¡œ Making AI Beneficial ì´ë¼ëŠ” ë„“ì€ ë¹„ì „ ì•„ë˜ì—ì„œ í•˜ê³  ì‹¶ì€ ë°©í–¥, í•´ì•¼í•œë‹¤ê³  ìƒê°í•˜ëŠ” ë°©í–¥ì˜ ì¼ì„ í•˜ê³  ìˆë‹¤ê³  ìƒê°í•œë‹¤. 8ì›” ì–´ëŠ ë‚ , ì—…ìŠ¤í…Œì´ì§€(ê·¸ ë•ŒëŠ” ë„ˆìš¸ì´ì—ˆë˜â€¦)ì˜ í•©ë¥˜ë¥¼ ê²°ì •ì§“ê³  ë‚´ê°€ ì´ ê³³ì—ì„œ ë°°ìš°ê³  ì‹¶ê³ , ì´ ê³³ì„ ê°€ì•¼ë§Œ í•œë‹¤ê³  ìƒê°í–ˆë˜ ì´ìœ ë¥¼ ì ì–´ë‘” ì¼ê¸°ê°€ ìˆì—ˆëŠ”ë° ëŒ€ë¶€ë¶„ì´ ì‹¤í˜„ë˜ê³  ìˆë‹¤. 2021ë…„ì—ëŠ” ì´ì „ê³¼ëŠ” ì¡°ê¸ˆ ë‹¤ë¥¸ ë°©í–¥ìœ¼ë¡œì˜ ì„±ì¥ì„ ê¿ˆê¾¸ê³  ì‹¶ë‹¤. ìš°ì„  í•¨ê»˜ ì¼í•˜ê³  ì‹¶ì€ ì‚¬ëŒì´ ë˜ê³  ì‹¶ë‹¤. soft skill ì¸¡ë©´ì—ì„œ ë‚´ê°€ ìƒê°í•˜ëŠ” ê°™ì´ ì¼í•˜ê³  ì‹¶ì€ ì‚¬ëŒì´ë€ ê²¸ì†í•˜ë©´ì„œ ë„ì „í•˜ê¸°ë¥¼ ë©ˆì¶”ì§€ ì•Šê³ , ì‚¬ëŒì„ ì´í•´í•˜ëŠ” ì‚¬ëŒì´ë‹¤. hard skill ì¸¡ë©´ì—ì„œëŠ” ìì‹ ë§Œì˜ ì—£ì§€ë¥¼ ê°€ì§„ ì‚¬ëŒì´ë‹¤. ê·¸ ì˜ì—­ì´ ê¸°ìˆ ì¼ ìˆ˜ë„ ìˆê² ì§€ë§Œ ë§¤ë‹ˆì§•ì´ë‚˜ ë©˜í† ë§ë„ í¬í•¨ëœë‹¤ê³  ìƒê°í•œë‹¤. í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ë‚´ìš©ì„, ì„¤ì‚¬ ê·¸ ë‚´ìš©ì´ ì•„í”Œì§€ë¼ë„ ë¶€ë“œëŸ½ê³  ì£¼ì €ì—†ì´ ì „ë‹¬í•˜ëŠ” ì‚¬ëŒì´ ë˜ê³  ì‹¶ë‹¤. ë³´ë‹¤ ìŠ¤ìŠ¤ë¡œì—ê²Œ ë–³ë–³í•œ ì‚¬ëŒì´ ë˜ê³ ë„ ì‹¶ë‹¤. í•˜ì§€ë§Œ ê°€ì¥ ë˜ê³  ì‹¶ì€ ëª¨ìŠµì€, ë§ì€ ê²ƒë“¤ì— ìµìˆ™í•´ì ¸ì„œ ì—¬ìœ ê°€ ìˆëŠ” ì‚¬ëŒì´ë‹¤. ë‚˜ì˜ ì¸ìƒì— slackì„ ë‘ê³  ì‹¶ê³ , ê·¸ ì‹œê°„ì— ë‚˜ë¥¼ í¬í•¨í•´ì„œ ë‚˜ì˜ ë„ì›€ì„ í•„ìš”ë¡œ í•˜ëŠ” ì‚¬ëŒì„ ì‚´í”¼ê³  ëŒë³´ê³  ì‹¶ë‹¤. ê·¸ ë°–ì—ë„ 2021ë…„ì—ëŠ” ë³´ë‹¤ ê·œì¹™ì ì¸ ìƒí™œì„ í•˜ê¸¸ ë°”ë¼ê³  ë§ˆìŒí¸íˆ ìš´ë™í•˜ê³  ì—¬í–‰ë‹¤ë‹ˆë©° ì¹œêµ¬ë“¤ê³¼ ìˆ˜ë‹¤ë–¨ ìˆ˜ ìˆëŠ” ë‚ ì´ ì˜¤ê¸¸ ì†Œë§í•œë‹¤.","link":"/2021/01/10/Adieu-2020-and-happy-new-year/"},{"title":"Attention in NLP","text":"You canâ€™t cram the meaning of a whole %&amp;!# sentence into a single &amp;!#* vector! Raymond Mooney Attentionì€ single vectorì— í•œ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ì™„ë²½í•˜ê²Œ ë‹´ì„ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— í•„ìš”í•œ ìˆœê°„ì—, í•„ìš”í•œ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë°©ë²•ì´ë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ query vectorì™€ key vectorì˜ ì¡°í•©ìœ¼ë¡œ attention weightê°€ ê³„ì‚°ëœë‹¤. ì—¬ê¸°ì„œ &quot;ì¡°í•©&quot;ì˜ ë°©ë²•ì—ëŠ” í¬ê²Œ ë‘ê°€ì§€ê°€ ìˆë‹¤. í•˜ë‚˜ëŠ” Additive Attentionìœ¼ë¡œ query vectorì™€ key vectorì— feed-forward networkë¥¼ ì ìš©í•œ ê²ƒì´ê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” Dot-Product Attentionìœ¼ë¡œ ë¬¸ìê·¸ëŒ€ë¡œ query vectorì™€ key vectorì˜ dot-productë¥¼ ì´ìš©í•œ ê²ƒì´ë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” ê° Attention ë°©ë²•ë“¤ê³¼ ì´ë“¤ì˜ ì¥ë‹¨ì ì„ ì†Œê°œí•˜ë ¤ê³  í•œë‹¤. Additive Attention Additive Attentionì€ query vectorì™€ key vectorì˜ ì¡°í•©ìœ¼ë¡œ attention ê°’ì„ ì–»ì„ ë•Œ ë‹¨ì¼ hidden layerë¥¼ ê°€ì§„ feed-forward networkë¥¼ ì´ìš©í•œë‹¤. query vector ($q$) ì™€ key vector ($k$) ê°€ ê°™ì€ dimensionì„ ê°€ì§ˆ í•„ìš”ê°€ ì—†ìœ¼ë©°, dimensionì˜ í¬ê¸°ì— ìƒê´€ì—†ì´ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤. Bilinear&lt;span class=â€œhintâ€“top hintâ€“error hintâ€“medium hintâ€“rounded hintâ€“bounceâ€ aria-label=&quot;Effective Approaches to Attention-based Neural Machine Translation &quot;&gt;[2] \\[a(q, k)= q^{T} Wk\\] \\(q\\) ì™€ \\(k\\) ì— \\(W\\) ë¥¼ ê³±í•˜ëŠ” ë°©ë²•ì´ë‹¤. \\(q\\) ë¥¼ linear transform ì‹œí‚¨ í›„, \\(k\\) ì™€ dot-productë¥¼ í•œ ê²ƒê³¼ ê°™ë‹¤. Multi-layer Perceptron&lt;span class=â€œhintâ€“top hintâ€“error hintâ€“medium hintâ€“rounded hintâ€“bounceâ€ aria-label=&quot;Neural Machine Translation by Jointly Learning to Align and Translate &quot;&gt;[3] \\[a(\\boldsymbol{q}, \\boldsymbol{k})=\\boldsymbol{w}_{2}^{\\top} \\tanh \\left(W_{1}[\\boldsymbol{q} ; \\boldsymbol{k}]\\right)\\] \\(q\\) ì™€ \\(k\\) ë¥¼ concatì‹œí‚¨ í›„ single hidden layerì™€ activation í•¨ìˆ˜ë¡œ tanhë¥¼ ì‚¬ìš©í•œ feed-forward networkë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤. ì´ ë°©ë²•ì€ ìµìˆ™í•  ê²ƒì´ë‹¤. ì™œëƒí•˜ë©´ Neural Machine Translation by Jointly Learning to Align and Translateì—ì„œ ì´ attentionì„ ì´ìš©í–ˆê¸° ë•Œë¬¸ì´ë‹¤. ì•„ë˜ì˜ ì˜¤ë¥¸ìª½ ìˆ˜ì‹ì—ì„œ \\(a\\)ëŠ” alignment modelë¡œ ìœ„ì—ì„œ ì–¸ê¸‰í•œ feed-forward networkì™€ ê°™ì€ ì—­í• ì„ í•œë‹¤. Dot-Product Attention Dot-Product attentionì€ \\(\\boldsymbol{q}^{\\top} \\boldsymbol{k}\\)ì„ ê¸°ë°˜ìœ¼ë¡œ attention weightë¥¼ êµ¬í•˜ëŠ” ë°©ë²•ì´ë‹¤. Additive attentionê³¼ëŠ” ë‹¬ë¦¬ hidden layerë¥¼ ê³±í•˜ëŠ” ê³¼ì •ì´ ì¶”ê°€ë˜ì§€ ì•Šì•„ì„œ ì—°ì‚° ì†ë„ì™€ space ì¸¡ë©´ì—ì„œ íš¨ìœ¨ì ì´ë‹¤. í•˜ì§€ë§Œ ë°˜ë“œì‹œ \\(q\\)ì™€ \\(k\\)ì˜ dimensionì´ ê°™ì•„ì•¼ í•œë‹¤ëŠ” ì œì•½ì¡°ê±´ì´ ìˆìœ¼ë©°, dimensionì´ í´ ë•Œ í•™ìŠµì— ë°©í•´ê°€ ëœë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤. Dot-Product \\[a(\\boldsymbol{q}, \\boldsymbol{k})=\\boldsymbol{q}^{\\top} \\boldsymbol{k}\\] \\(q\\)ì™€ \\(k\\)ì˜ elment-wise productì˜ í•©ì´ë‹¤. ì´ ì—°ì‚°ì˜ íŠ¹ì„± ìƒ, ë°˜ë“œì‹œ dimensionì´ ê°™ì•„ì•¼ í•œë‹¤. ë§Œì•½ \\(q\\)ì™€ \\(k\\)ì˜ ê° ìš”ì†Œê°€ ë…ë¦½ì ì´ê³  í‰ê· ì´ 0, ë¶„ì‚°ì´ 1 ì¸ ë¶„í¬ì˜ random variableì´ë¼ë©´, \\({q}^{\\top}{k}\\) ëŠ” í‰ê· ì´ 0ì´ê³  ë¶„ì‚°ì´ dimensionì˜ í¬ê¸°ì¸ ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤. ë¶„ì‚°ì´ ì¦ê°€ë˜ë©´ dot-productì— softmaxë¥¼ ì·¨í–ˆì„ ë•Œ ì–´ë–¤ ê°’ì€ êµ‰ì¥íˆ í¬ì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ ê°’ì€ êµ‰ì¥íˆ ì‘ê²Œ ë§Œë“ ë‹¤. ì‘ì€ ê°’ë“¤ì€ back-propagation ì‹œ gradientë„ ì‘ê¸° ë•Œë¬¸ì— ì „ì²´ì ìœ¼ë¡œ í•™ìŠµì´ ì˜ ë˜ì§€ ì•Šê²Œ ë§Œë“ ë‹¤. ë”°ë¼ì„œ dimensionì´ í° ê²½ìš° ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šë‹¤. Scaled Dot-Product&lt;span class=â€œhintâ€“top hintâ€“error hintâ€“medium hintâ€“rounded hintâ€“bounceâ€ aria-label=&quot;Attention is All You Need &quot;&gt;[4] \\[a(\\boldsymbol{q}, \\boldsymbol{k})=\\frac{\\boldsymbol{q}^{\\top} \\boldsymbol{k}}{\\sqrt{|\\boldsymbol{d}|}}\\] Scaled Dot-ProductëŠ” Attention is All You Need ì—ì„œ ì²˜ìŒìœ¼ë¡œ ì†Œê°œëœ ë°©ë²•ì´ë‹¤. Dot-Productì˜ dimensionì´ í´ ë•Œ í•™ìŠµì´ ì˜ ë˜ì§€ ì•ŠëŠ” ë‹¨ì ì„ ê·¹ë³µí•˜ê²Œ ìœ„í•´ dot-product ê²°ê³¼ë¥¼ \\(q\\)ì˜ dimension \\(d\\) (\\(k\\) ì˜ dimension ì´ê¸°ë„ í•˜ë‹¤) ì˜ root ê°’ìœ¼ë¡œ ë‚˜ëˆ„ì–´ì£¼ì—ˆë‹¤.[5] Conclusions Additive attentionì€ dimensionì— ìƒê´€ì—†ì´ ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚´ê³ , attentionì„ ê³„ì‚°í•˜ëŠ” ì¬ë£Œì¸ query vectorì™€ key vectorì˜ dimensionì— ìƒê´€ì—†ì´ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ìµœê·¼ì˜ NLP trendë¼ê³  í•  ìˆ˜ ìˆëŠ”, ëŒ€ëŸ‰ì˜ ë°ì´í„°ë¥¼ êµ‰ì¥íˆ í° ëª¨ë¸ë¡œ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì—ëŠ” ì•ˆê·¸ë˜ë„ ë§ì€ ì—°ì‚°ëŸ‰ì— ë¶€ë‹´ì´ ë˜ëŠ” ë°©ë²•ì´ë‹¤. ê·¸ë˜ì„œ ê³„ì‚°ì˜ ë¶€ë‹´ì´ ì ìœ¼ë©´ì„œ dimensionì´ í° ê²½ìš°ì— ëŒ€í•´ì„œë„ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” scaled dot-product ê¸°ë°˜ì˜ attentionì´ ì˜ ì“°ì´ëŠ” í¸ì´ë‹¤. References 1.ì „ë°˜ì ì¸ ë‚´ìš©ì€ Graham Neubigì˜ NN4NLP Attention ê°•ì˜ë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤. â†©2.Effective Approaches to Attention-based Neural Machine Translation â†©3.Neural Machine Translation by Jointly Learning to Align and Translate â†©4.Attention is All You Need â†©5.rootë¡œ ë‚˜ëˆ„ì–´ ì¤€ ì´ìœ ëŠ” scaled dot-productì˜ ê²°ê³¼ë¥¼ í‰ê· ì´ 0, ë¶„ì‚°ì´ 1 ì¸ ë¶„í¬ë¡œ ë§Œë“¤ê¸° ìœ„í•´ì„œë‹¤. â†©","link":"/2020/01/27/Attention-in-NLP/"},{"title":"ìˆ˜í•™ìœ¼ë¡œ ì´í•´í•˜ëŠ” ì–‘ìì»´í“¨í„°ì˜ ê¸°ì´ˆ","text":"ìµœê·¼ì— ìˆì—ˆë˜ êµ¬ê¸€ì˜ ì–‘ì ìš°ì›”ì„± (Quantum Supremacy) ë‹¬ì„±ì€ ì „ì„¸ê³„ì ìœ¼ë¡œ í° í™”ì œì˜€ë‹¤. ë¬¼ ë“¤ì–´ì˜¬ ë•Œ ë…¸ ì €ìœ¼ë¼ê³  í•˜ì§€ ì•Šì•˜ë˜ê°€, ì´ ë•Œê°€ ì•„ë‹ˆë©´ ë˜ ì–¸ì œ ì–‘ìì»´í“¨í„°ì— ëŒ€í•´ ê³µë¶€í• ê¹Œ ì‹¶ì–´ì„œ í…ìŠ¤íŠ¸ì™€ ë™ì˜ìƒì„ ë„˜ë‚˜ë“¤ë©° ê´€ë ¨ ì§€ì‹ì„ ìŠµë“í•´ë³´ì•˜ë‹¤. ì•„ë§ˆ ë‚˜ì™€ ê°™ì´ ê´€ë ¨ ê¸°ì‚¬ë‚˜ ì—¬ëŸ¬ ë¸”ë¡œê·¸ ê¸€, ìœ íŠœë¸Œ ë“±ì„ ì°¾ì•„ë³¸ ì‚¬ëŒë“¤ì´ë¼ë©´ ì–´ë µì§€ ì•Šê²Œ ì•„ë˜ì˜ ì •ë³´ëŠ” ì–»ì—ˆì„ ê²ƒì´ë‹¤. nê°œì˜ qbitì€ bitì™€ ë‹¬ë¦¬ \\(2^n\\)ì˜ stateë¥¼ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. superpositionì´ë€ ë™ì‹œì— 0ê³¼ 1ì˜ ìƒíƒœë¥¼ ë ëŠ” ì„±ì§ˆë¡œ, ë³‘ë ¬ì—°ì‚°ì´ ê°€ëŠ¥í•´ì ¸ì„œ ê³ ì „ì»´í“¨í„°ì— ë¹„í•´ ê³„ì‚° ì†ë„ì˜ ì´ì ì´ ìƒê¸´ë‹¤. í…ìŠ¤íŠ¸ë§Œ ë³´ë©´ â€œì•„ ê·¸ë ‡êµ¬ë‚˜.â€ ì‹¶ì€ ë‚´ìš©ë“¤ì´ë‹¤. ì´í•´ê°€ ëœ ê²ƒì¼ê¹Œ ì‹¶ì—ˆì§€ë§Œ ìŠ¤ìŠ¤ë¡œì—ê²Œ ì„¸ ì§ˆë¬¸ì„ ë˜ì¡Œì„ ë•Œ ë‹µí•˜ì§€ ëª»í•˜ëŠ” ê²ƒì„ ë³´ë©° ì œëŒ€ë¡œ ì´í•´í•˜ì§€ ëª»í–ˆìŒì„ ì¸ì§€í–ˆë‹¤. Q1. nê°œì˜ bitë¡œë„ \\(2^n\\)ì„ í‘œí˜„í•  ìˆ˜ ìˆëŠ”ê±° ì•„ë‹Œê°€? 3ê°œì˜ bitê°€ 000, 001, 010, 011, 100, 101, 110, 111 ì´ë ‡ê²Œ 8ê°œì˜ ìƒíƒœë¥¼ í‘œí˜„í•  ìˆ˜ ìˆìœ¼ë‹ˆê¹Œ. Q2. ì–‘ì ì„¸ê³„ëŠ” ë¶ˆí™•ì •ì„± ì›ë¦¬ì— ì§€ë°°ë°›ëŠ”ë‹¤ê³  í•˜ëŠ”ë°, ëŒ€ì²´ ì–‘ìì»´í“¨í„°ë¡œ ì–´ë–»ê²Œ ì—°ì‚°í•˜ê³  ìˆëŠ” ê²ƒì´ë©°, ì´ ì„±ì§ˆì´ ì–´ë–»ê²Œ ê³„ì‚° ë¹„ìš©ì„ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆëŠ”ê±¸ê¹Œ? Q3. EntanglementëŠ” qbitë“¤ì´ ì–´ë–»ê²Œ ëœ ìƒíƒœì¸ê±°ì§€? ì´ ì§ˆë¬¸ë“¤ì— ì œëŒ€ë¡œ ë‹µí•˜ê¸° ìœ„í•´ì„œëŠ” ìˆ˜í•™ì´ í•„ìš”í•˜ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. 4ì°¨ì› ì´ìƒì˜ ê³µê°„ì„ ì œëŒ€ë¡œ ì‹œê°í™”í•˜ì§€ ëª»í•˜ë“¯ì´ ì–‘ì ì„¸ê³„ë¥¼ ìì—°ì–´ë¡œ í‘œí˜„í•œë‹¤ëŠ” ê²ƒ ìì²´ê°€ ë§ì´ ë˜ì§€ ì•ŠëŠ” ê²ƒ ê°™ì•˜ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ë˜ì„œ ìˆ˜í•™ìœ¼ë¡œ ì„¤ëª…ëœ ìë£Œë¥¼ ì°¾ìœ¼ë ¤ê³  ë¶€ë˜íˆ ì• ë¥¼ ì¼ê³ , ëë‚´ â€œë‚´ ìˆ˜ì¤€ì— ë§ëŠ”â€ (= ì´ ê¸€ì„ ì½ì„ ëª¨ë‘ê°€ ë‹¤ ì´í•´í•  ìˆ˜ ìˆëŠ”) ìˆ˜í•™ìœ¼ë¡œ ì„¤ëª…ëœ ìë£Œë¥¼ ì°¾ì•˜ë‹¤. [slide] ì´ ì˜ìƒì„ ë³´ëŠ” ê²ƒì„ ì¶”ì²œí•˜ì§€ë§Œ ë¬´ë ¤ í•œì‹œê°„ì´ ë„˜ëŠ”ì§€ë¼ ê¸€ë¡œë„ ì •ë¦¬ë¥¼ í•´ë³´ì•˜ë‹¤. ì•„ë˜ì— ê¸°ìˆ ëœ ë‚´ìš©ì€ ë‚´ ë°©ì‹ëŒ€ë¡œ ìœ„ì˜ ì˜ìƒê³¼ ìë£Œë¥¼ ì¬êµ¬ì„±í•œ ê²ƒì´ë‹¤. ì‚¬ì‹¤ ì´ ìë£Œë¥¼ ë‹¤ ë³´ë”ë¼ë„ ì–‘ìì»´í“¨í„°ì— ëŒ€í•´ ë§ì€ ê²ƒì„ ì•Œì•˜ë‹¤ê³  ë³´ê¸´ ì–´ë µë‹¤. pythonì„ ì²˜ìŒ ì ‘í•œ ì‚¬ëŒì´ print(&quot;Hello World!&quot;)ë¥¼ ì„±ê³µí–ˆë‹¤ê³  í•´ì„œ pythonì„ ì˜ ì•Œì•˜ë‹¤ê³  í•˜ê¸° ì–´ë ¤ìš´ ê²ƒì²˜ëŸ¼. ê·¸ë¦¬ê³  ë”¥ëŸ¬ë‹ì— ê´€ì‹¬ìˆëŠ” ì‚¬ëŒì´ tutorialì„ ë”°ë¼í•´ë³´ë©° CNNì„ ëŒë ¤ë´¤ë‹¤ê³  í•´ì„œ ë”¥ëŸ¬ë‹ì„ ì˜ ì•Œì•˜ë‹¤ê³  í•˜ê¸° ì–´ë ¤ìš´ ê²ƒì²˜ëŸ¼. ê·¸ë ‡ì§€ë§Œ ì–‘ì ì„¸ê³„ì— í•œ ë²ˆì€ Hello World!ë¥¼ ë‚ ë ¤ë´ì•¼ í•˜ì§€ ì•Šì„ê¹Œ? Introduction The Deutsch-Jozsa problem ì´ë¼ëŠ” ì•„ì£¼ ê°„ë‹¨í•œ ë¬¸ì œë¥¼ í†µí•´ ì–‘ìì»´í“¨í„°ê°€ ê³ ì „ì»´í“¨í„°ì— ë¹„í•´ ì–´ë–»ê²Œ ì—°ì‚° ì†ë„ì—ì„œ ì´ì ì„ ë³´ì´ëŠ”ì§€ ì•Œì•„ë³´ë ¤ê³  í•œë‹¤. ì´ ê³¼ì •ì„ ì´í•´í•˜ê¸° ìœ„í•´ ì–‘ìì»´í“¨í„°ê°€ ì—°ì‚°í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì†Œê°œí•  ê²ƒì´ë©° matrix ì—°ì‚°ê³¼ ê¸°ì´ˆì ì¸ ë…¼ë¦¬íšŒë¡œì— ëŒ€í•œ ë‚´ìš©ì„ ì§šê³  ë„˜ì–´ê°ˆ ê²ƒì´ë‹¤. ì¶”ê°€ë¡œ, entanglementì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…ì´ ìˆë‹¤. Basics Qubit / Qbit Qubit í˜¹ì€ Qbitì€ ì–‘ìì»´í“¨í„° ê³„ì‚°ì˜ ê¸°ë³¸ì ì¸ ë‹¨ìœ„ì´ë‹¤. ì¡°ê¸ˆì´ë¼ë„ ì–‘ìì»´í“¨í„°ì— ëŒ€í•´ ì•Œì•„ë³¸ ì‚¬ëŒë“¤ì´ë¼ë©´ qbitì€ ì§€ê²¹ë„ë¡ ë³´ê³  ë“¤ì—ˆì„ ê²ƒì´ë‹¤. Qbitì€ ì–¸ì œë‚˜ ë‹¤ìŒì˜ ì¡°ê±´ì„ ë§Œì¡±ì‹œí‚¨ë‹¤. A qbit, represented by \\(\\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}\\) where \\(\\alpha\\) and \\(\\beta\\) are complex numbers must be constrained by the equation \\(||\\alpha||^2 + ||\\beta||^2 = 1\\) ë”°ë¼ì„œ ì•„ë˜ì˜ ì˜ˆì‹œë“¤ì€ qbitì— í•´ë‹¹ëœë‹¤. \\(\\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix}\\) \\(\\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix}\\) \\(\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\) \\(\\begin{pmatrix} 0 \\\\ -1 \\end{pmatrix}\\) ê·¸ë¦¬ê³  ì´ ëª¨ë“  ë²¡í„°ë“¤ì˜ basisê°€ ë˜ëŠ” \\(\\begin{pmatrix} 1 \\\\0 \\end{pmatrix}\\)ê³¼ \\(\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}\\)ì€ ê°ê° \\(\\mid 0\\rangle\\)ê³¼ \\(\\mid 1\\rangle\\)ì´ë¼ëŠ” íŠ¹ë³„í•œ ê¸°í˜¸ë¡œ ì •ì˜í•œë‹¤. Superposition ì–‘ìì»´í“¨í„°ì˜ qbitì„ ì„¤ëª…í•  ë•Œ ë¹ ì§€ì§€ ì•ŠëŠ” ì„±ì§ˆì´ë‹¤. &quot;ë™ì‹œì— 0ê³¼ 1ì„ ê°€ì§„ë‹¤.&quot;ëŠ” ë¬¸ì¥ìœ¼ë¡œ ìì£¼ ì„¤ëª…ë˜ì§€ë§Œ ì´ë³´ë‹¤ëŠ” ìŠˆë¢°ë”©ê±°ì˜ ê³ ì–‘ì´ ëŠë‚Œì´ ë¬¼ì”¬ ë‚˜ëŠ” â€œWhen we measure a qbit, it collapses to an actual value of 0 or 1.â€ ì´ë¼ëŠ” ë¬¸ì¥ì´ ë” ì¢‹ì€ ì„¤ëª…ì¸ ê²ƒ ê°™ë‹¤. ìœ„ì—ì„œ qbitì´ë¼ê³  ì–¸ê¸‰í–ˆë˜ ë²¡í„° í•˜ë‚˜ë¥¼ ì˜ˆì‹œë¡œ ë“¤ì–´ë³´ì. \\[\\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix}\\] ì´ qbitì€ \\(0\\) í˜¹ì€ \\(1\\)ë¡œ collapseë  í™•ë¥ ì´ \\(\\frac{1}{2}\\) ( \\(= || \\frac{1}{\\sqrt{2}} || ^2\\)) ì´ë‹¤. ê°ì‚¬í•˜ê²Œë„ IBMì€ ìì‚¬ì˜ ì–‘ìì»´í“¨í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” APIë¥¼ ë§Œë“¤ì–´ ë†“ì•˜ë‹¤. ì—¬ê¸°ì„œ ì´ qbitì„ ë§Œë“¤ê³  1024ë²ˆ ê´€ì¸¡í•´ë³´ë©´ 0ê³¼ 1ì´ 50%ì”© ë‚˜ì˜¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. \\(\\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix}\\) ì€ \\(0\\)ìœ¼ë¡œ collapse ë  í™•ë¥ ì´ \\(\\frac{1}{4}\\), \\(1\\)ë¡œ collapse ë  í™•ë¥ ì´ \\(\\frac{3}{4}\\)ì¸ qbitì´ë‹¤. \\(|0\\rangle\\)ì€ 0ìœ¼ë¡œë§Œ collapse í•œë‹¤. Tensor product ì—¬ëŸ¬ ê°œì˜ qbitì„ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ Tensor product ê°œë…ì´ í•„ìš”í•˜ë‹¤. ìˆ˜í•™ì ìœ¼ë¡œ ì—„ë°€í•œ í‘œí˜„ì€ ì•„ë‹ˆì§€ë§Œ, nê°œì˜ qbit ì—°ì‚°ì„ í‘œí˜„í•˜ê¸° ìœ„í•´ì„œëŠ” ì•„ë˜ì˜ í‘œê¸° ë°©ì‹ì„ ë”°ë¥´ëŠ” ê²ƒì´ ì¢‹ë‹¤. \\[ \\binom{x_0}{x_1} \\otimes \\binom{y_0}{y_1} = \\begin{pmatrix} x_0 \\binom{y_0}{y_1} \\\\ x_1 \\binom{y_0}{y_1} \\end{pmatrix} = \\begin{pmatrix} x_0 y_0 \\\\ x_0 y_1 \\\\ x_1 y_0 \\\\ x_1 y_1 \\end{pmatrix} \\] ì´ë¥¼ ì‘ìš©í•˜ë©´ 2ê°œ, 3ê°œì˜ qbitë„ ë²¡í„°ì²˜ëŸ¼ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. \\[ |01\\rangle = \\binom{1}{0} \\otimes \\binom{0}{1} = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\hspace{10pt} |100\\rangle = \\binom{0}{1} \\otimes \\binom{1}{0} \\otimes \\binom{1}{0} = \\begin{pmatrix} 0\\\\ 0\\\\0\\\\0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} \\] ì´ì™€ ê°™ì´ tensor productì˜ ê²°ê³¼ë¡œ í‘œí˜„ëœ ë²¡í„°ëŠ” product stateë¼ê³  í•œë‹¤. ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” \\(n\\)ê°œ qbitì˜ product state í¬ê¸°ê°€ \\(2^n\\) ì´ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ë§Œì•½ \\( \\binom{\\frac{1}{\\sqrt{2}}}{\\frac{1}{\\sqrt{2}}} \\otimes \\binom{\\frac{1}{\\sqrt{2}}}{\\frac{1}{\\sqrt{2}}} = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\\\ \\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} \\) ì˜ multiple qbits ì´ ìˆë‹¤ë©´ \\(\\mid 00\\rangle\\), \\(\\mid 01\\rangle\\), \\(\\mid 10\\rangle\\), \\(\\mid 11\\rangle\\)ìœ¼ë¡œ collapseë  í™•ë¥ ì´ ëª¨ë‘ \\(\\frac{1}{4}\\)ì´ë¯€ë¡œ ë™ì‹œì— 4ê°œì˜ stateë¥¼ í‘œí˜„í•  ìˆ˜ ìˆê²Œ ëœë‹¤. ì¦‰, qbitì´ bitì™€ëŠ” ë‹¤ë¥´ê²Œ \\(2^n\\)ê°œì˜ stateë¥¼ í‘œí˜„í•  ìˆ˜ ìˆë‹¤ê³  í•œ ê²ƒì€ ë™ì‹œì— ê°€ì§ˆ ìˆ˜ ìˆëŠ” ìµœëŒ€ state ê´€ì ì—ì„œ ë¹„êµí•œ ê²ƒì´ë‹¤. bitëŠ” ì ˆëŒ€ë¡œ ë™ì‹œì— 2ê°œ ì´ìƒì˜ stateë¥¼ ê°€ì§ˆ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ í•œ ë²ˆì— ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ì •ë³´ëŠ” 1ê°œ ë¿ì´ë‹¤. ë˜í•œ product stateëŠ”, ë’¤ì˜ entanglementì™€ êµ¬ë¶„ë˜ëŠ” ì¤‘ìš”í•œ ì„±ì§ˆë¡œ, ë…ë¦½ì ì¸ stateë“¤ë¡œ factorizeê°€ ê°€ëŠ¥í•˜ë‹¤ëŠ” ì ì´ ìˆë‹¤. Multiple qbitsì˜ product state ë˜í•œ single qbitê³¼ ê°™ì€ ì„±ì§ˆì„ ë§Œì¡±ì‹œí‚¨ë‹¤. \\[ \\binom{a}{b} \\otimes \\binom{c}{d} = \\begin{pmatrix} ac \\\\ ad \\\\ bc \\\\ bd \\end{pmatrix} \\] \\[ \\text{where, } ||ac||^2 + ||ad||^2 + ||bc||^2 + ||bd||^2 = 1 \\] 1-bit operations 1-bitì—ì„œ ê°€ëŠ¥í•œ ì—°ì‚°ì€ Identity, Negation, Constant-0, Constant-1ì˜ ì´ 4ê°€ì§€ê°€ ìˆë‹¤. ê°ê°ì˜ ì—°ì‚°ì€ matrixë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. \\[ \\text{Identity} = \\begin{pmatrix} 1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix} \\] \\[ \\text{Negation} = \\begin{pmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix} \\] \\[ \\text{Contant-0} = \\begin{pmatrix} 1 &amp; 1 \\\\ 0 &amp; 0 \\end{pmatrix} \\] \\[ \\text{Contant-1} = \\begin{pmatrix} 0 &amp; 0 \\\\ 1 &amp; 1 \\end{pmatrix} \\] CNOT (one of the 2-bit operations) CNOT ì—°ì‚°ì€ control bitì™€ target bitë¡œ êµ¬ì„±ëœ 2-bitê°€ ìˆì„ ë•Œ control bitê°€ 0ì´ë©´ target bitë¥¼ ë°”ê¾¸ì§€ ì•Šê³ , control bitê°€ 1ì¼ ë•Œ target bitë¥¼ ë°”ê¾¸ëŠ” ì—°ì‚°ì´ë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ ì´ ì—°ì‚°ë„ matrixë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. \\[ C = \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{pmatrix} \\] 2.4ì™€ 2.5ì—ì„œ operationë“¤ì„ matrixí™” í•œ ê²ƒì— ì£¼ëª©í•˜ì. í™•ë¥ ì´ ì§€ë°°í•˜ëŠ” ì–‘ì ì„¸ê³„ì—ì„œ deterministicí•œ ì—°ì‚°ì„ í•˜ê¸° ìœ„í•´ì„œëŠ” matrixë¥¼ ê´€ì¸¡í•˜ì§€ ì•Šì€ qbitì— ê³±í•˜ëŠ” ê²ƒì´ ìœ ì¼í•œ ë°©ë²•ì´ê¸° ë•Œë¬¸ì´ë‹¤. ì•„ë˜ì˜ ì˜ˆì‹œì—ì„œ ìš°ë¦¬ê°€ í™•ì‹ í•  ìˆ˜ ìˆëŠ” ì •ë³´ëŠ” qbitì´ 0ê³¼ 1ë¡œ ê´€ì¸¡ë  í™•ë¥ ì´ ë°˜ëŒ€ê°€ ë˜ì—ˆë‹¤ëŠ” ê²ƒì´ë‹¤. \\[ \\begin{pmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{\\sqrt{3}}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{\\sqrt{3}}{2} \\\\ \\frac{1}{2} \\end{pmatrix} \\] í•­ìƒ 0 í˜¹ì€ 1ë¡œ ê´€ì¸¡ë˜ëŠ” \\(\\mid0\\rangle\\)ì´ë‚˜ \\(\\mid1\\rangle\\)ì„ ì“°ë©´ matrix ì—°ì‚°ì„ ê³ ì§‘í•˜ì§€ ì•Šì•„ë„ ë˜ì§€ë§Œ ì´ëŸ° qbitë§Œ ì‚¬ìš©í• ê±°ë¼ë©´ ê³ ì „ì»´í“¨í„°ë¥¼ ì“°ë©´ ê·¸ë§Œì´ë‹¤. êµ³ì´ 0K ê°€ê¹Œì´ ë˜ëŠ” í—˜ì•…í•œ ì¡°ê±´ì„ ìœ ì§€í•´ê°€ë©° ê³„ì‚°í•  í•„ìš”ê°€ ì—†ë‹¤. ê·¸ë˜ì„œ matrix ì—°ì‚°ì€ ì–‘ì ì»´í“¨íŒ…ì—ì„œ êµ‰ì¥íˆ ì¤‘ìš”í•˜ë‹¤. ì—¬ê¸°ì—ëŠ” í•œê°€ì§€ ì¶”ê°€ì¡°ê±´ì´ ìˆëŠ”ë°, ë°˜ë“œì‹œ ì—°ì‚°ì— ì‚¬ìš©ë˜ëŠ” matrixëŠ” reversibleí•´ì•¼í•œë‹¤ëŠ” ê²ƒì´ë‹¤. ë”°ë¼ì„œ ì•ì„œ ë³¸ 1-bit ì—°ì‚° ì¤‘ Constant-1ê³¼ Constant-0ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” ë‹¨ìˆœ matrixë¥¼ ê³±í•˜ëŠ” ê²ƒ ì™¸ì˜ ë‹¤ë¥¸ ë°©ë²•ì´ í•„ìš”í•˜ë‹¤. The Deutsch-Jozsa problem ì´ ë¬¸ì œ[1]ëŠ” ì–‘ìì»´í“¨í„°ê°€ ê³ ì „ì»´í“¨í„°ì— ë¹„í•´ ê³„ì‚°ì ì¸ ì´ì ì„ ê°€ì§€ëŠ” ì•„ì£¼ ê°„ë‹¨í•œ (ë™ì‹œì— ì“¸ë°ì—†ëŠ”) ë¬¸ì œë‹¤. 1-bitë¥¼ ì…ë ¥ë°›ì•„ì„œ 1-bitë¥¼ ë‚´ë±‰ëŠ” ì–´ë–¤ í•¨ìˆ˜ê°€ ìˆë‹¤ê³  í•˜ì. ë§Œì•½ ì´ í•¨ìˆ˜ê°€ Constant(Contant-0, Constant-1)ì¸ì§€, ì•„ë‹ˆë©´ Variable(Identity, Negation)ì¸ì§€ ì•Œê¸° ìœ„í•´ì„œëŠ” ìµœì†Œ ëª‡ ë²ˆì˜ queryë¥¼ ë‚ ë ¤ì•¼ í• ê¹Œ? Classical computer ê³ ì „ì»´í“¨í„°ì—ì„œëŠ” 0ê³¼ 1ì„ ì…ë ¥í•´ì•¼í•˜ë¯€ë¡œ ì´ ë‘ ë²ˆì˜ ì—°ì‚°ì´ í•„ìš”í•˜ë‹¤. Quantum computer ì˜ˆìƒí–ˆë“¯ì´ ì •ë‹µì€ í•œ ë²ˆì´ë‹¤. ì™œì¸ì§€ ì•Œê¸°ìœ„í•´ì„œëŠ” ì¶”ê°€ì ì¸ ê°œë…ì´ í•„ìš”í•˜ë‹¤. Hadamard gate ì•ì„œ ì–¸ê¸‰ëœ ì  ìˆëŠ” H gateì´ë‹¤. \\[ H = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} &amp; \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\] Hadamard gateëŠ” 0- í˜¹ì€ 1-qbitì„ ë°›ì•„ì„œ 0ê³¼ 1ì„ ê°™ì€ í™•ë¥ ë¡œ ê°€ì§€ëŠ” qbitìœ¼ë¡œ ë°”ê¿”ì¤€ë‹¤. \\[ H\\mid0\\rangle = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} &amp; \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\] \\[ H\\mid1\\rangle = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} &amp; \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\] Hadamard gateëŠ” ë˜ ë‹¤ë¥¸ ì¤‘ìš”í•œ ì„±ì§ˆì´ ìˆë‹¤. 0ê³¼ 1ì„ ê°™ì€ í™•ë¥ ë¡œ ê°€ì§€ëŠ” qbitì„ ë‹¤ì‹œ 0- ê³¼ 1-qbitìœ¼ë¡œ ëŒë ¤ë³´ë‚¸ë‹¤ëŠ” ê²ƒì´ë‹¤. \\[ \\begin{pmatrix} \\frac{1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} &amp; \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\] \\[ \\begin{pmatrix} \\frac{1}{\\sqrt{2}} &amp; \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} &amp; \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\] X gate X gateëŠ” qbitì˜ ìœ„ ì•„ë˜ë¥¼ ë°”ê¿”ì¤€ë‹¤. \\[ X = \\begin{pmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix} \\] \\[ \\begin{pmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\] \\[ \\begin{pmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{pmatrix} \\begin{pmatrix} \\frac{-1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\] H gateì™€ X gate ì—°ì‚°ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ í‘œí˜„í•˜ë©´ ì•„ë˜ì˜ ê·¸ë¦¼ì´ ëœë‹¤. ë¶‰ì€ìƒ‰ì´ X gate, ë…¸ë€ìƒ‰ì´ H gate ì—°ì‚°ì˜ ë°©í–¥ì´ë‹¤. \\(\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\)ì— X - H - X - H - X gateë¥¼ ì”Œìš´ ê²°ê³¼ëŠ” ê·¸ë¦¼ìœ¼ë¡œ ë³´ë©´ ë” ì‰½ê²Œ ì´í•´ëœë‹¤. \\(\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}\\)ì—ì„œ ì¶œë°œí•´ ê° gateê°€ ì—°ì‚°ë˜ëŠ” ë°©í–¥ìœ¼ë¡œ í™”ì‚´í‘œë¥¼ ì›€ì§ì´ë©´ ë§ˆì§€ë§‰ì— ë„ë‹¬í•˜ëŠ” ê³³ì´ ê²°ê³¼ê°’ì´ ëœë‹¤. non-reversible matrix ì•ì„œ ì–‘ìì»´í“¨í„°ëŠ” non-reversibleí•œ matrix ë¥¼ ê³±í•˜ëŠ” ì—°ì‚°ì€ ë¶ˆê°€ëŠ¥í•˜ë‹¤ê³  í–ˆë‹¤. 1-bit ì—°ì‚° ì¤‘ì—ì„œ Constant-0ê³¼ Constant-1ì€ non-reversibleí•˜ë‹¤. ê·¸ë˜ì„œ ì–‘ì ì»´í“¨íŒ…ì—ì„œëŠ” 2ê°œì˜ qbitì„ ì‚¬ìš©í•œë‹¤. ì´ ê·¸ë¦¼ì˜ inputê³¼ output notationì„ ë³´ë©´ â€œì‘?â€ ì´ë¼ëŠ” ìƒê°ì´ ì ˆë¡œ ë“¤ ê²ƒì´ë‹¤. ì˜ìƒì—ì„œë„ ì‚¬ëŒë“¤ì´ ëŒ€ì²´ ì™œ &quot;Output&quot;ì´ Input ìª½ì— ê°€ ìˆëŠ”ì§€ì— ëŒ€í•´ ëŠì„ì—†ì´ ë¬»ëŠ”ë‹¤. ì•„ì‰½ê²Œë„ ê°•ì—°ìëŠ” ì†ì‹œì›í•˜ê²Œ ë‹µë³€ì„ í•´ì£¼ì§€ ì•Šì•„ì„œ ê·¸ëŸ°ê°€ë³´ë‹¤ í•˜ê³  ë„˜ì–´ê°”ëŠ”ë° ë‹¤ì‹œ ë³´ë‹ˆ ì´í•´ê°€ ëœ ë¶€ë¶„ì´ ìˆì–´ ê¸€ë¡œ ì„¤ëª…í•´ë³´ë ¤ê³  í•œë‹¤. Input'ê³¼ Output'ì´ ì‹¤ì œ 1-bit ì—°ì‚°ì˜ inputê³¼ outputì„ ë‚˜íƒ€ë‚¸ë‹¤. ê·¸ë¦¬ê³  Inputê³¼ Outputì€ Input'ê³¼ Output'ì´ BB ì´í›„ì— ìˆê¸° ë•Œë¬¸ì— BB ì´ì „ì— Input'ê³¼ Output'ì´ 1-bit ì—°ì‚°ì˜ inputê³¼ outputì´ ë˜ë„ë¡ ë„£ì–´ì£¼ëŠ”, ì–‘ìì»´í“¨í„° ì—°ì‚° ë°©ì‹ ë•Œë¬¸ì— í•„ìš”í•œ inputë“¤ì´ë‹¤. ì´ ì•½ì†ì— ë”°ë¼ì„œ ì–‘ìì»´í“¨í„°ê°€ 1-bit ì—°ì‚°ì„ ì–´ë–»ê²Œ ìˆ˜í–‰í•˜ëŠ”ì§€ ì•„ë˜ì˜ ì˜ˆì‹œë¥¼ í†µí•´ ì¢€ ë” ì´í•´í•´ë³´ì. Constant-0ì€ Input'ì´ \\(\\mid 0 \\rangle\\)ì¼ ë•Œì™€ \\(\\mid 1 \\rangle\\)ì¼ ë•Œ ëª¨ë‘ Output'ì´ \\(\\mid 0 \\rangle\\)ì´ì–´ì•¼ í•œë‹¤. ì–´ë–¤ gateë„ ì—†ëŠ” ì™¼ìª½ ìœ„ ê·¸ë¦¼ì˜ íšŒë¡œì—ì„œ Inputì— \\(\\mid 0 \\rangle\\) í˜¹ì€ \\(\\mid 1 \\rangle\\)ì„ ëŒ€ì…í•´ë³´ë©´ Input'ê³¼ Output'ì´ Constant-0ì˜ ê´€ê³„ë¥¼ ê°€ì§€ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. IndentityëŠ” Input'ì´ \\(\\mid 0 \\rangle\\)ì¼ ë•ŒëŠ” Output'ì´ \\(\\mid 0 \\rangle\\)ì´ê³  Input'ì´ \\(\\mid 1 \\rangle\\)ì¼ ë•ŒëŠ” Output'ì´ \\(\\mid 1 \\rangle\\)ì¸ í•¨ìˆ˜ë‹¤. ì™¼ìª½ ì•„ë˜ ê·¸ë¦¼ì˜ íšŒë¡œëŠ” CNOT gateë¥¼ í‘œí˜„í•˜ê³  ìˆë‹¤. ìƒ‰ì´ ì±„ì›Œì§„ ì›ì´ control bit ìª½ì„ ë‚˜íƒ€ë‚´ê³  ê·¸ë ‡ì§€ ì•Šì€ ìª½ ì›ì€ target bitë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. Inputì´ \\(\\mid 0 \\rangle\\) ì´ë©´ control bitê°€ 0ì´ë¯€ë¡œ target bitë„ ê·¸ëŒ€ë¡œ ìœ ì§€í•œë‹¤. ê·¸ë˜ì„œ Input'ë„ \\(\\mid 0 \\rangle\\), Output'ë„ \\(\\mid 0 \\rangle\\)ì´ ëœë‹¤. Inputì´ \\(\\mid 1 \\rangle\\) ì´ë©´ control bitê°€ 1ì´ë¯€ë¡œ target bitê°€ ë°”ë€ë‹¤. ê·¸ë˜ì„œ Input'ë„ \\(\\mid 1 \\rangle\\), Output'ë„ \\(\\mid 1 \\rangle\\)ì´ ëœë‹¤. ê·¸ëŸ¼ ë‹¤ì‹œ The Deutsch-Jozsa problemë¡œ ëŒì•„ê°€ì„œ, ì–‘ìì»´í“¨í„°ì—ì„œëŠ” ì–´ë–»ê²Œ í•œ ë²ˆì— êµ¬í•  ìˆ˜ ìˆì„ê¹Œ? ì •ë‹µì€ ì•„ë˜ì˜ ê·¸ë¦¼ì´ ì„¤ëª…í•´ì¤€ë‹¤. ì´ ì—°ì‚°ëŒ€ë¡œë¼ë©´ BBê°€ Constant(Contant-0, Constant-1)ì´ì—ˆì„ ê²½ìš°, ì¸¡ì • ê²°ê³¼ê°€ \\(\\mid11\\rangle\\)ì´ê³ , Variable(Identity, Negation)ì´ì—ˆì„ ê²½ìš°ì—ëŠ” \\(\\mid01\\rangle\\)ì´ ëœë‹¤. BBì˜ ê²½ìš°ì˜ ìˆ˜ë¥¼ ë”°ì ¸ê°€ë©° ì´í•´í•´ë³´ì. preprocessing (BB ì…ë ¥ ì§ì „ê¹Œì§€ì˜ ì—°ì‚°) BBì— ë“¤ì–´ê°€ê¸° ì „ input (\\(\\mid 0 \\rangle\\)) ê³¼ output qbit (\\(\\mid 0 \\rangle\\)) ëª¨ë‘ Xì™€ H gateë¥¼ ê±°ì³ì„œ \\(\\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}} \\end{pmatrix}\\) ê°€ ëœë‹¤. case 1) BBê°€ Constant-0 ì´ì—ˆì„ ê²½ìš° Constant-0ì€ inputê³¼ outputì— ì–´ë–¤ gateë„ ì”Œìš°ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ BBê°€ Constant-0ì´ì—ˆì„ ë•Œ Inputê³¼ Outputì€ H gateë§Œ í†µê³¼í•œ ì´í›„ ê´€ì¸¡ëœë‹¤. case 2) BBê°€ Contstant-1 ì´ì—ˆì„ ê²½ìš° Constant-1ì€ outputì—ë§Œ X gateë¥¼ ì ìš©í•œë‹¤. ë”°ë¼ì„œ BBê°€ Constant-1ì´ì—ˆì„ ë•ŒëŠ” Outputì— X gateê°€ ì¶”ê°€ë˜ê³ , ì´í›„ Inputê³¼ Output ëª¨ë‘ì— H gateê°€ ì ìš©ëœë‹¤. case 3) BBê°€ Identity ì´ì—ˆì„ ê²½ìš° IdentityëŠ” CNOT gateë¥¼ í†µí•´ ì—°ì‚°ëœë‹¤. ì•ì—ì„œ CNOT ì—°ì‚°ì€ \\( \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{pmatrix} \\) ì„ ê³±í•˜ëŠ” ê²ƒê³¼ ê°™ë‹¤ê³  ì„¤ëª…í–ˆë‹¤. Preprocessingì„ ê±°ì¹œ Inputê³¼ Outputì€ \\( \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\) ì´ë¯€ë¡œ CNOTì—°ì‚°ì€ ì•„ë˜ì™€ ê°™ì´ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. \\[ C \\begin{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\otimes \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\end{pmatrix} = C \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{-1}{2} \\\\ \\frac{-1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ -1 \\\\ 1 \\end{pmatrix} = \\frac{1}{2} \\begin{pmatrix} 1 \\\\ -1 \\\\ 1 \\\\ -1 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\otimes \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\] ì¦‰ Inputì€ \\( \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\) ì—ì„œ \\( \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix}\\) ë¡œ ë°”ë€Œê³  Outputì€ ê·¸ëŒ€ë¡œ \\( \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{-1}{\\sqrt{2}} \\end{pmatrix} \\) ì´ ëœë‹¤. ì´ ìƒíƒœì—ì„œ H gateê°€ ê°ê° ì ìš©ë˜ì–´ ìµœì¢… ê²°ê³¼ëŠ” \\(\\mid 01 \\rangle\\)ì´ ëœë‹¤. case 4) BBê°€ Negation ì´ì—ˆì„ ê²½ìš° Negationì€ Indentityì˜ ê²°ê³¼ ì¤‘ Outputì—ë§Œ X gateê°€ ì¶”ê°€ë˜ëŠ” ì—°ì‚°ì´ë‹¤. ë”°ë¼ì„œ ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ ì—°ì‚°ì´ ì´ë£¨ì–´ì§€ê³  Identityì™€ ë§ˆì°¬ê°€ì§€ë¡œ ìµœì¢… ê²°ê³¼ëŠ” \\(\\mid 01 \\rangle\\)ì´ ëœë‹¤. ì •ë¦¬í•˜ë©´, ì–‘ìì»´í“¨í„°ì—ì„œëŠ” íŠ¹ì • ì„¤ê³„ ìƒí™©ì—ì„œ ê³ ì •ëœ BB inputì— ëŒ€í•œ BB outputì„ &quot;í•œ ë²ˆ&quot;ë§Œ ê´€ì¸¡í•˜ë©´ BBê°€ Constantì¸ì§€ Variableì¸ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤! Entanglement EntanglementëŠ” ì§€ê¸ˆê¹Œì§€ì˜ íë¦„ì—ì„œëŠ” ë™ë–¨ì–´ì§„ ì´ì•¼ê¸°ì§€ë§Œ ì–‘ìì»´í“¨í„°ì—ì„œ í•­ìƒ ì†Œê°œë˜ëŠ” ë‚´ìš©ì´ê¸° ë•Œë¬¸ì— ì¶”ê°€í•˜ì˜€ë‹¤. ì•ì„œ qbitê³¼ product stateì˜ ì„±ì§ˆì„ ìˆ˜í•™ì ìœ¼ë¡œ ë‚˜íƒ€ë‚¸ ê²ƒì²˜ëŸ¼ entanglementë„ ìˆ˜í•™ì ì¸ ì„±ì§ˆë¡œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤. \\( \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ 0 \\\\ 0 \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\) ëŠ” entangleëœ qbitì¸ë°, ê·¸ ëª¨ì–‘ìƒˆê°€ product stateì™€ ë‹®ì•„ìˆë‹¤. í•˜ì§€ë§Œ product stateì™€ëŠ” ì¤‘ìš”í•œ ì„±ì§ˆì—ì„œ ì°¨ì´ë¥¼ ë³´ì¸ë‹¤. ìœ„ì—ì„œ ì„¤ëª…í–ˆë“¯ì´ product stateëŠ” ê°œë³„ì ì¸ qbitìœ¼ë¡œ factorizeëœë‹¤. í•˜ì§€ë§Œ entanlged qbitì€ ê°œë³„ì ì¸ qbitìœ¼ë¡œ factorize ë˜ì§€ ì•ŠëŠ”ë‹¤. (If the product state of two qbits cannot be factored, they are said to be entanlged.) ì´ ë•Œë¬¸ì— entangled qbitì€ ì°¨ì›ì´ ëŠ˜ì–´ë‚œ í•˜ë‚˜ì˜ qbitìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìœ¼ë©° ì¼ë¶€ë¥¼ ê´€ì¸¡í–ˆì„ ë•Œ ë‚˜ë¨¸ì§€ ì¼ë¶€ì˜ ìƒíƒœê°€ ìœ ì¶”ëœë‹¤. \\( \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ 0 \\\\ 0 \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\) ì´ entangle ë˜ì—ˆìŒì„ ì¦ëª…í•˜ëŠ” ê²ƒì€ ê°„ë‹¨í•˜ë‹¤. \\( \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ 0 \\\\ 0 \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} = \\begin{pmatrix} a \\\\ b \\end{pmatrix} \\otimes \\begin{pmatrix} c \\\\ d \\end{pmatrix} \\) ë¥¼ ë§Œì¡±í•˜ëŠ” \\(a\\), \\(b\\), \\(c\\), \\(d\\)ëŠ” ì¡´ì¬í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ì´ëŠ” entanlgeë˜ì–´ ìˆëŠ” qbitì´ë‹¤. Entanlged qbitì€ CNOTê³¼ H gateë¥¼ í†µí•´ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆë‹¤. \\[ CH_1 \\begin{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\otimes \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\end{pmatrix} = C \\begin{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\otimes \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\end{pmatrix} = \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ 0 \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ 0 \\\\ 0 \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\] ë§Œì•½ ì´í›„ì— ì´ëŸ° ê²Œì´íŠ¸ì˜ ì¡°í•©ì„ ë³¸ë‹¤ë©´ ê³§ë°”ë¡œ â€˜entanlge ë˜ì—ˆêµ°!â€™ ì´ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤ :) Conclusion ê°œì¸ì ìœ¼ë¡œ ì´ ì˜ìƒì„ ë³¸ ì´í›„, ì†ì´ ë»¥ ëš«ë¦¬ëŠ” ê¸°ë¶„ì´ ë“¤ì—ˆë‹¤. ì•„ì§ matrixë¡œ í‘œí˜„ë˜ëŠ” qbitì´ ë¬¼ë¦¬ì ìœ¼ë¡œ ì–´ë–¤ ëª¨ìŠµì¸ì§€, gateë“¤ì´ ë¬¼ë¦¬ì ìœ¼ë¡œ ì–´ë–»ê²Œ qbitì— ì ìš©ë˜ëŠ”ì§€ëŠ” ëª¨ë¥´ì§€ë§Œ (ì´ê±´ ì‹¤ì œ ì–‘ìì»´í“¨í„°ë¥¼ ëˆˆìœ¼ë¡œ ë³´ë©´ ì´í•´ê°€ ë˜ì§€ ì•Šì„ê¹Œ) ì´ ì •ë„ë¼ë„ ì–‘ìì»´í“¨í„°ì™€ ê³ ì „ì»´í“¨í„°ì˜ ì—°ì‚°ê³¼ì •ì—ì„œì˜ ì°¨ì´ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì•Œ ìˆ˜ ìˆì—ˆê¸° ë•Œë¬¸ì— ë§Œì¡±í•  ìˆ˜ ìˆì—ˆë‹¤. ì–‘ìì»´í“¨í„°ì˜ ì—°ì‚° ê³¼ì •ì„ ì´í•´í•˜ê³ ë‚˜ë‹ˆ ì–‘ì ìš°ì›”ì„±ì€ ê·¸ëƒ¥ ë‹¬ì„±ë˜ëŠ” ê²ƒì€ ì•„ë‹ˆì—ˆìœ¼ë©°, ì˜ ì„¤ê³„ëœ gateê°€ ë’·ë°›ì¹¨ë˜ì—ˆì„ ë•Œ ê°€ëŠ¥í•œ ê²ƒì„ì„ ê¹¨ë‹«ê²Œ ë˜ê¸°ë„ í–ˆë‹¤. ì´ ì •ë„ë©´ ì–‘ì ì„¸ê³„ì— Hello World!ë¥¼ í–ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ? References 1.https://en.wikipedia.org/wiki/Deutschâ€“Jozsa_algorithm#Problem_statement â†©","link":"/2019/11/07/Basics-of-Quantum-Computings/"},{"title":"General Language Understanding Evaluation (GLUE) benchmark","text":"General Language Understanding Evaluation benchmark, ì¤„ì—¬ì„œ GLUE benchmark ë¼ê³  ë¶ˆë¦¬ëŠ” ì´ ë°ì´í„°ì…‹ì€ NLP ë¶„ì•¼ì—ì„œ Language Model ê²€ì¦ì„ ìœ„í•´ ì‚¬ìš©ëœë‹¤. ICLR 2019ì™€ BlackboxNLP workshop 2018ì— ëª¨ë‘ publish ë˜ì—ˆìœ¼ë©°, ì „ìëŠ” ì„¤ëª…ì´ ìƒì„¸í•˜ê³  í›„ìëŠ” ìš”ì•½ë˜ì–´ ìˆë‹¤. ì´ ê¸€ì€ ê°€ì¥ ìµœê·¼(2019.2.22)ì— ì—…ë°ì´íŠ¸ëœ arXivì— ìˆëŠ” ë…¼ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆë‹¤. GLUE overall GLUEëŠ” ì´ 9ê°œì˜ taskë¡œ êµ¬ì„±ë˜ì—ˆìœ¼ë©° ê° taskëŠ” ì–¸ì–´ì˜ íŠ¹ì •í•œ ì„±ì§ˆì„ í‰ê°€í•˜ê¸° ìœ„í•œ ëª©ì ìœ¼ë¡œ ë§Œë“¤ì–´ì¡Œê³ , ìµœì¢… ì ìˆ˜ëŠ” ê° task ë³„ ì ìˆ˜ì˜ í‰ê·  ê°’ì„ ê°€ì ¸ê°„ë‹¤. taskëŠ” í¬ê²Œ 3ê°€ì§€ - Single-Sentence Tasks (CoLA, SST-2), Similarity and Paraphrase Tasks (MRPC, QQP, STS-B), Inference Tasks (MNLI, RTE, QNLI, WNLI) - ë¡œ êµ¬ë¶„í•  ìˆ˜ ìˆë‹¤. ì„¸ë¶€ taskì— ëŒ€í•´ ì‚´í´ë³´ê¸° ì „ì— ì „ë°˜ì ì¸ taskì˜ íŠ¹ì§•ì„ ì•„ë˜ì˜ í‘œì— ì •ë¦¬í–ˆë‹¤. ì› ë…¼ë¬¸ì— ì •ë¦¬ë˜ì–´ ìˆëŠ” ê²ƒì„ ë°”íƒ•ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì˜€ê³  ì§ì ‘ ë‹¤ìš´ë¡œë“œ ë°›ì€ ë°ì´í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¸¡ì •í–ˆê¸° ë•Œë¬¸ì— corpusì˜ sizeê°€ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤. data train dev test domain input task metrics Corpus of Linguistic Acceptability (CoLA) 8.5k 1.0k 1.2k linguistics literature single-sentence - grammatical acceptability - binary classification (grammatical / ungrammatical) Matthews correlation Stanford Sentiment Treebank (SST-2) 67k 872 1.8k movie reviews single-sentence - sentiment - binary classification (positive / negative) acc. Microsoft Research Paraphrase Corpus (MRPC) 3.7k 408 1.7k news two sentences paraphrase acc./F1 Quora Question Pairs (QQP) 364k 40k 391k social QA questions two sentences paraphrase acc./F1 Semantic Textual Similarity Benchmark (STS-B) 5.8k 1.5k 1.4k news caption forum two sentences - sentence similarity - regression Pearson / Spearman corr. Multi-Genre NLI corpus (MNLI) 393k 20k 20k fiction face-to-face government letters 9/11 oxford university press (oup) slate telephone travel verbatim two sentences ternary classification (entailment / contradiction / neutral) matched acc. / mismatched acc. The Recognizing Textual Entailment (RTE) 2.5k 276 3.0k news wikipedia two sentences binary classification (entailment / not_entailment) acc. The Stanford Question Answering NLI (QNLI) 105k 5.5k 5.5k wikipedia two sentences (question, sentence) binary classification (entailment / not_entailment) acc. The Winograd Schema Challenge NLI (WNLI) 634 71 146 fiction books two sentences binary classification (entailment / not_entailment) acc. Corpus of Linguistic Acceptability (CoLA)&lt;span class=â€œhintâ€“top hintâ€“error hintâ€“medium hintâ€“rounded hintâ€“bounceâ€ aria-label=&quot;https://arxiv.org/pdf/1805.12471.pdf &quot;&gt;[1] CoLAëŠ” ê³µê°œëœ ì–¸ì–´í•™ ë¬¸í—Œ(publised liguistics literature)ì—ì„œ ì¶”ì¶œëœ ì•½ 21k ë¬¸ì¥ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì´ ë¬¸ì¥ë“¤ì€ ë¬¸ë²•ì ìœ¼ë¡œ ì˜³ì€ì§€, ê·¸ë¥¸ì§€ê°€ í‘œê¸°ë˜ì–´ ìˆë‹¤. 1 They drank the pub dry.0 * They drank the pub. ë¬¸ë²•ì ìœ¼ë¡œ ì˜³ê³  ê·¸ë¦„ì„ íŒë‹¨í•˜ëŠ” ê¸°ì¤€ì€ ë‹¤ì–‘í•˜ë‹¤. ì•„ë˜ì˜ í‘œëŠ” corpusë¥¼ ì œì‘í•˜ë©´ì„œ ê¸°ì¤€ì—ì„œ í¬í•¨ëœ ê²ƒë“¤ê³¼ ì œì™¸ëœ ê²ƒë“¤ì„ ë‚˜íƒ€ë‚¸ë‹¤. Included (a) Morphological Violation: â€œshould leaveâ€ ê°€ ì˜¬ë°”ë¥¸ í‘œí˜„ì´ì§€ë§Œ &quot;should leaving&quot;ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆë‹¤. ë™ì‚¬ì˜ í˜•íƒœ(verbal inflection)ê°€ ë§ì§€ ì•ŠëŠ” ê²½ìš°ì— í•´ë‹¹í•œë‹¤. (b) Syntactic Violation: â€œWhat did Bill buy?â€ í˜¹ì€ â€œBill bought potatoes and _â€ ì´ ë˜ì–´ì•¼ í•œë‹¤. í†µì‚¬ êµ¬ì¡°ê°€ í‹€ë¦° ê²½ìš°ì— í•´ë‹¹í•œë‹¤. Â© Semantic Violation: ì˜ë¯¸ì ìœ¼ë¡œ ë§ì´ ë˜ì§€ ì•ŠëŠ” ë¬¸ì¥ì— í•´ë‹¹í•œë‹¤. Excluded (d) Pragmatic Anomalies: grammarì™€ ìƒê´€ì—†ëŠ” ì™¸ë¶€ ì§€ì‹ì´ í•„ìš”í•˜ë¯€ë¡œ ì œì™¸ë˜ì—ˆë‹¤. (e) Unavailable Meanings: ë¬¸ì¥ë§Œë³´ê³ ëŠ” íŒë‹¨ì´ ì• ë§¤í•˜ë¯€ë¡œ ì œì™¸ë˜ì—ˆë‹¤. (f) Prescriptive Rules: ì‚¬ëŒë„ ëˆ„êµ°ê°€ì˜ ê°€ë¥´ì¹¨ì—†ì´ëŠ” í„°ë“í•˜ê¸° ì–´ë ¤ìš´ ruleì´ê¸° ë•Œë¬¸ì— ì œì™¸ë˜ì—ˆë‹¤. (g) Nonce Words: &quot;arrivable&quot;ê³¼ ê°™ì´ typical word-level NLP ëª¨ë¸ì˜ vocabì—ëŠ” ë“±ì¥í•˜ì§€ ì•ŠëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ê²½ìš°ì´ë‹¤. NLP ëª¨ë¸ì˜ scopeì´ ì•„ë‹ˆë¼ê³  íŒë‹¨ë˜ì–´ ì œì™¸ë˜ì—ˆë‹¤. testset and metrics testsetì€ In-Domainê³¼ Out-of-Domainìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. In-Domainì€ training setì´ ì¶”ì¶œëœ sourceì™€ ê°™ì€ sourceì—ì„œ, Out-of-Domainì€ training setì´ ì¶”ì¶œë˜ì§€ ì•Šì€ sourceì—ì„œ êµ¬ì„±ë˜ì—ˆë‹¤. GLUEëŠ” ì›ë˜ êµ¬ë¶„ëœ ë‘ testsetì„ í•˜ë‚˜ë¡œ í•©ì³ ë‹¨ì¼ testsetì„ êµ¬ì¶•í•˜ì˜€ê³  ì´ 1,160 ë¬¸ì¥ì´ë‹¤. ì´ taskì˜ í‰ê°€ëŠ” unbalanced binary classification taskì—ì„œ ì‚¬ìš©ë˜ëŠ” Matthews correlationìœ¼ë¡œ í•œë‹¤. Stanford Sentiment Treebank (SST-2) rottentomatoes.comì˜ ì˜í™” ë¦¬ë·° corpusë¡œ êµ¬ì„±ë˜ì—ˆìœ¼ë©° AMT(Amazon Mechanical Turk)ë¥¼ í†µí•´ ë¦¬ë·°ì˜ sentimentê°€ labeling ë˜ì—ˆë‹¤. 1ì€ ê¸ì •, 0ì€ ë¶€ì •ì„ ë‚˜íƒ€ë‚¸ë‹¤. that loves its characters and communicates something rather beautiful about human nature 1on the worst revenge-of-the-nerds clichÃ©s the filmmakers could dredge up 0 testset and metrics ì¼ë°˜ì ì¸ binary classification ë¬¸ì œë¡œ accuracyë¥¼ í†µí•´ í‰ê°€í•œë‹¤. Microsoft Research Paraphrase Corpus (MRPC) MRPCëŠ” ì˜¨ë¼ì¸ ë‰´ìŠ¤ì—ì„œ ì¶”ì¶œëœ ë¬¸ì¥ë“¤ë¡œ êµ¬ì„±ë˜ì—ˆìœ¼ë©° 2ê°œì˜ ë¬¸ì¥ì´ ì˜ë¯¸ì ìœ¼ë¡œ ê°™ì€ì§€ ë‹¤ë¥¸ì§€ë¥¼ í‰ê°€í•˜ëŠ” taskì´ë‹¤. They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added . On June 10 , the ship 's owners had published an advertisement on the Internet , offering the explosives for sale .1Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion . Yucaipa bought Dominick 's in 1995 for $ 693 million and sold it to Safeway for $ 1.8 billion in 1998 .0 testset and metrics testsetì´ labelì´ ë¶ˆê· ë“±(68% positive, 32% negative)í•˜ë¯€ë¡œ accuracyì™€ F1 scoreë¥¼ metricìœ¼ë¡œ í•œë‹¤. Quora Question Pairs (QQP)&lt;span class=â€œhintâ€“top hintâ€“error hintâ€“medium hintâ€“rounded hintâ€“bounceâ€ aria-label=&quot;https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs &quot;&gt;[2] QQPëŠ” https://www.quora.com/ì˜ ì§ˆë¬¸ë“¤ë¡œ êµ¬ì„±ë˜ì—ˆìœ¼ë©°, ë‘ ê°œì˜ ì§ˆë¬¸ì´ ì˜ë¯¸ìƒ ê°™ì€ì§€ ë‹¤ë¥¸ì§€ê°€ í‘œê¸°ë˜ì–´ìˆë‹¤. How do you start a bakery?How can one start bakery business?1What are natural numbers?What is a least natural number?0 testset and metrics MRPCì™€ ë§ˆì°¬ê°€ì§€ë¡œ ë¶ˆê· ë“±(37% positive, 63% negative)í•˜ë¯€ë¡œ accuracyì™€ F1 scoreê°€ metricìœ¼ë¡œ í™œìš©ëœë‹¤. Semantic Textual Similarity Benchmark (STS-B) ë¬¸ì¥ì˜ ìœ ì‚¬ë„ëŠ” ë²ˆì—­, ìš”ì•½, ë¬¸ì¥ ìƒì„±, QA, ëŒ€í™” ëª¨ë¸ë§ ë“±ë“± ë‹¤ì–‘í•œ NLP ë¶„ì•¼ì—ì„œ ì¤‘ìš”í•˜ê²Œ ë‹¤ë¤„ì§„ë‹¤. STS shared taskëŠ” ëª¨ë¸ì´ ë¬¸ì¥ë“¤ì˜ ìœ ì‚¬ë„ë¥¼ ì–¼ë§ˆë‚˜ ì˜ íŒŒì•…í•˜ëŠ”ì§€ë¥¼ í‰ê°€í•˜ê¸° ìœ„í•´ ë“±ì¥í•˜ì˜€ê³ , 2012ë…„ë¶€í„° 2017ë…„ê¹Œì§€ ë§¤ë…„ ê°œìµœë˜ì—ˆìœ¼ë©° ê·¸ ë•Œë§ˆë‹¤ ë‹¤ë¥¸ datasetì´ ì‚¬ìš©ë˜ì—ˆë‹¤. ì´ ë•Œë¬¸ì— ê° ì—°ë„ì˜ ë°ì´í„°ì…‹ì„ ì ì ˆíˆ ì¡°í•©í•œ common evaluation setìœ¼ë¡œ STS-Bê°€ ì†Œê°œë˜ì—ˆë‹¤. ì´ ì „ì˜ taskì™€ëŠ” ë‹¤ë¥´ê²Œ STSëŠ” regression taskì´ë‹¤. human annotatorë“¤ì€ ë‘ ë¬¸ì¥ì˜ ì˜ë¯¸ì ì¸ ìœ ì‚¬ë„ë¥¼ 1~5ì ìœ¼ë¡œ í‰ê°€í•˜ì˜€ê³  ëª¨ë¸ì€ scoreë¥¼ ì˜ˆì¸¡í•´ì•¼í•œë‹¤. A plane is taking off. An air plane is taking off. 5.000Three men are playing chess. Two men are playing chess. 2.600A man is smoking. A man is skating. 0.500 testset and metrics Regression taskì´ë¯€ë¡œ human labelê³¼ì˜ Pearson correlationìœ¼ë¡œ í‰ê°€ëœë‹¤. Multi-Genre NLI corpus (MNLI) MNLI[3]ëŠ” SNLI(Stanford NLI) datasetì˜ ë‹¨ì ì„ ê°œì„ ì‹œí‚¨ ë°ì´í„°ì…‹ì´ë‹¤. SNLIëŠ” image captionìœ¼ë¡œë§Œ êµ¬ì„±ë˜ì—ˆê¸° ë•Œë¬¸ì— ì¥ë©´ì„ í‘œí˜„í•˜ëŠ” ì§§ê³  ê°„ë‹¨í•œ ë¬¸ì¥ì´ ë§ê³  NLU(Natural Language Understanding) taskì™€ ë¬´ê´€í•œ ë‹¨ì–´ë“¤ì´ ë§ì´ ë“±ì¥í•œë‹¤. ê·¸ë˜ì„œ NLU taskì˜ benchmarkë¡œ ì‚¬ìš©ë˜ê¸°ëŠ” ì–´ë µê¸° ë•Œë¬¸ì— ë‹¤ì–‘í•œ ë„ë©”ì¸(ë…¼ë¬¸ì—ì„œëŠ” genreë¼ê³  í‘œí˜„)ì˜ ì¡°í•©ì¸ MNLI benchmark datasetì´ ë“±ì¥í•˜ì˜€ë‹¤. ìœ„ì˜ í‘œì—ì„œ ë‚˜ì™€ìˆë“¯ì´ MNLIëŠ” ì´ 10ê°œì˜ Genreë¡œ êµ¬ì„±ë˜ì—ˆë‹¤. Fictionì„ ì œì™¸í•œ 9ê°œì˜ domainì€ Open American National Corpusì—ì„œ ì¶”ì¶œë˜ì—ˆê³  Fictionì€ fiction literatureì—ì„œ ê°€ì ¸ì™”ìœ¼ë©° mystery, humor, sci-fi ë“± ê·¸ ì•ˆì—ì„œë„ ë‹¤ì–‘í•œ ì¥ë¥´ë¡œ êµ¬ì„±ë˜ì—ˆë‹¤. OANC data constitutes the following nine genres: transcriptions from the Charlotte Narrative and Conversation Collection of two-sided, in-person conversations that took place in the early 2000s (FACE-TO-FACE); reports, speeches, letters, and press releases from public domain government websites (GOVERNMENT); letters from the Indiana Center for Intercultural Communication of Philanthropic Fundraising Discourse written in the late 1990sâ€“early 2000s (LETTERS); the public report from the National Commission on Terrorist Attacks Upon the United States released on July 22, 2004 2 (9/11); five non-fiction works on the textile industry and child development published by the Oxford University Press (OUP); popular culture articles from the archives of Slate Magazine (SLATE) written between 1996â€“2000; transcriptions from University of Pennsylvaniaâ€™s Linguistic Data Consortium Switchboard corpus of two-sided, telephone conversations that took place in 1990 or 1991 (TELEPHONE); travel guides published by Berlitz Publishing in the early 2000s (TRAVEL); and short posts about linguistics for non-specialists from the Verbatim archives written between 1990 and 1996 (VERBATIM). For our tenth genre, FICTION, we compile several freely available works of contemporary fiction written between 1912 and 2010, spanning various genres, including mystery (The Mysterious Affair at Styles, 3 Christie, 1921; The Secret Adversary, 4 Christie, 1922; Murder in the Gun Room, 5 Piper, 1953), humor (Password Incorrect, 6 Name, 2008), western (Rebel Spurs, 7 Norton, 1962), science fiction (Seven Swords, 8 Shea, 2008; Living History,9 Essex, 2016; The Sky Is Falling, 10 Del Rey, 1973; Youth, 11 Asimov, May 1952), and adventure (Captain Blood, 12 Sabatini, 1922). ì„ ë³„ëœ ë¬¸ì¥ì„ premiseë¡œ ë‘ê³  human annotatorë“¤ì´ premiseì™€ ê°™ì€ ê²°ë¡ ì„ ë„ì¶œí•˜ëŠ” ë¬¸ì¥(entailment), ë°˜ëŒ€ë˜ëŠ” ë¬¸ì¥(contradiction), ë‘ ê²½ìš° ëª¨ë‘ ì•„ë‹Œ ë¬¸ì¥(neutral)ì„ ìƒì„±í•˜ê³  labelì„ ë‹¨ë‹¤. How do you know? All this is their information again. This information belongs to them. entailmentVrenna and I both fought him and he nearly took us. Neither Vrenna nor myself have ever fought him. contradictionThere was nothing like that emotion now. There are few emotions that come close. neutral testset and metrics testsetì€ CoLAì²˜ëŸ¼ matched(in-domain)ì™€ mismatched(cross-domain)ë¡œ êµ¬ì„±ë˜ì—ˆë‹¤. mismatchedì—ëŠ” 9/11, FACE-TO-FACE, LETTERS, OUP, VERBATIMì²˜ëŸ¼ training setì—ëŠ” ì—†ëŠ” domainì´ í¬í•¨ë˜ì–´ ìˆë‹¤. (ìœ„ì˜ í‘œ ì°¸ê³ ) ê°ê°ì˜ ê²½ìš°ë¥¼ ë‚˜ëˆ„ì–´ì„œ accuracyë¡œ í‰ê°€í•œë‹¤. The Recognizing Textual Entailment (RTE) RTEë„ STSì²˜ëŸ¼ RTE1ë¶€í„° RTE7ê¹Œì§€ì˜ ë°ì´í„°ì…‹ì—ì„œ ë§Œë“¤ì–´ì¡Œë‹¤. êµ¬ì²´ì ìœ¼ë¡œëŠ” RTE1, RTE2, RTE3, RTE5ë¡œ êµ¬ì„±ë˜ì—ˆê³ , ë‚˜ë¨¸ì§€ ë°ì´í„°ì…‹ ì¤‘ RTE4ëŠ” ê³µê°œë˜ì§€ ì•Šì•„ì„œ, RTE6ì™€ 7ì€ NLI taskë¡œëŠ” ë¶€ì í•©í•´ì„œ ì œì™¸í–ˆë‹¤ê³  í•œë‹¤. ì·¨í•©í•˜ëŠ” ê³¼ì •ì—ì„œ ì¼ë¶€ëŠ” ì„¸ ê°œì˜ class, ì¼ë¶€ëŠ” ë‘ ê°œì˜ classë¡œ labelingì´ ë˜ì–´ìˆì–´ ì´ë¥¼ ì¼ê´„ì ìœ¼ë¡œ ë‘ ê°œì˜ class(entailment, not_entailment)ë¡œ êµ¬ë¶„ì§€ì—ˆë‹¤. Swansea striker Lee Trundle has negotiated a lucrative image-rights deal with the League One club. Lee Trundle is in business with the League One club. entailmentNo Weapons of Mass Destruction Found in Iraq Yet. Weapons of Mass Destruction Found in Iraq. not_entailment testset and metrics ì¼ë°˜ì ì¸ binary classification ë¬¸ì œì´ë¯€ë¡œ accuracyë¡œ ì¸¡ì •í•œë‹¤. The Stanford Question Answering NLI (QNLI) Stanfordì—ì„œ êµ¬ì¶•í•œ Machine Comprehension ëª©ì ì˜ QA Dataset, a.k.a SQuAD,ì„ NLI taskì— ë§ê²Œ ë³€í˜•í•œ ë°ì´í„°ì…‹ì´ë‹¤. SQuADëŠ” wikipediaì—ì„œ paragraphë¥¼ ê°€ì ¸ì™€ì„œ annotatorë“¤ì´ ì ì ˆí•œ ì§ˆë¬¸ì„ ë˜ì§€ëŠ”ë° ì´ì— ëŒ€í•œ ë‹µì„ paragraph ë‚´ì— ìˆëŠ” ë¬¸ì¥, êµ¬, ë‹¨ì–´ë¡œ ë‹µí•  ìˆ˜ ìˆê²Œ êµ¬ì„±ë˜ì—ˆë‹¤. QNLIëŠ” ì§ˆë¬¸ê³¼ paragraph ë‚´ì˜ í•œ ë¬¸ì¥ì„ ë¹„êµí•˜ì—¬ ì´ ë‘˜ì´ entailmentë˜ì—ˆëŠ”ì§€ ì•„ë‹Œì§€ë¥¼ íŒë‹¨í•˜ë„ë¡ ë°”ë€Œì—ˆë‹¤. What two things does Popper argue Tarski's theory involves in an evaluation of truth? He bases this interpretation on the fact that examples such as the one described above refer to two things: assertions and the facts to which they refer. entailmentWho was elected as the Watch Tower Society's president in January of 1917? His election was disputed, and members of the Board of Directors accused him of acting in an autocratic and secretive manner. not_entailment testset and metrics ì¼ë°˜ì ì¸ binary classification ë¬¸ì œì´ë¯€ë¡œ accuracyë¡œ ì¸¡ì •í•œë‹¤. The Winograd Schema Challenge NLI (WNLI) ì´ ë°ì´í„°ì…‹ë„ entailmentë¥¼ í‰ê°€í•˜ëŠ” ëª©ì ìœ¼ë¡œ ë§Œë“¤ì–´ì¡Œë‹¤. original sentenceì™€ ì´ ë¬¸ì¥ì—ì„œ ëŒ€ëª…ì‚¬ë¥¼ ì¼ë°˜ëª…ì‚¬ë¡œ ì¹˜í™˜í•œ ë¬¸ì¥ ì‚¬ì´ì˜ entailmentê°€ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ê°€ labelë¡œ ë‹¬ë ¤ìˆë‹¤. ì•„ë˜ ì˜ˆì‹œì˜ ì²« ë²ˆì§¸ ë¬¸ì¥ì—ì„œ â€œitâ€ had a holeì˜ itì´ &quot;The carrot&quot;ìœ¼ë¡œ ë°”ë€ ë¬¸ì¥ì´ ë‘ ë²ˆì§¸ ë¬¸ì¥ì´ê³  ì´ ë‘ ë¬¸ì¥ì˜ ê´€ê³„ê°€ entailment ë˜ì–´ ìˆìœ¼ë¯€ë¡œ label 1ì´ ë‹¬ë¦°ë‹¤. I stuck a pin through a carrot. When I pulled the pin out, it had a hole. The carrot had a hole. 1John was jogging through the park when he saw a man juggling watermelons. He was very impressive. John was very impressive. 0 testset and metrics GLUE FAQì˜ 12ë²ˆ ë¬¸í•­ì—ëŠ” WNLIì—ì„œ ì´ìƒí•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆëŠ” ì´ìœ ê°€ ì í˜€ìˆë‹¤. ê°™ì€ ë¬¸ì¥ì´ í¬í•¨ëœ ë‹¤ë¥¸ example ë¼ë¦¬ëŠ” ë°˜ëŒ€ì˜ labelì´ ë‹¬ë ¤ìˆëŠ”ë° ì´ ë•Œë¬¸ì— training setì— overfitëœ ëª¨ë¸ì€ dev setì—ì„œ ì„±ëŠ¥ì´ ë§¤ìš° ë‚˜ì  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤. ì‹¤ì œë¡œ BERTëŠ” ì´ ì´ìœ ë¡œ WNLIì˜ ì„±ëŠ¥ì€ report í•˜ì§€ ì•Šì•˜ë‹¤. Download ë§í¬ì— ìˆëŠ” python scriptë¥¼ ë‹¤ìš´ë¡œë“œí•œ ì´í›„ ì‹¤í–‰ì‹œí‚¤ë©´ ëœë‹¤. ì§€ì •í•œ dirì— ì „ì²´ taskë¥¼ ë°›ì„ ìˆ˜ë„ ìˆê³  ì¼ë¶€ taskë§Œ ë°›ì„ ìˆ˜ë„ ìˆë‹¤. python download_glue_data.py --data_dir data --tasks all Leaderboard ì—¬íƒœê¹Œì§€ ì œì¶œí•œ ëª¨ë¸ì˜ ì„±ëŠ¥ì€ GLUE leaderboardì— ì •ë¦¬ë˜ì–´ìˆë‹¤. Leaderboardì—ëŠ” ìˆœê¸°ëŠ¥ê³¼ ì—­ê¸°ëŠ¥ì´ ëª¨ë‘ ê³µì¡´í•˜ì§€ë§Œ, ì•„ì§ê¹Œì§€ëŠ” ìˆœê¸°ëŠ¥ì´ ë” ë§ë‹¤ê³  ìƒê°í•œë‹¤. ìƒëŒ€ì ìœ¼ë¡œ ê³µì •í•˜ê²Œ ë¹„êµí•  ìˆ˜ ìˆëŠ” ë°ì´í„°ì…‹ì´ê³  ë•ë¶„ì— ë‹¤ì–‘í•œ Language Modelì´ ì£¼ëª©ë°›ì„ ìˆ˜ ìˆì—ˆê¸° ë•Œë¬¸ì´ë‹¤. ë„ˆë¬´ ë‚¡ì•„ë²„ë¦¬ê¸° ì „ì— ìƒˆë¡œìš´ ë°ì´í„°ì…‹ì´ ë‚˜ì™€ì•¼í•œë‹¤ê³ ë„ ìƒê°í–ˆëŠ”ë°, Neurips 2019ì— &quot;Stickier Benchmark&quot;ë¼ëŠ” ë¶€ì œì™€ í•¨ê»˜ SuperGLUEê°€ ë“±ì¥í–ˆë‹¤!! ì´ë¡œ ì¸í•´ ì—´ë¦´ ìƒˆë¡œìš´ LMë“¤ì˜ ë“±ì¥ì„ ê¸°ëŒ€í•´ë³¸ë‹¤ :) References 1.https://arxiv.org/pdf/1805.12471.pdf â†©2.https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs â†©3.https://www.aclweb.org/anthology/N18-1101.pdf â†©","link":"/2019/12/22/GLUE-benchmark/"},{"title":"Don&#39;t Stop Pretraining: Adapt Language Models to Domains and Tasks","text":"ë‹¤ì–‘í•œ ì¶œì²˜ì˜ ë°ì´í„°ë¡œ í•™ìŠµí•œ pretrained modelì´ NLP taskì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤. í•˜ì§€ë§Œ ì•„ì§ ì£¼ì–´ì§„ labeled data ì˜ í¬ê¸°ë‚˜ target domainì˜ ì½”í¼ìŠ¤ì™€ ì‚¬ì „í•™ìŠµ ì½”í¼ìŠ¤ì˜ ìœ ì‚¬ë„ê°€ íŠ¹ì • taskì˜ ê²°ê³¼ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ì— ëŒ€í•´ ì•Œë ¤ì§„ ë°”ê°€ ì—†ë‹¤. ë˜í•œ RoBERTaì™€ ê°™ì€ LMì´ ì •ë§ ë‹¤ì–‘í•œ taskì— generalizeë ë§Œí¼ì˜ ë‹¤ì–‘í•œ sourceë¡œ í•™ìŠµë˜ì—ˆëŠ”ì§€ë„ í™•ì‹¤í•˜ì§€ ì•Šë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” pretrained modelì„ í’€ê³ ì í•˜ëŠ” íŠ¹ì • taskì˜ domainì— tailorì‹œì¼œì„œ ì¶”ê°€ë¡œ í•™ìŠµì‹œí‚¤ë©´ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¼ ìˆ˜ ìˆì„ê¹Œ? ë¼ëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ í•˜ê³  ìˆë‹¤. ê²°ê³¼ëŠ” &quot;ê·¸ë ‡ë‹¤&quot;ì´ë‹¤. ë³´ë‹¤ êµ¬ì²´ì ìœ¼ë¡œëŠ” ë‹¤ìŒì˜ 3ê°€ì§€ findingsê°€ ìˆì—ˆë‹¤. ì²«ë²ˆì§¸, pretrained modelì„ ì¶”ê°€ë¡œ in-domain ë°ì´í„°ì— í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ì„±ëŠ¥í–¥ìƒì— ë„ì›€ì„ ì¤€ë‹¤ (Domain-Adaptive PreTraining; DAPT). ë‘ë²ˆì§¸, DAPT ì´í›„ë¡œ í’€ê³ ì í•˜ëŠ” taskì˜ unlabeled dataì— ëŒ€í•´ ì¶”ê°€ë¡œ í•™ìŠµí•˜ëŠ” ê²ƒ(Task-Adaptive PreTraining; TAPT)ë„ ì„±ëŠ¥í–¥ìƒì— ë„ì›€ì„ ì¤€ë‹¤. ì„¸ë²ˆì§¸, DAPTë¥¼ í•  corpusê°€ ì—†ì„ ë•Œ ê°„ë‹¨í•œ data selection strategiesìœ¼ë¡œ task corpusë¥¼ augment í•œ í›„ TAPTë¥¼ ìˆ˜í–‰í•´ë„ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì¸ë‹¤. Experimental settings Pretrained model: RoBERTa-base 160GB heterogeneous dataë¡œ í•™ìŠµ bookcorpus, stories, wikipedia, and realnews Domains: biomedical papers (BIOMED) cs papers (CS) newstext from realnews (NEWS) Amazon reviews (REVIEWS) Tasks: 2 text classfication tasks per each domain Domain ì˜ ê¸°ì¤€? ë‚´ê°€ ì•„ëŠ” í•œì—ì„œëŠ”, domain ì´ë¼ëŠ” ìš©ì–´ì— ëŒ€í•œ í™•ì‹¤í•œ ì •ì˜ëŠ” ì—†ë‹¤. ì–´ë–¤ ë…¼ë¬¸ì€ domainì— ëŒ€í•´ ë‘ë£¨ë­‰ìˆ í•˜ê²Œ ì–¸ê¸‰í•˜ê³  ë„˜ì–´ê°€ê³ , ì–´ë–¤ ë…¼ë¬¸ì€ ë­ë¼ë„ ì •ì˜í•˜ê³  ë„˜ì–´ê°€ëŠ” ê²½ìš°ê°€ ìˆëŠ”ë° ì´ë²ˆ ë…¼ë¬¸ì—ì„œëŠ” domainì— ëŒ€í•œ ë…¼ì˜ê°€ ì¤‘ìš”í•˜ë‹¤ë³´ë‹ˆ ì„ ì •í•œ 4ê°œì˜ ë„ë©”ì¸ê³¼ pretraining domainì´ ì„œë¡œ ìƒì´í•¨ì„ ë°í í•„ìš”ê°€ ìˆì—ˆë‹¤. ìœ„ì˜ ì´ë¯¸ì§€ëŠ” Vocab overlap ì„ í†µí•œ domainì˜ similarity ë¥¼ êµ¬í•œ heatmapì´ë‹¤. ë¹ˆë²ˆí•œ 10K ì˜ vocab ì¤‘ ì–¼ë§ˆë‚˜ ê²¹ì¹˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ê³  ìˆìœ¼ë©° ê²°ê³¼ëŠ” ì§ê´€ê³¼ ì¼ì¹˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. PT corpusëŠ” news, reviewsì™€ ê°€ì¥ ìœ ì‚¬í•˜ë©° csì™€ ê°€ì¥ ê±°ë¦¬ê°€ ë©€ë‹¤. ë˜ reviewsì™€ csì˜ ê±°ë¦¬ê°€ ê°€ì¥ ë©€ê³ , newsì™€ reviewsëŠ” csì— ë¹„í•´ ìƒëŒ€ì ìœ¼ë¡œ ë” ìœ ì‚¬í•˜ë‹¤. DAPT Results Domain ë³„ LM loss ë³€í™” ê° ë„ë©”ì¸ì— RoBERTaë¥¼ 12.5K steps ì”© í•™ìŠµì‹œí‚¨ í›„ LM lossì˜ ì „í›„ë¥¼ ë¹„êµí•˜ì˜€ë‹¤. domain similarity ê°€ ê°€ì¥ ë†’ì•˜ë˜ newsë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë„ë©”ì¸ì—ì„œ marginalí•œ ì„±ëŠ¥í–¥ìƒì´ ìˆì—ˆë‹¤. PLM vs. DAPT vs. ~DAPT ëª¨ë¸ì˜ classification ê²°ê³¼ LM loss ì˜ ë³€í™”ê°€ ì‹œì‚¬í–ˆë˜ ê²ƒì²˜ëŸ¼ BMê³¼ CS ë„ë©”ì¸ì—ì„œì˜ íš¨ê³¼ê°€ ê°€ì¥ ì»¸ë‹¤. í•˜ì§€ë§Œ ì´ ë³€í™”ê°€ ë‹¨ìˆœíˆ ë” ë§ì€ ë°ì´í„°ì— ë…¸ì¶œë˜ì—ˆê¸° ë•Œë¬¸ì¸ì§€ ì•„ë‹Œì§€ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•´ out-of-domain corpusë¡œ DAPTë¥¼ ì‹œí‚¨ í›„ì˜ ê²°ê³¼ì™€ ë¹„êµí–ˆë‹¤. newsì˜ ê²½ìš° CSë¡œ DAPTí•œ LMì„, reviewsì˜ ê²½ìš° BIOMED LMì„, csì˜ ê²½ìš° news LMì„, biomedì˜ ê²½ìš° reviews LMì„ ì‚¬ìš©í–ˆë‹¤. DAPTê°€ ~DAPT ëª¨ë¸ë³´ë‹¤ ëª¨ë“  ê²½ìš°ì—ì„œ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¸ë‹¤. ì‹¬ì§€ì–´ RoBERTaì™€ ë¹„êµí•´ë³´ë©´ ~DAPT ì˜ ê²°ê³¼ëŠ” ë” ë‚˜ë¹ ì§€ëŠ” ê²½í–¥ì„ ë³´ì¸ë‹¤. ì´ëŠ” ë‹¨ìˆœíˆ ë” ë§ì€ ë°ì´í„°ì— ë…¸ì¶œë˜ëŠ” ê²ƒì´ í•­ìƒ ëª¨ë“  ë„ë©”ì¸ì˜ ê²°ê³¼ì—ì„œ íš¨ê³¼ì ì´ì§€ ì•Šë‹¤ëŠ” ì‚¬ì‹¤ì„ ì‹œì‚¬í•œë‹¤. Fuzzy í•œ domain boundary Vocab overlap ê²°ê³¼ì—ì„œë„ ì•Œ ìˆ˜ ìˆì§€ë§Œ domain ì´ë¼ëŠ” ê²ƒì´ ë¬´ìë¥´ë“¯ ë‚˜ë‰˜ëŠ” ê²ƒì´ ì•„ë‹ˆë‹¤. ì§€ê¸ˆê¹Œì§€ì˜ ì‹¤í—˜ì€ newsì™€ reviews ë„ë©”ì¸ì„ êµ¬ë¶„í–ˆì§€ë§Œ, reviews corpusê°€ news corpusì— ì•„ì˜ˆ ë„ì›€ì„ ì£¼ì§€ ì•ŠëŠ”ë‹¤ê³  ë³¼ ìˆ˜ ì—†ë‹¤. TAPT Domain ë³´ë‹¤ ë” í˜‘ì†Œí•œ ë²”ìœ„ì˜ Taskì— ëŒ€í•´ì„œë„ DAPTì™€ ê°™ì€ íš¨ê³¼ê°€ ìˆëŠ”ì§€ë¥¼ ê²€ì¦í•˜ì˜€ë‹¤. DAPTì™€ ë¹„êµí•´ì„œ ë” ì ì€ corpusë¡œ í•™ìŠµí•œë‹¤ëŠ” ë‹¨ì ì´ ìˆì§€ë§Œ ë” task relevantí•œ corpusë¼ëŠ” ì¥ì ì´ ìˆë‹¤. ë§Œì•½ ìµœì¢… ì„±ëŠ¥ì´ ë¹„ìŠ·í•˜ë‹¤ë©´ TAPTê°€ ë” ê°’ì‹¼ í•™ìŠµë°©ì‹ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. ì—¬ê¸°ì„œëŠ” labeled training dataë¥¼ ì‚¬ìš©í•´ì„œ second phase PLMì„ ì§„í–‰í–ˆë‹¤. PLM vs. DAPT vs. TAPT vs. DAPT+TAPT ëª¨ë¸ì˜ classification ê²°ê³¼ TAPTì˜ ê²½ìš°, corpus ì‚¬ì´ì¦ˆë¥¼ ê³ ë ¤í•´ì„œ, second phase of pretrainingì€ 100 epochë§Œ ì§„í–‰í•˜ì˜€ë‹¤. PLM vs TAPT ê²°ê³¼ë¥¼ ë³´ë©´, TAPTë¥¼ ì§„í–‰í•œ LMìœ¼ë¡œ classficiation taskë¥¼ ìˆ˜í–‰í•œ ê²½ìš°ê°€ RoBERTa-base ë³´ë‹¤ í•­ìƒ ê²°ê³¼ê°€ ë” ì¢‹ë‹¤. DAPT vs TAPT í•˜ì§€ë§Œ DAPTì™€ ë¹„êµí•´ë³´ë©´ ì–¸ì œë‚˜ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒì€ ì•„ë‹ˆì—ˆë‹¤. PLM vs DAPT + TAPT DAPT ì´í›„ TAPT ë¥¼ ì ìš©í•˜ëŠ” ê²ƒì´ ì–¸ì œë‚˜ ìµœê³ ì˜ ì„±ëŠ¥ì„ ë³´ì—¬ì¤€ë‹¤. PLMì— ë§ì´ í™œìš©ëœ ë°ì´í„°ê°€ AGNewsì™€ IMDBì™€ ë¹„ìŠ·í–ˆë‹¤ë©´ ê·¸ ë‘˜ì˜ ì„±ëŠ¥ í­ì´ ì‘ì€ ê²ƒì´ ì´í•´ê°€ ë˜ì§€ë§Œ, ì•„ë‹ˆë¼ë©´ HyperPartisanì´ë‘ Helpfulnessì˜ ì„±ëŠ¥í–¥ìƒì´ BIOMEDì™€ ë¹„ìŠ·í•˜ë‹¤ëŠ” ì ì—ì„œ ê¼­ PLMì˜ í•™ìŠµ ì½”í¼ìŠ¤ì˜ ë„ë©”ì¸ê³¼ ì„±ëŠ¥í–¥ìƒì´ ê´€ë ¨ìˆë‹¤ê³  ë³´ê¸´ ì–´ë µë‹¤. ê·¸ task ë¥¼ ì˜í•˜ê¸° ìœ„í•´ì„œëŠ” ë§ˆì§€ë§‰ì— weight ë¥¼ ì˜®ê²¨ì£¼ëŠ” ê²ƒì´ í•„ìš”í•˜ì§€ ì•Šì„ê¹Œ? Cross-Task Transfer ê°™ì€ ë„ë©”ì¸ ë‚´ì˜ 2 task ê°„ transfer íš¨ê³¼ê°€ ìˆëŠ”ì§€ì— ëŒ€í•´ì„œ ì‚´í´ë³´ì•˜ë‹¤. BIOMED ë‚´ì˜ RCT, ChemProt taskë¥¼ ì˜ˆë¡œ ë“¤ë©´, Transfer-TAPTëŠ” RCTì˜ unlabeled dataë¡œ pretrainingí•œ ì´í›„, ChemProtì˜ ê²°ê³¼ë¥¼ ë³¸ ê²ƒì´ë‹¤. ëª¨ë“  ê²½ìš° Transfer-TAPTì˜ ê²°ê³¼ê°€ TAPTë³´ë‹¤ ë‚®ì•˜ë‹¤. Augmenting Training data for TAPT task: RCT, HyperPartisan, IMDB case 1) target taskì˜ labeled dataì™€ ê°™ì€ distributionì˜ unlabeled target task corpus (by human) Curated TAPTì˜ ê²½ìš° TAPTë³´ë‹¤ ë” ë§ì€ task corpus (unlabeled)ë¡œ PLMì„ ì§„í–‰í•˜ì˜€ê³ , ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. DAPTì™€ í•¨ê»˜ ì§„í–‰í•˜ê²Œ ë˜ë©´ ê·¸ íš¨ê³¼ëŠ” ë”ìš± í™•ì‹¤í•˜ë‹¤. case 2) Automated Data selection for TAPT task setup ë‹¹ì‹œì— large unlabeled corpus ì¡°ì°¨ í’€ë¦¬ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ìˆë‹¤. ì´ ë•Œ, ìë™ìœ¼ë¡œ ê´€ë ¨ìˆëŠ” ë°ì´í„°ë¥¼ ì°¾ì•„ì„œ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ê²Œ ë˜ë©´ ì–´ë–¨ì§€ë¥¼ ì‹¤í—˜í•˜ì˜€ë‹¤. í•˜ì§€ë§Œ large in-domain corpus ì—¬ì•¼ í•˜ë©°, ì´ ì¤‘ì—ì„œ taskì™€ì˜ ì ‘ì ì´ ìˆëŠ” task-relevant dataë¥¼ ì°¾ëŠ” ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  embedding space ë‚´ì—ì„œ ì ‘ì ì„ ì°¾ëŠ” ê²ƒì´ë¯€ë¡œ ê²½ëŸ‰í™”ëª¨ë¸ì´ í•„ìš”í•˜ë‹¤. ì—¬ê¸°ì„œëŠ” vampire modelì„ ì‚¬ìš©í•˜ì˜€ë‹¤. rand-TAPT vs kNN-TAPT kNN &gt; rand-TAPT TAPT vs automated data selection ë°©ë²•ì´ ë¬´ì—‡ì´ë“  ì¶”ê°€ ë°ì´í„°ë¥¼ í™œìš©í•˜ëŠ” ê²ƒì´ ë‚˜ì˜ì§€ëŠ” ì•ŠìŒ ì•„ì§ RoBERTaì—ê²ŒëŠ” ë” í•™ìŠµí•  ìˆ˜ ìˆëŠ” ì—¬ì§€ê°€ ë‚¨ì•„ìˆë‹¤ê³ ë„ í•´ì„ ê°€ëŠ¥ (ë°ì´í„°ëŠ” ë§ì„ìˆ˜ë¡ ì¢‹ë‹¤) DAPT vs 500NN-TAPT ì•½ 500ê°œì˜ ë°ì´í„°ë§Œ ì‚¬ìš©í•´ë„ DAPT íš¨ê³¼ë¥¼ ì–´ëŠ ì •ë„ ë‚¼ ìˆ˜ ìˆìŒ Conclusions Task ë¬¸ì œë¥¼ ë” ì˜ í’€ê¸° ìœ„í•´ì„œ ê´€ë ¨ëœ distribution ì˜ ë°ì´í„°ë¡œ ì¶”ê°€ í•™ìŠµì„ í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì´ë‹¤ Task-specific data ì¼ í•„ìš”ëŠ” ì—†ë‹¤. Domainì´ ë¹„ìŠ·í•˜ë©´ íš¨ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤. ë‹¤ë§Œ ì•„ì‰¬ìš´ ê±´, PLM ìì²´ë¥¼ í•™ìŠµì‹œí‚¬ ë•Œ DAPT+TAPTì— ì‚¬ìš©í•œ ë°ì´í„°ë¥¼ í™œìš©í•˜ë©´ ì ìˆ˜ê°€ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€ ì•Œ ìˆ˜ ì—†ì—ˆë‹¤ëŠ” ì ì´ë‚˜, ì´ë²ˆ ë…¼ë¬¸ì˜ scopeì— ë“¤ì–´ê°ˆ í•„ìš”ëŠ” ì—†ì—ˆë‹¤ê³ ë„ ìƒê°í•œë‹¤. References https://www.aclweb.org/anthology/2020.acl-main.740.pdf","link":"/2020/11/30/Don-t-stop-pretraining/"},{"title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (a.k.a. T5)","text":"ìµœê·¼ NLP taskì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” ëª¨ë¸ì€ ëŒ€ëŸ‰ì˜ monolingual corpusë¥¼ í†µí•´ unsupervised pre-trainingì„ í•œ LMì„ taskì— ë§ê²Œ supervised fine-tuningì„ í•˜ëŠ” transfer learningì— ê¸°ë°˜í•˜ê³  ìˆë‹¤. ê°™ì€ transfer learning framework ì•ˆì—ì„œë„ ë‹¤ì–‘í•œ ëª¨ë¸ì´ ì¡´ì¬í•œë‹¤. ìš°ë¦¬ê°€ ì•„ëŠ” ëª¨ë¸ë§Œ í•˜ë”ë¼ë„ BERT, GPT, ELMO ë“±ì´ ìˆê³ , GLUE benchmarkì— ëŒ€í•´ì„œ í…ŒìŠ¤íŠ¸í•œ ì ìˆ˜ê°€ ìˆë‹¤. í•˜ì§€ë§Œ ê³¼ì—° ì ìˆ˜ê°€ ë” ë†’ë‹¤ê³  ë” ì¢‹ì€ ëª¨ë¸ì´ë¼ê³  í•  ìˆ˜ ìˆì„ê¹Œ? ìš°ë¦¬ê°€ ëª¨ë¸ì´ë¼ê³  ë¶€ë¥´ëŠ” ê²ƒ ì•ˆì—ëŠ” í•™ìŠµ ë°©ì‹ ì™¸ì—ë„ í•™ìŠµì— ì‚¬ìš©í•œ ë°ì´í„°ì…‹, optimizer, ëª¨ë¸ì˜ í¬ê¸° ë“± ë§ì€ ë‚´ìš©ì´ í•¨ì¶•ë˜ì–´ ìˆë‹¤. ê·¸ë˜ì„œ ê° ëª¨ë¸ì˜ ì•„ì´ë””ì–´ ì¤‘ ê³¼ì—° **â€œì–´ë–¤ íŠ¹ì§•ì´ ì¢‹ì€ ëª¨ë¸ ì„±ëŠ¥ì„ ë‚´ëŠ”ë°ì— ë„ì›€ì´ ë˜ì—ˆì„ê¹Œ?â€**ë¼ê³  ë¬»ëŠ”ë‹¤ë©´ ì‰½ê²Œ ëŒ€ë‹µí•˜ê¸° ì–´ë µë‹¤. ì´ ë…¼ë¬¸ì—ì„œ ì†Œê°œí•˜ëŠ” Text-to-Text Transfer Transformer (T5) ëŠ” ê·¸ ë‹µì„ ì°¾ê¸° ìœ„í•´ ê³ ì•ˆí•œ frameworkì´ë‹¤. Transfer learning framework: Text-to-Text Transfer Transformer (T5) T5ëŠ” ëª¨ë“  taskë¥¼ transformerì˜ building blockìœ¼ë¡œ í•˜ëŠ” seq2seq framework ì´ë‹¤ (ì£¼ì˜! encoder-decoder ì™€ëŠ” ë‹¤ë¥´ë‹¤. sequence Xê°€ ì…ë ¥ë˜ë©´ sequence Yê°€ ì¶œë ¥ë˜ëŠ” ê²ƒì¼ ë¿). ë‹¤ì–‘í•œ downstream tasks (question answering, document summarization, semtiment classification, machine translation, etc) ë¥¼ í•˜ë‚˜ì˜ ëª¨ë¸ ì•ˆì—ì„œ í•´ê²°í•´ì•¼ ì„œë¡œ ë‹¤ë¥¸ transfer learning ë°©ì‹ì˜ íš¨ê³¼ë¥¼ ê³µì •í•˜ê²Œ ë¹„êµí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì´ì™€ ê°™ì€ unified framework ê°€ ì œì•ˆë˜ì—ˆë‹¤. ë¶„ì„í•˜ê³  ì‹¶ì€ ë‚´ìš©ê³¼ ë¬´ê´€í•œ íŠ¹ì§•ë“¤ â€“ ì‚¬ìš©í•œ ë°ì´í„°, tokenizer, vocab size, learning rate ë“± â€“ ì€ taskì— ìƒê´€ì—†ì´ ê³ ì •ëœë‹¤. Pre-training dataset: Colossal Clean Crawled Corpus (C4) Transfer learning frameworkì— ì‚¬ìš©ë˜ëŠ” pre-trained modelì€ ì–´ë–¤ ì¢…ë¥˜ì˜ corpusë¥¼ ì‚¬ìš©í–ˆëŠ”ì§€, ì–¼ë§Œí¼ì˜ corpusë¥¼ ì‚¬ìš©í–ˆëŠ”ì§€ì— ë”°ë¼ì„œë„ íŠ¹ì§•ì´ ë‹¬ë¼ì§„ë‹¤. ì´ì— ëŒ€í•œ ì‹¤í—˜ì„ ìœ„í•´ ë…¼ë¬¸ì—ì„œëŠ” common crawlë¡œ ìˆ˜ì§‘í•œ ì•„ì£¼ ë§ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ ì†Œê°œí•œë‹¤. ì–‘ì— ë”°ë¥¸ ëª¨ë¸ ì„±ëŠ¥ì„ ë¹„êµí•˜ê¸° ìœ„í•´ ìš°ì„  ê¸°ì¡´ì˜ Wikipedia corpus ë³´ë‹¤ 2ë°° ì´ìƒ í° ì‚¬ì´ì¦ˆì˜ ë°ì´í„°ë¥¼ crawling í•œë‹¤. ì¸í„°ë„·ì—ì„œ crawlingí•œ ë¬¸ì„œëŠ” ë³´í†µ ë§¤ìš° ì§€ì €ë¶„í•˜ë‹¤. ì´ëŸ° ì§€ì €ë¶„í•œ ë°ì´í„°ë¥¼ í•™ìŠµì— ë°”ë¡œ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ side effect ê°€ ìˆì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì¤‘ë³µ ì œê±°, ë¯¸ì™„ì„± ë¬¸ì¥ ì œê±°, ê³µê²©ì ì´ê±°ë‚˜ biasê°€ ìˆëŠ” ë¬¸ì¥ ì œê±° ë“±ì˜ cleansing processë¥¼ ê±°ì¹˜ê³  ê¹”ë”í•œ ë°ì´í„°ë¥¼ ë‚¨ê¸´ë‹¤. ì´ ë°ì´í„°ì…‹ì˜ ì´ë¦„ì´ Colossal Clean Crawled Corpus (C4) ì´ë‹¤. ì—¬ëŸ¬ í•„í„°ë§ì„ ê±°ì³¤ìŒì—ë„ Wikipedia corpus í¬ê¸°ì˜ 2ë°° ì´ìƒì´ë¼ê³  í•œë‹¤. TF dastasetsì—ì„œ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•˜ë‹¤. Main Contributions of the paper ì•ì„œ ì†Œê°œí–ˆë“¯ì´, ì´ ë…¼ë¬¸ì—ì„œ í’€ê³  ì‹¶ì€ ì§ˆë¬¸ì€ &quot;ë‹¤ì–‘í•œ NLP transfer learning framework ì¤‘ì—ì„œ ì–´ë–¤ featureê°€ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ëŠ”ë°ì— ë„ì›€ì´ ë ê¹Œ?&quot;ì´ë‹¤. ë”°ë¼ì„œ ì¡°ê¸ˆì”© training schemaë¥¼ ë‹¬ë¦¬í•´ê°€ë©° ì—¬ëŸ¬ downstream taskì˜ ì„±ëŠ¥ì„ ë¹„êµí•´ì•¼ í•œë‹¤. ì´ ë…¼ë¬¸ì—ì„œëŠ” í¬ê²Œ 1) Pre-training architecture 2) Pre-training objective 3) Pre-training dataset 4) Pre-training datasize 5) Training strategy 6) Scaling strategyë¥¼ ì£¼ëª©í•˜ê³  ìˆë‹¤. ê·¸ë¦¬ê³  ì¤‘ìš”í•œ Disclaimerë¡œ, ì—¬ê¸°ì„œ ì†Œê°œí•˜ëŠ” architectureì™€ objectiveëŠ” GPT, ELMO ë“±ì˜ êµ¬í˜„ì„ ì•„ì£¼ ì •í™•í•˜ê²Œ replicate í•˜ê³  ìˆì§€ ì•Šë‹¤ê³  ì–¸ê¸‰í•œë‹¤. ì–´ëŠ ì •ë„ ì´ ëª¨ë¸ë“¤ì˜ êµ¬ì¡°ì— motivateëœ ë‚´ìš©ì´ ë³´ì´ì§€ë§Œ ì •í™•í•˜ê²Œ ê°™ì§€ëŠ” ì•Šë‹¤. Pre-training architecture Encoder-Decoder (Baseline) vs. Language Model vs. Prefix LM í¬ê²Œ ì„¸ê°€ì§€ ëª¨ë¸ êµ¬ì¡°ë¥¼ ì‹¤í—˜í•˜ì˜€ë‹¤. Encoder-Decoderì—ì„œ EncoderëŠ” fully-visible attentionì„ ì ìš©í•˜ì˜€ê³  decoderë§Œ causal attentionì„ ì ìš©í•˜ì˜€ë‹¤. LMì€ ì „ë¶€ causal attentionì´ë©°, ì´ëŠ” uni-directionalí•˜ê²Œ ì •ë³´ë¥¼ ìŠµë“í•˜ëŠ” ê²ƒì„ ë‚˜íƒ€ë‚¸ë‹¤. PrefixLMì˜ ê²½ìš° encoder-decoder ì™€ ìœ ì‚¬í•œ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. inputì¸ xì— ëŒ€í•´ì„œëŠ” bi-directionalí•˜ê²Œ ì •ë³´ë¥¼ ìŠµë“í•˜ê³  yë§Œ causal attentionì´ ì ìš©ëœë‹¤. Q. ì–´ë–¤ Pre-training model architecture ê°€ ê°€ì¥ íš¨ê³¼ì ì¼ê¹Œ? Encoder-Decoder architectureê°€ ê°€ì¥ íš¨ê³¼ì ì´ì—ˆë‹¤. LMì˜ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì§€ ì•Šì•˜ëŠ”ë°, ì´ë¥¼ í†µí•´ bi-directional contextë¥¼ inputìœ¼ë¡œ ë„£ì–´ì£¼ëŠ” ê²ƒì´ íš¨ê³¼ì ì´ë¼ëŠ” ì‚¬ì‹¤ì„ ì•Œ ìˆ˜ ìˆë‹¤. Pre-training objective ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë“¯, í¬ê²Œ ë„¤ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ì„œ ìƒê°í•´ë³¼ ìˆ˜ ìˆë‹¤: 1) High-level approaches 2) Corruption strategies 3) Corruption rate 4) Corrupted span length High-level approaches ì„¸ê°€ì§€ ë°©ì‹ì„ ë¹„êµí•œë‹¤. Prefix language modeling ì€ ë¬¸ì¥ì˜ ì•ë¶€ë¶„ì„ contextë¡œ ì œê³µí•˜ëŠ” ë°©ì‹, BERT-style ì€ Masked-LM (MLM) ë°©ì‹, ê·¸ë¦¬ê³  Deshuffling ì€ ë¬¸ì¥ì˜ tokenì„ ë’¤ì„ê³  ì› ë¬¸ì¥ì„ ë§ì¶”ëŠ” ë°©ì‹ì´ë‹¤. Objective Inputs Targets Prefix language modeling Thank you for inviting me to your party last week . BERT-style Thank you &lt;M&gt; &lt;M&gt; me to your party apple week. (original text) Deshuffling party me for your to . last fun you inviting week Thank (original text) Q. ì–´ë–¤ High-level approach ê°€ ê°€ì¥ íš¨ê³¼ì ì¼ê¹Œ? ìœ„ì˜ í‘œì˜ ê²°ê³¼ì— ë”°ë¥´ë©´ BERT-style (MLM) objective ê°€ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ë‹¤. Corruption strategies ì´ë²ˆì—ëŠ” High-level approaches ì¤‘ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ BERT-style approach ì— ëŒ€í•´ì„œ ì ìš©í•´ ë³¼ ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ corruption strategies ì— ë”°ë¼ ì‹¤í—˜í•œë‹¤. ì´ ì„¸ê°€ì§€ ì „ëµì´ ìˆë‹¤. ëª¨ë‘ i.i.d. ë¡œ maskingì„ í•˜ëŠ” ê²ƒì€ ë™ì¼í•˜ì§€ë§Œ, token ë‹¨ìœ„ë¡œ masking í•˜ëŠ” ë°©ì‹ì´ ìˆê³  (i.i.d. noise, mask tokens) span ë‹¨ìœ„ë¡œ masking í•´ì„œ ì˜ˆì¸¡í•˜ëŠ” ë¬¸ì¥ì€ ì…ë ¥ì—ì„œ maskingëœ ë¶€ë¶„ì„ ì˜ˆì¸¡í•˜ê³  ì•„ë‹Œ ë¶€ë¶„ì„ masked tokenìœ¼ë¡œ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ (i.i.d. noise, replace spans (a.k.a. Denoising, Baseline)), ê·¸ë¦¬ê³  ì›ë¬¸ì—ì„œ tokenì„ ì œì™¸í•˜ê³  ì œì™¸ëœ ë¶€ë¶„ì„ ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ (i.i.d. noise, drop tokens) ì´ ìˆë‹¤. Objective Inputs Targets i.i.d. noise, mask tokens Thank you &lt;M&gt; &lt;M&gt; me to your party &lt;M&gt; week. (original text) i.i.d. noise, replace spans (a.k.a, Denoising, Baseline) Thank you &lt;X&gt; me to your party &lt;Y&gt; week. &lt;X&gt; for inviting &lt;Y&gt; last &lt;Z&gt; i.i.d. noise, drop tokens Thank you me to your party week. for inviting last Q. BERT-style approachì˜ ë‹¤ì–‘í•œ corruption strategy ì¤‘ ë¬´ì—‡ì´ ê°€ì¥ íš¨ê³¼ì ì¼ê¹Œ? ìœ„ì˜ í‘œì— ë”°ë¥´ë©´ Denoising ë°©ì‹ì´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë‚¸ë‹¤. Corruption rate ë§ˆì°¬ê°€ì§€ë¡œ ìœ„ì—ì„œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë˜ Denoising ë°©ì‹ì—ì„œ corruption rateì„ 10%, 15%, 25%, 50%ë¡œ ë‹¤ë¥´ê²Œí•˜ë©° ì‚´í´ë³¸ë‹¤. Q. ì› ë¬¸ì¥ì˜ ì–¼ë§Œí¼ì„ corrupt í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¢‹ì„ê¹Œ? í‘œì— ë”°ë¥´ë©´ 15%ê°€ ì ë‹¹í•˜ë‹¤ëŠ” ê²°ë¡ ì´ ë‚˜ì˜¨ë‹¤. Random spans 15% ì •ë„ denoising ë°©ì‹ìœ¼ë¡œ corrupt í•  ë•Œ í‰ê· ì ì¸ spanì˜ ê¸¸ì´ë¥¼ ë‹¤ë¥´ê²Œ ì¡°ì •í•´ë³¼ ìˆ˜ ìˆë‹¤. Baselineìœ¼ë¡œ ì‚¬ìš©í•œ i.i.d.ì™€ 2, 3, 5, 10 ì˜ ê¸¸ì´ë¥¼ ë¹„êµí•  ìˆ˜ ìˆë‹¤. Q. corruptí•  ë•Œ ê°€ì¥ ì ì •í•œ í‰ê·  span ê¸¸ì´ëŠ” ëª‡ì¼ê¹Œ? í‘œì— ë”°ë¥´ë©´ i.i.d ì— ë”°ë¼ corruptí•˜ëŠ” ê²ƒì´ ê°€ì¥ íš¨ê³¼ì ì´ë‹¤. Pre-training Dataset Pre-training ëª¨ë¸ì˜ ì„±ëŠ¥ì€ ë°ì´í„°ì…‹ì— ë”°ë¼ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤. ì´ë¥¼ ì‹¤í—˜í•˜ê¸° ìœ„í•´ ë…¼ë¬¸ì—ì„œ ìˆ˜ì§‘í•œ C4ì™€ C4, unfiltered ê·¸ë¦¬ê³  ë‹¤ë¥¸ íŠ¹ì§•ì„ ê°€ì§„ ë°ì´í„°ì…‹ìœ¼ë¡œ pre-training í•œ í›„ task ë§ˆë‹¤ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ì˜€ë‹¤. ê²°ê³¼ëŠ” C4ë¥¼ ì“°ëŠ” ê²ƒì´ ê°€ì¥ ì¢‹ì•˜ë‹¤. Pre-training datasize GLUE benchmarkì˜ ìƒìœ„ê¶Œ ëª¨ë¸ì€ ë³´í†µ pre-trainingì— ì‚¬ìš©í•œ datasizeê°€ í¬ë©° ëª¨ë¸ì˜ ì‚¬ì´ì¦ˆë„ êµ‰ì¥íˆ í¬ë‹¤. T5ëŠ” ë‹¤í–‰íˆë„ ëª¨ë¸ì˜ capacityê°€ í° í¸ì´ë¼ ë°ì´í„° ì‚¬ì´ì¦ˆë¥¼ ì¡°ì ˆí•´ê°€ë©° ì‹¤í—˜ì„ í•  ìˆ˜ ìˆì—ˆê³ , C4 ì „ì²´ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•˜ë‹¤. ë‹¤ì‹œ ë§í•´, ì•„ì§ ëª¨ë¸ì˜ capacity ê°€ ë” í¬ë‹¤ê³  ì´í•´í•  ìˆ˜ ìˆë‹¤. Training strategy Transfer learning ì€ Training strategyì— ë”°ë¼ì„œë„ ì„±ëŠ¥ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆë‹¤. Training strategyëŠ” Fine-tuning, Multi-task learning ë°©ì‹ìœ¼ë¡œ ë‚˜ë‰˜ë©° ì´ë¥¼ ì–´ë–»ê²Œ ì¡°í•©í•˜ëŠ”ì§€ ë˜í•œ ì „ëµì— í¬í•¨ë˜ì—ˆë‹¤. Fine-tuning methods Fine-tuning ì€ ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ë‹¤. Multi-task learning (pre-training) T5 ì˜ taskëŠ” ë‹¤ì–‘í•œë°, ê³¼ì—° ê° taskë¥¼ ì–¼ë§Œí¼ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ì¢‹ì„ì§€ì— ëŒ€í•œ ì‹¤í—˜ì´ë‹¤. Equal ì˜ ê²½ìš° task datasetì˜ ì‚¬ì´ì¦ˆì— ìƒê´€ì—†ì´ ê°™ì€ ìˆ˜ì˜ ë¬¸ì¥ì„ í•™ìŠµì‹œí‚¤ëŠ” ë°©ì‹ì´ë‹¤. K threshold ë¥¼ ì‚¬ìš©í•œ ê²½ìš°, ê¸°ë³¸ì ìœ¼ë¡œ taskì˜ ë¬¸ì¥ ì‚¬ì´ì¦ˆë§Œí¼ ìƒ˜í”Œë§í•˜ë˜, K ì´ìƒì˜ ë°ì´í„°ëŠ” K ë§Œí¼ë§Œ í•™ìŠµì— í™œìš©í•œë‹¤. ê²°ê³¼ëŠ” sampling í•˜ì§€ ì•ŠëŠ” ê²ƒì´ ê°€ì¥ ì¢‹ë‹¤. Combining fine-tuning and multi-task learning ìœ„ì—ì„œ ì†Œê°œí•œ ë‹¤ì–‘í•œ ë°©ì‹ì„ ì¡°í•©í•˜ì—¬ ì‹¤í—˜í•˜ì˜€ê³ , multi-task pre-trainingê³¼ fine-tuning ì¡°í•©ì´ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. Scaling strategy scale-up í•  ìˆ˜ ìˆëŠ” hyperparameterì˜ ê°’ì„ ì¡°ì ˆí•´ê°€ë©° ì‹¤í—˜í•˜ì˜€ë‹¤. training steps, batch size, model size ë¥¼ ì¡°ì ˆí•œ ê²°ê³¼, model size ë¥¼ í‚¤ìš°ê³  training steps ì„ ëŠ˜ë¦° ê²½ìš°ì— ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. Conclusions ìœ„ì˜ ì—¬ëŸ¬ ì‹¤í—˜ë“¤ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ë©´, 1) Encoder-Decoder architecture 2) Span prediction objective 3) C4 dataset 4) Multi-task pre-training 5) Bigger models trained longer ì˜ êµ¬ì¡°ë¡œ í•™ìŠµí•  ë•Œ ê°€ì¥ ì¢‹ì€ transfer learning íš¨ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. References [1] https://youtu.be/eKqWC577WlI [2] https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html","link":"/2020/08/29/Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/"},{"title":"How multilingual is Multilingual BERT?","text":"â€œHow multilingual is Multilingual BERT?â€[1] ëŠ” ACL 2019 ì— ì–µì…‰ëœ ë…¼ë¬¸ìœ¼ë¡œ, Telmo Pires ê°€ Google AI Residency í”„ë¡œê·¸ë¨ ì¤‘ì— ì‘ì„±í•˜ì˜€ë‹¤. Unbabel ì—ì„œ Autumatic Post-Editing (APE) ìª½ ì—°êµ¬ë¥¼ ì§„í–‰í–ˆì—ˆë˜ ì—°êµ¬ìì˜€ê³ , ê·¸ë˜ì„œ multilingual BERTì— ëŒ€í•´ ë¶„ì„í•œ ë…¼ë¬¸ì„ ì“´ ê²ƒì´ ì•„ë‹ê¹Œ? Abstract In this paper, we show that Multilingual BERT (M-BERT), released by Devlin et al. (2018) as a single language model pre-trained from monolingual corpora in 104 languages, is surprisingly good at zero-shot cross-lingual model transfer, in which task-specific annotations in one language are used to fine-tune the model for evaluation in another language. To understand why, we present a large number of probing experiments, showing that transfer is possible even to languages in different scripts, that transfer works best between typologically similar languages, that monolingual corpora can train models for code-switching, and that the model can find translation pairs. From these results, we can conclude that M-BERT does create multilingual representations, but that these representations exhibit systematic deficiencies affecting certain language pairs. Motivation Pretrained LM ì´ ë‹¤ì–‘í•œ NLP downstream task ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. Pretrained LMì˜ probing ì—°êµ¬ë“¤ì€ ëª¨ë¸ì´ í•™ìŠµí•œ representation ì´ syntactic and named entity ì—ì„œ íŠ¹íˆ ìœ ìš©í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ì´ ì—°êµ¬ë“¤ì€ ì˜ì–´ì— ëŒ€í•´ì„œë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ ì§„í–‰ë˜ì–´ ì™”ë‹¤. (2019 ë…„ 6ì›” ê¸°ì¤€) (ì°¸ê³ ë¡œ, BERT ëŠ” 2018ë…„ 11ì›”ì— ì²« release) Main Idea ì˜ì–´ì— ëŒ€í•´ì„œ Pretrained LMì´ ê°€ì§€ê³  ìˆëŠ” ì •ë³´, ê·¸ ì¤‘ì—ì„œë„ syntactic and named entity information ì´ ì–¸ì–´ì— ìƒê´€ì—†ì´ ì˜ generalize ë˜ëŠ”ì§€ ë¶„ì„ Main task: NER, POS Main method: Zero-shot cross-lingual transfer (Multilingual BERT ëª¨ë¸ì„ í•œ ì–¸ì–´ì— ëŒ€í•´ finetuning ì‹œí‚¤ê³ , ë‹¤ë¥¸ ì–¸ì–´ì— ëŒ€í•´ ê°™ì€ taskì˜ ì„±ëŠ¥ì„ í‰ê°€) Main Findings ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ í•™ìŠµí•œ Multilingual BERT (M-BERT) ëŠ” NERê³¼ POS task ì— ëŒ€í•´ cross-lingual transfer ability ê°€ ì¢‹ë‹¤. language identifier ì—†ì´ ìœ„í‚¤í”¼ë””ì•„ì˜ ë¬¸ì„œë¡œ í•™ìŠµ (140 ê°œ ì–¸ì–´) w/ shared word piece vocab ëª¨ë“  ì–¸ì–´ìŒì— ëŒ€í•´ zero-shot transfer ê°€ ì˜ ëœ ê²ƒì€ ì•„ë‹ˆì—ˆëŠ”ë° ê·¸ë ‡ë‹¤ë©´ ì™œ ì´ëŸ° ì°¨ì´ê°€ ë°œìƒí• ê¹Œ? finetuning ì–¸ì–´ì™€ evaluation ì–¸ì–´ì˜ vocab overlap ë•Œë¬¸ì€ ì•„ë‹˜ ì˜¤íˆë ¤ ì–¸ì–´ì˜ typological íŠ¹ì§• ë•Œë¬¸ typological íŠ¹ì§•ë„ ì—¬ëŸ¬ ì¢…ë¥˜ê°€ ìˆëŠ”ë° (ì—¬ê¸°ì„œëŠ” subject/object/verb order, adjective/noun orderì— ëŒ€í•´ì„œë§Œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤Œ), ê·¸ ì¤‘ SVO order ì— ê°€ì¥ í° ì˜í–¥ì„ ë°›ìŒ transfer í•˜ê¸° ìœ„í•œ ì–¸ì–´ì— ëŒ€í•´ í•™ìŠµí•œ ì ì´ ìˆì„ ë•Œ transfer ê°€ëŠ¥ M-BERT ì˜ ì¤‘ê°„ layer (8/12) ì—ì„œ cross-lingual information ì´ ë†’ìŒ Detailed Experiments and Results Main Question: ë¬´ì—‡ì´ M-BERTì˜ zero-shot cross-lingual transferabilityë¥¼ ë§Œë“¤ì–´ë‚´ëŠ”ê°€? Preliminaries NER task dataset: CoNLL-2002, 2003 dataset, Google in-house dataset There are four types of phrases: person names (PER), organizations (ORG), locations (LOC) and miscellaneous names (MISC) lang: nl, es (2002) / en, de (2003) ì´ 4ê°œ + in-house dataset with 16 languages (Arabic, Bengali, Czech, German, English, Spanish, French, Hindi, Indonesian, Italian, Japanese, Korean, Portuguese, Russian, Turkish, and Chinese) example (en) NER tagged plain text: [PER Wolff ] , currently a journalist in [LOC Argentina ] , played with [PER Del Bosque ] in the final years of the seventies in [ORG Real Madrid ] . - NER data: Wolff B-PER , O currently O a Ojournalist O in O Argentina B-LOC , O played O with O Del B-PER Bosque I-PER in O the O final O years O of O the O seventies O in O Real B-ORG Madrid I-ORG . O POS task dataset: Universal Dependencies (UD) data (Universal dependencies v1: A multilingual treebank collection, Nivre, 2019) for 41 languages Arabic, Bulgarian, Catalan, Czech, Danish, German, Greek, English, Spanish, Estonian, Basque, Persian, Finnish, French, Galician, Hebrew, Hindi, Croatian, Hungarian, Indonesian, Italian, Japanese, Korean, Latvian, Marathi, Dutch, Norwegian (Bokmaal and Nynorsk), Polish, Portuguese (European and Brazilian), Romanian, Russian, Slovak, Slovenian, Swedish, Tamil, Telugu, Turkish, Urdu, and Chinese evaluation set: Multilingual Parsing from Raw Text to Universal Dependencies, Zemman et al. 2017 (CoNLL 2017 shared Task) example (ko): # sent_id = n01007012# text = ì´ ë¶€ë¶„ì—ì„œ ê²Œì„ê³¼ ìš°ë¦¬ ì¼ìƒ ìƒí™œ ì‚¬ì´ì˜ ìœ ì‚¬ì ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.# text_en = There are parallels to draw here between games and our everyday lives.# translit = .i .bu.bun.e.seo .ge.im.gwa .u.ri .il.sang .saeng.hwal .sa.i.yi .yu.sa.jeom.eul .chaj.eul .su .iss.seub.ni.da.1 ì´ _ DET DT _ 2 det _ Translit=.i|LTranslit=_2 ë¶€ë¶„ì—ì„œ ë¶€ë¶„ NOUN NN+CM Case=Advb|Polite=Form 9 advmod _ MSeg=ë¶€ë¶„-ì—ì„œ|Translit=.bu.bun.e.seo|LTranslit=.bu.bun3 ê²Œì„ê³¼ ê²Œì„ NOUN NN+CP Polite=Form 7 compound _ MSeg=ê²Œì„-ê³¼|Translit=.ge.im.gwa|LTranslit=.ge.im4 ìš°ë¦¬ _ PRON PRP Person=1 6 compound _ Translit=.u.ri|LTranslit=_5 ì¼ìƒ _ NOUN NN _ 6 compound _ Translit=.il.sang|LTranslit=_6 ìƒí™œ _ NOUN NN _ 3 conj _ Translit=.saeng.hwal|LTranslit=_7 ì‚¬ì´ì˜ ì‚¬ì´ NOUN NN+CM Case=Gen|Polite=Form 8 nmod:poss _ MSeg=ì‚¬ì´-ì˜|Translit=.sa.i.yi|LTranslit=.sa.i8 ìœ ì‚¬ì ì„ ìœ ì‚¬ì  NOUN NN+CM Case=Acc|Polite=Form 9 obj _ MSeg=ìœ ì‚¬ì -ì„|Translit=.yu.sa.jeom.eul|LTranslit=.yu.sa.jeom9 ì°¾ì„ _ VERB VV Form=Adn 10 acl:relcl _ Translit=.chaj.eul|LTranslit=_10 ìˆ˜ _ NOUN NNB _ 11 nsubj _ Translit=.su|LTranslit=_11 ìˆìŠµë‹ˆë‹¤ _ ADJ JJ Mood=Ind|VerbForm=Fin 0 root _ SpaceAfter=No|Translit=.iss.seub.ni.da|LTranslit=_12 . . PUNCT . _ 11 punct _ Translit=.|LTranslit=_ Code-switching (CS) and Transliterate (Tlit) task Code-switching: ì—¬ëŸ¬ ì–¸ì–´ê°€ í•œ ë¬¸ì¥ì— ë“±ì¥í•˜ëŠ” ê²½ìš° ex) I thought à¤®à¥Œà¤¸à¤® different à¤¹à¥‹à¤—à¤¾ à¤¬à¤¸ fog à¤¹à¥ˆ Tlit: ìŒì°¨ í‘œê¸° ex) I thought mosam different hoga bas fog hy M-BERT ì˜ cross-lingual transferability ëŠ” vocab overlap ë•Œë¬¸ì¼ê¹Œ? â†’ NO vocab overlap: fine-tuning dataset (train) ì˜ word piece ì™€ evaluation dataset (test) ì˜ word piece ê°„ì˜ overlap \\[overlap = \\frac{| E_{train} âˆ© E_{eval} |}{| E_{train} âˆª E_{eval}|}\\] ê²€ì¦ ë°©ì‹: NER task ì¤‘ 16ê°œì˜ ì–¸ì–´ì— ëŒ€í•œ in-house ë°ì´í„°ì…‹ìœ¼ë¡œ ê°€ëŠ¥í•œ ì–¸ì–´ìŒ (16 * 15 = 240 ê°œ) ì— ëŒ€í•´ overlapì„ êµ¬í•˜ê³ , trasfer score (F1) ë¥¼ report (ê²°ê³¼) M-BERTëŠ” vocab overlap ê³¼ ë¬´ê´€í•˜ê²Œ generally ì„±ëŠ¥ì´ ì¢‹ë‹¤. vocab overlap ì´ 0ì¸ ì–¸ì–´ìŒì— ëŒ€í•´ì„œë„ ìµœì†Œ 40%ì˜ F1 score ë¥¼ ë³´ì¸ë‹¤. ë°˜ë©´ EN-BERT ëŠ” vocab overlap ì— êµ‰ì¥íˆ ë§ì´ ì˜í–¥ì„ ë°›ëŠ”ë‹¤. M-BERTì˜ cross-lingual transferability ëŠ” ì–¸ì–´ì˜ typological íŠ¹ì§• ë•Œë¬¸ì¼ê¹Œ? â†’ YES ê·¼ê±°: POS accuracy of ur â†’ hi (91%) while enâ†’ ja (49.4%) (ë‘˜ ë‹¤ ë‹¤ë¥¸ script ë¥¼ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ìŒ, a.k.a vocab overlap ~= 0) typological features[2] (ê²°ê³¼) ê³µí†µëœ typological feature ì˜ ê°œìˆ˜ê°€ ë§ì„ìˆ˜ë¡ transferabiltiy í–¥ìƒ (ê²°ê³¼) ì—¬ëŸ¬ typological features ì¤‘ì—ì„œ SOV order ì™€ AN orderì˜ ì˜í–¥ì„ ë¹„êµí–ˆì„ ë•Œ ì „ìê°€ ë” ì˜í–¥ì´ í¼ M-BERTì˜ cross-lingual transferability ëŠ” CS í˜¹ì€ Tlit ê¹Œì§€ ì ìš©ë  ìˆ˜ ìˆì„ê¹Œ? â†’ CS (YES) / Tlit (NO) CS ì‹¤í—˜ ëª©ì : Generalizing to code-switching is similar to other cross-lingual transfer scenarios, but would beneï¬t to an even larger degree from a shared multilingual representation. Tlit ì‹¤í—˜ ëª©ì : Generalizing to transliterated text is similar to other cross-script transfer experiments, but has the additional caveat that M-BERT was not pre-trained on text that looks like the target. (ê²°ê³¼) M-BERTëŠ” CS text ì— ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„ (90.56% â‡’ 86.59%). í•˜ì§€ë§Œ Tlit ì€ ì´ëŸ¬í•œ ì¢…ë¥˜ì˜ ë°ì´í„°ì— í•™ìŠµë˜ì§€ ì•Šê³ ì„œëŠ” trasferabilityë¥¼ ê¸°ëŒ€í•˜ê¸° ì–´ë ¤ì›€ (85.64% â‡’ 50.41%) 4. M-BERTì˜ feature space WMT16 ë³‘ë ¬ ì½”í¼ìŠ¤ë¥¼ ì‚¬ìš©í•´ì„œ ì–¸ì–´ìŒ ê°„ì˜ NN accuracy ì¸¡ì • (ê²°ê³¼) ì¤‘ê°„ layerì—ì„œ linguistic informationì„ ê³µìœ í•˜ê³  ì´ëŠ” ì–¸ì–´ì— ê´€ê³„ì—†ì´ ë¹„ìŠ·í•˜ê²Œ ë‚˜íƒ€ë‚¨ My Thoughts on the Results vocab overlap ì‹¤í—˜ì—ì„œ EN-BERTì™€ì˜ ë¹„êµëŠ” ì •ë‹¹í•œê°€? ì œ ì¶”ì¸¡ìœ¼ë¡œëŠ”, vocab overlap ì‹¤í—˜ì—ì„œ M-BERT ë§Œì„ ë³´ì•˜ì„ ë•Œ, ì´ ê²½í–¥ì„±ì´ overlapì— ì˜í–¥ì„ ë°›ëŠ” ê²ƒì¸ì§€ ì•„ë‹Œì§€ íŒë‹¨í•˜ê¸° ì–´ë ¤ì› ê¸° ë•Œë¬¸ì— ìƒëŒ€ ë¹„êµë¥¼ í• ë§Œí•œ ê²°ê³¼ê°€ í•„ìš”í•´ì„œ EN-BERTì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë„£ì€ ê²ƒ ê°™ë‹¤. ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ corr ì„ ë³´ë©´ ì–´ëŠ ì •ë„ ìœ ì˜ë¯¸í•´ ë³´ì´ëŠ” ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ë‚˜ì˜¬ ê²ƒ ê°™ê³ , ê·¸ë ‡ë‹¤ë©´ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ê³  í•´ì„í•´ì•¼í•  ìˆ˜ë„ ìˆì§€ë§Œ, vocab overlapì´ 0ì„ì—ë„ 40%ì˜ ì„±ëŠ¥ì„ ë³´ì´ë¯€ë¡œ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ê³  í•˜ê¸°ë„ ì• ë§¤í•œ ìƒí™©ì´ ì•„ë‹ˆì—ˆì„ê¹Œ? ê·¸ë ‡ì§€ë§Œ EN-BERTì™€ì˜ ë¹„êµê°€ ì •ë‹¹í•˜ë‹¤ê³  ìƒê°í•˜ê¸´ ì–´ë ¤ìš´ ê²ƒ ê°™ë‹¤. NER ì˜ˆì¸¡ task ëŠ” sent -&gt; model (either M-BERT or EN-BERT) -&gt; last activation -&gt; add.layer -&gt; NER prediciton ë¡œ ì§„í–‰ë˜ëŠ”ë°, sent ê°€ ì˜ì–´ê°€ ì•„ë‹Œ ê²½ìš° tok ë‹¨ê³„ì—ì„œë¶€í„° unkìœ¼ë¡œ ì¸ì‹ë  ê°€ëŠ¥ì„±ì´ ë†’ê¸° ë•Œë¬¸ì— transferëŠ” ê³ ì‚¬í•˜ê³  fine-tuningë„ ì–´ë ¤ìš¸ ìˆ˜ ìˆë‹¤. ì´ ë•Œë¬¸ì— ë…¼ë¬¸ì—ì„œ EN-BERTì™€ XLMì„ ë¹„êµí•˜ëŠ”ë°, Indo-european ì¸ (de, nl, es) ì— ëŒ€í•´ì„œë§Œ ë‚˜ì™€ìˆë‹¤. (Table 3) ì˜ì–´ì™€ alphabet ì´ ë¹„ìŠ·í•˜ë©´, unk ì´ ë‚˜ì˜¤ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ê³  ìƒê°í•´ì„œ ìœ„ì˜ ê²°ê³¼ê°€ EN-BERTë¡œ ì–»ì–´ì§„ ê²ƒì— ëŒ€í•´ í¬ê²Œ ê±°ë¶€ê°ì´ ë“¤ì§€ ì•Šì•˜ê³ , ì˜¤íˆë ¤ CJK ì— ëŒ€í•´ì„œ ë³´ì˜€ì–´ì•¼ í•˜ëŠ” ê²ƒ ì•„ë‹Œê°€ í•˜ëŠ” ì˜ì‹¬ì´ ë“¤ì—ˆë‹¤. ê·¸ë˜ì„œ ğŸ¤— ë¡œ ê°„ë‹¨í•˜ê²Œ tokenize ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì•˜ë‹¤. sent ê°€ es ì¸ ê²½ìš° sent: Por su parte , el Abogado General de Victoria , Rob Hulls , indicÃ³ que no hay nadie que controle que las informaciones contenidas en CrimeNet son veraces . M-BERT tok: Por su parte , el Ab ##oga ##do General de Victoria , Rob Hull ##s , ind ##ic ##Ã³ que no hay nadie que controle que las informa ##ciones conte ##nida ##s en Crime ##Net son vera ##ces . EN-BERT tok: Po ##r su part ##e , el A ##bo ##gado General de Victoria , Rob Hull ##s , in ##dic ##Ã³ que no hay na ##die que control ##e que las inform ##ac ##ione ##s con ##ten ##idas en Crime ##Net son ve ##race ##s . sent ê°€ ko ì¸ ê²½ìš° sent: ì–¸ì–´(è¨€èª)ì— ëŒ€í•œ ì •ì˜ëŠ” ì—¬ëŸ¬ê°€ì§€ ì‹œë„ê°€ ìˆì—ˆë‹¤. M-BERT tok: ì–¸ ##ì–´ ( è¨€ èª ) ì— ëŒ€í•œ ì • ##ì˜ ##ëŠ” ì—¬ëŸ¬ ##ê°€ì§€ ì‹œ ##ë„ê°€ ìˆì—ˆë‹¤ . EN-BERT tok: [UNK] ( [UNK] [UNK] ) [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] . ìœ„ì˜ ê²°ê³¼ë¡œ ë¯¸ë£¨ì–´ë³´ì•„, vocab overlap ì´ ë‚®ìœ¼ë©´ì„œ ì„±ëŠ¥ë„ ë‚®ì•˜ë˜ ì ë“¤ì˜ ì–¸ì–´ìŒì—ëŠ” EN-BERTì—ì„œ unkì´ ë§ì´ ë‚˜ì™”ë˜ ì–¸ì–´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì„ê¹Œí•˜ëŠ” ìƒê°ì´ ë“¤ì—ˆê³ , ë¹„êµê°€ ê³µì •í•˜ì§€ ì•Šë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ë˜í•œ tlit. ì„ M-BERT ê°€ ëª»í•˜ëŠ” ì´ìœ ë¡œ, pre-train stepì—ì„œ tlit. corpus ê°€ ì—†ì—ˆê¸° ë•Œë¬¸ì´ë¼ê³  ì–¸ê¸‰í•˜ì˜€ëŠ”ë° EN-BERT ë˜í•œ ê°™ì€ ì´ìœ ë¡œ ì„±ëŠ¥ì´ ë‚®ì„ ìˆ˜ ë°–ì— ì—†ì—ˆì„ ê²ƒì´ë¼ê³  ìƒê°. SOV order ê°€ ì¤‘ìš”í•œ ì ì´ì—ˆì„ê¹Œ? ë…¼ë¬¸ì—ì„œëŠ” ì•„ë˜ í‘œì—ì„œ SVO -&gt; SVO (81.55) &gt; SVO -&gt; SOV (66.52) ë¼ëŠ” ì  ë•Œë¬¸ì— SOV order ê°€ ê°€ì¥ ì¤‘ìš”í•˜ë‹¤ê³  ì£¼ì¥í•œë‹¤. í•˜ì§€ë§Œ ë°˜ëŒ€ë¡œ SOV -&gt; SOV (64.22) &gt; SOV -&gt; SVO (63.98) ì˜ ì°¨ì´ê°€ ì ê²Œ ë‚˜ëŠ” ì ì€ ì„¤ëª…í•  ìˆ˜ ì—†ë‹¤. ì œ ì¶”ì¸¡ìœ¼ë¡œëŠ”, ì˜¤íˆë ¤ ê° ê·¸ë£¹ì„ êµ¬ì„±í•˜ëŠ” ì–¸ì–´ì™€ ê·¸ ì–¸ì–´ë“¤ì´ Wikipedia ì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨, ì¦‰ M-BERT í•™ìŠµì— ì˜í–¥ì„ ë§ì´ ë¼ì¹œ ì–¸ì–´ê°€ ì¤‘ìš”í•œ ì—­í• ì„ í–ˆì„ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ë‹¤. SVO languages: Bulgarian, Catalan, Czech, Danish, English, Spanish, Estonian, Finnish, French, Galician, Hebrew, Croatian, Indonesian, Italian, Latvian, Norwegian (Bokmaal and Nynorsk), Polish, Portuguese (European and Brazilian), Romanian, Russian, Slovak, Slovenian, Swedish, and Chinese. SOV Languages: Basque, Farsi, Hindi, Japanese, Korean, Marathi, Tamil, Telugu, Turkish, and Urdu. Urdu -&gt; Hindi ì˜ ì„±ëŠ¥ì´ 91% ì˜€ë˜ ì ì„ ê³ ë ¤í•˜ë©´ ì´ ì¤‘ ì–´ë–¤ ì–¸ì–´ìŒì—ì„œ êµ‰ì¥íˆ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì˜€ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ (í‰ê· ì´ 64.22 ì´ì–´ì•¼í•˜ë¯€ë¡œ) ê·¸ë£¹ì˜ í‰ê· ì¹˜ë¥¼ ë³´ì§€ ì•Šì•˜ë‹¤ë©´ ë‹¤ë¥¸ í•´ì„ì´ ê°€ëŠ¥í–ˆì„ ìˆ˜ë„â€¦? SVO order ê°€ ë¹„ìŠ·í•˜ë©´ -&gt; transfer ê°€ ì˜ëœë‹¤! ë¼ëŠ” ì£¼ì¥ì„ í•˜ê³  ì‹¶ì—ˆë‹¤ë©´ ë¹„êµí•˜ë ¤ëŠ” ëŒ€ìƒ ì–¸ì–´ìŒë“¤ê°„ì— SVO order ë¹¼ê³ ëŠ” ì¡°ê±´ì„ ë™ì¼í•˜ê²Œ ë§Œì¡±ì‹œì¼°ì–´ì•¼ í•˜ì§€ ì•Šì„ê¹Œí•˜ëŠ” ì•„ì‰¬ì›€ì´ ë‚¨ëŠ”ë‹¤. Feature space MLMì€ ë³´í†µ ì¤‘ê°„ layer ì—ì„œ semantic í•œ ì„±ì§ˆì´ ê°€ì¥ ë‘ë“œëŸ¬ì§€ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒ ê°™ë‹¤. ë…¼ë¬¸ì˜ ë¶„ì„ ë‚´ìš© ë…¼ë¬¸ì—ì„œ ë¶„ì„í•œ ê²°ë¡ ì´ ì§€ë‚˜ì¹œ ì¼ë°˜í™”ê°€ ì•„ë‹ê¹Œí•˜ëŠ” ìƒê°ë„ ë“ ë‹¤. ì¼ë‹¨ M-BERTê°€ zero-shot transferability ê°€ ë†’ì€ ì´ìœ ëŠ” ì–´ì©Œë©´ ê°™ì€ ë‚´ìš©ì˜ Wikipedia ë¬¸ì„œë¡œ í•™ìŠµí–ˆê¸° ë•Œë¬¸ì¼ ìˆ˜ ìˆë‹¤. ë§Œì•½ì— í•œêµ­ì–´ëŠ” ë™ì¼ ë‚´ìš©ì— ëŒ€í•œ ë²ˆì—­ëœ ë¬¸ì„œê°€ ì—†ëŠ” (e.g., ë„¤ì´ë²„ ë¸”ë¡œê·¸) ë¡œ í•™ìŠµí•˜ê³ , ì˜ì–´ë„ ì˜ì–´ ë‚˜ë¦„ëŒ€ë¡œì˜ ë²ˆì—­ë¬¸ì´ ì—†ëŠ” ë¬¸ì„œë¡œ í•™ìŠµëœ BERT ì˜€ë”ë¼ë„ ê°™ì€ ê²°ê³¼ê°€ ë„ì¶œë˜ì—ˆì„ì§€ëŠ” ëª¨ë¥´ê² ë‹¤. M-BERT ì˜ í•™ìŠµ ë°ì´í„°ì˜ íŠ¹ì§•ì—ì„œ ê¸°ì¸í•œ íŠ¹ì§•ì´ ì–¼ë§ˆë‚˜ ë˜ëŠ”ì§€ë„ ê¶ê¸ˆí•˜ë‹¤. ì˜¤íˆë ¤ ì—¬ê¸°ì—ì„œ ì˜í–¥ì„ ë§ì´ ë°›ì•˜ì„ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ë‹¤. References 1.https://www.aclweb.org/anthology/P19-1493.pdf â†©2.https://www.aclweb.org/anthology/P12-1066.pdf â†©","link":"/2020/06/20/How-multilingual-is-multilingual-BERT/"},{"title":"Gitì˜ ë‹¤ì–‘í•œ ë¨¸ì§€ ì „ëµ ë¹„êµ - ìš°ë¦¬ íŒ€ì€ ì–´ë–¤ ì „ëµì„ ë„ì…í•´ì•¼ í• ê¹Œ?","text":"Gitì€ í•œ ë¸Œëœì¹˜ì—ì„œ ì‘ì—…í•œ ë‚´ìš©ì„ Main ë¸Œëœì¹˜ì— ë³‘í•©(Merge)í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë°©ë²•ë“¤ì„ ì œê³µí•œë‹¤. ì´ëŸ¬í•œ ë°©ë²•ë“¤ì„ Merge ì „ëµì´ë¼ê³  ë¶€ë¥´ëŠ”ë°, ë‹¤ì–‘í•œ ë°©ë²•ë“¤ ì¤‘ì—ì„œë„ ì´ë²ˆ ê¸€ì—ì„œëŠ” ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë°©ë²•ì¸ 1) Merge Commit, 2) Squash and Merge, 3) Rebase and Mergeì— ëŒ€í•´ ì†Œê°œí•˜ë ¤ê³  í•œë‹¤. ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì€ ìƒíƒœì˜ commitì´ ìƒì„±ë˜ì—ˆë‹¤ê³  ê°€ì •í•˜ì. feat/multiplyë¼ëŠ” ë¸Œëœì¹˜ê°€ ìˆê³ , feat/sumì´ë¼ëŠ” ë¸Œëœì¹˜ê°€ ìˆë‹¤. ê° commit ë‚´ì˜ ìˆ«ìëŠ” commitì˜ global ìˆœì„œë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. Merge Commit ë¸Œëœì¹˜ì˜ commit logì™€ merge logê°€ ë™ì‹œì— ê¸°ë¡ëœë‹¤. Commit logëŠ” commitì„ í–‰í•œ ìˆœì„œëŒ€ë¡œ ê¸°ë¡ë˜ê³ , merge logëŠ” mergeê°€ ëœ ìˆœì„œëŒ€ë¡œ ê¸°ë¡ëœë‹¤. ë™ì‹œì— ê¸°ë¡ë˜ê¸° ë•Œë¬¸ì— commit logê°€ verboseí•´ì§€ë©° commit logì˜ ìˆœì„œê°€ merge ìˆœì„œì™€ ë‹¤ë¥´ê¸° ë•Œë¬¸ì— history ê´€ë¦¬ ë° ì´í•´ê°€ ì–´ë µë‹¤. Squash and Merge Mergeëœ ìˆœì„œëŒ€ë¡œ master/main ë¸Œëœì¹˜ì— ê¸°ë¡ëœë‹¤. ê·¸ë¦¬ê³  ì‘ì—… ì™„ë£Œëœ ë¸Œëœì¹˜ì˜ commitì€ ìƒˆë¡œìš´ commit ìœ¼ë¡œ ëª¨ë‘ squashë˜ë©°, ìƒˆë¡œìš´ commitì˜ ì œëª©ì€ PR ì œëª©ì´ ë˜ê³ , í•©ì³ì§„ commitì˜ ì œëª©ì€ ìƒˆë¡œìš´ commitì˜ ìƒì„¸ ë‚´ìš©ì´ ëœë‹¤. ì´ëŸ¬í•œ íŠ¹ì§• ë•Œë¬¸ì— master/main ë¸Œëœì¹˜ì˜ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ê°€ ì‰¬ìš°ë‚˜, atomic commit levelë¡œ rollback í•˜ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•˜ë‹¤. Rebase and Merge Commit ìˆœì„œê°€ ì•„ë‹Œ merge ìˆœì„œëŒ€ë¡œ ê¸°ë¡ëœë‹¤. ê·¸ë˜ì„œ í•˜ë‚˜ì˜ PRì— ë‹´ê¸´ commit messageê°€ ë‹¤ë¥¸ PRì˜ commit messageì™€ ì„ì´ì§€ ì•ŠëŠ”ë‹¤. ê·¸ë¦¬ê³  rebase ë•ë¶„ì— mergeëœ ì´í›„ì˜ ë¡œê·¸ë¥¼ ë³´ì•˜ì„ ë•Œ í•˜ë‚˜ì˜ ë¸Œëœì¹˜ì—ì„œ ì—°ì†ì ìœ¼ë¡œ ì‘ì—…í•œ ê²ƒê³¼ ê°™ì€ ë¡œê·¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ ë•Œë¬¸ì— ì–¼ë§ˆë“ ì§€ í•­ìƒ ì›í•˜ëŠ” ìˆ˜ì¤€ìœ¼ë¡œ rollback ì´ ê°€ëŠ¥í•˜ë‹¤. í•˜ì§€ë§Œ ì˜ ì ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” commitì„ ìƒì„±í•  ë•Œë¶€í„° ì˜¬ë°”ë¥¸ commit ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•´ì•¼ í•˜ë©°, commit message ë˜í•œ ì„¤ëª…ë ¥ì„ ê°€ì§€ê³  ìˆì–´ì•¼ í•œë‹¤. ê·¸ë¦¬ê³  ë‹¤ë¥¸ PRì´ ë¨¼ì € mergeë˜ëŠ” ê²½ìš°, rebase ì‘ì—…ì´ í•„ìš”í•  ìˆ˜ ìˆê³  ì´ ë•Œ ë°œìƒí•  ìˆ˜ ìˆëŠ” conflictë¥¼ ì˜ í•´ê²°í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤. Summary Merge Strategy Pros Cons Merge Commit ì•„ì§ ì°¾ì§€ ëª»í•¨ ë¶ˆí•„ìš”í•œ commit messageê°€ ìƒê¸°ê³  merge ìˆœì„œì™€ commit ìˆœì„œê°€ ë³„ë„ë¡œ ê¸°ë¡ë˜ì–´ history ê´€ë¦¬ê°€ ì–´ë ¤ì›€ Squash and Merge Commit ë‹¨ìœ„ ë³„ë¡œ ê¼¼ê¼¼í•˜ê²Œ ê´€ë¦¬í•˜ì§€ ì•Šì•„ë„ PR title ë§Œ ì œëŒ€ë¡œ ê´€ë¦¬í•˜ë©´ historyê°€ ê¹”ë”í•˜ê²Œ ì •ë¦¬ë¨ Atomic levelì˜ rollbackì´ ì–´ë ¤ì›€ Rebase and Merge Atomic levelì˜ rollbackì´ ìš©ì´í•˜ë©° commit ë‹¨ìœ„ì˜ history ê¸°ë¡ì´ ë¨ Commitì„ ì˜ ë‹¤ë£¨ì§€ ëª»í•˜ëŠ” ê²½ìš°, rebaseì— ìµìˆ™í•˜ì§€ ì•Šì€ ê²½ìš° ì–´ë ¤ì›€ì´ ë°œìƒ ì•ì„œ ì†Œê°œí•œ ì „ëµë“¤ì˜ ì¥/ë‹¨ì ì„ ì •ë¦¬í•˜ë©´ ìœ„ì™€ ê°™ë‹¤. ê°œì¸ì ìœ¼ë¡œëŠ” ì•„ì§ Merge Commitì˜ ì¥ì ì„ ë°œê²¬í•˜ì§€ ëª»í–ˆë‹¤. ê²°ë¡ ì ìœ¼ë¡œ íŒ€ì› ì „ì²´ê°€ gitì„ ë‹¤ë£¨ëŠ”ë°ì— êµ‰ì¥íˆ ìµìˆ™í•´ì„œ commit ë‹¨ìœ„, commit message, rebase ë“±ì— ì–´ë ¤ì›€ì´ ì—†ëŠ” ê²½ìš°, í˜¹ì€ atomic levelì˜ rollbackì´ í•„ìš”í•œ ê°œë°œ ìƒí™©ì—ì„œ Rebase and Mergeê°€ ì„ í˜¸ëœë‹¤. í•˜ì§€ë§Œ atomic level ê¹Œì§€ì˜ rollbackì€ í•„ìš”í•˜ì§€ ì•Šê³  íŒ€ì´ ì´ì œ ë§‰ gitìœ¼ë¡œ ë²„ì „ê´€ë¦¬í•˜ëŠ” ë²•ì„ ë°°ìš°ê¸° ì‹œì‘í–ˆë‹¤ë©´ Squash and Mergeê°€ ì¢‹ì„ ê²ƒì´ë‹¤.","link":"/2021/07/11/Git-merge-strategy/"},{"title":"ë©˜í† ì—ê²Œ ì¢‹ì€ ì§ˆë¬¸ì„ í•˜ëŠ” ë°©ë²•","text":"ì‡ë‹¤ ë©˜í† ë¡œ í™œë™í–ˆë˜ 3ê°œì›” ë‚¨ì§“í•œ ê¸°ê°„ì— ìƒê°ë³´ë‹¤ ë‹¤ì–‘í•œ ì§ˆë¬¸ì„ ë°›ì•˜ë‹¤. ê·¸ ì¤‘ì—ëŠ” ë‹µë³€í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ì´ ìˆì—ˆê³ , ê¸€ì´ ë¬´ê±°ìš´ ë‚˜ë¨¸ì§€ ë‚´ê°€ ì ê²Œë  ë‹µë³€ í•˜ë‚˜í•˜ë‚˜ê°€ ì¡°ì‹¬ìŠ¤ëŸ¬ì›Œ ê²°êµ­ ê¸°ê°„ ë‚´ì— ì‘ì„±í•˜ì§€ ëª»í•˜ê²Œ ëœ ì§ˆë¬¸ë„ ìˆì—ˆê³ , ë‹µë³€í•˜ê¸° ì‹«ì€ ì§ˆë¬¸ë„ (ë‹¹ì—°íˆ) ìˆì—ˆë‹¤. ì§ˆë¬¸ì´ ë„ì°©í–ˆìŒì„ ì•Œë¦¬ëŠ” ì§„ë™ì´ ë‘ë ¤ì›Œì§„ ì ë„ ìˆì—ˆë‹¤. ì¢‹ì€ ì§ˆë¬¸ì´ë©´ í° ì–´ë ¤ì›€ì—†ì´ ê¸€ì„ ì ì„ ìˆ˜ ìˆì§€ë§Œ ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ì‹¬ì ìœ¼ë¡œ ë¶€ë‹´ì´ ë§ì´ ë˜ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ëŸ¬ë‹¤ ë¬¸ë“, ë©˜í‹°ì˜ ì…ì¥ì—ì„œ ì¢‹ì€ ì§ˆë¬¸ì„ ì ëŠ” ê²ƒì´ ìƒê°ë³´ë‹¤ ì–´ë ¤ìš¸ ìˆ˜ ìˆê² ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ë‹¹ì¥ ìŠ¤ìŠ¤ë¡œê°€ í˜¼ë€ìŠ¤ëŸ¬ìš´ë°, ì–´ë””ì„œë¶€í„° ì–´ë–»ê²Œ ê·¸ ìƒí™©ì„ ì „ë‹¬í•´ì•¼í• ì§€ ë§‰ì—°í•˜ì§€ ì•Šì„ê¹Œ? ê·¸ë˜ì„œ ì´ ê¸€ì„ ì“°ê²Œ ë˜ì—ˆë‹¤. ì¢‹ì€ ì§ˆë¬¸ì„ ê³ ë¯¼í•˜ëŠ” ê³¼ì •ì—ì„œ ë©˜í‹°ë“¤ì´ ìŠ¤ìŠ¤ë¡œ ë‹µì„ ì°¾ê²Œë˜ê¸¸ ë°”ë¼ëŠ” ê¸°ëŒ€ë„ í•¨ê»˜í•˜ë©´ì„œ ë§ì´ë‹¤. ìµœëŒ€í•œ ìŠ¤ìŠ¤ë¡œì˜ ê³ ë¯¼, ìƒê°, ê²½í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ ì ì. ë©˜í† ëŠ” ì§ˆë¬¸ì„ ë°›ê³  ìµœëŒ€í•œ ì¢‹ì€ ë‹µë³€ì„ í•˜ê¸° ìœ„í•´ ê¸€ë§Œìœ¼ë¡œ ë“œëŸ¬ë‚˜ëŠ” ë©˜í‹°ë¥¼ ìˆëŠ” í˜ê» ì´í•´í•˜ë ¤ê³  ë…¸ë ¥í•œë‹¤. ë¬¸ì²´ë¥¼ ë³´ê³ , ìŠ¤í™ê³¼ ê¸°íƒ€ì‚¬í•­ì„ ì½ê³ , ìµœëŒ€í•œ ì§ˆë¬¸í•œ ì‚¬ëŒì˜ ì…ì¥ì„ í—¤ì•„ë¦°ë‹¤. ê·¸ë˜ì„œ ì¶”ìƒì ì´ê³  ì§§ì€ ì§ˆë¬¸, ë„ˆë¬´ ê°„ëµí•œ ìŠ¤í™ê³¼ ê¸°íƒ€ì‚¬í•­ì„ ê°€ì§„ ë©˜í‹°ì—ê²ŒëŠ” ë‹µë³€í•˜ê¸°ê°€ êµ‰ì¥íˆ ì–´ë µë‹¤. ë§›ì§‘ì„ ì°¾ëŠ” ì§ˆë¬¸ì„ ë– ì˜¬ë ¤ë³´ì. A. ì €ëŠ” ë§›ìˆëŠ” ê²ƒì„ ë¨¹ê³  ì‹¶ì–´ìš”. ì¶”ì²œí•´ì£¼ì„¸ìš”. B. ì €ëŠ” ë§µê³  ìê·¹ì ì¸ ìŒì‹ì„ ì‹«ì–´í•˜ê³ , ì˜¤ëŠ˜ì€ ë°€ê°€ë£¨ ìŒì‹ì´ ë¨¹ê³  ì‹¶ì§€ ì•Šì•„ìš”. ì¡°ë¯¸ë£Œê°€ ë§ì´ ì²¨ê°€ë˜ì§€ ì•Šê³  ë‹¨ë°±ì§ˆ í•¨ëŸ‰ì´ ë†’ì€ ìŒì‹ì„ ë¨¹ê³  ì‹¶ì€ë°, ì œê°€ ê°€ì§„ ëˆì´ ë³„ë¡œ ì—†ì–´ìš”. ë¹„ì‹¸ì§€ ì•Šìœ¼ë©´ì„œ ê´œì°®ì€ ì‹ë‹¹ì„ ì•Œê³  ê³„ì‹ ê°€ìš”? ëˆ„ê°€ë´ë„ Bì˜ ì§ˆë¬¸ì´ ë” ë§¤ë ¥ì ì´ê³ , ë‹µë³€í•˜ê¸° ì‰½ë‹¤. ë•Œë¡ , ë©˜í† ë¡œì„œ ì˜ ëª¨ë¥´ëŠ” ë¶„ì•¼ì´ë”ë¼ë„ ì–´ë–»ê²Œë“  ì£¼ë³€ì— ë¬¼ì–´ë¬¼ì–´ ì•Œë ¤ì£¼ê³  ì‹¶ì„ ì •ë„ë‹¤. ì§ˆë¬¸ì€ ë‚ ì¹´ë¡­ê²Œ ëë‚´ì. ì‡ë‹¤ í”Œë«í¼ì€ ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ì±„íŒ…ì²˜ëŸ¼ ê°€ëŠ¥í•œ í˜•ì‹ì´ ì•„ë‹ˆë‹¤. ê·¸ë˜ì„œ ì¢‹ì€ ë‹µë³€ì„ ë‹¨ë²ˆì— ì´ëŒì–´ë‚´ê¸° ìœ„í•´ì„œëŠ” ì§ˆë¬¸ì´ ì¡°ê¸ˆ ë½€ì£¡í•´ì§ˆ í•„ìš”ê°€ ìˆë‹¤. ë‹¤ì‹œ ë§›ì§‘ ì˜ˆì‹œë¥¼ ë“¤ì–´ë³´ì. A. ì €ëŠ” ë§µê³  ìê·¹ì ì¸ ìŒì‹ì„ ì‹«ì–´í•˜ê³ , ì˜¤ëŠ˜ì€ ë°€ê°€ë£¨ ìŒì‹ì´ ë¨¹ê³  ì‹¶ì§€ ì•Šì•„ìš”. ì¡°ë¯¸ë£Œê°€ ë§ì´ ì²¨ê°€ë˜ì§€ ì•Šê³  ë‹¨ë°±ì§ˆ í•¨ëŸ‰ì´ ë†’ì€ ìŒì‹ì„ ë¨¹ê³  ì‹¶ì€ë°, ì œê°€ ê°€ì§„ ëˆì´ ë³„ë¡œ ì—†ì–´ìš”. B. ì €ëŠ” ë§µê³  ìê·¹ì ì¸ ìŒì‹ì„ ì‹«ì–´í•˜ê³ , ì˜¤ëŠ˜ì€ ë°€ê°€ë£¨ ìŒì‹ì´ ë¨¹ê³  ì‹¶ì§€ ì•Šì•„ìš”. ì¡°ë¯¸ë£Œê°€ ë§ì´ ì²¨ê°€ë˜ì§€ ì•Šê³  ë‹¨ë°±ì§ˆ í•¨ëŸ‰ì´ ë†’ì€ ìŒì‹ì„ ë¨¹ê³  ì‹¶ì€ë°, ì œê°€ ê°€ì§„ ëˆì´ ë³„ë¡œ ì—†ì–´ìš”. ë¹„ì‹¸ì§€ ì•Šìœ¼ë©´ì„œ ê´œì°®ì€ ì‹ë‹¹ì„ ì•Œê³  ê³„ì‹ ê°€ìš”? Aì™€ Bì˜ ì°¨ì´ëŠ” ê³ ì‘ ë§ˆì§€ë§‰ ë¬¸ì¥ì´ë‹¤. ê·¸ëŸ¬ë‚˜ ë©˜í† ì˜ ì…ì¥ì—ì„œ Aì™€ BëŠ” í¬ê²Œ ë‹¤ë¥¸ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ê°€ì˜¨ë‹¤. AëŠ” ìŠ¤ìŠ¤ë¡œì˜ ìƒí™©ì€ êµ¬ì²´ì ì´ì§€ë§Œ, ë©˜í† ì—ê²Œ ë¬´ì—‡ì„ ê¸°ëŒ€í•˜ëŠ”ì§€ ì•Œê¸° ì–´ë µë‹¤. ëˆì´ ë³„ë¡œ ì—†ìœ¼ë‹ˆ ëˆì„ ë§ì´ ë²Œ ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì•Œë ¤ë‹¬ë¼ëŠ” ê²ƒì¸ì§€, ë¹„ì‹¸ì§€ ì•Šìœ¼ë©´ì„œ ê´œì°®ì€ ì‹ë‹¹ì„ ì•Œê³  ì‹¶ì€ ê²ƒì¸ì§€, ì €ë ´í•œ ì¬ë£Œë¡œ ë§Œë“¤ì–´ ë¨¹ì„ ìˆ˜ ìˆëŠ” ìŒì‹ì˜ ë ˆì‹œí”¼ë¥¼ ì•Œê³  ì‹¶ì€ ê²ƒì¸ì§€ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì•Œ ìˆ˜ ì—†ë‹¤. ë°˜ë©´ BëŠ” ë©˜í† ì—ê²Œ ì§ˆë¬¸í•œ ëª©ì ì´ ëšœë ·í•˜ë‹¤. ì¢‹ì€ ì§ˆë¬¸ì´ ì¤€ë¹„ê°€ ë˜ì—ˆë‹¤ë©´, ë°˜ë“œì‹œ ì ì ˆí•œ ë©˜í† ì—ê²Œ ë˜ì§€ì. ë‚˜ì˜ ë©˜í† ë§ ë¶„ì•¼ ì¤‘ì—ëŠ” â€œë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ë¡œ ì¼í•˜ëŠ” ê²ƒâ€ì´ ìˆë‹¤. ê·¸ëŸ°ë° ë•Œë¡œ ë©˜í‹°ë“¤ ì¤‘ì— ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ì™€ í”„ë¡œê·¸ë˜ë¨¸ë¥¼ í˜¼ë™í•´ì„œ í”„ë¡œê·¸ë˜ë¨¸ ê´€ë ¨ ì§ˆë¬¸ì„ ë˜ì§€ëŠ” ê²½ìš°ê°€ ìˆë‹¤. ì¢‹ì€ ì§ˆë¬¸ì„ì—ë„ ì£¼ì¸ì„ ì˜ëª» ë§Œë‚œ ê¸°ë¶„ì´ ë“¤ì–´ ë‚œì²˜í•´ì§„ë‹¤. ì•„ì˜ˆ ê´€ë ¨ì´ ì—†ì–´ì„œ ë‹µë³€ì„ ëª»í•˜ëŠ” ì •ë„ëŠ” ì•„ë‹ˆì§€ë§Œ, í”„ë¡œê·¸ë˜ë¨¸ë³´ë‹¤ëŠ” ë‹µë³€ì˜ ì§ˆì´ ë–¨ì–´ì§ˆ ìˆ˜ ë°–ì— ì—†ë‹¤. ê·¸ëŸ¬ë‹ˆ, ì¢‹ì€ ì§ˆë¬¸ì´ ì¤€ë¹„ë˜ì—ˆë‹¤ë©´ ê¼­ ì¢‹ì€ ëŒ€ë‹µì„ ê¸°ëŒ€í•  ìˆ˜ ìˆì„ ë©˜í† ì—ê²Œ ë˜ì§€ì. ê¼­ ì‡ë‹¤ê°€ ì•„ë‹ˆë”ë¼ë„ ì¡°ì–¸ì„ êµ¬í•˜ê³  ì‹¶ì€ ì„ ë°°ë‚˜ ë©˜í† ê°€ ìˆë‹¤ë©´, ì¢‹ì€ ì§ˆë¬¸ì„ ê³ ë¯¼í•˜ëŠ” ê³¼ì •ì—ì„œ í•˜ë‚˜ì˜ íŒíŠ¸ê°€ ë˜ê¸¸ ë°”ë€ë‹¤. [ì‡ë‹¤ì—ì„œ ë³´ê¸°]","link":"/2019/01/08/How-to-ask-good-question-to-my-mentor/"},{"title":"ì¢‹ì•„í•˜ëŠ” ì¼ì€ ì–´ë–»ê²Œ ì°¾ì„ ìˆ˜ ìˆì„ê¹Œ?","text":"ì‡ë‹¤ë¼ëŠ” ì˜¨ë¼ì¸ ë©˜í† ë§ í”Œë«í¼ì—ì„œ ë©˜í† ë¡œ í™œë™í•˜ë©´ì„œ ê°€ì¥ ë§ì´ ë°›ëŠ” ì§ˆë¬¸ì€ â€œì¢‹ì•„í•˜ëŠ” ì¼ì„ ì–´ë–»ê²Œ ì°¾ì„ ìˆ˜ ìˆë‚˜ìš”?â€ ì´ë‹¤. ì¢‹ì•„í•˜ëŠ” ì¼, ì–´ë–»ê²Œ ì°¾ì„ ìˆ˜ ìˆì„ê¹Œìš”? ì£¼ë³€ì—ì„œ ì¢‹ì•„í•˜ëŠ” ì¼ì„ í•˜ë¼ê³ ë“¤ ë§ì´ ë§í•˜ëŠ”ë° ë§‰ìƒ ì €ì— ëŒ€í•´ ìƒê°í•´ë³´ë©´ ì§„ì§œ ì œê°€ ë­˜ ì¢‹ì•„í•˜ëŠ”ì§€ ëª¨ë¥´ê² ìŠµë‹ˆë‹¤. ë­˜ ì¢‹ì•„í•˜ëŠ”ì§€ë¶€í„° ì•Œì•„ì•¼ ì•ìœ¼ë¡œ ë‚˜ì•„ê°ˆ ìˆ˜ ìˆì„ ê²ƒì´ë¼ê³  ìƒê°ì´ ë“œëŠ”ë° ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ ì°¾ì„ ìˆ˜ ìˆì„ì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤. ë‚˜ë¥¼ íƒìƒ‰í•˜ëŠ” ë°©ë²•ì´ë‚˜ ì¶”ì²œí•˜ê³  ì‹¶ì€ ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”. ì§„ë¡œëŠ” ì–´ë–»ê²Œ ì°¾ì•„ê°€ì…¨ë‚˜ìš”? ì‚¬ì‹¤ ì§€ê¸ˆ ì§ì¥ì€ ë‚˜ì´ë•Œë¬¸ì— ë¶€ë´ë¶€ë´ ë“¤ì–´ê°„ ê³³ì´ë¼ ë³´ëŒê° í˜¹ì€ ì„±ì·¨ê° ì—†ì´ ë‹¤ë‹ˆê³ ìˆìŠµë‹ˆë‹¤, ì œê°€ ì •ë§ ì„±ì¥í•˜ê³  í¥ë¯¸ë¥¼ ëŠë‚„ë§Œí•œ ë¶„ì•¼ë¥¼ ì°¾ê³ ì‹¶ì€ë° ì‚¬ì‹¤ ì§„ë¡œë¥¼ ì°¾ê³  ë°œì„ ë‚´ë”›ê¸°ê°€ ì—„ë‘ë„ì•ˆë‚˜ê³  ë§‰ë§‰í•˜ê¸°ë§Œ í•˜ë„¤ìš”, ë©˜í† ë‹˜ì€ ìì‹ ì˜ ì§„ë¡œë¥¼ ì–´ë–»ê²Œ ì°¾ì•„ê°€ì…¨ë‚˜ìš”? ì§€ê¸ˆ ì´ ì‹œì ì— ëŒì´ì¼œë³´ë‹ˆ ê·¸ì € ì†Œì†ëœ ê³³ì—ì„œ í˜ëŸ¬ê°€ëŠ”ëŒ€ë¡œ ì‚´ì•„ì™”ë˜ ê²ƒ ê°™ê³ , ì´ì œ ë¬´ì†Œì†ì´ ëœ ì§€ê¸ˆ ì´ ì‹œì ì— ì–´ë–¤ ì§ì—…ì„ ê°€ì ¸ì•¼ í• ì§€ ë‚´ê°€ ê³¼ì—° ì›í•˜ëŠ” ê²ƒì´ ë¬´ì—‡ì¼ì§€ ë„ˆë¬´ ë‹µë‹µí•´ì„œ (ì¤‘ëµ) í˜¹ì‹œë‚˜ ë©˜í† ë¡œì„œ ì¡°ì–¸í•´ì£¼ì‹¤ ê²ƒì´ ìˆë‹¤ë©´ ì–´ë–¤ í”¼ë“œë°±ì´ë¼ë„ ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤. ì¢‹ì•„í•˜ëŠ” ì¼ì€ ë§ê³  í•˜ê¸°ì—ëŠ” ë‘ë ¤ì›Œìš”. ê¸°ê³„ê³µí•™ê³¼ë¥¼ ì˜¤ê¸´ í–ˆì§€ë§Œ ì œê°€ ì •ë§ í•˜ê³ ì‹¶ì€ ì¼ì´ ê¸°ê³„ë¥¼ ë‹¤ë£¨ëŠ” ì¼ì¼ê¹Œë¼ëŠ” ê±±ì •ë„ ë§ì´ ë˜ê³ â€¦ ë©˜í† ë‹˜ì€ ì¢‹ì•„í•˜ëŠ” ì¼ì„ ì–´ë–»ê²Œ ì°¾ìœ¼ì…¨ëŠ”ì§€ ê¶ê¸ˆí•©ë‹ˆë‹¤! ë©˜í‹°ë“¤ì˜ ì§ˆë¬¸ì„ ë§ˆì£¼í•˜ê³  ê¸€ ì´ë©´ì— ìˆ¨ê²¨ì§„ ê°ìì˜ ì–´ë ¤ì›€ì„ ìƒìƒí•˜ë‹¤ë³´ë©´, ë‚˜ì˜ ëŒ€í•™ì‹œì ˆì˜ ëª¨ìŠµì´ ë§ì´ ë– ì˜¤ë¥¸ë‹¤. ë¬´ë¹„íŒì ìœ¼ë¡œ ì§€ì‹ê³¼ ì´ë¡ ì„ ìŠµë“í•˜ê¸°ì— ë°”ë¹´ë˜ ê³ ë“±í•™ìƒì´ ëŒ€í•™ìƒì´ ë˜ì–´ ìŠ¤ìŠ¤ë¡œì˜ ìƒê°ìœ¼ë¡œ ê±¸ì–´ë‚˜ê°€ê¸° ìœ„í•´ ë¬´ìˆ˜íˆ ë§ì´ ë„˜ì–´ì¡Œë˜ ì‹œì ˆì´. ë‚˜ì— ëŒ€í•´ ê¹Šê²Œ ê³ ë¯¼í•´ ë³¸ ì‹œê°„ì´ ì—†ì—ˆê¸° ë•Œë¬¸ì— ë‚´ê°€ ë¬´ì–¸ê°€ë¥¼ ì¢‹ì•„í•œë‹¤ëŠ” ê²ƒì´ ë¬´ì—‡ì¸ì§€ì¡°ì°¨ ì•Œ ìˆ˜ ì—†ì—ˆë˜ ì‹œì ˆì´. ë‚˜ì˜ ìƒê°ë³´ë‹¤ íƒ€ì¸ì˜ ìƒê°ì„ ë” ë†’ê²Œ í‰ê°€í–ˆê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ í•˜ëŠ” ì„ íƒê³¼ ë‚¨ë“¤ì´ ì¢‹ë‹¤ê³  ìƒê°í•˜ëŠ” ê²ƒì— ì´ë¦¬ì €ë¦¬ íœ˜ë‘˜ë¦¬ê¸°ë„ í–ˆë˜ ì‹œì ˆì´. ì´ë¯¸ ë³¸ì¸ì˜ ê¸¸ì„ ê±¸ì–´ê°€ê³  ìˆëŠ” ì¹œêµ¬ë“¤ì„ ë³´ë©° ë¶€ëŸ¬ì›€ê³¼ ë™ì‹œì— ë‚˜ì˜ ê¸¸ì´ ê³¼ì—° ì„¸ìƒì— ì¡´ì¬ëŠ” í•˜ëŠ” ê²ƒì¼ì§€ì— ëŒ€í•œ ë¶ˆì•ˆê°ì„ ëŠê¼ˆë˜ ê·¸ ì‹œì ˆì´. ì´ ëª¨ë“  í˜¼ë€ìŠ¤ëŸ¬ì›€ê³¼ ë¶ˆì•ˆì˜ ì‹œê°„ì„ ê±°ì³, ë‚˜ëŠ” ëë‚´ ë‚´ê°€ ê¸°êº¼ì´ ê±·ê¸°ë¡œ ì„ íƒí•œ ë‚˜ë§Œì˜ ê¸¸ì„ ì°¾ì„ ìˆ˜ ìˆì—ˆë‹¤. ë©˜í‹°ë“¤ì˜ ìƒí™©ì´ ëª¨ë‘ ë‚˜ì˜ ì˜ˆì „ê³¼ ê°™ë‹¤ê³ ëŠ” í•  ìˆ˜ ì—†ì§€ë§Œ ë‚´ê°€ ë¹„ìŠ·í•œ ì‹œê¸°ì— ìŠ¤ìŠ¤ë¡œì—ê²Œ ì§ˆë¬¸ì„ ë˜ì§€ê³  ì´ì— ë‹µí–ˆë˜ ë‚´ìš©ë“¤ì´ ì¡°ê¸ˆì´ë¼ë„ ë©˜í‹°ë“¤ì—ê²Œ íŒíŠ¸ê°€ ë˜ê¸¸ ë°”ë¼ë©° ì´ ê¸€ì„ ì“°ê²Œ ë˜ì—ˆë‹¤. ìš°ë¦¬ëŠ” ì™œ ì¢‹ì•„í•˜ëŠ” ì¼ì„ ì°¾ìœ¼ë ¤ê³  í• ê¹Œ? ì¸ìƒì—ì„œ ëŒ€ë¶€ë¶„ì˜ ì‹œê°„ì„ ì¼ì„ í•˜ë©° ë³´ë‚´ê¸°ì— ê·¸ ì‹œê°„ì„ í–‰ë³µí•˜ê²Œ ì“°ê³ ì í•˜ê¸° ìœ„í•¨ì´ë‹¤. ê·¸ë˜ì„œ ë‚˜ì—ê²Œ â€œì¢‹ì•„í•˜ëŠ” ì¼ì„ ì–´ë–»ê²Œ ì°¾ì„ ìˆ˜ ìˆë‚˜ìš”?â€ë¼ëŠ” ì§ˆë¬¸ì€ â€œë‚´ê²Œ í–‰ë³µì„ ì£¼ëŠ” ì¼ì€ ì–´ë–»ê²Œ ì°¾ì„ ìˆ˜ ìˆë‚˜ìš”?â€ì™€ ê°™ë‹¤. ì´ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ í•˜ê¸° ìœ„í•´ ë‚˜ëŠ” ìŠ¤ìŠ¤ë¡œì—ê²Œ ë‹¤ìŒì˜ ì„¸ ì§ˆë¬¸ì„ ë˜ì¡Œë‹¤. ë‚´ê°€ í–‰ë³µí–ˆë˜ ê²½í—˜ë“¤ì€ ë¬´ì—‡ì´ê³  ê·¸ ê²½í—˜ë“¤ì˜ ì–´ë–¤ íŠ¹ì§•ì´ ë‚˜ë¥¼ í–‰ë³µí•˜ê²Œ ë§Œë“¤ì—ˆì„ê¹Œ? ë‚´ í–‰ë³µì˜ ìš”ì¸ì„ ì§€ì†ì ìœ¼ë¡œ ì œê³µí•  ìˆ˜ ìˆëŠ” ì¼ì€ ë¬´ì—‡ì¼ê¹Œ? ê·¸ ì¼ì„ ì„ íƒí•˜ê²Œ ë¨ìœ¼ë¡œì¨ ë‚´ê°€ ë¶€ë”ªí ìˆ˜ë§ì€ ì–´ë ¤ì›€ì„ ë‚˜ëŠ” ê°ë‹¹í•  ìì‹ ì´ ìˆì„ê¹Œ? ë‚´ê°€ í–‰ë³µí–ˆë˜ ê²½í—˜ë“¤ì€ ë¬´ì—‡ì´ê³  ê·¸ ê²½í—˜ë“¤ì˜ ì–´ë–¤ íŠ¹ì§•ì´ ë‚˜ë¥¼ í–‰ë³µí•˜ê²Œ ë§Œë“¤ì—ˆì„ê¹Œ? ì´ ì§ˆë¬¸ì— ë‹µí•˜ê¸° ì „ì— &quot;í–‰ë³µ&quot;ì´ë¼ëŠ” ê²ƒì— ëŒ€í•´ í•œ ë²ˆ ì§šê³  ë„˜ì–´ê°ˆ í•„ìš”ê°€ ìˆë‹¤. ìš°ë¦¬ê°€ í–‰ë³µì´ë¼ëŠ” ë§ì„ í†µí•´ ì˜ë¯¸í•˜ëŠ” ê²ƒì€ ëŒ€ê°œ ì ì‹œì˜ ì¾Œê°ì— ê°€ê¹ë‹¤. í–‰ë³µì´ë€, ì˜¨ì²œë¬¼ì— ë“¤ì–´ê°„ í›„ 10ì´ˆ ê°™ì€ ê²ƒ. ê·¸ëŸ¬í•œ ëŠë‚Œì€ ì˜¤ë˜ ì§€ì†ë  ìˆ˜ ì—†ë‹¤. ì˜¤ë˜ ì§€ì†ë  ìˆ˜ ì—†ëŠ” ê²ƒì„ ë°”ë¼ë‹¤ë³´ë©´, ê·¸ ë§ì—†ìŒìœ¼ë¡œ ë§ë¯¸ì•”ì•„ ì‚¬ëŒì€ ì‰½ê²Œ ë¶ˆí–‰í•´ì§„ë‹¤. ê¹€ì˜ë¯¼í•œêµ­ì¼ë³´ ì¹¼ëŸ¼ ìƒˆí•´ì— í–‰ë³µí•´ì§€ê² ë‹¤ëŠ” ê³„íšì€ ì—†ë‹¤ ì§§ì€ ìˆœê°„ì— ë¨¸ë¬´ë¥´ëŠ” ë§ì´ˆì ì´ê³  ìê·¹ì ì¸ ì¾Œë½ì„ í–‰ë³µì´ë¼ê³  ì •ì˜í•´ì„  ì•ˆëœë‹¤. ë˜í•œ í–‰ë³µì˜ ì›ì¸ì´ íƒ€ì¸ì´ë‚˜ ì£¼ìœ„ì˜ í™˜ê²½(ì£¼ë³€ì˜ ê¸°ëŒ€, ë™ê²½, ì¸ì • ë“±)ì— ì˜ì¡´ì ì´ë¼ë©´, ë‹¤ì‹œ ìƒê°í•´ë³´ì•„ì•¼ í•œë‹¤. ê·¸ë˜ì„œ ë‚˜ëŠ” í–‰ë³µí–ˆë˜ ê²½í—˜ì„ ì°¾ê¸° ìœ„í•´ ìˆœê°„ì˜ ê°ì •ì— ì§‘ì¤‘í•˜ê¸°ë³´ë‹¤ ì˜¤ëœ ê¸°ê°„ ì§€ì†í•´ì˜¨, í˜¹ì€, í•´ì™”ë˜ í™œë™ë“¤ì— ì§‘ì¤‘í–ˆë‹¤. ì‚¬ëŒì€ ì €ë§ˆë‹¤ ê°ìì˜ í–‰ë³µì„ ìœ„í•´ ì‚°ë‹¤[1]. ê·¸ë¦¬ê³  ì‚¶ì€ ìœ í•œí•˜ë‹¤. ì£¼ì–´ì§„ ì‹œê°„ì„, ì‚¬ëŒë“¤ì€ ì €ë§ˆë‹¤ì˜ í–‰ë³µì„ ìµœëŒ€í™”í•  ìˆ˜ ìˆëŠ” ì„ íƒë“¤ìœ¼ë¡œ ì±„ì›Œë‚˜ê°„ë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— ìˆ˜ë§ì€ ì„ íƒì§€ë“¤ ì¤‘ì—ì„œ í•˜í•„ ì™œ &quot;ê·¸ ì„ íƒ&quot;ì„ ë‚´ë ¸ëŠ”ê°€ì— ë‹µì´ ë“¤ì–´ìˆì„ ê²ƒì´ë¼ ë¯¿ì—ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ë³´ì. ë‚˜ëŠ” ì‡ë‹¤ì—ì„œ ë©˜í† ë¡œ í™œë™í•˜ê³  ìˆë‹¤. ì‡ë‹¤ì˜ ë©˜í† ëŠ” ì•„ë¬´ëŸ° ê¸ˆì „ì  ë³´ìƒì„ ë°›ì§€ ì•ŠëŠ”ë‹¤. ê·¸ëŸ¼ì—ë„ ë©˜í† ë§ì„ í•˜ëŠ” ì´ìœ ëŠ” ë‚´ ë„ì›€ì„ í•„ìš”ë¡œ í•˜ëŠ” ë©˜í‹°ë“¤ì´ ë‚´ ë‹µë³€ì„ í†µí•´ ë„ì›€ì„ ì–»ì—ˆì„ ë•Œ ë¿Œë“¯í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ ìˆœê°„ì´ ë‚´ê²ŒëŠ” ë³´ìƒì´ë‹¤. ì´ëŸ° ë‚˜ì˜ ì„ íƒì„ í†µí•´ ë‚˜ë¼ëŠ” ì‚¬ëŒì—ê²Œ ëˆì´ë¼ëŠ” ê°€ì¹˜ëŠ” í¬ê²Œ ì¤‘ìš”í•˜ì§€ ì•Šë‹¤ëŠ” ì‚¬ì‹¤ì„ ìœ ì¶”í•  ìˆ˜ ìˆë‹¤. ì˜¤íˆë ¤ ë‚´ê²Œ ì¤‘ìš”í•œ ê²ƒì€ íƒ€ì¸ì—ê²Œ ë¯¸ì¹˜ëŠ” ê¸ì •ì ì¸ ì˜í–¥ë ¥ì´ë‹¤. ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ë‚˜ë¡œ ì¸í•´ ì¢€ ë” ë‚˜ì€ ì‚¶ì„ ì˜ìœ„í•˜ê²Œ ë˜ì—ˆì„ ë•Œ í–‰ë³µí•´ì§„ë‹¤. ë‚´ í–‰ë³µì˜ ìš”ì¸ì„ ì§€ì†ì ìœ¼ë¡œ ì œê³µí•  ìˆ˜ ìˆëŠ” ì¼ì€ ë¬´ì—‡ì¼ê¹Œ? ë‚´ í–‰ë³µí•œ ê²½í—˜ì˜ íŠ¹ì§•ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ìƒê°í•´ë³´ì. ì¢€ ë” ë‚˜ì€ ì‚¶ì´ë€ ë¬´ì—‡ì¸ê°€? ëª¸ì´ ì•„í”ˆ ì‚¬ëŒì´ ê±´ê°•í•´ì§€ëŠ” ê²ƒ? ëª¨ë“  ì‚¬ëŒì—ê²Œ ë™ì¼í•œ ê¸°íšŒê°€ ì œê³µë˜ëŠ” ê²ƒ? ë‚˜ì˜ ë‹µì€ ì„œë¹„ìŠ¤ë¥¼ í†µí•´ ë” í¸ë¦¬í•´ì§€ê³  ìœ ìµí•´ì§€ëŠ” ì‚¶. ê·¸ë¦¬ê³  íšì¼í™”ëœ ì‚¬ê³ ë°©ì‹ì„ ê°•ìš”í•˜ëŠ” êµìœ¡ì´ ì•„ë‹Œ, ë‹¤ì–‘í•œ ê°€ì¹˜ë¥¼ ì¡´ì¤‘í•˜ê³  ë‚˜ë§Œì˜ ê³ ìœ í•¨ì„ ì¸ì •ë°›ëŠ” êµìœ¡ì„ ì œê³µë°›ëŠ” ì‚¶ì´ì—ˆë‹¤. ì‚¬ëŒë“¤ì˜ ì‚¶ì´ ë” í¸ë¦¬í•´ì§€ê³  ìœ ìµí•´ì§ˆ ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ë¥¼ ì§ì ‘ ë§Œë“¤ê±°ë‚˜, ì´ë¯¸ ë§Œë“¤ê³  ìˆëŠ” ê¸°ì—…ì— ì°¸ì—¬í•˜ëŠ” ê³¼ì •ì¼ ê²ƒì´ë‹¤. ê·¸ëŸ° ì„œë¹„ìŠ¤ëŠ” ë¬´ì—‡ì¼ê¹Œ? ë‚˜ì˜ ë‹µì€ ì‚¬ëŒë“¤ì´ ì›í•˜ëŠ” ê²ƒì„ ì½ì–´ë‚´ ê·¸ ë¶€ë¶„ì„ ì±„ì›Œì£¼ëŠ” ì„œë¹„ìŠ¤ì˜€ë‹¤. ê·¸ë¦¬ê³  ê·¸ ë°©ë²•ìœ¼ë¡œ ë– ì˜¬ë¦° ê²ƒì´ â€œë°ì´í„° ë¶„ì„â€ì´ì—ˆë‹¤. ê³ ë“±í•™êµ ë•Œë¶€í„° ë°ì´í„°ì—ëŠ” í˜ì´ ìˆë‹¤ê³  ë¯¿ì—ˆë‹¤. ì”ë°˜ëŸ‰ì´ ë¬¸ì œì˜€ë˜ ê³ ë“±í•™êµ ì‹œì ˆ, ìŒì‹ì˜ ë§›ê³¼ ì”ë±ëŸ‰ì˜ ìƒê´€ê´€ê³„ë¥¼ ë°ì´í„°ë¡œ íŒŒì•…í•  ìˆ˜ ìˆë‹¤ë©´ ê¸ˆë°© ì”ë°˜ëŸ‰ì„ ìµœì†Œí™”í•˜ëŠ” ë°©ë²•ì„ ë§ˆë ¨í•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ê³  ìƒê°í–ˆë‹¤. ë§›ì—†ëŠ” ìŒì‹ì€ ê¸‰ì‹ì˜ í’ˆì§ˆì— ë‹¬ë ¤ìˆê³ , í’ˆì§ˆì€ ê¸‰ì‹ë¹„ì™€ í° ê´€ë ¨ì´ ìˆê¸° ë•Œë¬¸ì— ì ì ˆí•˜ê²Œ ê¸‰ì‹ë¹„ë¥¼ ì˜¬ë¦¬ë©´ í•´ê²°ë  ìˆ˜ ìˆëŠ” ë¬¸ì œì˜€ë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ, ì‚¬ëŒë“¤ì´ ì‚¬ìš©í•˜ëŠ” ì„œë¹„ìŠ¤ì—ëŠ” ì–´ì©” ìˆ˜ ì—†ì´ ì‚¬ëŒë“¤ì´ ë‚¨ê¸´ í”ì ë“¤ì´ ìˆì„ ê²ƒì´ë‹¤. ê·¸ í”ì ì„ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìë“¤ì´ ì›í•˜ëŠ” ë°”ë¥¼ ì½ì–´ë‚´ê³ , ìƒˆë¡œì´ ì„œë¹„ìŠ¤ì— ë°˜ì˜í•˜ë©´ ì‚¬ëŒë“¤ì˜ ì‚¶ì´ ë” í¸ë¦¬í•´ì§ˆ ê²ƒì´ë¼ê³  ë¯¿ì—ˆë‹¤. ì´ ì¼ì„ í•˜ëŠ” ì‚¬ëŒë“¤ì€ ë°ì´í„° ë¶„ì„ê°€, ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë¶ˆë¦¬ê³  ìˆì—ˆê³ , í˜„ì‹¤ì ìœ¼ë¡œë„ ë‚´ê°€ ë„ì „í•´ë³¼ ìˆ˜ ìˆëŠ” ì˜ì—­ ì•ˆì— ìë¦¬í–ˆë‹¤. ê³ ìœ í•¨ì„ ì¸ì •ë°›ëŠ” êµìœ¡ì„ ì‹¤í˜„í•˜ëŠ” ê³¼ì •ì„ êµ¬ì²´í™”í•˜ëŠ” ê²ƒì€ ì–´ë ¤ì› ë‹¤. í˜„ì¬ì˜ êµìœ¡ ì‹œìŠ¤í…œì„ ë°”ê¾¸ì–´ì•¼ ê°€ëŠ¥í•œë°, êµìœ¡ì— ê´€ë ¨ëœ ë§ì€ ì‚¬ëŒë“¤-í•™ë¶€ëª¨, í•™ìƒ, í•™ì› ê°•ì‚¬, í•™ì› ì›ì¥, êµìœ¡ë¶€, í•™êµ, êµì‚¬ ë“±-ì˜ ê³µê°ì„ ì–»ì–´ì•¼ë§Œ ê°€ëŠ¥í•œ ì¼ì´ê¸° ë•Œë¬¸ì— ì‰½ê²Œ ê·¸ë ¤ì§€ì§€ ì•Šì•˜ë‹¤. êµìœ¡ì— ê´€ë ¨ëœ ì¼ì„ í•˜ê³  ìˆëŠ” ì§ì—…ë„ ë‚´ê°€ í•˜ê³ ì‹¶ì€ ì¼ì´ë¼ê³  ëŠê»´ì§€ì§€ ì•Šì•˜ë‹¤. êµì‚¬ì™€ í•™ì› ê°•ì‚¬ëŠ” ì´ë¯¸ í˜„ì¬ êµìœ¡ ì‹œìŠ¤í…œ ì•ˆì—ì„œ í™œë™í•˜ëŠ” ì‚¬ëŒì´ê¸° ë•Œë¬¸ì— í˜ì‹ ê³¼ëŠ” ê±°ë¦¬ê°€ ë©€ì—ˆë‹¤ê³  ìƒê°í–ˆê¸° ë•Œë¬¸ì´ì—ˆê³ , êµìœ¡ë¶€ì¥ê´€ì€ êµìœ¡ì— ê´€ë ¨ëœ ìˆ˜ë§ì€ ì´í•´ê´€ê³„ìë“¤ ì†ì—ì„œ ë§ˆë•…í•œ í•´ê²°ì±…ì„ ì œì•ˆí•  ìˆ˜ ì—†ì„ ë¿ë”ëŸ¬ top-down ë°©ì‹ìœ¼ë¡œëŠ” ì ˆëŒ€ êµìœ¡ì˜ í˜ì‹ ì´ ì´ë£¨ì–´ì§€ì§€ ëª»í•  ê²ƒì´ë¼ê³  ìƒê°í•˜ì˜€ê¸°ì— ì œì™¸í•˜ì˜€ë‹¤. ì˜¤íˆë ¤ ë‚´ê°€ ì§ì ‘ í•™êµë¥¼ ì„¸ì›Œ ê·¸ ì•ˆì—ì„œ ììœ ë¡­ê²Œ ë‚´ê°€ ìƒê°í•˜ëŠ” êµìœ¡ì„ ì‹¤í˜„í•˜ëŠ” ë°©ì‹ì„ ê¿ˆê¾¸ì—ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‹¹ì‹œ ë‚´ê°€ ì²˜í•œ í˜„ì‹¤-í™”í•™ìƒë¬¼ê³µí•™ ì „ê³µì˜ 3í•™ë…„ ëŒ€í•™ìƒ-ì—ì„œëŠ” ê¸¸ì´ ë³´ì´ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ë§ˆìŒ ì†ì—ë§Œ ê°„ì§í•´ë‘” ì±„ë¡œ ì–¸ì  ê°€ ë‹¤ê°€ì˜¬ ê¸°íšŒë§Œì„ ê¸°ë‹¤ë¦¬ê¸°ë¡œ í–ˆë‹¤. ê·¸ ì¼ì„ í•˜ê¸°ë¡œ ê²°ì •í•˜ê²Œ ë¨ìœ¼ë¡œì¨ ì•ìœ¼ë¡œ ë¶€ë”ªí ìˆ˜ë§ì€ ì–´ë ¤ì›€ì„ ë‚˜ëŠ” ê°ë‹¹í•  ìì‹ ì´ ìˆì„ê¹Œ? ì—¬ê¸°ê¹Œì§€ êµ¬ì²´í™”ë˜ì—ˆë‹¤ë©´, ë‚¨ì€ ê²ƒì€ ëª©í‘œë¥¼ í–¥í•´ ì›€ì§ì´ëŠ” ê²ƒ ë¿ì´ì—ˆë‹¤. ë¨¼ì €, ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ëŠ” ì–´ë–»ê²Œ í•´ì•¼ ë  ìˆ˜ ìˆëŠ”ì§€ë¥¼ ì•Œì•„ë³´ì•„ì•¼ í–ˆë‹¤. ê·¸ ë‹¹ì‹œë§Œí•´ë„ ì§€ê¸ˆì²˜ëŸ¼ ì´ ì§ì—…ì´ í•«í•˜ì§€ëŠ” ì•Šì•˜ë‹¤. ê·¸ë˜ì„œ ì–´ë–¤ íšŒì‚¬ì— ë“¤ì–´ê°€ì•¼ ë°ì´í„° ë¶„ì„ê°€ë¡œ ì¼í•  ìˆ˜ ìˆëŠ”ì§€, ì–´ë–»ê²Œ í•´ì•¼ ë°ì´í„° ë¶„ì„ê°€ê°€ ë  ìˆ˜ ìˆëŠ”ì§€ ìì„¸íˆ ì•Œê¸° ì–´ë ¤ì› ë‹¤. ë”ìš±ì´ ë‚˜ì˜ ì „ê³µì€ ì´ ë¶„ì•¼ì™€ ê´€ë ¨ì´ ì—†ì–´ì„œ ì£¼ë³€ì— ë°ì´í„° ë¶„ì„ê°€ë¡œ ì¼í•˜ê³  ìˆëŠ” ì„ ë°°ë¥¼ ì†Œê°œë°›ê¸°ë„ ì–´ë ¤ì› ë‹¤. ë˜í•œ, ë°ì´í„° ë¶„ì„ê³¼ ê´€ë ¨ëœ ê³µë¶€ë¥¼ ì‹œì‘í•´ì•¼í–ˆë‹¤. ë‚´ê°€ ì›í•˜ëŠ” ë°”ì™€ ê°€ì¥ ê°€ê¹Œì› ë˜ ì—°êµ¬ì‹¤-ì‚°ì—…ê³µí•™ ë°ì´í„°ë§ˆì´ë‹ ì—°êµ¬ì‹¤-ì„ ì°¾ì•˜ê³ , ê·¸ ì—°êµ¬ì‹¤ì— ì…í•™í•˜ê³  ì‹¶ê¸°ë„ í–ˆê³ , êµìˆ˜ë‹˜ì˜ ìˆ˜ì—…ì„ ë“£ê³  ì‹¶ì—ˆë‹¤. ê·¸ë ‡ê²Œ ì‚°ì—…ê³µí•™ ë¶€ì „ê³µì„ ì‹œì‘í•˜ê²Œ ë˜ì—ˆë‹¤. ë‚´ ì£¼ë³€ì—ì„œëŠ” ì•„ë¬´ë„ ì„ íƒí•˜ì§€ ì•Šì•˜ë˜ ê¸¸ì´ë¼ ë§ì´ ë‘ë ¤ì› ë‹¤. ë‹¤ë¥¸ ì‚¬ëŒë“¤ì— ë¹„í•´ ì¶œë°œì´ ëŠ¦ì—ˆë‹¤ê³  ìƒê°í–ˆê¸° ë•Œë¬¸ì— ë¶ˆì•ˆí•˜ê¸°ë„ í–ˆë‹¤. ê·¸ë ‡ì§€ë§Œ, ì§€ê¸ˆì´ë¼ë„ ëŠ¦ì§€ ì•Šì•˜ë‹¤ê³  ë‚˜ë¥¼ ë‹¤ë…ì˜€ë‹¤. í•˜ê³  ì‹¶ì€ ê²ƒì„ í–¥í•´ ë‚˜ì•„ê°€ëŠ” ê³¼ì •ì—ì„œ ë” ë§ì€ ì–´ë ¤ì›€ì´ ìˆì„ ê²ƒì„ ì§ê°í–ˆë‹¤. í˜„ì‹¤ì ì¸ ì œì•½ìœ¼ë¡œ ìˆ˜ë§ì€ ì¢‹ì€ ë°©ë²•ì„ í¬ê¸°í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì—, ì „í˜€ ë‹¤ë¥¸ ë¶„ì•¼ì—¬ì„œ ë‚´ê°€ ë°°ì›Œì•¼í•  ê²ƒì´ ì •ë§ ë§ê¸° ë•Œë¬¸ì—, ë‹¤ë¥¸ ì‚¬ëŒë“¤ì— ë¹„í•´ ë’¤ì³ì ¸ ìˆê¸° ë•Œë¬¸ì—, ê·¸ëŸ° ì™€ì¤‘ì—ë„ ê°™ì€ ëª©í‘œë¥¼ í–¥í•´ê°€ëŠ” ìˆ˜ë§ì€ ì‚¬ëŒë“¤ ì†ì—ì„œ ë‚˜ë§Œì˜ ê³ ìœ í•¨ì„ ê³„ì† ê°ˆê³  ë‹¦ì•„ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì •ë§ ë§ì´ ë„˜ì–´ì§€ê³ , ê¹¨ì§€ê³ , ì¢Œì ˆí•˜ëŠ” ê²½í—˜ì´ ë§ì„ ê²ƒì´ì—ˆë‹¤. ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³ , ë‚˜ëŠ” ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ê°€ ë˜ê³  ì‹¶ì—ˆë‹¤. ê·¸ë˜ì„œ ë‚´ ì„ íƒì— ì´ì–´ì§ˆ ëª¨ë“  ìˆœê°„ë“¤ì„ ë°›ì•„ë“¤ì´ê¸°ë¡œ ê²°ì‹¬í–ˆë‹¤. ì—¬ê¸°ê¹Œì§€ ìƒê°ì´ ì •ë¦¬ë˜ì, ë‚´ê²Œ ë¬´ì–¸ê°€ë¥¼ í•  ìš©ê¸°ê°€ ìƒê²¼ë‹¤. ìŠ¤ìŠ¤ë¡œì—ê²Œ ëŠì„ì—†ì´ ë¬¼ì—ˆë˜ ì‹œê°„ë“¤ë§Œí¼ ë‚˜ì˜ ê²°ì •ì— ë¬´ê²Œê°ì´ ì‹¤ë ¸ë‹¤. ì‹¤ì œë¡œ ê·¸ ì´í›„ì˜ ë§ì€ ì‹œê°„ë“¤ì€ í˜ê²¨ì› ì§€ë§Œ í¬ê¸°í•˜ì§„ ì•Šì•˜ë‹¤. ê·¸ ë•Œ ë²„í…¨ëƒˆë˜ ê²½í—˜ ë•ë¶„ì— ì§€ê¸ˆì˜ ë‚˜ëŠ” í–‰ë³µí•  ìˆ˜ ìˆì—ˆê³ , ê·¸ ê²½í—˜ìœ¼ë¡œ ë‹¹ì‹œì˜ ë‚˜ì™€ ê°™ì€ ê³ ë¯¼ì„ í•˜ê³  ìˆì„ ë©˜í‹°ë“¤ì—ê²Œ ë„ì›€ì„ ì¤„ ìˆ˜ ìˆì—ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ, ì—¬ê¸°ê¹Œì§€ ê¸€ì„ ì½ì—ˆì„, ìŠ¤ìŠ¤ë¡œì— ëŒ€í•œ ê³ ë¯¼ì´ ë§ì„ ì‚¬ëŒë“¤ì—ê²Œ ì „í•´ì£¼ê³  ì‹¶ì€ ë¬¸ì¥ì„ ì¸ìš©í•˜ë©° ë§ˆë¬´ë¦¬ ì§€ìœ¼ë ¤ê³  í•œë‹¤. ì‹¤ë§ì´ë¼ëŠ” í–¥ìœ . ì‹¤ë§ì€ ë¶ˆí–‰ì´ë¼ê³  ê°„ì£¼ë˜ì§€ë§Œ, ì´ëŠ” ë¶„ë³„ì—†ëŠ” ì„ ì…ê²¬ì¼ ë¿ì´ë‹¤. ì‹¤ë§ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ìš°ë¦¬ê°€ ë¬´ì—‡ì„ ê¸°ëŒ€í•˜ê³  ì›í–ˆëŠ”ì§€ ì–´ë–»ê²Œ ë°œê²¬í•  ìˆ˜ ìˆìœ¼ë´? ë˜í•œ ì´ëŸ° ë°œê²¬ ì—†ì´ ìê¸° ì¸ì‹ì˜ ê·¼ë³¸ì„ ì–´ë–»ê²Œ ì•Œ ìˆ˜ ìˆìœ¼ë´? ê·¸ëŸ¬ë‹ˆ ì‹¤ë§ì´ ì—†ì´ ìê¸° ìì‹ ì— ëŒ€í•œ ëª…í™•í•¨ì„ ì–´ë–»ê²Œ ì–»ì„ ìˆ˜ ìˆìœ¼ë´? ë¦¬ìŠ¤ë³¸í–‰ ì•¼ê°„ì—´ì°¨ [ì‡ë‹¤ì—ì„œ ë³´ê¸°] 1.ë¬¸ìœ ì„, ê°œì¸ì£¼ì˜ì ì„ ì–¸ â†©","link":"/2018/11/24/How-to-find-my-job/"},{"title":"ìœ ì¾Œí•œ ìŠ¬ëŸ¼í”„","text":"ì–´ë ¸ì„ ë•Œì˜ ë‚˜ëŠ” ë¬´ì–¸ê°€ ìƒˆë¡­ê²Œ â€˜ì‹œì‘â€™í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í–ˆë‹¤. ë¬´ì–¸ê°€ë¥¼ ë¹¨ë¦¬ ë°°ìš°ëŠ” í¸ì´ì—ˆê³ , ìƒˆë¡­ê²Œ ì–´ë–¤ í™˜ê²½ì´ë‚˜ ê°œë…ì— ì ì‘í•˜ëŠ”ë°ì— ë“œëŠ” ì‹œê°„ì´ ì ê²Œ ë“¤ì—ˆê¸° ë•Œë¬¸ì— â€˜ì‹œì‘â€™ì„ ì¦ê¸¸ ìˆ˜ ìˆì—ˆê¸° ë•Œë¬¸ì´ì—ˆë˜ ê²ƒ ê°™ë‹¤. â€˜ì‹œì‘â€™ì´ ì£¼ëŠ” ê·¸ ëª°ì…ê°ê³¼ ì„±ì·¨ê°ì€ ê¶Œíƒœë¡œì›€ì—ì„œ ë‚˜ë¥¼ êº¼ë‚´ì£¼ëŠ” ì¢‹ì€ ì²˜ë°©ì „ì´ì—ˆë‹¤. í•˜ì§€ë§Œ ë™ì‹œì—, ë‚´ê°€ â€˜ì‹œì‘â€™í–ˆë˜ ë§ì€ ìì˜í•œ ì¼ë“¤ì€ ì†Œìœ„ë§í•´ â€˜ê¿€ë§Œ ë¹¨ê³ â€™ ê·¸ë§Œ ë‘˜ ìˆ˜ ì—†ì—ˆë‹¤. ì²˜ìŒì´ ì£¼ëŠ” ì‹ ì„ í•¨ì— ì–´ëŠ ì •ë„ ìµìˆ™í•´ì§€ê³ ë‚˜ë©´ ì´ ë¶„ì•¼ì˜ â€˜íƒì›”í•¨â€™ì´ ë³´ì´ê¸° ì‹œì‘í•˜ê³ , ë‚˜ëŠ” í•œì°¸ ë°‘ì— ìë¦¬í•˜ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì¸ì§€í•˜ê²Œ ëœë‹¤. ê·¸ë¦¬ê³ , ê·¸ë•Œì¯¤ í•­ìƒ ê·¸ë§Œë‘ê³  ì‹¶ì–´ì¡Œë‹¤. ì´ ì‹œê¸°ë¥¼ ê²¬ë””ì§€ ëª»í•˜ëŠ” ì´ìœ ëŠ”, ì•„ë§ˆ ê¸°ì¤€ì´ ë‚®ì•˜ê¸° ë•Œë¬¸ì´ì—ˆì„ ê²ƒì´ë‹¤. ë‚´ê°€ ì„±ì·¨í•˜ê³ ì í•˜ëŠ” ê²ƒì€ êµ‰ì¥íˆ ë‚®ì€ ìˆ˜ì¤€ì˜ ê²ƒì´ì—ˆê³  ê·¸ ìˆ˜ì¤€ì„ ë¹ ë¥´ê²Œ ë‹¬ì„±í•˜ê³  ë‚˜ë©´ ë” ì´ìƒì˜ ì—´ì •ì´ ìƒê¸°ì§€ ì•Šì•˜ë‹¤. ì˜¤íˆë ¤ â€˜ì™œ í•´ì•¼í•˜ì§€?â€™ ë¼ëŠ” ìƒê°ì´ ë‚˜ë¥¼ í•©ë¦¬í™”ì‹œí‚¤ë©´ì„œ ê¸ˆë°© í¬ê¸°í•˜ê²Œ ë§Œë“¤ì—ˆë‹¤. ê·¸ë˜ì„œ ì°¸ ë§ì€, ì¡ë‹¤í•œ ë¬´ì–¸ê°€ë¥¼ í•˜ì§€ë§Œ ì–´ëŠ ê²ƒ í•˜ë‚˜ ì œëŒ€ë¡œ ë§ˆì¹˜ì§€ ëª»í•˜ëŠ” ë‚˜ë¥¼ ë°œê²¬í•˜ê³¤, â€˜ì˜â€™í•˜ëŠ” ê²ƒì— ì¢€ ë” ì§‘ì¤‘í•´ë³´ê¸°ë¡œ í–ˆë‹¤. ê·¸ ì´í›„ë¡œ ì‹œì‘ì— ëŒ€í•œ ë‘ë ¤ì›€ì´ ì»¤ì¡Œë‹¤. ì‹œê°„ê³¼ ì‹¤ë ¥ì˜ ê´€ê³„ë¥¼ ê·¸ë˜í”„ í˜•íƒœë¡œ ë‚˜íƒ€ë‚´ë©´, â€˜ê³„ë‹¨â€™í˜•ì´ë¼ê³  í•  ìˆ˜ ìˆê² ë‹¤. ê¸°ë‚˜ê¸´ ìŠ¬ëŸ¼í”„ ëì— ì˜¤ëŠ” ì–´ëŠ ìˆœê°„ì˜ ê¹¨ë‹¬ìŒìœ¼ë¡œ, ì‹¤ë ¥ì´ ê°‘ìê¸° ë°˜ë“±í•œë‹¤. ë‚´ê²Œ ë‘ë ¤ìš´ ê¸°ê°„ì€ ë°”ë¡œ ì´ â€˜ìŠ¬ëŸ¼í”„â€™ì˜ ì‹œê¸°ë‹¤. ì´ ë˜í•œ ì§€ë‚˜ê°€ë¦¬ë¼ëŠ” ê²ƒì„ ì•Œë©´ì„œë„, ê·¸ ìˆœê°„ë“¤ì€ ì–¸ì œë‚˜ ê³ í†µìŠ¤ëŸ½ë‹¤. ë§ˆì¹˜ ê·¼ë ¥ìš´ë™ì„ í•  ë•Œ ì •ë§ í˜ë“¤ì§€ë§Œ, ì´ ìˆœê°„ì„ ê²¬ëŒë‚´ì•¼ ê·¼ìœ¡ì´ ë¶™ëŠ”ë‹¤ëŠ” ì‚¬ì‹¤ì„ ì¸ì§€í•˜ëŠ” ëŠë‚Œì´ë‹¤. ê·¸ ë•Œì— ë‚˜ëŠ” ê³ ë¯¼í•œë‹¤. ìƒˆë¡œìš´ ì‹œì‘ì„ í•  ë•Œì¸ê°€ ì•„ë‹ˆë©´, ë²„í…¨ë‚´ì•¼í•  ë•Œì¸ê°€ë¥¼. ì˜í•˜ê³  ì‹¶ê¸°ì— ë²„í…¨ë‚´ì•¼ í•œë‹¤ëŠ” ë‹µì„ ë‚´ë¦¬ì§€ë§Œ, ì´ê²Œ ë¬´ìŠ¨ ì˜ë¯¸ê°€ ìˆì§€? ë¼ê³  ë¬¼ì—ˆì„ ë•, ì‰½ê²Œ ë‹µí•˜ê¸°ê°€ ì–´ë ¤ìš¸ ë•Œê°€ ë§ë‹¤. ì™œ ë²„í…¨ë‚´ì•¼ í•˜ëŠ”ì§€, ìŠ¤ìŠ¤ë¡œë¥¼ ê²©ë ¤í•˜ì§€ ì•Šìœ¼ë©´ ìê¾¸ë§Œ ê³¼ê±°ì˜ ìŠµê´€ì´ íŠ€ì–´ë‚˜ì™€ ìƒˆë¡œìš´ ì‹œì‘ì„ ì‹œë„í•˜ë ¤ê³  í•œë‹¤. ì•ˆíƒ€ê¹Œìš´ ê±´, ì´ì   ìƒˆë¡œìš´ ì‹œì‘ë§ˆì €ë„ ê·¸ ê³¼ì •ì—ì„œ ë‹¤ì‹œê¸ˆ ìŠ¬ëŸ¼í”„ë¥¼ ë§ˆì£¼í•œë‹¤ëŠ” ì‚¬ì‹¤ì„ ì¸ì§€í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ì˜ í•˜ë ¤ê³  ë“¤ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì´ë‹¤. ê·¸ë˜ì„œ, ì°¨ì•…ìœ¼ë¡œ, ë‚´ê°€ ê²ªê³  ìˆëŠ” ìŠ¬ëŸ¼í”„ì˜ ì‹œê¸°ë¥¼ ë²„í‹°ê²Œ ë˜ëŠ” ìš”ì¦˜ì´ë‹¤. ë‹¹ì‹ ì˜ ìŠ¬ëŸ¼í”„ëŠ” ì•ˆë…•í•˜ì‹ ê°€ìš”? ìœ ì¾Œí•œ ìŠ¬ëŸ¼í”„ë€, ì¡´ì¬í•  ìˆ˜ ì—†ëŠ” ê°œë…ì¼ê¹Œìš”?","link":"/2019/05/15/Joyful-slump/"},{"title":"Machine Learning Yearning ìš”ì•½: Ch.13~19","text":"ëª©ì ì— ë§ëŠ” Devì™€ Test setì„ êµ¬ì¶•í–ˆë‹¤ë©´, ì´ì œ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì˜í•˜ê³  ìˆëŠ”ì§€, ëª»í•œë‹¤ë©´ ê·¸ ì´ìœ ëŠ” ë¬´ì—‡ì¸ì§€ì— ëŒ€í•œ ë¶„ì„ì„ í•  ìˆ˜ ìˆë‹¤. ê·¸ë˜ì„œ ì´ë²ˆì— ë‹¤ë£° ì£¼ì œëŠ” Basic Error Analysisì´ë‹¤. Ch.13: Build your first system quickly, then iterate Ch.14: Error analysis: Look at dev set examples to evaluate ideas Ch.15: Evaluating multiple ideas in parallel during error analysis Ch.16: Cleaning up mislabeled dev and test set examples Ch.17: If you have a large dev set, split it into two subsets, only one of which you look at Ch.18: How big should the Eyeball and Blackbox dev sets be? Ch.19: Takeaways: Basic error analysis ì´í•´ì˜ ìš©ì´ì„±ì„ ìœ„í•´, ë‚´ê°€ ì†í•œ íŒ€ì´ ì‚¬ìš©ìë“¤ì´ ì˜¬ë¦° ì´ë¯¸ì§€ë¥¼ classificationí•˜ëŠ” ëª¨ë¸ì„ ì„œë¹„ìŠ¤í•œë‹¤ê³  ê°€ì •í•´ë³´ì. íŒ€ì›ë“¤ì€ ëª¨ë¸ì˜ classification accuracyë¥¼ í–¥ìƒì‹œí‚¤ê³  ì‹¶ì„ ê²ƒì´ê³ , ì´ë¥¼ ìœ„í•´ ì ì ˆí•œ training, dev, test setì„ êµ¬ì¶•í•˜ì˜€ë‹¤. í•™ìŠµì‹œí‚¨ ëª¨ë¸ì˜ ì •í™•ë„ëŠ” 90%ì´ë‹¤. í•˜ì§€ë§Œ ì´ ì •ë„ë¡œëŠ” ì„œë¹„ìŠ¤ì— ë°˜ì˜í•˜ê¸° ì–´ë µë‹¤. ì, ì´ì œ ìš°ë¦¬ëŠ” ì–´ë–»ê²Œ í•´ì•¼í• ê¹Œ? ì¼ë‹¨, 10%ì˜ ì—ëŸ¬ê°€ ì–´ë–¤ ë°ì´í„°ì— ëŒ€í•´ì„œ ë°œìƒí•˜ëŠ”ì§€ ë¶„ì„(=error analysis)í•´ì•¼ í•œë‹¤. ì¢‹ì€ ë¶„ì„ì€ ì ì ˆí•œ ê°€ì •ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì´ë£¨ì–´ì§„ë‹¤. ìš°ë¦¬ íŒ€ì´ ìƒê°í•œ ëª¨ë¸ì˜ ë¬¸ì œëŠ” â€œê°œ(dog) ì´ë¯¸ì§€ë¥¼ ì˜ëª» ë¶„ë¥˜í•œë‹¤â€ì´ë‹¤. ì§€ë‚œ Chapterì—ì„œ dev setì´ error analysisë¥¼ ìœ„í•œ data setì„ì„ ì„¤ëª…í–ˆë‹¤. ì´ ì¤‘ ëª¨ë¸ì´ misclassifyí•œ ë°ì´í„°ì—ì„œ 100ê°œë¥¼ samplingí•œë‹¤. ê·¸ë¦¬ê³  ìš°ë¦¬ì˜ ê°€ì„¤-ê°œ ì´ë¯¸ì§€ë¥¼ ì˜ëª» ë¶„ë¥˜-ê³¼ ì¼ì¹˜í•˜ëŠ” caseë¥¼ ì„¼ë‹¤. ë§Œì•½ 5ê°œì˜€ë‹¤ë©´, ì—ëŸ¬ìœ¨ 10%ì˜ 5%ê°€ í•´ë‹¹ ì¼€ì´ìŠ¤ì¸ ê²ƒì´ë¯€ë¡œ ëª¨ë¸ì´ ì•ìœ¼ë¡œ â€œê°œ ì´ë¯¸ì§€ë¥¼ ì œëŒ€ë¡œ ë¶„ë¥˜â€í•œë‹¤ê³  í•˜ë”ë¼ë„ 10% * 0.05 = .5% ì •ë„ì˜ í–¥ìƒì„ ê¸°ëŒ€í•  ìˆ˜ ìˆë‹¤. ì¢€ ë” íš¨ìœ¨ì„ ë†’ì—¬ë³´ì. ìš°ë¦¬ëŠ” ì§€ê¸ˆ ê°€ì„¤ 1ê°œì— ëŒ€í•´ì„œ 100ê°œì˜ samplingëœ ë°ì´í„°ë¥¼ ì‚´í´ë³´ì•˜ëŠ”ë°, ì´ ì‘ì—…ì€ ê°€ì„¤ ì—¬ëŸ¬ê°œì— ëŒ€í•´ì„œ ë™ì‹œì— ì§„í–‰í•  ìˆ˜ ìˆë‹¤. ê°€ì„¤1: ê°œ ì´ë¯¸ì§€ë¥¼ ì˜ëª» ë¶„ë¥˜ ê°€ì„¤2: ê³ ì–‘ì´ê³¼(ì‚¬ì, í‘œë²” ë“±) ì´ë¯¸ì§€ë¥¼ ì˜ëª» ë¶„ë¥˜ ê°€ì„¤3: íë¦° ì´ë¯¸ì§€ë¥¼ ì˜ëª» ë¶„ë¥˜ Andrew Ngì€ í—·ê°ˆë¦¬ì§€ ì•Šë„ë¡ ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ spreadsheetì„ ë§Œë“¤ì–´ì„œ ì‘ì—…ì„ ì§„í–‰í•œë‹¤ê³  í•œë‹¤. % of totalì„ í†µí—¤ í˜„ì¬ ëª¨ë¸ì´ ê°€ì¥ criticalí•˜ê²Œ ê°œì„ í•´ì•¼ í•˜ëŠ” ì ì´ ë¬´ì—‡ì¸ì§€ë¥¼ ë°”ë¡œ íŒŒì•…í•  ìˆ˜ ìˆë‹¤. ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì„ ë•Œ í•­ìƒ ì—¼ë‘ì— ë‘ì–´ì•¼ í•˜ëŠ” ê°€ì„¤ì´ ìˆë‹¤. ë°”ë¡œ, â€œmislabeled dataì˜ ë¹„ìœ¨ì´ ì–¼ë§ˆë‚˜ ë˜ëŠ”ê°€?â€ì´ë‹¤. ë°ì´í„°ì˜ ì–‘ì´ ë§ì„ìˆ˜ë¡ ìˆ˜ì§‘ê³¼ì •ì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤. mislabeled dataê°€ ë°œê²¬ëœë‹¤ë©´ training dataì˜ mislabelì€ ì–´ì©” ìˆ˜ ì—†ìœ¼ë‹ˆ ë‚´ë²„ë ¤ë‘ê³ , dev setê³¼ test setì€ ìˆ˜ì •í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•œë‹¤. (devì™€ test setì˜ distributionì€ ê°™ì•„ì•¼ í•˜ë¯€ë¡œ) ì§€ê¸ˆê¹Œì§€ ì†Œê°œí•œ error analysis ë°©ë²•ì€ misclassifyëœ data ì¤‘ì—ì„œ 100ê°œì— ì ìš©ë˜ì—ˆë‹¤. ì´ ë§ì€ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ 95%ì˜ accuracyë¼ê³  ê°€ì •í–ˆì„ ë•Œ, dev setì˜ í¬ê¸°ê°€ 100/0.05 = 2,000 ì •ë„ë¼ëŠ” ëœ»ì„ í•¨ìœ í•˜ê³  ìˆë‹¤. ë§Œì•½ ë‚˜ì˜ dev setì´ ì´ ì •ë„ì˜ ê·œëª¨ë³´ë‹¤ ì‘ë‹¤ë©´, í˜¹ì€ í¬ë‹¤ë©´ ì–´ë–»ê²Œ í•´ì•¼í• ê¹Œ? Andrew Ngì´ ì œì•ˆí•œ 100ê°œì˜ error data ê°œìˆ˜ëŠ” ì´ ì •ë„ê°€ ëª¨ë¸ì˜ major error sourceë¡œì„œ ë§¤ìš° ì¢‹ì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ë°œê²¬í•  ìˆ˜ ìˆë‹¤ê³  ìƒê°í–ˆê¸° ë•Œë¬¸ì´ë‹¤. ~100ê°œ: ë§¤ìš° ì¢‹ì€ ì¸ì‚¬ì´íŠ¸ ë°œê²¬ ~50ê°œ: ì¢‹ì€ ì¸ì‚¬ì´íŠ¸ ë°œê²¬ ~20ê°œ: ê°œëµì ì¸ ì¸ì‚¬ì´íŠ¸ ë°œê²¬ ~10ê°œ: ë¶ˆì¶©ë¶„. í•˜ì§€ë§Œ ì ì€ dev setì„ ê°€ì§€ê³  ìˆë‹¤ë©´ ì—†ëŠ” ê²ƒë³´ë‹¤ëŠ” ë‚˜ì€ ì •ë„ ê·¸ë˜ì„œ dev setì´ ì‘ë‹¤ë©´ ëª¨ë“  ë°ì´í„°ë¥¼ error analysisë¥¼ ìœ„í•´ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤. ë§Œì•½ dev setì´ í¬ë‹¤ë©´, eyeball dev setê³¼ blackbox dev setìœ¼ë¡œ ë‚˜ëˆ„ì–´ ì‚¬ìš©í•œë‹¤. eyeball dev setì€ error analysisë¥¼ í•˜ë©´ì„œ ê³„ì† ëª¨ë¸ì´ ì˜í•˜ê±°ë‚˜ ëª»í•˜ëŠ” ê²ƒì„ ì‚´í´ë³¼ ìš©ë„ë¡œ ì‚¬ìš©í•˜ëŠ” dev setì´ê³ , blackbox dev setì€ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œë§Œ ì‚¬ìš©í•˜ëŠ” dev setì´ë‹¤. ë§Œì•½ eyeball error rate &lt;&lt; blackbox error rate ì´ë¼ë©´ ëª¨ë¸ì´ eyeball dev setì— overfittingí•˜ê³  ìˆìœ¼ë¯€ë¡œ ìƒˆë¡œìš´ eyeball dev setì„ êµ¬ì¶•í•˜ëŠ” ê²ƒìœ¼ë¡œ ê·¸ ìœ„í—˜ì„ ë°©ì§€í•œë‹¤. ì—¬ê¸°ì—ë„ ì˜ˆì™¸ê°€ ìˆëŠ”ë°, ì‚¬ëŒì¡°ì°¨ í’€ê¸° ì–´ë ¤ìš´ ê³¼ì œë¥¼ ìœ„í•œ ëª¨ë¸ì„ ë§Œë“¤ê³  ìˆë‹¤ë©´ eyeball dev setì€ ì „í˜€ ë„ì›€ì´ ë˜ì§€ ì•Šì„ ê²ƒì´ë¯€ë¡œ eyeball dev setì„ ë§Œë“¤ì§€ ì•Šì•„ë„ ì¢‹ë‹¤. ê·¸ë¦¬ê³  ì—¬ê¸°ê¹Œì§€ ì†Œê°œëœ ì¼ë ¨ì˜ ê³¼ì •-ë°ì´í„° ìˆ˜ì§‘ -&gt; ëª¨ë¸ êµ¬ì„± -&gt; í•™ìŠµ -&gt; ê²°ê³¼ ë¶„ì„ pipeline-ì´ ìµœëŒ€í•œ ë¹¨ë¦¬ iterateí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. ì²˜ìŒë¶€í„° ì™„ë²½í•œ ê²ƒì€ ì—†ë‹¤. ì¼ë‹¨ ì‹œì‘í•˜ì!","link":"/2019/01/01/Machine-Learning-Yearning-summary-Ch.13~19/"},{"title":"ë‹µì€ ì–¸ì œë‚˜ ë‚˜ì—ê²Œ ìˆë‹¤","text":"ì‚¶ì„ ì‚´ì•„ë‚˜ê°„ë‹¤ëŠ” ê²ƒì€ ëª¨ë‘ì—ê²Œ ì£¼ì–´ì§„ ê°™ì€ 24ì‹œê°„ì„, ë‚˜ì˜ ì„ íƒë“¤ë¡œ ì±„ì›Œë‚˜ê°€ëŠ” ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ê³ ë“±í•™êµ ë•Œê¹Œì§€ ë‚˜ì—ê²Œ ì£¼ì–´ì§„ ëŒ€ë¶€ë¶„ì˜ ì‹œê°„ì€ ë‹¤ë¥¸ ëˆ„êµ°ê°€ì— ì˜í•´ ì •í•´ì¡Œë‹¤. ë¶€ëª¨ë‹˜ì— ì˜í•´, í•™êµì— ì˜í•´, í•™ì›ì— ì˜í•´. íŠ¹íˆ ê³ ë“±í•™êµ ë•ŒëŠ” 7ì‹œê¹Œì§€ 11ì‹œê¹Œì§€ ì •í•´ì§„ ìˆ˜ì—…ì‹œê°„, ì•¼ìì‹œê°„ìœ¼ë¡œ ì±„ì›Œì ¸ ìˆì–´ ë‚´ê°€ ììœ ë¡­ê²Œ ì“¸ ìˆ˜ ìˆëŠ” ì‹œê°„ì€ ë”ìš± ì—†ë‹¤. â€œëŒ€í•™ ì…í•™â€ì´ë¼ëŠ” ê³µë™ì˜ ëª©ì ì„ í–¥í•´ â€œì„±ì ì„ ì˜¬ë¦¬ëŠ” ê²ƒâ€ì„ ê³µë™ì˜ ëª©í‘œë¡œ, ìš°ë¦¬ ëª¨ë‘ëŠ” ì •í•´ì§„ ì‹œê°„ ì†ì— ì‚´ì•„ê°„ë‹¤. í•˜ì§€ë§Œ ëŒ€í•™ ì…í•™ ì´í›„, í™˜ê²½ì€ ê°‘ìê¸°, ê·¹ì ìœ¼ë¡œ ë‹¬ë¼ì§„ë‹¤. ê°‘ìê¸° ê³µë™ì˜ ëª©í‘œê°€ ì‚¬ë¼ì§€ê³ , ê°‘ìê¸° ì„ íƒì˜ ììœ ê°€ ìƒê¸°ê³ , ê°‘ìê¸° ê²°ì •ì— ëŒ€í•œ ì±…ì„ì´ ì£¼ì–´ì§„ë‹¤. ê°‘ìê¸° ë°©í–¥ì„ ìƒì–´ë²„ë¦° í•™ìƒë“¤ì—ê²Œ ê°‘ìê¸° â€œë„¤ê°€ ì¢‹ì•„í•˜ëŠ” ê²ƒì„ í•˜ê³  ì‚´ë¼â€ê³  í•œë‹¤. ê·¸ë˜ì„œ ì†Œì‹¬í•˜ê²Œ ë‚´ê°€ í•˜ê³  ì‹¶ì€ ê²ƒì„ ì°¾ì•„ ì‹œê°„ì„ ì¡°ê¸ˆì”© ì±„ì›Œë³¸ë‹¤. ë°”ì´ì˜¬ë¦°ì„ ë°°ìš°ê³  ì‹¶ì–´ì„œ ì˜¤ì¼€ìŠ¤íŠ¸ë¼ ë™ì•„ë¦¬ì— ë“¤ê³ , ë…ë¦½ì´ í•˜ê³  ì‹¶ì–´ì„œ ìì·¨ë¥¼ ì‹œì‘í•œë‹¤. ìˆ ìë¦¬ë¥¼ ê°€ì§€ê³ , ë¯¸íŒ…ì— ë‚˜ê°€ë³´ê³ , ì£¼ì ì„ ì—´ê³ , í•™êµ ì¶•ì œì—ë„ ì°¸ì—¬í•´ë³¸ë‹¤. ê·¸ëŸ¬ë‹¤ ë³´ë©´ ì–´ëŠìƒˆ, ì¡¸ì—…ì„ í•œ ì´í›„ì˜ ë‚˜ì˜ ëª¨ìŠµì„ ê³ ë¯¼í•´ì•¼ í•  ì‹œê¸°ê°€ ë‹¤ê°€ì˜¨ë‹¤. ì£¼ë³€ì„ ë‘˜ëŸ¬ë³´ê¸° ì‹œì‘í•œë‹¤. ì„ ë°°ë“¤ì€ ì–´ë–¤ ì§„ë¡œë¥¼ íƒí–ˆëŠ”ì§€, ì¹œêµ¬ë“¤ì€ ì–´ë–¤ ì§„ë¡œë¥¼ íƒí•˜ë ¤ê³  í•˜ëŠ”ì§€ë¥¼ ì‚´í•€ë‹¤. ì§€ë„ êµìˆ˜ë‹˜, ë¶€ëª¨ë‹˜ í˜¹ì€ ì„ ë°°ì˜ ì¡°ì–¸ì„ êµ¬í•œë‹¤. ë‹¤ì–‘í•œ ì¶©ê³ , ì¡°ì–¸ì´ ìŸì•„ì ¸ ë‚˜ì˜¨ë‹¤. â€œí™•ì‹¤íˆ ëŒ€ê¸°ì—…ì´ ì¢‹ê¸´ ì¢‹ë‹¤. ë³µì§€ë„ ì¢‹ê³ , ì›”ê¸‰ë„ ë§ê³ . ëŒ€ê¸°ì—… ì™€, ê´œì°®ì•„.â€ â€œì‚¬íšŒì— ë‚˜ì™€ë³´ë‹ˆê¹Œ ì™œ ì˜ì‚¬, ì˜ì‚¬ í•˜ëŠ”ì§€ ì•Œê² ë”ë¼. ë„ˆëŠ” ê¼­ ê¸°íšŒê°€ ë‚¨ì•„ìˆì„ ë•Œ ì˜ì „ ê°€ë¼.â€ â€œ4ì°¨ ì‚°ì—… í˜ëª… ë•Œë¬¸ì— ë‚œë¦¬ë‹¤. ìš°ë¦¬ íšŒì‚¬ì—ì„œë„ ê·¸ìª½ ê´€ë ¨ëœ ì „ê³µìë“¤ ì—„ì²­ ë½‘ìœ¼ë ¤ê³  í•˜ë”ë¼. ë„ˆë„ ê·¸ìª½ ê³µë¶€í•´ë‘ëŠ” ê²Œ ì¢‹ì„ ê±°ì•¼.â€ â€œê·¸ ì „ê³µìœ¼ë¡  ì·¨ì§ ì–´ë ¤ìš¸ ê±°ë‹¤. ì°¨ë¼ë¦¬ ê³µë¬´ì› ì¤€ë¹„ë¥¼ í•˜ë“ ì§€, ë¡œìŠ¤ì¿¨ ê°€.â€ â€œëŒ€í•™ì› ì ˆëŒ€ ì˜¤ì§€ ë§ˆë¼.â€ ì§„ë¡œ ê³ ë¯¼ì„ ëœì–´ë‚´ê³ ì ë§Œë‚¬ë˜ ì‚¬ëŒë“¤ì´ì§€ë§Œ ì˜¤íˆë ¤ ê³ ë¯¼ì˜ ë¬´ê²Œë§Œ ëŠ˜ì–´ë‚œë‹¤. ëŒ€ê¸°ì—…ì— ì·¨ì§í• ê¹Œ ì‹¶ë‹¤ê°€ë„, ì˜ì „ì´ë‚˜ ë¡œìŠ¤ì¿¨ì— ì§€ì›í•˜ëŠ” ê²ƒì´ ì¢‹ì•„ ë³´ì´ë‹¤ê°€ë„, ì•„ì§ ì‚¬íšŒì— ë‚˜ê°ˆ ì¤€ë¹„ê°€ ì•ˆëë‹¤ëŠ” ë¶ˆì•ˆê°ì— ëŒ€í•™ì›ì— ê°ˆê¹Œ ì‹¶ë‹¤ê°€ë„, ìµìˆ™í•˜ê²Œ ê³ ì‹œ ê³µë¶€ë¥¼ í•˜ëŠ” ê²ƒì´ ë§ì•„ ë³´ì´ê¸°ë„ í•œë‹¤. í•˜ì§€ë§Œ, ê·¸ë“¤ì˜ ê²½í—˜ê³¼ â€˜ë‚˜â€™ì˜ ê²½í—˜ì€ ë‹¤ë¥´ë‹¤. ê·¸ë“¤ì˜ ì„±í–¥ê³¼ â€˜ë‚˜â€™ì˜ ì„±í–¥ì€ ë‹¤ë¥´ë‹¤. ê·¸ë“¤ì´ ì˜í•˜ëŠ” ê²ƒê³¼ â€˜ë‚´â€™ê°€ ì˜í•˜ëŠ” ê²ƒì€ ë‹¤ë¥´ë‹¤. ê·¸ë“¤ì˜ ê´€ì‹¬ì‚¬ì™€ â€˜ë‚˜â€™ì˜ ê´€ì‹¬ì‚¬ëŠ” ë‹¤ë¥´ë‹¤. ê·¸ë“¤ì˜ ì¡°ì–¸ì€ ì–´ë””ê¹Œì§€ë‚˜ ê·¸ë“¤ì˜ ì…ì¥ì—ì„œì˜ ì´ì•¼ê¸°ì¼ ë¿ì´ë‹¤. ê·¸ë˜ì„œ ê·¸ ì´ì•¼ê¸°ì— ì¢Œì§€ìš°ì§€ë  í•„ìš”ê°€ ì—†ë‹¤. ëŒ€ì‹ , 'ë‚˜â€™ì˜ ì´ì•¼ê¸°ëŠ” ê¼­ ë“¤ì–´ë³´ì•„ì•¼ í•œë‹¤. ë¯¸ë˜ì— ëŒ€í•œ ë¶ˆì•ˆê°ê³¼ ë‘ë ¤ì›€ì€ ë‹¨ì§€, ì–´ë–¤ ì„ íƒì„ í•¨ìœ¼ë¡œì¨ ë‹¥ì³ì˜¬ ë¯¸ë˜ì˜ ì¼ë“¤ì„ ë‚´ê°€ ì–¼ë§ˆë‚˜ ì˜ ê°ë‹¹í•  ìˆ˜ ìˆê³ , ë” ë‚˜ì•„ê°€ í–‰ë³µí•  ìˆ˜ ìˆì„ì§€ ì•Œì§€ ëª»í•˜ëŠ” â€œë‚˜ì— ëŒ€í•œ ë¬´ì§€í•¨â€ ë•Œë¬¸ì— ë¹„ë¡¯ëœ ê²ƒì´ê¸° ë•Œë¬¸ì´ë‹¤. ìŠ¤ìŠ¤ë¡œì—ê²Œ ë¬¼ì–´ë³´ì. ê·¸ë¦¬ê³  ì†”ì§í•˜ê²Œ ëŒ€ë‹µí•´ë³´ì. ë³µì§€ê°€ ì¢‹ê³ , ì›”ê¸‰ì´ ë§ì€ ê²ƒì´ ë‚˜ì—ê²Œ ì¤‘ìš”í•œê°€? ë‚¨ë“¤ì´ ë™ê²½í•˜ëŠ” ì§ì—…ì—, ê°œì¸ ë³‘ì›ì„ ì°¨ë¦¬ë©´ ëˆì„ ë§ì´ ë²Œ ìˆ˜ ìˆë‹¤ëŠ” ì‚¬ì‹¤ì´ ë‚˜ì—ê²Œ ì¤‘ìš”í•œê°€? 4ì°¨ ì‚°ì—… í˜ëª…ì´ ë¬´ì—‡ì¸ì§€ ì²´ê°ì´ë‚˜ í•˜ê³  ìˆëŠ” ê²ƒì¼ê¹Œ? ê·¸ë˜ì„œ ê·¸ê²Œ ì™œ, ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ë„ ë‚˜ëŠ” ì•Œê³  ìˆì„ê¹Œ? ë‚˜ëŠ” í•œ ë¶„ì•¼ì— ëŒ€í•œ ì¢€ ë” ì „ë¬¸ì ì¸ ì§€ì‹ì„ ì•Œê³  ì‹¶ì€ë°, ë‚´ê°€ ëŒ€í•™ì›ì— ê°€ì§€ ë§ì•„ì•¼ í•  ì´ìœ ë€ ëŒ€ì²´ ë¬´ì—‡ì¼ê¹Œ? ì„±ì ì´ ì¢‹ì•˜ê¸° ë•Œë¬¸ì— ì£¼ë³€ ì‚¬ëŒë“¤ ëª¨ë‘ ì˜ì‚¬ê°€ ë˜ê¸¸ ê¸°ëŒ€í–ˆê³ , ìŠ¤ìŠ¤ë¡œë„ ì˜ì‚¬ê°€ ë˜ê³  ì‹¶ë‹¤ê³  ìƒê°í•´ì„œ ì˜ê³¼ ì „ë¬¸ëŒ€í•™ì›ì— ì§„í•™í•˜ê¸° ìœ„í•´ í™”í•™ìƒë¬¼ê³µí•™ë¶€ë¥¼ ì „ê³µìœ¼ë¡œ íƒí•œ í•™ìƒì„ ë§Œë‚œ ì ì´ ìˆë‹¤. ì›í•˜ëŠ” ëŒ€í•™, ì›í•˜ëŠ” ì „ê³µì— í•©ê²©í–ˆì§€ë§Œ ì–´ë”˜ê°€ ëª¨ë¥´ê²Œ ë‹µë‹µí•˜ê³  â€˜ì´ê²Œ ë§ëŠ” ê±¸ê¹Œ?â€™ë¼ëŠ” ìƒê°ì´ ìê¾¸ë§Œ ë“ ë‹¤ê³  í–ˆë‹¤. ì£¼ë³€ì— ì´ëŸ° ë¶ˆì•ˆê°ì„ í† ë¡œí•´ë„ â€˜ë„¤ê°€ í”¼ê³¤í•´ì„œ ê·¸ëŸ° ê±¸ ê±°ì•¼.â€™, â€˜ì‚´ë‹¤ ë³´ë©´ ê·¸ëŸ´ ë•Œê°€ ìˆì§€.â€™ë¼ëŠ” ê°€ë²¼ìš´ ëŒ€ë‹µë§Œ ëŒì•„ì™”ë‹¤ê³  í–ˆë‹¤. ì²˜ìŒì—ëŠ” ê°€ë³ê²Œ ë„˜ê²¼ì§€ë§Œ, í•™ë…„ì´ ì˜¬ë¼ê°ˆìˆ˜ë¡ â€˜ì´ê±´ ì•„ë‹ˆë‹¤â€™ë¼ëŠ” ìƒê°ì´ ë” ê°•í•˜ê²Œ ë“¤ì—ˆë‹¤ê³ ë„ í–ˆë‹¤. â€œì§€ê¸ˆì€ ì˜ì‚¬ê°€ ë˜ê³  ì‹¶ì§€ ì•Šì€ ê±´ê°€ìš”?â€ ê·¸ëŸ° ê²ƒ ê°™ì•„ìš”. â€œì™œ ê·¸ëŸ° ê²ƒ ê°™ë‚˜ìš”?â€ ì–´ë ¸ì„ ë•, ì˜ì‚¬ë¼ëŠ” ì§ì—…ì— ëŒ€í•œ ì´í•´ê°€ ë¶€ì¡±í–ˆì–´ìš”. ë§‰ì—°íˆ ì–´ë¥¸ë“¤ì´ ì¢‹ë‹¤ê³  í•˜ë‹ˆê¹Œ, ê·¸ë¦¬ê³  ë‚˜ëŠ” ë­ë“  í•  ìˆ˜ ìˆëŠ” ì‚¬ëŒì´ë‹ˆê¹Œ, ê²Œë‹¤ê°€ ì•„ë¬´ë‚˜ ê¿ˆê¾¸ëŠ” ê²Œ ì•„ë‹ˆì—ˆìœ¼ë‹ˆê¹Œ ê·¸ëƒ¥ í•˜ê³  ì‹¶ì—ˆë‚˜ ë´ìš”. ê·¸ëŸ°ë° ì§€ê¸ˆì€ ì•„ë‹ˆì—ìš”. ì˜ì‚¬ë¼ëŠ” ì§ì—…ì´ í˜„ì‹¤ì ìœ¼ë¡œ ë‹¤ê°€ì˜¤ë©´ì„œ ë‚˜ì™€ ë§ì§€ ì•ŠëŠ” ê²ƒì´ ì¡°ê¸ˆì”© ë³´ì—¬ìš”. ê³¼ì—ì„œ ìƒë¬¼í•™ì„ ë°°ìš°ëŠ”ë°, ì •ë§ ì•ˆ ì™¸ì›Œì ¸ìš”. â€˜ì´ê±° ì•Œì•„ì„œ ì–´ë””ì— ì“°ì§€?â€™ë¼ëŠ” ìƒê° ë•Œë¬¸ì— ë™ê¸°ë¶€ì—¬ê°€ ë˜ì§ˆ ì•Šì•„ìš”. ë˜ ì˜ì‚¬ëŠ” ë§¤ë²ˆ ì•„í”„ê³  í˜ë“  ì‚¬ëŒì„ ë§Œë‚˜ì–ì•„ìš”. ì €ëŠ” ì‚¬ëŒë“¤ì„ í†µí•´ í˜ì„ ë§ì´ ì–»ê³ , ì£¼ë³€ ì‚¬ëŒì˜ ì˜í–¥ì„ ë§ì´ ë°›ëŠ”ë° í•­ìƒ ë§Œë‚˜ëŠ” ì‚¬ëŒë“¤ì´ í™˜ìë¼ë©´ ê²¬ë””ì§€ ëª»í•  ê²ƒ ê°™ì•„ìš”. ëˆì—ë„ í° ê´€ì‹¬ì´ ì—†ê³ ìš”. â€œìŠ¤ìŠ¤ë¡œì— ëŒ€í•œ ì´í•´ê°€ ì¢‹ì€ í¸ì¸ ê²ƒ ê°™ì•„ìš”. ì§€ê¸ˆ ë“£ê¸°ì—ëŠ” ì˜ì‚¬ë¥¼ í•˜ê³  ì‹¶ì§€ ì•Šì€ ê²ƒì´ ëª…í™•í•œë°, ì–´ë–¤ ê³ ë¯¼ì´ ìˆë‚˜ìš”?â€ ì´ì œì•¼, ë‚´ê°€ í•˜ê³  ì‹¶ì€ ê²ƒì´ ìƒê¸´ ê²ƒ ê°™ì€ë° ì§€ê¸ˆ ì „ê³µê³¼ ë„ˆë¬´ ë‹¬ë¼ì„œ ë¶ˆì•ˆí•˜ê³  ë‘ë ¤ì›Œìš”. ì˜í•  ìˆ˜ ìˆì„ì§€, ì´ë˜ë„ ë˜ëŠ” ê²ƒì¸ì§€ ëª¨ë¥´ê² ì–´ìš”. â€œí•˜ê³  ì‹¶ì€ ê²Œ ë­”ë°ìš”? ë¬´ì—‡ì´ ë¶ˆì•ˆí•œê°€ìš”?â€ ì €ëŠ” ì‚¬ì‹¤ ê³ ë“±í•™êµ ë•Œë¶€í„° ë°ì´í„°ì—ëŠ” í˜ì´ ìˆë‹¤ê³  ë¯¿ì—ˆì–´ìš”. ì–´ë–¤ ë¬¸ì œ ìƒí™©ì´ ìˆì„ ë•Œ, ê·¸ ìƒí™©ì— ëŒ€í•œ ë°ì´í„°ë§Œ ìˆë‹¤ë©´ ëª¨ë¥¼ê²Œ í•˜ë‚˜ë„ ì—†ë‹¤ê³  ìƒê°í–ˆìœ¼ë‹ˆê¹Œìš”. ëŒ€í•™ìƒí™œì„ í•˜ë‹¤ ë³´ë‹ˆê¹Œ ì €ëŠ” ë‚¨ë“¤ë³´ë‹¤ ê·¸ëŸ° ìƒí™©ì„ ë” ë§ì´ ë°œê²¬í•˜ê³ , ê·¸ë˜ì„œ í•´ê²°í•´ë³´ê³  ì‹¶ë‹¤ëŠ” ìš•êµ¬ë¥¼ ë§ì´ ëŠë¼ë”ë¼ê³ ìš”. ë‹¤ì–‘í•œ ì•±ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì¢‹ì•„í•˜ëŠ”ë°ìš”, ì•±ì˜ ì—…ë°ì´íŠ¸ë˜ëŠ” ë°©í–¥ì„ ë³´ë©´ ì–´ë–¨ ë•ŒëŠ” â€˜ì™€ ì§„ì§œ ì˜í•œë‹¤â€™í•˜ëŠ” ê²ƒì´ ìˆê³  â€˜ì´ê±¸ ì™œ í–ˆì§€? ì‚¬ìš©ìë“¤ì˜ ë§ˆìŒì„ ì´ë ‡ê²Œë‚˜ ëª¨ë¥´ë‚˜?â€™ ì‹¶ì„ ë•Œê°€ ìˆì–´ìš”. í›„ìì˜ ê²½ìš°ì— ì œê°€ ë§‰ ë°ì´í„°ë¥¼ ë³´ê³  ì‹¶ì–´ ì ¸ìš”. ì¸í„°ë„·ì— ê²€ìƒ‰ì„ í•´ë´¤ë”ë‹ˆ ì´ëŸ° ì¼ì„ ë°ì´í„° ë§ˆì´ë‹ì´ë¼ê³  í•˜ë”ë¼ê³ ìš”. ë” ì°¾ì•„ë³´ë‹ˆê¹Œ ì‚°ì—…ê³µí•™ê³¼ì—ì„œ ì œê°€ ìƒê°í•œ ì¼ì„ í•˜ëŠ” ì—°êµ¬ì‹¤ì´ ìˆì—ˆê³ , ë‹¤í–‰ì¸ì§€ ë¶ˆí–‰ì¸ì§€ í•™ë¶€ë§Œ ì¡¸ì—…í•´ì„œëŠ” ì´ëŸ° ì¼ì„ í•  ìˆ˜ ì—†ëŒ€ìš”. ê·¸ëŸ°ë° ì‚°ì—…ê³µí•™ê³¼ë¥¼ ë¶€ì „ê³µìœ¼ë¡œ í•˜ëŠ” ì‚¬ëŒì€ ì œ ì£¼ë³€ì—ì„œ ë³´ì§€ ëª»í–ˆê³ , ë˜ ì €í•œí…ŒëŠ” ë„ˆë¬´ ìƒì†Œí•˜ê³  ì´ì œ ì²˜ìŒ ì‹œì‘í•˜ëŠ” ê±´ë° ì œê°€ ì–¼ë§ˆë‚˜ ì˜í•  ìˆ˜ ìˆì„ì§€ ëª¨ë¥´ê² ì–´ì„œ ë‘ë ¤ì›Œìš”. ì²˜ìŒë¶€í„° ì´ í•™ìƒì´ ì´ë ‡ê²Œ ëŒ€ë‹µí–ˆë˜ ê²ƒì€ ì•„ë‹ˆì—ˆë‹¤. ë‚¨ì—ê²Œ ë³´ì´ê³  ì‹¶ì€ ëŒ€ë¡œ ë§í•˜ê¸°ë„ í–ˆê³ , ê³ ë¯¼í•´ë³¸ ì ì´ ì—†ì–´ì„œ ì‹œê°„ì„ ë‘ê³  ë‹µì„ í•˜ê¸°ë„ í–ˆë‹¤. í•˜ì§€ë§Œ ì ì  ìŠ¤ìŠ¤ë¡œì—ê²Œ ì†”ì§í•˜ê²Œ ì´ì•¼ê¸°ë¥¼ í•˜ê³ , ë‹¤ì–‘í•œ ê°ë„ì—ì„œ ìŠ¤ìŠ¤ë¡œì—ê²Œ ë¬»ëŠ” ì§ˆë¬¸ë“¤ì— ëŒ€ë‹µì„ í•˜ëŠ” ê³¼ì • ì†ì—ì„œ ìì‹ ì´ ì–¼ë§ˆë‚˜ ë°ì´í„°ì— ê´€ì‹¬ì´ ìˆì—ˆëŠ”ì§€ë¥¼ ì˜¤íˆë ¤ ê¹¨ë‹«ê²Œ ë˜ì—ˆë‹¤. ê·¸ë¦¬ê³  ë” ì´ìƒ ì£¼ë³€ì˜ ë§ì— íœ˜ë‘˜ë¦¬ì§€ ì•ŠëŠ” êµ³ê±´í•¨ì„ ì–»ê²Œ ë˜ì—ˆë‹¤. í™”í•™ìƒë¬¼ê³µí•™ì—ì„œ ì‚°ì—…ê³µí•™ìœ¼ë¡œ ì§„ë¡œë¥¼ í‹€ì—ˆì„ ë•Œ ì£¼ë³€ì—ì„œ ëª¨ë‘ë“¤ â€˜ì™œ? í™”í•™ìƒë¬¼ê³µí•™ì„ ì¡¸ì—…í–ˆì„ ë•Œ ë” ëˆì„ ë§ì´ ë²Œ ìˆ˜ ìˆì—ˆì„ í…ë°.â€™ë¼ê³  ì´ì•¼ê¸°í–ˆì§€ë§Œ, ê·¸ ì „ê³µì„ íƒí•œ ê²°ì •ì˜ ì´ë©´ì—ëŠ” â€˜ë‚˜â€™ì˜ ìƒê°, â€˜ë‚˜â€™ì˜ ê²½í—˜, â€˜ë‚˜â€™ì˜ ëŠë‚Œì´ ê°•í•˜ê²Œ ìˆì—ˆê¸° ë•Œë¬¸ì— í”ë“¤ë¦¬ì§€ ì•Šì•˜ë‹¤ê³  í–ˆë‹¤. ìŠ¤ìŠ¤ë¡œë¥¼ ì–´ë µê²Œ ì„¤ë“í•œ í›„ì— ê²°ì •ì„ ë‚´ë¦° ë§Œí¼ ê·¸ ê²°ì •ì— í›„íšŒê°€ ì—†ì„ ìˆ˜ ìˆë„ë¡ ë§ì€ ë…¸ë ¥ì„ í–ˆê³ , ì§€ê¸ˆì€ ë„¤ì´ë²„ì—ì„œ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë°ì´í„° ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸ë¡œ ì¼í•˜ê³  ìˆë‹¤. ì¸ìƒì€ ì–¸ì œë‚˜ ìš°ë¦¬ì—ê²Œ ì‰¬ìš´ ì§ˆë¬¸ì„ ë˜ì§€ëŠ” ë²•ì´ ì—†ë‹¤. â€œì–´ë–»ê²Œ ì‚´ ê²ƒì¸ê°€?â€, â€œí–‰ë³µì´ë€ ë¬´ì—‡ì¸ê°€?â€ì²˜ëŸ¼ ê°ˆìˆ˜ë¡ ë” ì–´ë ¤ìš´ ì§ˆë¬¸ì´ ìš°ë¦¬ë¥¼ ê¸°ë‹¤ë¦¬ê³  ìˆë‹¤. ê·¸ë ‡ë‹¤ê³  íšŒí”¼í•˜ê±°ë‚˜, ë‘ë ¤ì›Œí•  í•„ìš” ì—†ë‹¤. ë‹µì€ ì–¸ì œë‚˜ ë‚´ ì•ˆì— ìˆë‹¤.","link":"/2019/01/20/I-always-had-an-answer/"},{"title":"Machine Learning Yearning ìš”ì•½: Ch.1~4","text":"Deep learningìœ¼ë¡œ ì˜ˆì „ì—ëŠ” í’€ì§€ ëª»í–ˆë˜ ë¬¸ì œë“¤ì„ í’€ê²Œ ë˜ë©´ì„œ ë‹¤ì–‘í•œ ê¸°ì—…ì—ì„œ ìì‹ ë“¤ì˜ ì„œë¹„ìŠ¤ì— Deep learningì„ í™œìš©í•˜ë ¤ëŠ” ì‹œë„ê°€ ë§ì•„ì¡Œë‹¤. ê·¸ëŸ¬ë‚˜ ìƒê°ë³´ë‹¤ Deep learningì„ ì„œë¹„ìŠ¤ì— ì ìš©í•˜ëŠ” ê³¼ì •ì€ ê°„ë‹¨í•˜ì§€ ì•Šë‹¤. ì—°êµ¬ ëª©ì ìœ¼ë¡œ ì‚¬ìš©ë˜ëŠ” ê²ƒë³´ë‹¤ ë°ì´í„°ê°€ í›¨ì”¬ í¬ê³ , ì´ ë•Œë¬¸ì— í•œë²ˆ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ”ë° ì†Œìš”ë˜ëŠ” ì‹œê°„ì´ ë” ê¸¸ë‹¤. ë”ìš±ì´ ì„œë¹„ìŠ¤ë¡œ ë°°í¬ë˜ê¸° ìœ„í•´ì„œëŠ” ë§¤ìš° ì •í™•í•´ì•¼ í•˜ë¯€ë¡œ (ì„œë¹„ìŠ¤ì˜ íŠ¹ì§•ì— ë”°ë¥¸ ì°¨ì´ëŠ” ìˆê² ì§€ë§Œ ëŒ€ì²´ì ìœ¼ë¡œ) ëª¨ë¸ì˜ ê²€ì¦ê³¼ ì¬í•™ìŠµì˜ iterationì´ ë” ë§ì´ ì´ë£¨ì–´ì§„ë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì—°êµ¬ì‹¤ì—ì„œë³´ë‹¤ íšŒì‚¬ì—ì„œ ë” ì „ëµì ì¸ íŒë‹¨ì˜ ê³¼ì •ì´ í•„ìš”í•˜ë‹¤. ìš°ë¦¬ íŒ€ë„ NMTë¥¼ ì„œë¹„ìŠ¤ì— ë°˜ì˜í•˜ë©´ì„œ ë‹¤ì–‘í•œ ê³ ë¯¼ì— ë¶€ë”ªí˜€ì™”ë‹¤. ê·¸ë˜ì„œ Andrew Ngì´ ì“´ &lt;&gt;ì„ ê°™ì´ ì½ê³  ìˆëŠ”ë°, ì±… êµ¬ì„êµ¬ì„ ê³ ë¯¼í•´ì™”ë˜ ë¬¸ì œë“¤ì— ëŒ€í•œ Andrew Ng ë§Œì˜ í•´ê²°ì±…ì´ ì í˜€ìˆì–´ ì†ì´ ë»¥ ëš«ë¦¬ëŠ” ê¸°ë¶„ì„ ë§›ë³´ê³  ìˆë‹¤. (ì•„ë¬´ë˜ë„ Andrew Ng ì€ Geoffrey Hinton, Yann Lecun, Joshua Bengioì™€ ë‹¤ë¥´ê²Œ ì‚°ì—…ì ì¸ ì¸¡ë©´ì—ì„œì˜ Deep Learningì— ë” ê´€ì‹¬ì´ ë§ì€ ë¶„ì¸ ë“¯í•˜ë‹¤.) ì±… ìì²´ê°€ ì‰½ê²Œ ì“°ì—¬ì ¸ ìˆê³ , ê° ì±•í„°ê°€ 1~2ì¥ ì •ë„ë°–ì— ë˜ì§€ ì•Šì•„ ë¶€ë‹´ì€ ì ì§€ë§Œ í° ì£¼ì œ ë³„ë¡œ ìš”ì•½í•˜ë©´ ë” ë§ì€ ì‚¬ëŒë“¤ì´ ì‰½ê²Œ ë‚´ìš©ì„ ì´í•´í•˜ê³ , ê°ìì˜ ë¶„ì•¼ì— ì ‘ëª©ì‹œí‚¬ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„ì„œ ì´ ê¸€ì„ ì“°ê²Œ ë˜ì—ˆë‹¤. Chapter 1~4ëŠ” â€œì™œ ì´ ì±…ì´ í•„ìš”í•œì§€, ì–´ë–»ê²Œ ì´ ì±…ì„ í™œìš©í•˜ë©´ ì¢‹ì„ì§€â€ì— ëŒ€í•œ ë‚´ìš©ì´ ë‹´ê²¼ë‹¤. ëª©ì°¨ë¥¼ ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. Ch.1: Why Machine Learning Strategy Ch.2: How to use this book to help your team Ch.3: Prerequisites and Notation Ch.4: Scale drives machine learning progress Chapter 2ëŠ” â€œì´ ì±…ì€ í•œ ì±•í„°ê°€ ì§§ìœ¼ë‹ˆ ì¸ì‡„í•´ì„œ íŒ€ì›ì—ê²Œ ë³´ì—¬ì¤˜ë¼â€ë¡œ ìš”ì•½í•  ìˆ˜ ìˆê³ , Chapter 3ì€ â€œSupervised Learningê³¼ Neural Networkì— ëŒ€í•œ ì§€ì‹Andrew Ngì˜ MOOCë¥¼ ë“¤ì–´ë¼â€ìœ¼ë¡œ ìš”ì•½ê°€ëŠ¥í•˜ë‹¤. Chapter 1ê³¼ 4ë¥¼ ì¢…í•©í•˜ë©´ ì•„ë˜ì˜ ë‚´ìš©ì´ë‹¤. (ì„œë¹„ìŠ¤ì— ì ìš©í•˜ê¸° ìœ„í•´ ë„ë‹¬í•´ì•¼ í• ) ë†’ì€ ì •í™•ë„ì˜ ëª¨ë¸ì€ ë§ì€ ë°ì´í„°ë¥¼, ì´ë¥¼ ê°ë‹¹í•  ìˆ˜ ìˆì„ë§Œí¼ í° Neural Networkì— í•™ìŠµì‹œí‚¬ ë•Œ ì–»ì„ ìˆ˜ ìˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ê³¼ì •ì€ (ë‹¹ì—°íˆ) í•œ ë²ˆì— ì´ë£¨ì–´ì§€ì§€ ì•Šê³ , ë‹¤ì–‘í•œ ì‹œí–‰ì°©ì˜¤ê°€ ìˆ˜ë°˜ëœë‹¤. ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì„ ë•Œ, ìš°ë¦¬ê°€ íƒí•  ìˆ˜ ìˆëŠ” ì „ëµì€ ë‹¤ì–‘í•˜ë‹¤. ë” ë§ì€ ë°ì´í„°ë¥¼ ì–»ëŠ”ë‹¤. ë‹¤ì–‘í•œ training setì„ êµ¬í•œë‹¤. ë” ì˜¤ë˜ í•™ìŠµì‹œí‚¨ë‹¤. ë” í° Neural Networkë¥¼ í•™ìŠµì‹œí‚¨ë‹¤. ë” ì‘ì€ Neural Networkë¥¼ í•™ìŠµì‹œí‚¨ë‹¤. Regularizationì„ ì¶”ê°€í•œë‹¤. Neural Network êµ¬ì¡°ë¥¼ ë°”ê¾¼ë‹¤. â€¦ ì´ ì¤‘ ë¬´ì—‡ì„ ìš°ì„ ì ìœ¼ë¡œ ì‹œë„í•´ ë³´ì•„ì•¼í• ê¹Œ? ê·¸ ë‹µì€ í˜„ì¬ ë‚´ê°€ í•™ìŠµì‹œí‚¨ modelì— ìˆë‹¤. ê·¸ë¦¬ê³  ì´ ì±…ì€ modelì´ ë‚¨ê¸´ ë‹¨ì„œë“¤ì„ ì–´ë–»ê²Œ í™œìš©í•´ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•œ ë‚´ìš©ì„ ë‹´ê³  ìˆë‹¤. Andrew Ngì€ ë°”ìœ ì§ì¥ì¸ë“¤ë„ ì‰½ê²Œ ë‚´ìš©ì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì±…ì— ë‹¤ì–‘í•œ ë°°ë ¤ë¥¼ ì‹¬ì–´ë‘ì—ˆëŠ”ë°, ê·¸ ì¤‘ í•˜ë‚˜ê°€ Chapter ë“¤ì„ ì†Œì£¼ì œë¡œ ë¬¶ì–´ë‘” ê²ƒì´ë‹¤. Setting up development and test sets Basic Error Analysis Bias and Variance Learning curves Comparing to human-level performance Training and Testing on different distributions Debugging inference algorithms End-to-end deep learning Error analysis by parts ì´ ì£¼ì œë¥¼ ë³´ë©´ ì±…ì˜ í° íë¦„ì„ ì•Œ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. ë‹¤ìŒ ê¸€ì€ Setting up development and test setsì— ëŒ€í•œ ë‚´ìš©ì´ë‹¤.","link":"/2018/12/25/Machine-Learning-Yearning-summary-Ch.1~4/"},{"title":"Machine Learning Yearning ìš”ì•½: Ch.5~12","text":"ì´ë²ˆì— ìš”ì•½í•  Chapter 5~12 ì˜ ì†Œì œëª©ì€ Setting up development and test sets ì´ê³ , ì•„ë˜ì™€ ê°™ì€ ì œëª©ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. Ch.5: Your development and test sets Ch.6: Your dev and test sets should come from the same distribution Ch.7: How large do the dev/test sets need to be? Ch.8: Establish a sinlge-number evaluation metric for your team to optimize Ch.9: Optimizing and satisficing metrics Ch.10: Having a dev set and metric speeds up iterations Ch.11: When to change dev/test sets and metrics Ch.12: Takeaways: Setting up development and test sets Machine Learning / Deep Learning ëª¨ë¸ì„ ì „ëµì ìœ¼ë¡œ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” Ideaë¥¼ ë‚´ê³ , Codeë¡œ êµ¬í˜„í•˜ê³ , ê²€ì¦í•˜ê³ , ì¬í•™ìŠµì‹œí‚¤ëŠ” ì¼ë ¨ì˜ iterationì´ ì •í™•í•˜ê³  ë¹ ë¥´ê²Œ ì§„í–‰ë˜ì–´ì•¼ í•œë‹¤. ì½”ë“œë¥¼ í†µí•´ êµ¬í˜„ëœ ëª¨ë¸ì„ ì‹¤í—˜í•œ í›„, ì˜¬ë°”ë¥¸ ë°©í–¥ìœ¼ë¡œì˜ ì¬í•™ìŠµì´ ì´ë£¨ì–´ì§€ê¸° ìœ„í•´ì„œëŠ” error analysisê°€ í•„ìˆ˜ì ì´ë‹¤. ì‹ ë¢°ë„ ìˆëŠ” Error analysisëŠ” ì‹ ë¢°ë„ ìˆëŠ” dev/test setê³¼ evaluation metricì„ í†µí•´ ì–»ì–´ì§„ë‹¤. ê·¸ë˜ì„œ ì´ë²ˆ ChapterëŠ” ì¢‹ì€ dev/test set ê·¸ë¦¬ê³  evalutaion metricì— ëŒ€í•œ ì¡°ê±´ì— ëŒ€í•´ ì„œìˆ í•˜ê³  ìˆë‹¤. Dev/Test set ë¨¼ì €, training set, dev set, test setì— ëŒ€í•´ ì •ì˜í•´ë³´ì. Training set: ìš°ë¦¬ê°€ ì•Œê³ ë¦¬ì¦˜ì„ í•™ìŠµí•  ë•Œ ì‚¬ìš©í•˜ëŠ” ë°ì´í„° Dev set: ì•Œê³ ë¦¬ì¦˜ì˜ parameterë¥¼ íŠœë‹í•˜ê³ , featureë¥¼ ì„ íƒí•˜ëŠ” ë“±ì˜ ê²°ì •ì„ ë‚´ë¦¬ê¸° ìœ„í•œ ë°ì´í„° Test set: ì•Œê³ ë¦¬ì¦˜ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë°ì´í„° ì¦‰, ëª¨ë¸ì´ ì˜í•˜ê³  ìˆëŠ”ì§€ ì•„ë‹Œì§€ì˜ ì—¬ë¶€ëŠ” test setì— ë‹¬ë ¤ìˆë‹¤. ê·¸ë¦¬ê³  â€œì˜í•œë‹¤â€ë¼ëŠ” ê¸°ì¤€ì€ ì„œë¹„ìŠ¤ì— ëŒ€í•´ì„œëŠ” ë‹¹ì—°íˆ â€œì‚¬ìš©ìì˜ ë§Œì¡±ë„â€ì´ë‹¤. ê·¸ëŸ¬ë¯€ë¡œ test setì€ â€œì‚¬ìš©ìì˜ ë§Œì¡±ë„ë¥¼ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´ ì„¸ìš´ íŒ€ì˜ ëª©ì â€ê³¼ ë¶€í•©í•´ì•¼ í•˜ë©°, â€œì„œë¹„ìŠ¤ê°€ ì˜ í•˜ê³  ì‹¶ì€ ì˜ì—­â€ê³¼ â€œì„œë¹„ìŠ¤ ì‚¬ìš©ìë¥¼ í†µí•´ ë“¤ì–´ì˜¬ ë²•í•œ ë°ì´í„°â€ë¥¼ ë°˜ì˜í•´ì•¼ í•œë‹¤. ê·¸ë¦¬ê³  dev setì€ ë°˜ë“œì‹œ test setê³¼ ê°™ì€ distributionì„ ê°€ì ¸ì•¼ í•œë‹¤. ì™œëƒí•˜ë©´ ëª¨ë¸ì˜ ì„¸ë¶€ì‚¬í•­ì€ dev setì„ í†µí•´ ê²°ì •ë˜ê¸° ë•Œë¬¸ì— ë§Œì•½ distributionì´ ë‹¤ë¥´ë‹¤ë©´ â€œì£½ ì’€ì„œ ê°œ ì¤€ ê¼´â€ì´ ë‚  ê²ƒì´ë‹¤. ë¿ë§Œ ì•„ë‹ˆë¼ ì¶”í›„ dev setì—ì„œ error analysisë¥¼ í†µí•œ ëª¨ë¸ì˜ ì§„ë‹¨ì´ ì–´ë ¤ì›Œì§„ë‹¤. ì ì ˆí•œ Dev setì˜ í¬ê¸°ëŠ” í•™ìŠµí•œ ëª¨ë¸ë“¤ì˜ ì°¨ì´ë¥¼ ì¸ì§€í•  ìˆ˜ ìˆì„ ì •ë„ì´ì–´ì•¼ í•œë‹¤. ë³´í†µ 1,000ì—ì„œ 10,000ê°œ ì •ë„ê°€ ì ë‹¹í•œë°, ì´ë¯¸ ê¸°ë³¸ì ì¸ ëª¨ë¸ì˜ ì„±ëŠ¥ì´ ë†’ê³ , 0.01%ì˜ ì°¨ì´ì— ë¯¼ê°í•´ì•¼ í•œë‹¤ë©´ 10,000ê°œë³´ë‹¤ ì»¤ì•¼ í•œë‹¤. Test setì˜ ê²½ìš°ì—ëŠ” ëª¨ë¸ì˜ ì„±ëŠ¥ì— ëŒ€í•´ ë†’ì€ confidenceë¥¼ ì¤„ ìˆ˜ ìˆì„ ì •ë„ì˜ ì‚¬ì´ì¦ˆê°€ ì ë‹¹í•˜ë‹¤. êµê³¼ì„œì—ì„œëŠ” ì „ì²´ ë°ì´í„°ì˜ 30%ë¥¼ ì“°ë¼ê³  í•˜ì§€ë§Œ, ë¹…ë°ì´í„° ì‹œëŒ€ì—ëŠ” ê·¸ë³´ë‹¤ ë¹„ìœ¨ì´ ì‘ì•„ë„ ëœë‹¤. Evaluation metric 2ê°œ ì´ìƒì˜ metricì„ ì“°ëŠ” ê²ƒë³´ë‹¤ ë‹¨ì¼ metricì„ ì“°ëŠ” ê²ƒì´ ì¢‹ë‹¤. Aì™€ Bì˜ ì¸¡ë©´ì—ì„œ í‰ê°€í•´ì•¼í•˜ëŠ”ë° Aë¥¼ ë²„ë¦¬ë¼ëŠ” ëœ»ì´ ì•„ë‹ˆë‹¤. Aì™€ Bë¥¼ ì ì ˆíˆ ì„ì€ (í‰ê· , ê°€ì¤‘ í‰ê·  ë“±) ë‹¨ì¼ ìˆ˜ì¹˜ë¥¼ ë§Œë“¤ë¼ëŠ” ê²ƒì´ë‹¤. ë‹¨ì¼ metricì´ì–´ì•¼ ë¹ ë¥´ê²Œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ê³  ê²°ì •í•  ìˆ˜ ìˆë‹¤. ê·¸ëŸ¬ë‚˜ Aì™€ Bì™€ ê°™ì€ metricì„ ì ì ˆíˆ ì„ê¸° ì–´ë ¤ìš´ ê²½ìš°ê°€ ìˆì„ ìˆ˜ ìˆë‹¤. ì•„ë˜ ê·¸ë¦¼ì˜ ì •í™•ë„ì™€ running timeì²˜ëŸ¼ (Accuracy - 0.5*RunningTimeì™€ ê°™ì€ ë‹¨ì¼ metricì´ ë¶€ìì—°ìŠ¤ëŸ½ë‹¤). ì´ëŸ´ ë•, satisficing metricê³¼ optimizing metricì„ ë‚˜ëˆ„ì–´ì„œ ìƒê°í•˜ë©´ ëœë‹¤. ì´ Nê°œì˜ metricì´ ì¡´ì¬í•  ë•Œ, N-1 ê°œì˜ satisficing metricê³¼ 1ê°œì˜ optimizing metricìœ¼ë¡œ ë‚˜ëˆˆë‹¤. ìœ„ì˜ ì˜ˆì œì˜ ê²½ìš°, Running timeì€ satisficing metricìœ¼ë¡œ, AccuracyëŠ” optimizing metricìœ¼ë¡œ ë‘ì—ˆì„ ë•Œ, Running timeì€ íŠ¹ì • ê¸°ì¤€ì„ ë„˜ê¸°ê¸°ë§Œ í•˜ë©´ ë˜ê³ , AccuracyëŠ” ê·¸ ì•ˆì—ì„œ ìµœëŒ€ì¸ ëª¨ë¸ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì´ë¼ê³  í‰ê°€í•  ìˆ˜ ìˆë‹¤. Dev/Test set ë° evaluation metricì˜ ì—…ë°ì´íŠ¸ ìœ„ì˜ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” dev/test setê³¼ evaluation metricì„ ê²°ì •í•˜ëŠ” ê²ƒì€ ì‰½ì§€ ì•Šì„ ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ì™„ë²½í•˜ì§„ ì•Šë”ë¼ë„ ë¹ ë¥´ê²Œ ë¬´ì—‡ì´ë¼ë„ êµ¬ì¶•í•˜ê³ , ì—…ë°ì´íŠ¸í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤. dev/test setì´ ë”ì´ìƒ ì‹¤ì œ ì‚¬ìš©ìì˜ distributionì„ ëŒ€í‘œí•˜ì§€ ì•Šì„ ë•Œ, dev setì— ë„ˆë¬´ overfit ë˜ì–´ë²„ë ¸ì„ ë•Œ, metricì´ íŒ€ì˜ ë°©í–¥ì„ ëŒ€ë³€í•˜ì§€ ëª»í•  ë•Œ, ê³¼ê°íˆ ë³€í™”ë¥¼ ì‹œë„í•˜ì.","link":"/2018/12/26/Machine-Learning-Yearning-summary-Ch.5~12/"},{"title":"Naver News Comment Analysis (1)","text":"ì˜¬ì´ˆ(3ì›”)ë¶€í„° ê°™ì€ íŒ€ì˜ ì¬ëª…ë‹˜ê³¼ ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ ë°ì´í„°ë¡œ ì‚¬ì´ë“œ í”„ë¡œì íŠ¸ë¥¼ ì‹œì‘í–ˆë‹¤. ì§ì ‘ í¬ë¡¤ë§í•˜ì‹  ë°ì´í„°ì˜€ëŠ”ë°, ê·¸ ì–‘ì´ ë°©ëŒ€í•´ì„œ â€œì´ ì •ë„ ë°ì´í„°ê°€ ìˆìœ¼ë©´, ë­”ê°ˆ í•´ë³¼ ìˆ˜ ìˆê² ì§€!â€ ë¼ëŠ” ê°€ë²¼ìš´ ë§ˆìŒìœ¼ë¡œ ì‚¬ì´ë“œ í”„ë¡œì íŠ¸ ì œì•ˆì„ ë¥ì„ ë°›ì•„ë¬¼ì—ˆë‹¤. ê·¸ë¦¬ê³  ì—¬ëŠ ì‚¬ì´ë“œ í”„ë¡œì íŠ¸ê°€ ê·¸ë ‡ë“¯ ê·¸ ê³¼ì •ì€ ê²°ì½” ìƒê°ë§Œí¼ ê°€ë³ì§€ëŠ” ì•Šì•˜ë”ë¬ë‹¤â€¦ ë§ˆì¹¨ ì‘ë…„ ì‚¬ë‚´ Hackdayì—ì„œ Abuser Detection ë¶„ì„ìœ¼ë¡œ ì¢‹ì€ ì„±ê³¼ë¥¼ ì–»ì—ˆë˜í„°ë¼ ì–´ë·°ì € ë¶„ì„ì„ í•´ë³´ê³  ì‹¶ì—ˆê³ , ê·¸ ê²°ê³¼ë¡œ ë‚˜ë¦„ ì¬ë°ŒëŠ” ê²ƒë“¤ì´ ë°œê²¬ë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ì¢‹ì€ ë°œí‘œ ìë¦¬(ì´ë¥¼í…Œë©´ íŒŒì´ì½˜ì´ë¼ë“ ì§€,)ì— ë“±ë¡í•  ì‹œê¸°ë¥¼ ë†“ì³ì„œ ë…¼ë¬¸ì„ arXivì— ì˜¬ë ¤ë‘ë“¯ì´ ë¸”ë¡œê·¸ì— ëŒ“ê¸€ ë¶„ì„í•œ ë‚´ìš©ì„ ê³µìœ í•˜ê³ ì í•œë‹¤. ë‚´ìš©ì€ í¬ê²Œ ë‰´ìŠ¤ ëŒ“ê¸€ ìˆ˜ì§‘ê³¼ ë‰´ìŠ¤ ëŒ“ê¸€ ë¶„ì„ íŒŒíŠ¸ë¡œ ë‚˜ë‰˜ë©°, ì „ìëŠ” ì¬ëª…ë‹˜ì´ í›„ìëŠ” ë‚´ê°€ ì£¼ë¡œ ë‹´ë‹¹í•´ì„œ ì •ë¦¬í•˜ì˜€ë‹¤. ì´ë²ˆ ê¸€ì€ ë‰´ìŠ¤ ëŒ“ê¸€ ë¶„ì„ 1í¸ì´ë‹¤. Data ìˆ˜ì§‘ ê¸°ê°„ 2006.04.26 ~ 2018.05.25 (ìˆ˜ì§‘ ì‹œì : 2018.10) ìˆ˜ì§‘ ë‚´ìš© ë„¤ì´ë²„ ë‰´ìŠ¤ì˜ 6ê°œ ë¶„ì•¼ë³„(ì •ì¹˜, ê²½ì œ, ì‚¬íšŒ, ìƒí™œ/ë¬¸í™”, ì„¸ê³„, IT/ê³¼í•™) ê°€ì¥ ë§ì´ ë³¸ ë‰´ìŠ¤ 30ê±´ ê°™ì€ ê¸°ì‚¬ì´ì§€ë§Œ 2-3ì¼ ë™ì•ˆ ë­í‚¹ë‰´ìŠ¤ì— ì˜¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¤‘ë³µ ê¸°ì‚¬ë¥¼ ì œê±°í•´ì£¼ì—ˆë‹¤. ì¤‘ë³µ ì œê±° ì „ ê¸°ì‚¬ #: 751,751 (ì•½ 75ë§Œ) ì¤‘ë³µ ì œê±° í›„ ê¸°ì‚¬ #: 643,226 (ì•½ 64ë§Œ) ë¶„ì„ì— ì‚¬ìš©í•œ í•„ë“œ ê¸°ì‚¬: ê¸°ì‚¬ id, ê¸°ì‚¬ ì œëª©, ê¸°ì‚¬ ì…ë ¥ ì‹œê°, ê¸°ì‚¬ ë‚´ìš©, ì–¸ë¡ ì‚¬, ê¸°ì‚¬ ê°ì • ëŒ“ê¸€: ëŒ“ê¸€ ì‘ì„± ê¸°ì‚¬id, ì‘ì„±ì hashed id, ëŒ“ê¸€ ì‘ì„± ì‹œê°, ëŒ“ê¸€ ë‚´ìš©, ê³µê°ìˆ˜, ë¹„ê³µê°ìˆ˜ Basic Statistics ì¤‘ë³µ ì œê±°ëœ ê¸°ì‚¬ì— ëŒ€í•´, ê¸°ì‚¬ ì‘ì„± ì‹œì ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ ë‹¬ ë‹¨ìœ„ë¡œ ê¸°ì‚¬ì— ë‹¬ë¦° ì½”ë©˜íŠ¸ë¥¼ ì§‘ê³„í•´ì„œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ë„¤ì´ë²„ ë‰´ìŠ¤ ê°œí¸ history[1] ì™€ ì—®ì–´ì„œ ì´ ê·¸ë˜í”„ë¥¼ í•´ì„í•˜ë©´ ì¬ë°Œì–´ì§„ë‹¤. 2009ë…„ 2009ë…„ ê°œí¸ ë•ŒëŠ” ë©”ì¸ í˜ì´ì§€ ë‰´ìŠ¤ ë°•ìŠ¤ í¸ì§‘ê¶Œì„ ì‹ ë¬¸ì‚¬ì— ë„˜ê²¼ê³ , ê¸°ì‚¬ë¥¼ í´ë¦­í•˜ë©´ ë°”ë¡œ ì‹ ë¬¸ì‚¬ ë§í¬ë¡œ ì—°ê²°ë˜ê²Œ ë°”ë€Œì—ˆë‹¤. ì´ë¡œ ì¸í•´ ë„¤ì´ë²„ ë‰´ìŠ¤ì˜ íŠ¸ë˜í”½ì´ ê°ì†Œí•˜ê²Œ ë˜ì—ˆê³  ì˜ˆì „ê³¼ ë¹„êµí•´ì„œ ë¦¬í”Œ ê°œìˆ˜ë‚˜ ì¡°íšŒìˆ˜ê°€ ìƒë‹¹íˆ ì¤„ì–´ë“¤ì—ˆë‹¤. 2010ë…„ 2010ë…„ëŒ€ ì´ˆë°˜ì— ë‰´ìŠ¤ ìŠ¤íƒ ë“œê°€ ë„ì…ë˜ë©´ì„œ ë©”ì¸í™”ë©´ ë‰´ìŠ¤ í¸ì§‘ê¶Œì„ í¬ê¸°í•˜ê²Œ ëœë‹¤. ê¸°ì‚¬ë¥¼ í´ë¦­í•˜ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ë„¤ì´ë²„ í˜ì´ì§€ê°€ ì•„ë‹Œ ì–¸ë¡ ì‚¬ ì‚¬ì´íŠ¸ë¡œ ì—°ê²°ëœë‹¤. ëª¨ë°”ì¼ë¡œ ëŒ“ê¸€ì„ ë‹¬ ìˆ˜ ì—†ì—ˆë‹¤. ë˜í•œ ëŒ“ê¸€ í˜•íƒœê°€ ëŒ“ê¸€ ì œëª©ì„ í´ë¦­í•´ì•¼ë§Œ ë‚´ìš©ì„ ë³¼ ìˆ˜ ìˆëŠ” í˜•íƒœë¼ì„œ ê²°ê³¼ì ìœ¼ë¡œëŠ” ë‹¹ì‹œ ë‰´ìŠ¤ ëŒ“ê¸€ ë€ì€ ì§€ê¸ˆë³´ë‹¤ í›¨ì”¬ íì‡„ì ì¸ ëª¨ì–‘ìƒˆì˜€ë‹¤. 2012ë…„ ê²€ìƒ‰ê³¼ ì§€ì‹ì¸ì˜ ì¸ê¸°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë„¤ì´ë²„ê°€ 2012ë…„ 1ì¼ ë°©ë¬¸ì 1800ë§Œ ëª…ì„ ê¸°ë¡í•  ì •ë„ë¡œ ì„±ì¥í•˜ëŠ” ë™ì•ˆ, ë„¤í‹°ì¦Œì˜ ë‰´ìŠ¤ ì½ê¸° ë°©ì‹ë„ ë‹¬ë¼ì¡Œë‹¤. ì¢…ì´ì‹ ë¬¸ì„ ì½ê±°ë‚˜ ì‹ ë¬¸ë°©ì†¡ì˜ í™ˆí˜ì´ì§€ë¥¼ ì°¾ì•„ê°€ëŠ” ëŒ€ì‹ , ë„¤ì´ë²„ë‚˜ ë‹¤ìŒ ë“± í¬í„¸ì˜ ë‰´ìŠ¤ìºìŠ¤íŠ¸ë¥¼ í†µí•´ ì—¬ëŸ¬ ì–¸ë¡ ì‚¬ ê¸°ì‚¬ë¥¼ í•œêº¼ë²ˆì— ì½ëŠ” ì‚¬ëŒë“¤ì´ í¬ê²Œ ëŠ˜ì–´ë‚œ ê²ƒì´ë‹¤. ì´ ë•Œë¬¸ì— ë‰´ìŠ¤ í¸ì§‘ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ëŠ” í¬í„¸ì„ ì–¸ë¡ ì‚¬ë¡œ ë´ì•¼ í•  ê²ƒì´ëƒ ì•„ë‹ˆëƒ í•˜ëŠ” ë…¼ìŸì´ ì–¸ë¡ ê´€ë ¨ ì‹¬ì˜ê¸°êµ¬ ë“±ì—ì„œ ë²Œì–´ì§€ê³  ìˆê¸°ë„ í•˜ë‹¤.[2] 2012ë…„ ì¤‘ë°˜ë¶€í„° ëª¨ë°”ì¼ë¡œë„ ëŒ“ê¸€ì„ ë‹¬ ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. ë„¤ì´ë²„ ì•„ì´ë””ë¡œ ë¡œê·¸ì¸í•˜ì§€ ì•Šì•„ë„ íŠ¸ìœ„í„°ë‚˜ í˜ì´ìŠ¤ë¶ ë“±ì˜ SNS ê³„ì •ìœ¼ë¡œ ëŒ“ê¸€ì„ ë‹¬ ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. ì´ ë•Œë¬¸ì— ë„¤ì´ë²„ ì˜í™” í‰ì  ì¡°ì‘ì²˜ëŸ¼ ì¶”ì²œìˆ˜ ì¡°ì‘í•˜ê¸°ë„ ì‰¬ì›Œì¡Œë‹¤. ë„¤ì´ë²„, ë¯¸íˆ¬ë°ì´, íŠ¸ìœ„í„°, í˜ì´ìŠ¤ë¶, ë‹¤ìŒìœ¼ë¡œ í•œ ë²ˆì”©ë§Œ ë¡œê·¸ì¸í•´ë„ ê³µê° ë° ë¹„ê³µê° 5ê°œë¥¼ ì¤„ ìˆ˜ ìˆë‹¤. 2016ë…„ 10ì›”, JTBCì—ì„œ ìµœìˆœì‹¤ì˜ íƒœë¸”ë¦¿ pcë¥¼ ë°œê²¬í•˜ì˜€ê³  ìµœìˆœì‹¤ ê²Œì´íŠ¸ ì‚¬ê±´ì˜ í¬ë¬¸ì´ ì—´ë¦¬ê¸° ì‹œì‘í–ˆë‹¤. (íŠ¸ë˜í”½ ì¸¡ë©´ì—ì„œ ë„¤ì´ë²„ ë‰´ìŠ¤ëŠ” ìµœìˆœì‹¤ì—ê²Œ ê°ì‚¬í•˜ëŠ” ë§ˆìŒì´ ì—†ì§€ ì•Šì•„ ìˆì„ ê²ƒì´ë‹¤â€¦) ê·¸ë¦¬ê³  ë™ì‹œì—, ë“œë£¨í‚¹ì˜ ëŒ“ê¸€ ì¡°ì‘ ì‚¬ê±´ë„ ì‹œì‘[3]ë˜ì—ˆë‹¤. 2018ë…„ 5ì›” ë§, íŠ¹ê²€ë²•ì´ í†µê³¼ëœ ì´í›„ì— ëŒ“ê¸€ì´ ì¤„ì—ˆë‹¤ëŠ” ê¸°ì‚¬[4] ê°€ ë³´ë„ë˜ì—ˆë‹¤. 2018ë…„ 6ì›” ì´í›„ì˜ ëŒ“ê¸€ì´ ìˆì—ˆë‹¤ë©´ ê·¸ê°„ ëŒ“ê¸€ë¶€ëŒ€ì˜ ìœ„ë ¥ì´ ì–´ëŠ ì •ë„ì˜€ëŠ”ì§€ ê°€ëŠ í•´ë³¼ ìˆ˜ ìˆì—ˆì„ ê²ƒì´ë‹¤. ê²°ë¡ ì ìœ¼ë¡œ 2016ë…„ í›„ë°˜ë¶€ ì´í›„ í­ë°œì ì¸ ëŒ“ê¸€ ìˆ˜ì˜ ì¦ê°€ëŠ” ì •ì¹˜ ë° ì‚¬íšŒ ì˜ì—­ì˜ ì—„ì²­ë‚œ íŠ¸ë˜í”½ ë•ë¶„ì´ì—ˆì„ ê²ƒì´ë‹¤. ê°€ì„¤ ê²€ì¦ ì°¨ì›ì—ì„œ ì„¹ì…˜ ë³„ë¡œ ë‚˜ëˆ„ì–´ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ëŒ“ê¸€ì„ ì§‘ê³„í•´ ë³´ì•˜ë‹¤. News Sentiment Analysis ë„¤ì´ë²„ ë‰´ìŠ¤ëŠ” ê¸°ì‚¬ì— â€œì¢‹ì•„ìš”â€ ë¥¼ ì‹œì‘ìœ¼ë¡œ â€œí›ˆí›ˆí•´ìš”â€, â€œìŠ¬í¼ìš”â€, â€œí™”ë‚˜ìš”â€, â€œí›„ì†ê¸°ì‚¬ ì›í•´ìš”â€ ì˜ labelì„ ë‹¬ ìˆ˜ ìˆê²Œ ë§Œë“¤ì—ˆë‹¤. â€œì¢‹ì•„ìš”â€: 2014ë…„ ì´ˆ ì‹œì‘ â€œí›ˆí›ˆí•´ìš”â€, â€œìŠ¬í¼ìš”â€, â€œí™”ë‚˜ìš”â€, â€œí›„ì†ê¸°ì‚¬ ì›í•´ìš”â€: 2017ë…„ ì´ˆ ì‹œì‘ â€œì¢‹ì•„ìš”â€ ë§Œ ìˆì„ ë•Œì™€ ë‹¤ì„¯ ê°€ì§€ì˜ ê°ì •ì´ ìˆì„ ë•Œì˜ ì¶”ì´ê°€ ë˜ ì¬ë°Œë‹¤. â€œì¢‹ì•„ìš”â€ ì™¸ì˜ ë‹¤ë¥¸ ê°ì •ì´ í—ˆê°€ëœ ìˆœê°„ ì´í›„ë¡œ â€œí™”ë‚˜ìš”â€ ê°€ ê¸‰ê²©íˆ ì¦ê°€í•œë‹¤. ì •ì¹˜ ì°¸ê³ : ì‚¬ë“œë°°ì¹˜ (2017.03), ë¬¸ì¬ì¸ ë‹¹ì„  (2017.05)[5], í‰ì°½ ë™ê³„ ì˜¬ë¦¼í”½ (2018.02), ì´ëª…ë°• ìˆ˜ê° (2018.03)[6] ê²½ì œ ì‚¬íšŒ ë¬¸í™” 2018ë…„ 2ì›”ì—ëŠ” ë¬´ìŠ¨ ì¼ì´â€¦ (ì¶”ìš´ ë‚ ì”¨, ì„±ì¶”í–‰ ë“±ì˜ ì‚¬ê±´ ë•Œë¬¸ìœ¼ë¡œ ì¶”ì¸¡ë¨) IT ì„¸ê³„ Conclusions ì—¬ê¸°ê¹Œì§€ëŠ” ê¸°ì´ˆì ì¸ ë°ì´í„° íƒìƒ‰ ì‘ì—…ì´ì—ˆë‹¤. ê°„ë‹¨íˆ ì‹œê°„ ìˆœìœ¼ë¡œ ëŒ“ê¸€ ìˆ˜ë¥¼ ì§‘ê³„í•˜ê¸°ë§Œ í•´ë„ ì¬ë¯¸ìˆëŠ” ë¶„ì„ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì—ˆë‹¤. (ê°€ë ¹, ë°•ê·¼í˜œ-ìµœìˆœì‹¤ ê²Œì´íŠ¸ê°€ ì–¼ë§ˆë‚˜ í° ì´ìŠˆì˜€ëŠ”ì§€, ë‰´ìŠ¤ëŠ” ëŒ€ë¶€ë¶„ ìš°ë¦¬ë¥¼ ì—´ë°›ê²Œ í•˜ëŠ” ë‚´ìš©ì´ë¼ë“ ì§€ ë“±) ì´ ë‹¤ìŒ ë¶„ì„ì€, ì˜ì‹¬í•˜ê¸°ë§Œ í–ˆë˜ ëŒ“ê¸€ ì–´ë·°ì € ì§‘ë‹¨ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ì— ëŒ€í•´ ë‹¤ë£° ì˜ˆì •ì´ë‹¤. ë§ˆì¹¨ ëŒ“ê¸€ ìˆ˜ì§‘ ê¸°ê°„ê³¼ ë“œë£¨í‚¹ì˜ ëŒ“ê¸€ ì¡°ì‘ ê¸°ê°„ì´ ë§ë¬¼ë ¤ ìˆì–´ì„œ ë¶„ì„í•´ ë³¼ ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ ì†ì— ì¥ì–´ì¡Œë‹¤. ìµœëŒ€í•œ ì„ ì…ê²¬ì—†ì´ ë‹´ë°±í•œ ë¶„ì„ì„ í•´ë³´ë ¤ê³  ë…¸ë ¥í–ˆë‹¤. ì •ë§ì¸ì§€ ì•„ë‹Œì§€ ë‹¤ìŒ ê¸€ì—ì„œ í™•ì¸í•´ë³´ì. References 1.https://namu.wiki/w/ë„¤ì´ë²„_ë‰´ìŠ¤ â†©2.https://www.wikitree.co.kr/main/news_view.php?id=71675 â†©3.https://www.mk.co.kr/news/society/view/2018/05/294952/ â†©4.https://web.archive.org/web/20180619040311/http://www.munhwa.com/news/view.html?no=2018061101070103011001 â†©5.https://ko.wikipedia.org/wiki/2017ë…„_ëŒ€í•œë¯¼êµ­ â†©6.https://ko.wikipedia.org/wiki/2018ë…„_ëŒ€í•œë¯¼êµ­ â†©","link":"/2019/07/25/Naver-News-Comments-Analysis-(1)/"},{"title":"Naver News Comment Analysis (3)","text":"TL;DR ì–´ë·°ì €ëŠ” ì¡´ì¬í•œë‹¤. í•˜ì§€ë§Œ ê·¸ë“¤ì„ ì™„ì „íˆ í†µì œí•˜ê³  ì œê±°í•˜ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•˜ë‹¤. ê·¸ë ‡ë‹¤ë©´ ì–´ë·°ì €ë¥¼ ë§‰ëŠ” ê²ƒì— ì§‘ì¤‘í•˜ì§€ ë§ê³ , ì–´ë·°ì§•ì€ ë‚´ë²„ë ¤ë‘ë˜ ê·¸ íš¨ê³¼ë¥¼ ë­í‚¹ ì‹œìŠ¤í…œì„ ë°”ê¾¸ì–´ ì™„í™”ì‹œí‚¤ëŠ” ë°©ë²•ì€ ì–´ë–¨ê¹Œ? ë„¤ì´ë²„ ë‰´ìŠ¤ í”Œë«í¼ì—ì„œëŠ” ìˆœê³µê°ê³¼ ê³µê°ë¹„ìœ¨ì„ í†µí•´ ê³µê°ì´ ë§ì€ ì˜ê²¬ì„ ìƒìœ„ì— ë­í¬ì‹œí‚¤ê³  ìˆë‹¤. ê°ê°ì˜ ì•Œê³ ë¦¬ì¦˜ì´ ê°€ì§„ ê²°í•¨ë„ ë¬¸ì œì§€ë§Œ, ê³¼ì—° ì •ì¹˜ì  ì˜ê²¬ì˜ ì¥ì—ì„œ ê³µê°ì´ ë§ì€ ì˜ê²¬ë§Œì´ ìš°ë¦¬ê°€ ë“£ê³  ë³´ì•„ì•¼ í•  ì˜ê²¬ì¼ê¹Œ? íŠ¹íˆë‚˜ ì–´ë·°ì§•ì´ ìˆëŠ” ìƒí™©ì—ì„œ ê³µê°ìˆ˜ê°€ ë§ì€ ì˜ê²¬ì€ ë”ìš± íšì¼í™”ëœ ì£¼ì¥ì„ í¼ì¹  ìˆ˜ ë°–ì— ì—†ìœ¼ë©° ëŒ€ì¤‘ì€ í¸í–¥ëœ ì˜ê²¬ë§Œ ì ‘í•˜ê²Œ ë˜ì–´ ë¬´ì˜ì‹ì ìœ¼ë¡œ ë‹¤ì–‘í•œ ì‚¬ê³ ì— ëŒ€í•œ ê°€ëŠ¥ì„±ì„ ì°¨ë‹¨ë°›ëŠ”ë‹¤. ê·¸ë˜ì„œ ì´ë²ˆ ê¸€ì—ì„œëŠ” ë‹¤ì–‘í•œ ì˜ê²¬ì´ ìƒìœ„ì— ë­í¬ë  ìˆ˜ ìˆëŠ” sorting algorithmë“¤ì„ ì œì•ˆí•œë‹¤. redditê³¼ yelp ë“±ì—ì„œ ì‚¬ìš©í•˜ê³  ìˆëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ë¹„ë¡¯í•˜ì—¬, ë…¼ìŸì ì¸ ëŒ“ê¸€ì´ ìƒìœ„ì— ìœ„ì¹˜í•  ìˆ˜ ìˆëŠ” ì•Œê³ ë¦¬ì¦˜, ê·¸ë¦¬ê³  ë¹„ê³µê°ì´ ë§ì€ ëŒ“ê¸€ì— ë” ë†’ì€ ì ìˆ˜ë¥¼ ë¶€ì—¬í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ 3ê°€ì§€ë¥¼ ì†Œê°œí•œë‹¤. Introduction ëª¨ë‘ê°€ ë‹¤ ì•Œê³  ìˆëŠ” ì‚¬ì‹¤ì´ì§€ë§Œ, ì–´ë·°ì €ëŠ” ì¡´ì¬í•œë‹¤. ë“œë£¨í‚¹ê³¼ ì—ì„œ ë‚˜ì˜¨ ê²°ë¡ ìœ¼ë¡œë„ ë’·ë°›ì¹¨ë  ìˆ˜ ìˆì§€ë§Œ íŠ¸ìœ„í„°ì— m.news.naver.com/comment ë¼ê³  ê²€ìƒ‰í•˜ê¸°ë§Œ í•´ë„ ì•„ë˜ì™€ ê°™ì´ ëŒ“ê¸€ ì¡°ì‘ì˜ í”ì ì„ ì‰½ê²Œ ë°œê²¬í•  ìˆ˜ ìˆë‹¤. ì´ë ‡ë“¯ ì‰½ê²Œ ì–´ë·°ì €ì˜ ì¡´ì¬ë¥¼ ì°¾ì„ ìˆ˜ ìˆìŒì—ë„ ë„¤ì´ë²„ê°€ ì–´ë·°ì €ë¥¼ ì¡ì§€ ì•ŠëŠ” ì´ìœ ëŠ” ê·¸ ì¼ì´ ìƒê°ì²˜ëŸ¼ ì‰¬ìš´ ì¼ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì´ë‹¤. nì´ˆ ì•ˆì— ì—¬ëŸ¬ë²ˆ ê³µê°ê³¼ ë¹„ê³µê°ì„ ì§€ì†ì ìœ¼ë¡œ ë°›ì€ ëŒ“ê¸€ì€ ì–´ë·°ì§•ì˜ ê²°ê³¼ë¡œ ì˜ì‹¬í•œë‹¤. ê·¸ ëŒ“ê¸€ì„ ì§€ì›Œì•¼ í• ê¹Œ? ë§Œì•½ ëŒ“ê¸€ì„ ì“´ ìœ ì €ê°€ ì–´ë·°ì €ê°€ ì•„ë‹ˆì—ˆë‹¤ë©´ ë¬¸ì œê°€ ë  ìˆ˜ ìˆë‹¤. ì‚¬í›„ ë¶„ì„ì„ í†µí•´ ì–´ë·°ì €ë¡œ ì˜ì‹¬ë˜ëŠ” ëŒ“ê¸€ì˜ ë‚´ìš©ì„ ì§€ìš°ëŠ” ë°©ë²•ì€ ì–´ë–¨ê¹Œ? ë‰´ìŠ¤ë¼ëŠ” ë§¤ì²´ì˜ íŠ¹ì„± ìƒ ì‹œê°„ì´ ì§€ë‚œ ê¸°ì‚¬ëŠ” ì‚¬ëŒë“¤ì´ ê´€ì‹¬ìˆê²Œ ë³´ì§€ ì•ŠëŠ”ë‹¤. ê·¸ëŸ¬ë¯€ë¡œ ì´ ë°©ë²•ì€ ì–´ë·°ì €ë¥¼ ë§‰ëŠ”ë‹¤ê³  ë³¼ ìˆ˜ ì—†ë‹¤. ë¶„ì„ì„ í†µí•´ ì–´ë·°ì €ë¼ê³  ê°•í•˜ê²Œ ì˜ì‹¬ë˜ëŠ” ìœ ì €ë¥¼ ì°¨ë‹¨í•œë‹¤ê³  í•˜ë”ë¼ë„ ìƒˆë¡œìš´ íŒ¨í„´ìœ¼ë¡œ ì–´ë·°ì§•ì„ í•˜ëŠ” ìœ ì €ë“¤ì´ ìƒê²¨ë‚  ê²ƒì´ë‹¤. ì–´ë·°ì €ì˜ ê¸°ì¤€ì„ ì„¸ìš°ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ë°˜ë©´ ìƒˆë¡œìš´ ë°©ì‹ìœ¼ë¡œ ì–´ë·°ì§•ì„ í•˜ëŠ” ê²ƒì€ ì¢€ ë” ì‰½ê¸° ë•Œë¬¸ì— ì´ë ‡ê²Œ ë¬¼ê³  ë¬¼ë¦¬ëŠ” ì‹¸ì›€ì€ ì–´ë·°ì €ì—ê²Œ ìœ ë¦¬í•˜ë‹¤. ê·¸ë ‡ë‹¤ë©´ ì–´ë·°ì €ë¥¼ ì°¨ë‹¨í•˜ëŠ” ê²ƒì—ë§Œ ì§‘ì¤‘í•˜ì§€ ë§ê³ , ì–´ë·°ì§•ì€ ë‚´ë²„ë ¤ë‘ë˜ ê·¸ íš¨ê³¼ë¥¼ ì™„í™”ì‹œí‚¤ëŠ” ë°©ë²•ì€ ì–´ë–¨ê¹Œ? ì§€ê¸ˆ ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ ë­í‚¹ ë°©ì‹ì€ ê·¸ê²ƒì´ ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì— ë¹„í•´ ë„ˆë¬´ ê°„ë‹¨í•˜ê³  ë‹¨í¸ì ì´ë‹¤. êµ¬ê¸€ì˜ ê²€ìƒ‰ ë­í‚¹ì´ ì‹ ë¢°ë„ë¥¼ ê°€ì§€ê³  ìˆëŠ” ì´ìœ ëŠ” ìƒìœ„ì— ë­í¬ëœ ê¸€ì´ 'ì¡°ì‘â€™ì„ í†µí•´ ë§Œë“¤ì–´ì§€ì§€ ì•Šì•˜ë‹¤ëŠ” ì  ë•Œë¬¸ì¼ ê²ƒì´ë‹¤. ê·¸ ì´ìœ ëŠ” ì •ë³´ê°€ ë˜ëŠ” ê¸€ì— ëŒ€í•œ ì •ë³´ëŸ‰, í’ˆì§ˆ ê¸°ì¤€ì´ ë³´ë‹¤ ì—„ê²©í•˜ê³  ë‹¨í¸ì ì¸ ë©´ìœ¼ë¡œë§Œ ìˆœìœ„ë¥¼ ë§¤ê¸°ì§€ ì•Šê¸° ë•Œë¬¸ì´ë‹¤. ë§Œì•½ êµ¬ê¸€ ë­í‚¹ì´ ì›¹ë¬¸ì„œì˜ í´ë¦­ìˆ˜ë¡œë§Œ ë˜ì–´ ìˆì—ˆë‹¤ë©´ ì–´ë• ì„ê¹Œ? ë§ì€ ê¸°ì—…ë“¤ì´ ë³¸ì¸ì˜ í™ˆí˜ì´ì§€ë¥¼ ìƒìœ„ì— ë­í¬ì‹œí‚¤ê¸° ìœ„í•´ ë§ì€ ì¡°ì‘ì´ ì¼ì–´ë‚¬ì„ ê²ƒì´ë‹¤. ê·¸ë˜ì„œ ì´ë²ˆ ê¸€ì—ì„œëŠ” ê·¸ë ‡ê²Œ ê°„ë‹¨í•˜ë‹¤ê³ ëŠ” ë³¼ ìˆ˜ ì—†ëŠ” ë‹¤ë¥¸ ë­í‚¹ algorithmì— ëŒ€í•´ ì†Œê°œí•´ë³´ë ¤ê³  í•œë‹¤. í˜„ì¬ ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ ë­í‚¹ ë°©ì‹ ì¤‘ ìˆœê³µê°ìˆœ, ê³µê°ë¹„ìœ¨ìˆœ, ë‹µê¸€ìˆœì˜ í•œê³„ì ì„ ì‚´í´ë³´ê³  redditê³¼ yelpì—ì„œ ì‹ ë¢°ë„ìˆê²Œ ì“°ì´ëŠ” best ë­í‚¹ê³¼ ìƒˆë¡œìš´ ê´€ì ì˜ controversial ë­í‚¹ algorithmì„ ì†Œê°œí•œë‹¤. Naver News Comment Sorting System Sorting Algorithms 2019ë…„ 9ì›” ê¸°ì¤€, ì´ 5ê°œì˜ ì •ë ¬ë°©ìœ¼ë¡œ ì„œë¹„ìŠ¤ë˜ê³  ìˆë‹¤. ë“œë£¨í‚¹ ë…¼ë€ ì´í›„ ëŒ“ê¸€ ì œê³µ ì—¬ë¶€ì™€ ì •ë ¬ë°©ì‹ì„ ì–¸ë¡ ì‚¬ê°€ ì„ íƒí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë°”ë€Œì—ˆë‹¤. ìˆœê³µê°ìˆœ: ê³µê° - ë¹„ê³µê°[1] ê³µê°ë¹„ìœ¨ìˆœ: ê³µê° / (ê³µê° + ë¹„ê³µê°) ë‹µê¸€ìˆœ ìµœì‹ ìˆœ ê³¼ê±°ìˆœ ì´ ì¤‘, ëŒ“ê¸€ì— ëŒ€í•œ ì‚¬ìš©ìì˜ ì¸í„°ë™ì…˜(ê³µê°, ë¹„ê³µê°, ë‹µê¸€)ìœ¼ë¡œ ìˆœìœ„ë¥¼ ë§¤ê¸°ëŠ” ìˆœê³µê°ìˆœ, ê³µê°ë¹„ìœ¨ìˆœ, ë‹µê¸€ìˆœì— ëŒ€í•œ ë¬¸ì œì ì„ í•˜ë‚˜ì”© ì§šì–´ë³´ê³ ì í•œë‹¤. Limitations ìˆœê³µê°ìˆœ ìˆœê³µê°ìˆœì€ ìš°ë¦¬ì˜ ì§ê´€ê³¼ ë²—ì–´ë‚˜ëŠ” ë­í‚¹ì´ë¼ëŠ” ì ì—ì„œ í•œê³„ê°€ ìˆë‹¤. ìš°ë¦¬ëŠ” ì ˆëŒ€ì ì¸ ê³µê° ìˆ˜ì¹˜ë³´ë‹¤, ê³µê°ë¹„ìœ¨ë¡œ ëŒ“ê¸€ì˜ ì‹ ë¢°ë„ë¥¼ í‰ê°€í•œë‹¤. ì•„ë˜ì˜ ì‚¬ë¡€ëŠ” ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€[2]ì˜ ì‹¤ì œ ì˜ˆì‹œì´ë‹¤. ì²«ë²ˆì§¸ ëŒ“ê¸€ì€ ìˆœê³µê° 344ê°œ(= 455 - 111) ë¡œ, 300ê°œ(= 316 - 16)ì˜ ìˆœê³µê°ì„ ì§€ë‹ˆëŠ” ë‘ë²ˆì§¸ ëŒ“ê¸€ë³´ë‹¤ ë” ë†’ì€ ìˆœìœ„ì— ìë¦¬í•œë‹¤. í•˜ì§€ë§Œ ê°ê°ì˜ ëŒ“ê¸€ì˜ ê³µê°ë¹„ìœ¨ì€ 80.4%(= 455 / (455 + 11)) ë¡œ, ë‘ë²ˆì§¸ ëŒ“ê¸€ì˜ ê³µê°ë¹„ìœ¨ì¸ 95.2% (= 316 / (316 + 16)) ë³´ë‹¤ ì‘ë‹¤. ê³µê°ë¹„ìœ¨ìˆœ ì•ì„œ ì„¤ëª…í•œ ê²ƒì²˜ëŸ¼ ê³µê°ë¹„ìœ¨ìˆœì´ ì¢€ ë” ìš°ë¦¬ì˜ ì§ê´€ê³¼ ìœ ì‚¬í•œ ì²™ë„ì´ë‹¤. í•˜ì§€ë§Œ ê³µê°ë¹„ìœ¨ìˆœì€ ì „ì²´ ê³µê°, ë¹„ê³µê° ìˆ˜ê°€ ì ì„ ë•Œ ë¬¸ì œê°€ ëœë‹¤. ì†Œìˆ˜ì˜ ì‚¬ëŒë“¤ì—ê²Œë§Œ ë…¸ì¶œëœ ëŒ“ê¸€ì€ ê³µê°ê³¼ ë¹„ê³µê°ì˜ ê°œìˆ˜ê°€ ëª¨ë‘ ì ì–´ 100% ë¼ëŠ” ê³µê°ë¹„ìœ¨ì´ ì‰½ê²Œ ë§Œë“¤ì–´ì§€ëŠ” ë°˜ë©´, ì—¬ëŸ¬ ëª…ì—ê²Œ ë…¸ì¶œëœ ëŒ“ê¸€ì€ í•˜ë‚˜ì˜ ë¹„ê³µê°ë§Œ ë‹¬ë¦¬ë”ë¼ë„ ê·¸ë³´ë‹¤ ë‚®ì€ ê³µê°ë¹„ìœ¨ì„ ì§€ë‹ˆê²Œ ë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•œë‹¤. ì•„ë˜ì˜ ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ ì˜ˆì‹œ[3]ì—ì„œ ê³µê°ìˆ˜ê°€ 20, ë¹„ê³µê°ìˆ˜ê°€ 0ì¸ ëŒ“ê¸€ì´ ë¹„ê³µê°ì„ ì „í˜€ ë°›ì§€ ì•Šì•„ ê³µê°ë¹„ìœ¨ 100%ê°€ ë˜ì–´ ë” ë§ì€ ì‚¬ëŒë“¤ì´ ì½ê³  ê³µê°ì„ í‘œí•œ ê³µê°ìˆ˜ 1021, ë¹„ê³µê°ìˆ˜ 58ì¸ ëŒ“ê¸€ë³´ë‹¤ ë” ìƒë‹¨ì— ìœ„ì¹˜í•œë‹¤. ë‹µê¸€ìˆœ ì—¬ëŸ¬ ê°œì˜ ë‹µê¸€ì´ ë‹¬ë¦¬ëŠ” ëŒ“ê¸€ì€ ì£¼ë¡œ ì¼ì° ë‚¨ê²¨ì§„ ëŒ“ê¸€ ì¤‘ì— ì¸ì‹ ê³µê²©ì´ë‚˜ ë‰´ìŠ¤ ì™¸ ì£¼ì œì— ëŒ€í•œ ëŒ“ê¸€ì¸ ê²½ìš°ê°€ ë§ë‹¤. ëŒ“ê¸€ ê³µê°„ì—ì„œëŠ” ëª…í™•í•œ ë‚´ìš©ìœ¼ë¡œ êµ¬ì„±ëœ ëŒ“ê¸€ì— ëŒ€í•´ì„œëŠ” ëŒ€ëŒ“ê¸€ ë³´ë‹¤ë„ ê³µê° í˜¹ì€ ë¹„ê³µê°ìœ¼ë¡œ ë³¸ì¸ì˜ ì£¼ì¥ì„ í‘œì‹œí•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ë‹¤. ê·¸ëŸ¬ë‚˜ ê°ì •ì ìœ¼ë¡œ ì“°ì—¬ì§„ ëŒ“ê¸€ì€ ê·¸ ëŒ“ê¸€ì— ìê·¹ì„ ë°›ì€ ë‹¤ë¥¸ ì‚¬ìš©ìì˜ ë‹µê¸€ë¡œ ì´ì–´ì§€ê³  ë˜ë¯€ë¡œ ë‹µê¸€ ê°œìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëŒ“ê¸€ì„ ì •ë ¬í•˜ë©´ ë‰´ìŠ¤ ë‚´ìš©ê³¼ëŠ” ë¬´ê´€í•œ ìê·¹ì ì¸ ëŒ“ê¸€ë“¤ì´ ìš°ì„ ì ìœ¼ë¡œ ë…¸ì¶œëœë‹¤. ë˜í•œ ì¼ì° ì“°ì—¬ì§„ ëŒ“ê¸€ì¼ìˆ˜ë¡ ë” ë§ì€ ì‚¬ëŒë“¤ì—ê²Œ ë…¸ì¶œë  ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë¯€ë¡œ ëŒ€ë¶€ë¶„ ë‰´ìŠ¤ ì‘ì„± ì‹œì ê³¼ ê°€ê¹Œìš´ ëŒ“ê¸€ì´ ìƒìœ„ì— ë­í¬ëœë‹¤. ë­í‚¹ algorithmìœ¼ë¡œ ë³´ê¸°ì—ëŠ” ì •ë ¬ ê¸°ì¤€ì´ controllableí•˜ì§€ ì•Šìœ¼ë©° ëŒ“ê¸€ì˜ ìœ ìµí•œ ì†ì„±ì´ ë†’ê²Œ í‰ê°€ë˜ì–´ ì •ë ¬ë˜ëŠ” ë­í‚¹ì´ë¼ê³  ë³¼ ìˆ˜ ì—†ë‹¤. ì•„ë˜ì˜ ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ ì˜ˆì‹œ[4]ë¥¼ ë³´ë©´ vote ìˆ˜ê°€ ë§ì§€ ì•Šì•„ë„, ê³µê°ìˆ˜ê°€ ì „í˜€ ì—†ê³  ë¹„ê³µê°ë§Œ ë°›ë”ë¼ë„ top 10ì— ìœ„ì¹˜í•  ìˆ˜ ìˆë‹¤. Reddit Comment Sorting Algorithms ëŒ“ê¸€ì´ í™œë°œí•˜ê²Œ ìƒì„±ë˜ëŠ” í”Œë«í¼ì€ ë¹„ë‹¨ ë„¤ì´ë²„ ë‰´ìŠ¤ ë¿ë§Œì€ ì•„ë‹ˆë‹¤. ë„¤ì´ë²„ ì‡¼í•‘, ë„¤ì´ë²„ í˜¸í…”, ë§ê³  í”Œë ˆì´íŠ¸, reddit, stackoverflow, yelp, amazon ë“±ì˜ ë‹¤ì–‘í•œ í”Œë«í¼ì—ì„œ ìˆ˜ì§‘ë˜ë©° í”Œë«í¼ì—ì„œëŠ” ë‹¤ì‹œ ì´ ë°ì´í„°ë¥¼ ê°€ê³µí•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ìœ ìµí•œ ì •ë³´ë¥¼ ì œê³µí•œë‹¤. ê·¸ ì¤‘ì—ì„œë„ redditì˜ ë­í‚¹ ì‹œìŠ¤í…œì´ ì•ì„œ ë¹„íŒí–ˆë˜ ìˆœê³µê°ìˆœ, ê³µê°ë¹„ìœ¨ìˆœì˜ í•œê³„ë¥¼ ê·¹ë³µí•œ sorting algorithmì„ ì œê³µí•˜ê³  ìˆê¸°ì— ìì„¸íˆ ì‚´í´ë³´ë ¤ê³  í•œë‹¤. redditì˜ ë­í‚¹ ë°©ì‹ì—ëŠ” best, top, new, controversial, old, q&amp;aê°€ ìˆë‹¤. topì´ ìˆœê³µê°ìˆœ, newê°€ ìµœì‹ ìˆœ, oldê°€ ê³¼ê±°ìˆœì´ë‹¤. Best Best ranking[5][6] ì€ Wilson score[7]ë¡œ ì •ë ¬í•œ ê²ƒìœ¼ë¡œ, ê³µê°ë¹„ìœ¨ìˆœì˜ ë‹¨ì ìœ¼ë¡œ ì–¸ê¸‰ë˜ì—ˆë˜, ì „ì²´ voteìˆ˜ê°€ ì ì€ ìƒí™©ì„ smoothingì‹œì¼œì¤€ algorithmì´ë‹¤. redditë¿ ì•„ë‹ˆë¼ yelpì—ì„œë„ ì‚¬ìš©í•œë‹¤ê³  í•œë‹¤[8]. Wilson scoreëŠ” ì£¼ì–´ì§„ positiveì™€ negative voteê°€ binomial distributionì„ ë”°ë¥¸ë‹¤ê³  ê°€ì •í–ˆì„ ë•Œ, positive ë°œìƒ í™•ë¥ ì„ 95% ì‹ ë¢°êµ¬ê°„ì˜ ìµœì†Œê°’ìœ¼ë¡œ ì¶”ì •í•œ ê°’ì´ë‹¤. ë™ì „ ë’¤ì§‘ê¸° ìƒí™©ì—ì„œ ì•ë©´ì„ positive, ë’·ë©´ì„ negativeë¼ê³  í•˜ì. në²ˆ ë˜ì§„ í›„ ì•ë©´ì´ ë‚˜ì˜¬ í™•ë¥ (\\(p\\))ì„ ì¶”ì •í•  ë•Œ nì´ ì¶©ë¶„íˆ í° ê²½ìš° central limit theoremì— ì˜í•´ \\(p\\)ëŠ” normal distributionì„ ë”°ë¥¸ë‹¤. ë”°ë¼ì„œ 95%ì˜ ì‹ ë¢°ë„ë¡œ \\(p\\)ë¥¼ ì¶”ì •í•˜ì—¬ \\(p\\)ì˜ ìµœì†Œê°’, ìµœëŒ€ê°’ì„ êµ¬í•  ìˆ˜ ìˆê³  ì´ ë•Œ ìµœì†Œê°’ì´ Wilson scoreê°€ ëœë‹¤. ìì„¸í•œ ìˆ˜ì‹ì€ Appendix Aì— ì •ë¦¬í•´ë‘ì—ˆë‹¤. \\[ w^- = max(0, \\frac{2n\\hat{p} + z^2 - z\\sqrt{z^2 + 4n\\hat{p}(1-\\hat{p})}}{2(n+z^2)})=\\text{wilson score} \\] ìœ„ì˜ ì‹ì„ í•¨ìˆ˜ë¡œ êµ¬í˜„í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. import numpy as np# ref: http://www.evanmiller.org/how-not-to-sort-by-average-rating.htmldef best(up, down): try: z = 1.96 # 95% confidence level n = up + down p_up = up / n p_down = 1 - p_up denominator = 2 * (n + z**2) numerator = 2 * n * p_up + z**2 - z * np.sqrt(z**2 + 4 * n * p_up * p_down) lower = numerator / denominator except ZeroDivisionError as e: lower = 0 return max(0, lower) ì•„ë˜ì˜ ì˜ˆì‹œëŠ” ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ì— Best ranking algorithmì„ ì ìš©í•´ë³¸ ê²°ê³¼ì´ë‹¤. ê³µê°ë¹„ìœ¨ìˆœ ì •ë ¬ì´ì—ˆë‹¤ë©´ &quot;ì›ì¹™ëŒ€ë¡œë§Œ í•˜ì‹œë©´ ë©ë‹ˆë‹¤ ì—­ì‚¬ì— ë¶€ë„ëŸ½ì§€ ì•Šê²Œ ì˜ í•´ ì£¼ì„¸ìš”&quot;ëŠ” 1000ê°œ ì´ìƒì˜ voteë¥¼ ê°€ì§„ &quot;ë²•ëŒ€ë¡œ í•´ë¼ ë²•ì€ ë§Œì¸ ì•ì— í‰ë“±í•˜ë‹¤&quot;ëŠ” ëŒ“ê¸€ì„ ì œì¹˜ê³  ìƒìœ„ì— ë­í¬ë˜ì—ˆì„ ê²ƒì´ë‹¤. í•˜ì§€ë§Œ Best ì •ë ¬ë°©ì‹ì—ì„œëŠ” vote ìˆ˜ê°€ ì ì€ ê²½ìš° ì•½ê°„ì˜ penaltyë¥¼ ë°›ê¸° ë•Œë¬¸ì— í•˜ìœ„ì— ë­í¬ë˜ì—ˆë‹¤. MB â€˜ì •ì¹˜ë³´ë³µâ€™ ë°˜ë°œì— ë¬¸ë¬´ì¼ ì´ì¥ â€œë²•ì  ì ˆì°¨ëŒ€ë¡œ í•˜ê² ë‹¤â€[9] comments ê³µê°ìˆ˜ ë¹„ê³µê°ìˆ˜ best score ê³µê°ë¹„ìœ¨ ë²•ëŒ€ë¡œ í•´ë¼ ë²•ì€ ë§Œì¸ ì•ì— í‰ë“±í•˜ë‹¤ 1091 55 0.938 0.952006980803 ë²•ëŒ€ë¡œ í•˜ë©´ ì‚¬í˜•ì¸ë° !! 562 39 0.936 0.935108153078 ì œë°œ ë²•ëŒ€ë¡œë§Œ í•´ì£¼ì„¸ìš”. ê·¸ë˜ë„ ë‚˜ë¼ë¥¼ ì§€ì˜¥ìœ¼ë¡œ ë§Œë“  ì£„ëŠ” ë¬¼ì„ ë²•ë„ ì—†ë‹¤. ì´ ì•…ë§ˆì•¼!!! 252 14 0.933 0.947368421053 ì§€ê¸ˆê¹Œì§€ ë°˜ë°œí•˜ê³  ë‚˜ì„œ ì‚´ì•„ë‚¨ì€ ë„˜ì„ ëª»ë´¤ë‹¤. 565 38 0.933 0.936981757877 í˜“ë°”ë‹¥ëª‡ë²ˆ ë‚¼ë¦„ê±°ë¦´ê¹Œë‚˜í–ˆë”ë‹ˆ ì°”ë ¸ë‚˜ë³´ë„¤ã…ã… 595 37 0.932 0.941455696203 ë³¸ì¸ì´ êµ¬ë¦°ì§“ì„ í–ˆìœ¼ë‹ˆê¹Œ ë¨¼ì € ë°œê´‘í•˜ëŠ”ê±°ê² ì§€â€¦ 686 43 0.931 0.941015089163 ë²•ëŒ€ë¡œ í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ì •ì˜ë¡œìš´ ì ˆì°¨ëŠ” ì„¸ìƒì— ì—†ë‹¤ 4146 317 0.926 0.928971543805 ë‹¹ì—°íˆ ë²•ëŒ€ë¡œ í•˜ì…”ì•¼ì£  296 14 0.921 0.954838709677 ì›ì¹™ëŒ€ë¡œë§Œ í•˜ì‹œë©´ ë©ë‹ˆë‹¤ ì—­ì‚¬ì— ë¶€ë„ëŸ½ì§€ ì•Šê²Œ ì˜ í•´ ì£¼ì„¸ìš” 302 13 0.921 0.95873015873 ë²•ëŒ€ë¡œ í•©ì‹œë‹¤ 919 51 0.92 0.947422680412 ê¸°ë³¸ì ìœ¼ë¡œ ê³µê°ìˆ˜ê°€ ë§ì€ ëŒ“ê¸€ì„ ìƒìœ„ì— ë­í¬ì‹œí‚¤ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ê¸° ë•Œë¬¸ì— ì–´ë·°ì§• ì‘ì—…ìœ¼ë¡œ ê³µê°ìˆ˜ê°€ ë¶€í’€ë ¤ì§„ ëŒ“ê¸€ì´ top 10 ë°–ìœ¼ë¡œ ë°€ë ¤ë‚˜ì§€ëŠ” ëª»í•œë‹¤. í•˜ì§€ë§Œ voteìˆ˜ê°€ ì ë”ë¼ë„ ê²½í–¥ì„±ì„ íŒŒì•…í•´ ëŒ“ê¸€ì„ ì •ë ¬ì‹œí‚¤ê¸° ë•Œë¬¸ì— ë‹¨ìˆœí•œ ìˆœê³µê°ì´ë‚˜ ê³µê°ë¹„ìœ¨ìˆœìœ¼ë¡œëŠ” í•˜ìœ„ê¶Œì— ìˆë˜ ëŒ“ê¸€ì´ ìƒìœ„ê¶Œì— ìœ„ì¹˜í•  ê¸°íšŒë¥¼ ì¦ê°€ì‹œì¼°ë‹¤. ì–´ë·°ì € ì…ì¥ì—ì„œëŠ” ì‰½ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ì •ë ¬ë°©ì‹ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì— ì¡°ì‘ì´ ì–´ë ¤ì›Œì§ˆ ê²ƒì´ë‹¤. ì–´ë·°ì§•ì„ í•  ë•Œ ê³ ì˜ë¡œ ê³µê°ê³¼ ë¹„ê³µê°ì„ ì„ì–´ì„œ í•´ë‹¹ ëŒ“ê¸€ì„ ìƒìœ„ì— ë­í¬ì‹œí‚¤ëŠ”ë°, Best ì •ë ¬ì´ë¼ë©´ &quot;ì ë‹¹&quot;í•œ ë¹„ìœ¨ì„ ë§ì¶”ê¸° ê¹Œë‹¤ë¡œì›Œì§ˆ ê²ƒì´ë‹¤. Controversial controversial[10]ì€ ì´ë¦„ ê·¸ëŒ€ë¡œ, ê³µê°ê³¼ ë¹„ê³µê°ì´ íŒ½íŒ½í•˜ê²Œ ë§ì„œëŠ” ëŒ“ê¸€ì„ ìƒìœ„ì— ìœ„ì¹˜ì‹œí‚¤ë ¤ëŠ” ì•Œê³ ë¦¬ì¦˜ì´ë‹¤. ë‹¨ìˆœíˆ íŒ½íŒ½í•˜ê¸°ë§Œ í•˜ë©´ ê³µê°ê³¼ ë¹„ê³µê°ì´ 1:1ì¸ ìƒí™©ê³¼ 10:10ì¸ ìƒí™©ì´ ê°™ë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆê¸°ì— voteìˆ˜ë„ sorting algorithmì— í¬í•¨ì‹œì¼œì„œ 10:10ì´ 1:1ì¸ ìƒí™©ë³´ë‹¤ ë” controversialí•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì¡Œë‹¤. ì•„ë˜ì˜ ì‹ì—ì„œ upvoteëŠ” ê³µê°ì„, downvoteëŠ” ë¹„ê³µê°ì„ ì˜ë¯¸í•œë‹¤. upvoteì™€ downvoteì˜ ì°¨ì´ê°€ ê°™ì•„ì„œ ë¶„ëª¨ê°€ ê°™ì•„ì§„ ê²½ìš°ì—ëŠ” ê·¸ í¬ê¸°ê°€ í° ìª½ì´ ë†’ê³ , voteì˜ í¬ê¸°ê°€ ê°™ì€ ê²½ìš°ì—ëŠ” ì°¨ì´ê°€ ì‘ì€ ìª½ì´ ë†’ë‹¤. \\[ \\text{controversial} = \\frac{match \\times log(match + 1)}{| upvote - downvote | + 1},\\text{ where }match=min(upvote, downvote) \\] pythonìœ¼ë¡œ êµ¬í˜„í•œ ì‹ì´ë‹¤. import mathdef controversial(upvote, downvote): match = min(upvote, downvote) top = match * math.log(match + 1) bottom = abs(upvote - downvote) + 1 return float(top) / bottom ì¢€ ë” ì§ê´€ì ì¸ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ ê°€ê³µí•œ ì•„ë˜ì˜ ì˜ˆì‹œë¥¼ ë³´ì. upvote downvote controversial score 1001 1000 3454.38 999 1000 3450.42 100 100 461.52 101 100 230.76 1000 700 15.24 130 100 14.89 100 130 14.89 1 1 0.69 1 2 0.35 upvote, downvoteì˜ ë¹„ìœ¨ì´ ë¹„ìŠ·í•œ ëŒ“ê¸€ ìˆœì„œë¡œ ì •ë ¬ë˜ê³ , ê·¸ ë¹„ìœ¨ ë‚´ì—ì„œëŠ” vote ìˆ˜ê°€ í° ëŒ“ê¸€ì´ ë” ìœ„ì— ë†“ì´ê²Œ ëœë‹¤. controversial algorithmì„ ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ì— ì ìš©í•´ë³´ì•˜ë‹¤. ì˜ˆìƒëŒ€ë¡œ ê³µê°ê³¼ ë¹„ê³µê° ìˆ˜ì¹˜ê°€ ë¹„ìŠ·í•˜ë©´ì„œë„ voteìˆ˜ê°€ ë§ì€ ëŒ“ê¸€ì´ ê°€ì¥ ë¨¼ì € ë³´ì¸ë‹¤. voteìˆ˜ê°€ ì‘ì€ ì´ìœ ëŠ” ì´ë¯¸ ìˆœê³µê° ë…¸ì¶œë¡œ ì¸í•´ voteë¥¼ ë°›ì„ ê¸°íšŒë¥¼ ë°•íƒˆë‹¹í•œ ëŒ“ê¸€ë“¤ì´ê¸° ë•Œë¬¸ì´ë‹¤. ìˆ˜ì¹˜ì™€ëŠ” ë¬´ê´€í•˜ê²Œ top 10 ëŒ“ê¸€ì˜ ë‚´ìš©ì€ ì–¼ë§ˆë‚˜ controversialí•˜ê²Œ êµ¬ì„±ë˜ì–´ ìˆëŠ”ì§€ ì •ì„±ì ìœ¼ë¡œ í‰ê°€í•´ë³´ì•˜ë‹¤. ë³´ë„ìë£Œì— ëŒ€í•œ ì°¬ì„±ì€ í‘¸ë¥¸ìƒ‰, ë°˜ëŒ€ëŠ” ë¶‰ì€ìƒ‰ , ì• ë§¤í•œ ë¬¸ì¥ì€ í‘œê¸°í•˜ì§€ ì•Šì•˜ë‹¤. controversialí•˜ë‹¤ë©´ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì£¼ì œì— ëŒ€í•´ ì°¬ì„±ê³¼ ë°˜ëŒ€ê°€ ê³¨ê³ ë£¨ ì„ì—¬ìˆì–´ì•¼ í•  ê²ƒì´ë‹¤. ì•„ë²  â€œí•œë¯¸êµ°ì‚¬í›ˆë ¨ ì˜ˆì •ëŒ€ë¡œâ€â€¦æ–‡ëŒ€í†µë ¹ â€œë‚´ì •ë¬¸ì œ ê±°ë¡  ê³¤ë€â€(ì¢…í•©)[11] userId comments ê³µê°ìˆ˜ ë¹„ê³µê°ìˆ˜ user 1 ëŒ€í†µë ¹ ê°í•˜, â€˜ì‚¬ë“œ ë¬¸ì œâ€™ ê°–ê³  ê±°í’ˆë¬´ëŠ” ì¤‘êµ­ì—ë„ ë‚´ì • ê°„ì„­ì´ë¼ê³  ê±°ì¹¨ ì—†ì´ ë§ì”€í•´ì£¼ì„¸ìš” 26 26 user 2 ì´ì œëŠ” í•œë¯¸ì¼êµ°ì‚¬í›ˆë ¨ì„ í•´ì•¼ í•œë‹¤. 81 85 user 3 ê·¼ë° ì™œ ì¤‘êµ­í•œí…ŒëŠ” ëŒ€ë†“ê³  ë‚´ì •ê°„ì„­ ë°›ëŠ”ê±°ì£ , ëŒ€í†µë ¹ë‹˜? ì¹˜ìš•ìŠ¤ëŸ¬ì› ë˜ ì¡°ì„ ì‹œëŒ€ê°€ ê·¸ë¦¬ìš´ê±´ê°€ìš”? 22 22 user 4 ë´ë¼ ã…‹ã…‹ã…‹ \\ní•œë¯¸ì—°í•©í›ˆë ¨ ì—°ê¸°í•˜ì§€?\\në¯¸êµ° ì² ìˆ˜ ì–˜ê¸°ë‚˜ì˜¨ë‹¤ ë°±í¼ ã…‹ã…‹ã…‹ã…‹ \\në¯¸êµ°ì² ìˆ˜í•˜ë©´ ë² íŠ¸ë‚¨ê¼´ ë‚˜ëŠ”ê±°ì•¼ ã…‹ã…‹ã…‹ \\nê°œë¼ì§€ë“¤ì•„ ì •ì‹  ì¢€ ì°¨ë¦¬ì 33 31 user 5 ì•„ë² ë§Œë„ëª»í•œ ë¬¸í†µ; 11 11 user 6 ë¬¸ì¬ì¸ ì•„ê°€ë¼ ë‹¥ì³ë¼. ì‚¬ë“œë„ ë‚´ì •ë¬¸ì œì¸ë° ì¤‘êµ­í•œí…ŒëŠ” ë½ì†Œë¦¬ ëª» í•˜ë˜ ìƒ‰íˆê°€ ì–´ë””ì„œ ì£¼ë‘¥ì•„ë¦¬ ì”¨ë¶€ë¦¬ë…¸. 10 10 user 7 ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ê³§ ì–‘ë…ë‹¨ì™€ì„œ ë˜ í‰í™”ì˜¬ë¦¼í”½ ìš¸ë¶€ì§–ê² ë„¤. 66 57 user 8 ë¯¸êµ­ì´ í•œêµ­ì„ ë²„ë ¤ì•¼ í•  ë“¯.\\në‹µì´ ì—†ë„¤. 15 14 user 9 ë¯¸êµ­ì„ ëŒ€ë³€í•˜ëŠ”ê±°ë‹¤.\\nì•„ë² ëŠ” êµ­ìµì„ ìµœìš°ì„ ìœ¼ë¡œ í•˜ëŠ”ê±°ì§€\\nì¼ë³¸ì€ ì‹«ì§€ë§Œ ì•„ë² ê°€ ë˜‘ë˜‘í•˜ì§€ì•ŠëŠ”ëƒ.\\nìƒê°ì¢€í•˜ê³  ì‚´ì. 8 8 user 10 ì–¼ë§ˆë‚˜ ë‹µë‹µí•˜ë©´ ì €ëŸ°ë§ì„ í• ì§€ ìƒê° ì•ˆí•´ë³´ì…¨ë‚˜ìš”?? ë¶ì—ì„œ ì›í•˜ëŠ” ëŒ€ë¡œ í˜ëŸ¬ê°€ë„¤ìš”. ì•ìœ¼ë¡œ í•œë¯¸êµ°ì‚¬í›ˆë ¨ ì—°ê¸°ë¿ë§Œ ì•„ë‹ˆë¼ ì¶•ì†Œë˜ê³  ì—†ì–´ì§€ê³  ë‚œë¦¬ë‚˜ê² ë„¤ 8 8 ë¶„ëª… ê³µê°ìˆ˜ì™€ ë¹„ê³µê°ìˆ˜ëŠ” controversialí•˜ì§€ë§Œ ëŒ€ë¶€ë¶„ì´ ë‹¹ì‹œì˜ ì—¬ë¡ ê³¼ ë°˜ëŒ€ëŒ€ëŠ” ë‚´ìš©ìœ¼ë¡œ ì¹˜ìš°ì³ìˆë‹¤. ì •ì„±ì ìœ¼ë¡œ controversialí•œ ëŒ“ê¸€ì€ ê³µê°: ë¹„ê³µê°ì´ 1:1ì´ ì•„ë‹Œ ì¢€ë” ê³µê° ë¹„ìœ¨ì´ ë†’ì€ ë¹„ìœ¨ì„ ê°€ì§„ë‹¤ëŠ” ì‚¬ì‹¤ì„ ìœ ì¶”í•´ë³¼ ìˆ˜ ìˆë‹¤. ê³µê°ë¹„ìœ¨ê³¼ ë¹„ìŠ·í•˜ê²Œ controversialë„ voteìˆ˜ê°€ ë§ì€ ê²½ìš°ì— ë¶ˆë¦¬í•´ì§„ë‹¤. controversialì˜ ë¶„ëª¨ëŠ” upvoteì™€ downvoteì˜ ì°¨ì´ê°’ì¸ë°, voteìˆ˜ê°€ ë§ì„ìˆ˜ë¡ í•œë‘ê°œì°¨ì´ë¥¼ ìœ ì§€í•˜ê¸°ê°€ ì–´ë ¤ì›Œì§„ë‹¤. ê³µê° 66, ë¹„ê³µê° 57ì„ ê°€ì§„ ëŒ“ê¸€ì´ ê³µê° 10, ë¹„ê³µê° 10ë³´ë‹¤ ì•„ë˜ì— ë†“ì¸ë‹¤. New Sorting Algorithms reddit ranking algorithm ì¤‘ì—ì„œ controversialì˜ ë¬¸ì œì ì„ í•´ê²°í•œ ìƒˆë¡œìš´ controversial algorithmê³¼ ë¹„ê³µê°ì´ ë§ì€ ì˜ê²¬ë„ ë…¸ì¶œí•˜ëŠ” best anti ì •ë ¬ë°©ì‹ì„ ì œì•ˆí•˜ê³ ì í•œë‹¤. New controversial ì•ì„œ ì§€ì í–ˆë“¯ì´ controversialì€ ê³µê°: ë¹„ê³µê°ì˜ ë¹„ìœ¨ ì¬ì¡°ì •ê³¼ vote ìˆ˜ê°€ ë§ì€ ê²½ìš° ë¶„ëª¨ê°’ì˜ ê¸°ì¤€ì„ ì™„í™”ì‹œì¼œì•¼í•˜ëŠ” ì´ìŠˆê°€ ìˆë‹¤. ê³µê° : ë¹„ê³µê° ì •ì„±ì ìœ¼ë¡œ í™•ì¸í•´ë³´ì•˜ì„ ë•Œ ê³µê°: ë¹„ê³µê° = 6.5 : 3.5 ì •ë„ì—ì„œ ê¸°ì‚¬ ë‚´ìš©ì— ëŒ€í•œ ì°¬ì„±ê³¼ ë°˜ëŒ€ì˜ ëŒ“ê¸€ì´ ê³¨ê³ ë£¨ ë“±ì¥í•˜ì˜€ë‹¤. ë•Œë¬¸ì— new controversialì—ì„œ upvoteì™€ downvoteì˜ ê°’ì„ ì¡°ì •í•´ì£¼ì–´ì•¼ í•œë‹¤. voteìˆ˜ê°€ ë§ì€ ê²½ìš° ì´ ë¬¸ì œëŠ” ê³µê°ë¹„ìœ¨ìˆœê³¼ ë¹„ìŠ·í–ˆë‹¤. upvoteì™€ downvoteì˜ ì ˆëŒ€ì¹˜ì— ì˜ì¡´í•˜ê¸°ë³´ë‹¤ wilson scoreë¡œ ë„ì¶œëœ ê°’ì„ upvoteì™€ downvoteë¡œ ëŒ€ì²´í•˜ë©´ voteìˆ˜ê°€ ë§ê³  ì ìŒì„ ê³ ë ¤í•˜ë©´ì„œë„ 0ê³¼ 1 ì‚¬ì´ì˜ ê°’ì„ ê°€ì§€ê²Œ ë˜ì–´ upvoteì™€ downvoteì˜ ì°¨ì´ì— ëŒ€í•œ íš¨ê³¼ê°€ ì™„í™”ëœë‹¤. ë³€ê²½ëœ ë‚´ìš©ì„ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. import mathdef controversial(upvote, downvote): p_up = best(upvote, downvote) * 3.5 p_down = best(downvote, upvote) * 6.5 match = min(p_up, p_down) top = match * math.log(match + 1) bottom = abs(p_up - p_down) + 1 return float(top) / bottom ì•„ë²  â€œí•œë¯¸êµ°ì‚¬í›ˆë ¨ ì˜ˆì •ëŒ€ë¡œâ€â€¦æ–‡ëŒ€í†µë ¹ â€œë‚´ì •ë¬¸ì œ ê±°ë¡  ê³¤ë€â€(ì¢…í•©) [11] userId comments ê³µê°ìˆ˜ ë¹„ê³µê°ìˆ˜ user 11 ì•„ë² í•œí…Œ ëŒ€í•˜ë“¯ ë˜‘ê°™ì´ ê¹€ì •ì€í•˜ê³  ë¶í•œ, ì¤‘êµ­í•œí…Œë„ ë‹¹ë‹¹í•˜ê²Œ ë‚˜ì™€ë¼! 16 11 user 12 ê°œ~~ìƒˆë¼ ì•„ë²  í•œí…ŒëŠ” ê·¸ë ‡ê²Œ ë‹¹ë‹¹í•˜ë©´ì„œ ê¹€ì •ì€í•œí…ŒëŠ” ì™œ ê·¸ë ‡ê²Œ ê¼¬ë¦¬ë¥¼ ë‚´ë¦°ë‹¤ëƒ? í•µì´ ë¬´ì„­ê¸´ ë¬´ì„œìš´ê°€ ë³´ë‹¤ 11 7 user 13 í•œë¯¸ ë™ë§¹ë„ ì¢‹ë‹¤ ê·¸ëŸ¬ë‚˜ ìš°ë¦¬ ë‚˜ë¼ ìŠ¤ìŠ¤ë¡œ ê°•í•œ ë‚˜ë¼ê°€ ë˜ì–´ì•¼ í•œë‹¤. ë¬¸ëŒ€í†µí˜• ìˆ˜ê³  ë§ìœ¼ì‹­ë‹ˆë‹¤ !! 9 6 user 14 ì•„ë² ì—ê²Œ ì¼ì¹¨ì„ ë†”ì£¼ì‹ \\n ë¬¸ ëŒ€í†µë ¹ë‹˜ ì§€ì§€ í•©ë‹ˆë‹¤.\\nì•„ë²  ë‚˜ëŒ€ì§€ ë§ˆì‹œì˜¤ 9 6 user 15 ìª½ë°”ë¦¬ ì¶”ì¢…ìë“¤ ë§ë„¤!! íŠ¹íˆ ë²Œë ˆ í‹€ë”±ë“¤~~ 8 5 user 16 ë°˜ëŒ€ë¡œ ìš°ë¦¬ë‚˜ë¼ê°€ ì¼ë³¸ë³´ê³  ììœ„ëŒ€ í›ˆë ¨í•˜ëŠ”ê±° ë³´ê³  ì°¸ê²¬í•˜ë©´ ì¼ë³¸ì´ ê°€ë§ì´ ìˆê² ëƒ?\\nì´ ë²Œë ˆë“¤ì•„! ë¹„íŒì„ í•˜ë ¤ë©´ êµ­ë‚´ ë‚´ì •ì— ê°„ì„­í•˜ëŠ” ì•„ë² ë¥¼ ë¹„íŒí•´ì•¼ì§€ ì•„ë² ë¥¼ ë‘ë‘”í•˜ëƒ? ì´ ìŠ¤ë ˆê¸°ë“¤ì•„â€¦ 8 5 user 17 ì•„ë² ê°€ ì˜³ì€ë§í–ˆë„¤ ì§€ê¸ˆì´ë¼ê³  ê¹€ì •ì€ ì°¸ìˆ˜ í•œë¯¸ì—°í•©í›ˆë ¨ì„ ì‹œì‘í•˜ë¼ ë¹¨ê°±ì´í•œí…Œ ì´ ë‚˜ë¼ë¥¼ ì¤„ ìˆ˜ ì—†ë‹¤ 6 4 user 18 ëŒ€í•œë¯¼êµ­ì€ ë‹¤ì‹œ í•œë²ˆ ë§í•´ë´ì•¼ ì •ì‹ ì°¨ë¦¬ì§€â€¦\\në§ë¡œëŠ” ì•ˆëœë‹¤. 6 4 user 19 ì¼ë³¸ì´ ìš°ë°©ì´ë€ì• ë“¤ ë©ì²­í•œê±° ì•„ë‹ˆëƒ ì¼ë³¸ì• ë“¤ë„ ê·¸ë ‡ê²Œ ìƒê°ì•ˆí•˜ëŠ”ë° ì™œ ë‹ˆí˜¼ì ë§ìƒí•´ ì°ë”°ìƒˆë¼ì¸ê°€ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ 6 4 user 20 ë¬¸ì¬ì¸ì”¨ ë‹¹ì‹ ì˜ êµ­ì ì€ ì–´ë””ì…ë‹ˆê¹Œ? ë‹¤ìŠ¤ ì‹¤ì†Œìœ ì£¼ë¥¼ ë°íˆëŠ” ê²ƒë³´ë‹¤ í›¨ì”¬ ë” ì¤‘ìš”í•œ ë¬¸ì œì…ë‹ˆë‹¤. 6 4 ê³µê° ë¹„ìœ¨ì„ ì¡°ê¸ˆ ë†’ì—¬ì£¼ì—ˆì„ ë•Œ ê¸°ì‚¬ ë‚´ìš©ì— ì°¬ì„±í•˜ëŠ” ëŒ“ê¸€ê³¼ ë°˜ëŒ€í•˜ëŠ” ëŒ“ê¸€ì´ top 10ì— ê³¨ê³ ë£¨ ì„ì´ê²Œ ë˜ì—ˆë‹¤. ë˜ wilson scoreë¡œ ë³€í™˜í•œ ìƒíƒœì—ì„œ ë¹„ìœ¨ì„ ì¡°ì •í•´ì£¼ê²Œë˜ì–´ voteìˆ˜ê°€ ë†’ì€ ê²½ìš°ì— upê³¼ downì˜ ì°¨ì´ì— ëœ ë¯¼ê°í•´ì§ˆ ìˆ˜ ìˆì—ˆë‹¤. Best-Anti ê¼­ ê³µê°ìˆ˜ê°€ ë§ì€ ê²ƒë§Œ ê´œì°®ì€ ì˜ê²¬ì´ë¼ê³  ë³¼ ìˆ˜ ìˆì„ê¹Œ? ë¹„ê³µê°ìˆ˜ê°€ ë§ì€ ì˜ê²¬ ë˜í•œ ë°˜ëŒ€ ì§„ì˜ì˜ ì…ì¥ì„ ëŒ€ë³€í•˜ëŠ” ì¢‹ì€ ì˜ê²¬ì´ë¼ê³ ë„ ë³¼ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ? ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ì€ ëŒ€ë¶€ë¶„ ë‹¹ì‹œì˜ ì—¬ë¡ ì— ë”°ë¼ ë¶„ìœ„ê¸°ê°€ í˜ëŸ¬ê°„ë‹¤. ìˆœê³µê°ìˆœì´ë“  ê³µê°ë¹„ìœ¨ìˆœì´ë“  í•œê°€ì§€ ì£¼ì¥ì„ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ í‘œí˜„í•˜ê³  ìˆëŠ” ëŒ“ê¸€ë“¤ì´ top 10ì´ ëœë‹¤. ì´ë¥¼ ë³´ëŠ” ëŒ€ì¤‘ì€ í•œìª½ì˜ ì˜í–¥ë§Œ ë°›ê²Œ ë˜ì–´ ìƒê°ì´ ë”ìš± ì¹˜ìš°ì³ì§„ë‹¤. ì •ì¹˜ì  ë‹¤ì–‘ì„±ì„ ìˆ˜ìš©í•˜ëŠ” ê²ƒì€ ì˜ê²¬ì˜ ê°ê´€ì„±ì„ ìœ ì§€í•˜ëŠ”ë°ì— ë„ì›€ì´ ëœë‹¤. ê·¸ëŸ° ì˜ë¯¸ì—ì„œ ë‹¹ì‹œ ì—¬ë¡ ê³¼ ë°˜ëŒ€ë˜ëŠ” ë‚´ìš©ì˜ ëŒ“ê¸€ ë˜í•œ ë³´ì—¬ì£¼ëŠ” ê²ƒì€ ëŒ“ê¸€ì— ì˜í–¥ì„ ë°›ì„ ë‹¤ë¥¸ ì‚¬ìš©ìë¥¼ ìœ„í•´ì„œë„, í”Œë«í¼ì˜ ì¤‘ë¦½ì„±ì„ ë‹´ë³´í•˜ê¸° ìœ„í•´ì„œë„ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•œë‹¤. Best-AntiëŠ” negative voteì— ëŒ€í•œ Wilson scoreë¥¼ êµ¬í•œ ê²ƒì´ë‹¤. \\[ w_{neg}^- = max(0, \\frac{2n(1-\\hat{p}) + z^2 - z\\sqrt{z^2 + 4n\\hat{p}(1-\\hat{p})}}{2(n+z^2)}) \\] python êµ¬í˜„ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. import numpy as npdef best_anti(up, down): try: z = 1.96 # 95% confidence level n = up + down p_up = up / n p_down = 1 - p_up denominator = 2 * (n + z**2) numerator = 2 * n * p_down + z**2 - z * np.sqrt(z**2 + 4 * n * p_up * p_down) lower = numerator / denominator except ZeroDivisionError as e: lower = 0 return max(0, lower) ì•„ë²  â€œí•œë¯¸êµ°ì‚¬í›ˆë ¨ ì˜ˆì •ëŒ€ë¡œâ€â€¦æ–‡ëŒ€í†µë ¹ â€œë‚´ì •ë¬¸ì œ ê±°ë¡  ê³¤ë€â€(ì¢…í•©)[11] userId comments ê³µê°ìˆ˜ ë¹„ê³µê°ìˆ˜ user 21 í‰í™”í˜‘ì •í›„ ë¯¸êµ°ì² ìˆ˜ ë°”ëë‹ˆë‹¤ 0 5 user 22 í™ë°œì •ì”¨â€¦íŠ¸ëŸ¼í”„ë„ ì¢ŒíŒŒ ë¹¨ê°±ì´ì£ ?? 0 4 user 23 ëŠ™ë‹¤ë¦¬ ë¯¸ì¹˜ê´‘ì´ëŠ” ë¹ ì ¸ ì¤„ë˜!\\nìš°ë¦¬ë¼ë¦¬ ìì£¼í†µì¼ì¢€ í•˜ì! 0 4 user 24 ìêµ­ë‹¹ì€ ì‚¬í˜•ê° ë§ë˜ë°â€¦ ë¯¸êµ­ì² ìˆ˜ ì• ê¸°í–ˆë‹¤ê³  íŒŒë©´? ìêµ­ë‹¹ 5ì›”ì—ëŠ” ë¬¸ì •ì¸ìœ¼ë¡œ ë†€ê³ ë¨¹ê² êµ°~! 0 4 user 25 ë´ë¼. ì§€ë„ì í•˜ë‚˜ê°€ ì´ë ‡ê²Œë‚˜ ì„¸ìƒì„ ë°”ê¿€ ìˆ˜ ìˆë‹¤. ë¬¼ë¡  ì´›ë¶ˆ ë“¤ê³ , ì§ì ‘ë¯¼ì£¼ì£¼ì˜ë¥¼ êµ¬í˜„í•œ êµ­ë¯¼ ë˜í•œ ìœ„ëŒ€í•˜ì§€. ì§€ë°©ì„ ê±° ë•Œ íˆ¬í‘œ ì˜ í•˜ì. 0 4 user 26 ì•„ì§ë„. ë¯¸êµ­ì´ ì¸ê³„ì² ì„ ì´ë¼ë¯¿ê³  50ë…„ëŒ€ ì‚¬ê³ ë°©ì‹ì´ ì¡´ì¬í•˜ëŠ”êµ¬ë‚˜ êµ°ì‚¬ë ¥ ì„¸ê³„10ìœ„ì•ˆì—ë“¤ê³  1-1ë¶™ì–´ë„ ì•ˆì§€ë‹ˆ ë„ˆë¬´ ë¯¸êµ°ì² ìˆ˜ë¡œ ì—¬ë¡ ì „ë§ê³  ì°¸ì‹ í•œê±°ì—†ì–´ìš” ? ìí•œë‹¹ë¶„ë“¤? 1 6 user 27 ê·¹ìš° ìí•œë‹¹ì€ ë¯¸êµ­ë„ ë¹¨ê°±ì´ë€ë‹¤ ì œë¹„ê°€ ì™”ë‹¤ê³  ë´„ì€ ì•„ë‹ˆëŒì„œ ã…‹ã…‹ã…‹ 0 3 user 28 ì›ìƒ·-ë¹…ë”œ! 0 3 user 29 ìí•œë‹¹ë¶„ë“¤ê»˜ì„œ íŠ¸ëŸ¼í”„ë„ ì¢ŒíŒŒë˜ìš”â€¦ 0 3 user 30 ìŠì§€ë§ˆì„¸ìš” ì§€ê¸ˆë„ ë¶í•œì€ ì„¸ê³„ ìµœì•…ì˜ ì¸ê¶Œìœ ë¦° êµ­ê°€ì…ë‹ˆë‹¤ ì´ì‹œê°„ì—ë„ ë¶í•œ ì£¼ë¯¼ë“¤ì€ ê¹€ì •ì€í•œí…Œ ì´ì‚´ë‹¹í•˜ê±°ë‚˜ ì•„ì˜¤ì§€íƒ„ê´‘ìœ¼ë¡œ ëŒë ¤ê°€ê³  ìˆìŠµë‹ˆë‹¤ ë¶í•œ ì—¬ì„±ë“¤ì€ ê¹€ì •ì€ì˜ ì„±ë…¸ì˜ˆê°€ ë˜ê³  ìˆêµ¬ìš” ëŒ€í•œí•œê³µ ì¡°í˜„ë¯¼ì˜ ê°‘ì§ˆ í™”ê°€ë‚˜ì£  ë¯¸íˆ¬ìš´ë™ìœ¼ë¡œ ë“œëŸ¬ë‚œ ê¶Œë ¥ìë“¤ì˜ ì„±í­ë ¥ ì •ë§ ì‹«ìŠµë‹ˆë‹¤ ê·¸ëŸ°ë° ì´ê²ƒë³´ë‹¤ ìˆ˜ë°±ë°°ëŠ” ë”ì‹¬í•œ ê°‘ì§ˆê³¼ ì„±í­ë ¥ì„ ì¼ì‚¼ëŠ”ê²Œ ë¶í•œ ê¹€ì •ì€ì…ë‹ˆë‹¤ 0 3 Conclusions í˜„ì¬ì˜ ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ ì •ë ¬ë°©ì‹ì€ ê³µê°ìˆ˜ê°€ ë†’ì€ ëŒ“ê¸€ì„ ìœ„ì£¼ë¡œ ë³´ì—¬ì£¼ê³  ìˆê³ , ê¸°ì¤€ ë˜í•œ ì‰½ë‹¤. ì¡°ì‘ì— ë“¤ì–´ê°€ëŠ” ë¹„ìš© ëŒ€ë¹„ ì–»ì„ ìˆ˜ ìˆëŠ” íš¨ê³¼ê°€ í° ìƒí™©ì—ì„œ ì¡°ì‘ìœ¼ë¡œ ì¸í•´ ì´ìµì„ ë³¼ ì§‘ë‹¨ì€ ë‹¹ì—°íˆ ì–´ë·°ì§•ì„ í•  ìˆ˜ ë°–ì— ì—†ë‹¤. ê·¸ë¦¬ê³  ì´ë¯¸ ì¡°ì§ì ì¸ ì„¸ë ¥ì´ ë˜ì–´ë²„ë¦° ì–´ë·°ì €ë“¤ì€ ì™„ë²½íˆ ì°¨ë‹¨í•  ìˆ˜ ì—†ë‹¤. ë•Œë¬¸ì— ì–´ë·°ì§•ì„ í•´ê²°í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì¢‹ì€ ë°©ë²•ì€ í˜„ì¬ì˜ ì •ë ¬ ë°©ì‹ì˜ ë‹¨ì ì„ ê·¹ë³µí•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ê¸°ì¤€ì´ ë³µì¡í•´ì§€ê²Œ ë§Œë“œëŠ” ê²ƒê³¼ ì‚¬ëŒë“¤ì´ ì¡°ì‘ëœ ì˜ê²¬ì— í¬ê²Œ í”ë“¤ë¦¬ì§€ ì•Šì„ ìˆ˜ ìˆë„ë¡ ë‹¤ì–‘í•œ ì˜ê²¬ì„ ë³´ì—¬ì£¼ëŠ” ê²ƒì´ë‹¤. í˜„ì¬ì˜ ë„¤ì´ë²„ ì •ë ¬ ë°©ì‹ ì¤‘ ìˆœê³µê°ìˆœê³¼ ê³µê°ë¹„ìœ¨ìˆœì´ ê°€ì§€ëŠ” í•œê³„ëŠ” redditì—ì„œ ì‚¬ìš©í•˜ê³  ìˆëŠ” best ì •ë ¬ë°©ì‹ìœ¼ë¡œ í•´ê²°ëœë‹¤. ê³µê°ìˆ˜ì— ê°€ì¤‘ì¹˜ë¥¼ ë‘” ì •ë ¬ë°©ì‹ ì™¸ì— ê³µê°ìˆ˜ì™€ ë¹„ê³µê°ìˆ˜ê°€ ë¹„ìŠ·í•œ ëŒ“ê¸€ì— ê°€ì¤‘ì¹˜ë¥¼ ë‘ëŠ” ë°©ì‹, ë¹„ê³µê°ìˆ˜ì— ê°€ì¤‘ì¹˜ë¥¼ ë‘ëŠ” ë°©ì‹ì„ ì œì•ˆí•˜ì˜€ë‹¤. í•œ ìª½ì˜ ì˜ê²¬ë§Œ ë“£ëŠ” ê²ƒì€ ì–¸ì œë‚˜ í¸í–¥ëœ ê²°ê³¼ë¥¼ ì•¼ê¸°í•œë‹¤ê³  ìƒê°í•œë‹¤. í•œ ìª½ì´ ëª…ë°±íˆ ì˜ëª»í•œ ê²ƒì²˜ëŸ¼ ë³´ë„ë  ë•Œ, ê·¸ ë°˜ëŒ€ì˜ ì˜ê²¬ì—ë„ ê·€ë¥¼ ê¸°ìš¸ì¼ ìˆ˜ ìˆëŠ” í”Œë«í¼ì´ ë˜ê¸¸ ë°”ë€ë‹¤. Future works ì§€ê¸ˆê¹Œì§€ëŠ” ëŒ“ê¸€ì˜ contentsë³´ë‹¤ëŠ” ëŒ“ê¸€ì— ë¶€ê³¼ëœ ê³µê°, ë¹„ê³µê°ì˜ interaction ë°ì´í„°ë¡œ ë¬¸ì œì ê³¼ í•´ê²°ë°©ì‹ì„ ì œì•ˆí–ˆë‹¤. controversialë¡œ ì˜ê²¬ì˜ ë‹¤ì–‘ì„±ì„ ì¶”êµ¬í–ˆì§€ë§Œ textë¥¼ ë³´ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ì˜ê²¬ì˜ ë‹¤ì–‘ì„±ì„ ê°„ì ‘ì ìœ¼ë¡œ ë³´ì¥í•˜ê¸°ì—” ë¶ˆì•ˆì •í•  ìˆ˜ ìˆë‹¤. ì‡¼í•‘ ë¦¬ë·°ì—ì„œ ê°€ê²©, ë‚´êµ¬ì„±, ë””ìì¸ ë“± ë‹¤ì–‘í•œ ì¸¡ë©´ì„ ë³´ì—¬ì£¼ë“¯ì´ ì •ì¹˜ì  ì˜ê²¬ë„ ê¸°ì‚¬ì—ì„œ ì–¸ê¸‰ëœ ì¤‘ìš”í•œ ë‹¨ì–´ë“¤ì— ëŒ€í•œ ì‚¬ëŒë“¤ì˜ ë°˜ì‘ì„ ë³´ëŠ” ë°©ì‹ë„ ìƒê°í•´ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ë‹¤. Appendix A: Wilson score ì‚¬ì‹¤ ë³¸ë¬¸ì—ì„œ ê¸°ìˆ í•œ ë‚´ìš©ì€ ì¼ë°˜ì ì¸ Normal approximation intervalì´ë‹¤. \\[ p = \\hat{p} \\pm z\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\] ì—¬ê¸°ì„œ \\(\\hat{p}\\)ì€ Bernoulli processì˜ ì„±ê³µí™•ë¥ ì„ ì˜ë¯¸í•œë‹¤. Wilson scoreëŠ” confidence intervalì„ \\(\\hat{p}\\)ê°€ ì•„ë‹Œ \\(p\\)ë¡œ ì¶”ì •í•œ score intervalì˜ ìµœì†Œê°’ì´ë‹¤. \\[ p = \\hat{p} \\pm z\\sqrt{\\frac{p(1-p)}{n}} \\] \\(p\\)ì— ëŒ€í•´ ì •ë¦¬í•˜ì—¬ \\(p\\)ì— ëŒ€í•œ 2ì°¨ë°©ì •ì‹ì„ ë§Œë“ ë‹¤. \\[ (1 + \\frac{z^2}{n}) p^2 - (2\\hat{p} + \\frac{z^2}{n})p + \\hat{p}^2 = 0 \\] ê·¼ì˜ ê³µì‹ì„ ì‚¬ìš©í•´ \\(p\\)ë¥¼ êµ¬í•œë‹¤. \\[ p = \\frac{2n\\hat{p} + z^2 \\pm z\\sqrt{z^2 + 4n\\hat{p}(1-\\hat{p})}}{2(n+z^2)} \\] Wilson scoreëŠ” \\(p\\)ì˜ lower boundì´ë¯€ë¡œ - ì— ëŒ€í•´ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. \\[ w^- = max(0, \\frac{2n\\hat{p} + z^2 - z\\sqrt{z^2 + 4n\\hat{p}(1-\\hat{p})}}{2(n+z^2)}) = \\text{wilson score} \\] 95%ì˜ ì‹ ë¢°ë„ë¡œ ê³ ì •í•˜ëŠ” ê²½ìš° zì— 1.96ì„ ëŒ€ì…í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  ì´ ê²½ìš° ë³¸ë¬¸ì˜ python í•¨ìˆ˜ì—ì„œ êµ¬í˜„í•œ bestê°€ ëœë‹¤. References 1.2017ë…„ 11ì›” 30ì¼ë¶€í„° í˜¸ê°ìˆœì—ì„œ ìˆœê³µê°ìˆœìœ¼ë¡œ ë³€ê²½ë˜ë©´ì„œ ë‹¤ì‹œ 2016ë…„ ì´ì „ì˜ í˜¸ê°ìˆœì²˜ëŸ¼ í˜¸ê°ë„ë¥¼ â€œê³µê°-ë¹„ê³µê°â€ìœ¼ë¡œ ê³„ì‚°í•˜ê²Œ ë˜ì—ˆë‹¤. â†©2.í™ì¤€í‘œ â€œë‚˜ê²½ì›, ì•„ë“¤ ì´ì¤‘êµ­ì  ì—¬ë¶€ ë°í˜€ë¼â€¦1ì–µ í”¼ë¶€ê³¼ ì—°ìƒâ€, ë„¤ì´ë²„ ë‰´ìŠ¤ â†©3.ì¬íŒì— ë„˜ê²¨ì§„ ì¡°êµ­ ë¶€ì¸ ì •ê²½ì‹¬ êµìˆ˜â€¦ê²€ì°° 'ì†Œí™˜ ì„ë°•', ë„¤ì´ë²„ ë‰´ìŠ¤ â†©4.ëŒ€í•™êµìˆ˜ ì´ì–´ ì˜ì‚¬ 4400ëª…ë„ â€œì¡°êµ­ í‡´ì§„, ì¡°êµ­ ë”¸ í‡´êµâ€ ì‹œêµ­ì„ ì–¸ë¬¸ ì„œëª…, ë„¤ì´ë²„ ë‰´ìŠ¤ â†©5.https://redditblog.com/2009/10/15/reddits-new-comment-sorting-system â†©6.http://www.evanmiller.org/how-not-to-sort-by-average-rating.html â†©7.https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval â†©8.https://blog.yelp.com/2011/02/the-most-romantic-city-on-yelp-is â†©9.MB 'ì •ì¹˜ë³´ë³µ' ë°˜ë°œì— ë¬¸ë¬´ì¼ ì´ì¥ â€œë²•ì  ì ˆì°¨ëŒ€ë¡œ í•˜ê² ë‹¤â€, ë„¤ì´ë²„ ë‰´ìŠ¤ â†©10.https://www.reddit.com/r/NoStupidQuestions/comments/3xmlh8/what_does_something_being_labeled_controversial/?sort=confidence â†©11.ì•„ë²  â€œí•œë¯¸êµ°ì‚¬í›ˆë ¨ ì˜ˆì •ëŒ€ë¡œâ€â€¦æ–‡ëŒ€í†µë ¹ â€œë‚´ì •ë¬¸ì œ ê±°ë¡  ê³¤ë€â€(ì¢…í•©), ë„¤ì´ë²„ ë‰´ìŠ¤ â†©","link":"/2019/09/23/Naver-News-Comments-Analysis-(3)/"},{"title":"Naver News Comment Analysis (2)","text":"NOTICE: ì•ìœ¼ë¡œ ì†Œê°œë  ë‚´ìš©ì€ NAVERì™€ ë¬´ê´€í•˜ë©°, ì˜¤íˆë ¤ NAVER ë‰´ìŠ¤ê°€ ì •ì¹˜ì ì¸ í¸í–¥ì„±ì„ ê°€ì§€ê³  ìˆì§€ ì•Šì€ ì¤‘ë¦½ì ì¸ í”Œë«í¼ì´ë¼ê³  ìƒê°í•˜ê¸° ë•Œë¬¸ì— ë¶„ì„ì„ í•˜ê²Œ ë˜ì—ˆìŒì„ ì•Œë¦½ë‹ˆë‹¤. TL;DR 2015ë…„ 12ì›”ë¶€í„° 2018ë…„ 5ì›”ê¹Œì§€ì˜ ë°ì´í„°ë¡œ ì†Œìœ„ ë§í•˜ëŠ” ì–´ë·°ì €ì˜ ì¡´ì¬ë¥¼ í™•ì¸í•´ë³´ì•˜ë‹¤. ì—¬ê¸°ì„œ ë§í•˜ëŠ” ì–´ë·°ì €ì˜ criteriaëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. íƒ€ì¸ì˜ ìƒê°ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë„ë¡ ì‘ì„±í•œ ëŒ“ê¸€ì´ top 10 ë‚´ì— í•œ ë²ˆ ì´ìƒ ë“¤ì—ˆì–´ì•¼ í•œë‹¤. ì‹¤ì œ ì–´ë·°ì €ì˜€ì–´ë„ top ëŒ“ê¸€ì´ ì•„ë‹ˆì–´ì„œ íƒ€ì¸ì—ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ëª»í–ˆë‹¤ë©´ ì–´ë·°ì €ë¼ê³  ë¶ˆë¦´ ìê²©(?)ì´ ì—†ë‹¤. ë°œìƒí•˜ê¸° ì–´ë ¤ìš´ íŒ¨í„´ì„ ë³´ì—¬ì•¼ í•œë‹¤. ì´ ê¸°ì¤€ì— ë”°ë¼ ë¶„ì„í•œ ê²°ê³¼, ì´ 386ë²ˆ ëŒ“ê¸€ì„ ë‚¨ê²¼ê³  ê·¸ ì¤‘ì—ì„œ 369ë²ˆ(95.6%) top 10 ë‚´ì— ë“¤ì—ˆë˜ ìœ ì €ì™€ ì´ 289ë²ˆ ëŒ“ê¸€ì„ ë‚¨ê¸°ê³  269ë²ˆ(93.1%) top 10 ë‚´ì— ë“¤ì—ˆë˜ ìœ ì €ë¥¼ ì˜ì‹¬í•´ë³´ê²Œ ë˜ì—ˆë‹¤. Abuser, who are you? Introduction â€œì •ë§ 2016ë…„ 4ë¶„ê¸°ë¶€í„° ì •ë§ ëŒ“ê¸€ ì¡°ì‘ì„ í–ˆë˜ ì‚¬ìš©ìë“¤ì´ ìˆì—ˆì„ê¹Œ?â€ ë¼ëŠ” ë‹¨ìˆœí•œ ì˜ë¬¸ê³¼ ê¶ê¸ˆì¦ì—ì„œ ë¶„ì„ì„ ì‹œì‘í•˜ê²Œ ë˜ì—ˆë‹¤. ë‹¤ë§Œ, ë°ì´í„°ì— &lt;ê³µê°&gt; &lt;ë¹„ê³µê°&gt; ì„ ëˆŒë €ë˜ interaction ì •ë³´ê°€ ëˆ„ë½ë˜ì–´ ìˆê¸°ì— (ì´ ë°ì´í„°ëŠ” ë„¤ì´ë²„ ë‰´ìŠ¤ ì¸¡ì—ì„œ ì œê³µí•´ì£¼ì§€ ì•ŠëŠ” ì´ìƒ ì–»ì„ ìˆ˜ ì—†ë‹¤) ì ì–´ë„ ëŒ“ê¸€ì„ í•œ ë²ˆì´ë¼ë„ ë‚¨ê²¼ë˜ ì‚¬ìš©ìì— ëŒ€í•´ì„œë§Œ ì–´ë·°ì €ë¡œ ì˜ì‹¬í•´ ë³¼ ìˆ˜ ìˆì—ˆë‹¤. labelì´ ì—†ëŠ” ìƒí™©ì—ì„œ ì–´ë·°ì €ë¥¼ íŠ¹ì •ì§“ëŠ” ê²ƒê³¼ ê·¸ ì‚¬ìš©ìê°€ ì–´ë·°ì €ì„ì„ ë‹¤ë¥¸ ì‚¬ëŒì—ê²Œ ì„¤ë“í•˜ëŠ” ê²ƒì€ ì–´ë ¤ìš´ ì¼ì´ë‹¤. ë˜í•œ ë¬´ì£„ì¶”ì •ì˜ ì›ì¹™ì— ì˜ê±°í•´ ëŒ“ê¸€ ì‘ì„±ìë¥¼ í•¨ë¶€ë¡œ ì–´ë·°ì €ë¼ê³  ë‹¨ì •ì§€ì„ ìˆ˜ë„ ì—†ì—ˆë‹¤. ê·¸ë˜ì„œ ì´ë²ˆ ë¶„ì„ì—ì„œëŠ”, â€œëª¨ë“  ì‘ì„±ìëŠ” ì–´ë·°ì €ê°€ ì•„ë‹ˆë‹¤.â€ ë¼ëŠ” ê°€ì •ì„ ê¸°ë°˜ìœ¼ë¡œ íŠ¹ì • íŒ¨í„´ì´ ë“±ì¥í•  í™•ë¥ ì„ ê³„ì‚°í•´ì„œ ì–´ë·°ì €ì˜€ì„ ê°€ëŠ¥ì„±ì„ ê°„ì ‘ì ìœ¼ë¡œ ì¶”ì¸¡í•˜ëŠ” ë°©ì‹ì„ ì·¨í–ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ëˆ„êµ°ê°€ëŠ” ê·¸ ì •ë„ í™•ë¥ ë¡œëŠ” ì–´ë·°ì €ë¼ê³  ë‹¨ì •ì§“ê¸° ì–´ë µë‹¤ê³  íŒë‹¨í•  ìˆ˜ë„ ìˆê³ , ì•„ë‹ ìˆ˜ë„ ìˆë‹¤. ë˜ ì¶”ê°€ì ì¸ ë¶„ì„ ê²°ê³¼ê°€ ìˆë‹¤ë©´ ì–´ë·°ì € ê°€ëŠ¥ì„±ì´ ë” ë†’ì•„ì§ˆ ìˆ˜ë„ ìˆë‹¤. í›„ìë¼ë©´ ì–¸ì œë“  ëŒ“ê¸€ë¡œ ì¶”ê°€ ë¶„ì„í•  ë‚´ìš©ì„ ìš”ì²­í–ˆìœ¼ë©´ í•˜ëŠ” ë°”ëŒì´ë‹¤. Abuser Criteria ì–´ë·°ì €ëŠ” ì–´ë–¤ ì¡´ì¬ì¼ê¹Œ? ì´ì— ë‹µí•˜ê¸° ì•ì„œ, ì–´ë·°ì§•ì˜ ëª©ì ê³¼ ì–´ë·°ì§•ì´ ë¬¸ì œê°€ ë˜ëŠ” ìƒí™©ì— ëŒ€í•´ ë¨¼ì € ì •ë¦¬í•´ë³´ì•˜ë‹¤. ì–´ë·°ì§•ì˜ ëª©ì  ì–´ë·°ì €ë“¤ì˜ ëª©í‘œëŠ” ë„¤ì´ë²„ì˜ ëŒ“ê¸€ ì •ë ¬ ê¸°ì¤€ì— ë§ì¶”ì–´ 10ìœ„ê¶Œ ë‚´ì— ë“œëŠ” ê²ƒì´ë‹¤. ë„¤ì´ë²„ ë‰´ìŠ¤ì˜ UI ìƒ, top 10 ë‚´ì— ë“¤ë©´ ê·¸ ê¸°ì‚¬ë¥¼ ì½ëŠ” ëˆ„êµ¬ë‚˜ ì‰½ê²Œ ê·¸ ëŒ“ê¸€ì˜ ë‚´ìš©ì— ì ‘í•˜ê²Œ ë˜ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ë¦¬ê³  ê·¸ ë‚´ìš©ì´ ëŒ€ì¤‘ì„ ëŒ€í‘œí•œë‹¤ê³  ìƒê°í•˜ê¸° ë•Œë¬¸ì— ì‰½ê²Œ íƒ€ì¸ì˜ ìƒê°ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë‹¤. ì–´ë·°ì§•ì´ ë¬¸ì œê°€ ë˜ëŠ” ìƒí™© ì–´ë·°ì§•ì´ ë¬¸ì œê°€ ë˜ì—ˆë˜ ì´ìœ ëŠ” ê³µì •í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë°©ì‹ìœ¼ë¡œ ì§‘ê³„ë˜ì—ˆë‹¤ê³  ë¯¿ì—ˆë˜ top 10 ëŒ“ê¸€ì´ ì‹¤ì œë¡œëŠ” ì–´ë–¤ ì„¸ë ¥ì— ì˜í•´ ì˜ë„ë¥¼ ê°€ì§€ê³  ì¡°ì‘ë˜ì—ˆê¸° ë•Œë¬¸ì´ì—ˆë‹¤. top ëŒ“ê¸€ì´ íŠ¹ì • ì§‘ë‹¨ì— ì˜í•´ ì¡°ì‘ë˜ì—ˆë‹¤ë©´, ê·¸ê²ƒë“¤ì´ ê³¼ì—° ë„¤ì´ë²„ ë‰´ìŠ¤ í”Œë«í¼ì— ì°¸ì—¬í•˜ëŠ” ì‚¬ìš©ìë“¤ì˜ ìƒê°ì„ ëŒ€í‘œí•˜ëŠ” ëŒ“ê¸€ì´ë¼ê³  ë³¼ ìˆ˜ ìˆì„ê¹Œ? ê·¸ë˜ì„œ, ì´ ê¸€ì—ì„œ ì´ì•¼ê¸° í•  ì–´ë·°ì €ì˜ criteriaëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ì–´ë·°ì§•ì˜ ëª©ì ì„ ë‹¬ì„±í•´ì•¼ í•œë‹¤. ì¦‰, íƒ€ì¸ì˜ ìƒê°ì— ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆë„ë¡ ì‘ì„±í•œ ëŒ“ê¸€ì´ top 10 ë‚´ì— í•œ ë²ˆ ì´ìƒ ë“¤ì—ˆì–´ì•¼ í•œë‹¤. ì‹¤ì œ ì–´ë·°ì €ì˜€ì–´ë„ top ëŒ“ê¸€ì´ ì•„ë‹ˆì–´ì„œ íƒ€ì¸ì—ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ëª»í–ˆë‹¤ë©´ ì–´ë·°ì €ë¼ê³  ë¶ˆë¦´ ìê²©(?)ì´ ì—†ë‹¤. (ì•ˆìŠµ) ìì—°ì ìœ¼ë¡œ ë°œìƒí•˜ê¸° ì–´ë ¤ìš´, í™•ë¥ ì´ ë‚®ì€ íŒ¨í„´ì´ ë“±ì¥í•´ì•¼ í•œë‹¤. Data preprocessing ì—ì„œ ì‚¬ìš©í–ˆë˜ ë°ì´í„°ì—ì„œ ì¶”ê°€ë¡œ í•„í„°ë§ì´ í•„ìš”í–ˆë‹¤. í¬ë¡¤ë§í•œ ëŒ“ê¸€ ë°ì´í„°ì— hashing ëœ ì•„ì´ë””ê°€ í¬í•¨ëœ ê²ƒì´ 2015ë…„ 12ì›” ì´í›„ì˜€ê¸° ë•Œë¬¸ì´ë‹¤. ì‚¬ìš©í•œ ëŒ“ê¸€ ë°ì´í„° ê¸°ê°„: 2015.12.08 ~ 2018.05.25 Analysis ë¨¼ì €, ì •ì¹˜ ë¶„ì•¼ì—ì„œ ëŒ“ê¸€ì´ top 10 ë‚´ì— ë“¤ì—ˆë˜ íšŸìˆ˜ë¥¼ ì‘ì„±ì ë³„ë¡œ ì§‘ê³„í•œ í›„, íšŸìˆ˜ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•˜ì˜€ì„ ë•Œì˜ ì¶”ì´ë¥¼ ì‚´í´ë³´ì•˜ë‹¤. mean stdev max 75% med min 2.240442 4.607621 369 2 1 1 ëŒ€ë¶€ë¶„ì˜ ì‘ì„±ìëŠ” 1~2ë²ˆ ì •ë„ ëŒ“ê¸€ì´ top 10 ë‚´ì— ë“œëŠ” ë°˜ë©´, ì¼ë¶€ ì‚¬ìš©ìë“¤ì€ 100ë²ˆ ì´ìƒ ìˆœìœ„ê¶Œ ë‚´ì— ë“ ë‹¤. ì´ ê·¸ë˜í”„ë§Œ ë³¸ë‹¤ë©´ ìì£¼ top 10ì— ë“œëŠ” ì‚¬ìš©ìë“¤ ëª¨ë‘ê°€ ì˜ì‹¬ìŠ¤ëŸ¬ìš¸ ìˆ˜ ìˆì§€ë§Œ ì´ëŸ° skewed graphëŠ” ëŒ€ë¶€ë¶„ì˜ ì‚¬íšŒê³¼í•™ ë°ì´í„°ì—ì„œ ë°œê²¬ë˜ë¯€ë¡œ ì´ë“¤ì„ ì–´ë·°ì €ë¡œ ì†ë‹¨í•˜ê¸´ ì´ë¥´ë‹¤. ê²€ì¦ì„ ìœ„í•´ ë‹¤ë¥¸ ì„¹ì…˜(ì‚¬íšŒ, ê²½ì œ, ë¬¸í™”, IT, ì„¸ê³„)ì— ëŒ€í•´ì„œë„ ë§ˆì°¬ê°€ì§€ ë°©ë²•ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ë³´ì•˜ë‹¤. ìì£¼ ìˆœìœ„ê¶Œ ë‚´ì— ë“œëŠ” ëŒ“ê¸€ì„ ì‘ì„±í•œ ì‚¬ìš©ìë¥¼ top user ë¼ê³  í–ˆì„ ë•Œ, ë‹¤ë¥¸ ë¶„ì•¼ì—ì„œë„ top userëŠ” ì‰½ê²Œ ì°¾ì•„ë³¼ ìˆ˜ ìˆì—ˆë‹¤. ì–´ì©Œë©´ ì´ë“¤ì€ (ì–´ë·°ì €ê°€ ì•„ë‹Œ ì´ìƒ) ë„¤ì´ë²„ ë‰´ìŠ¤ í”Œë«í¼ì—ì„œ ë†’ì€ &quot;ê³µê°ìˆ˜-ë¹„ê³µê°ìˆ˜&quot;ë¥¼ ë°›ì„ ìˆ˜ ìˆëŠ” ì „ëµì´ í•™ìŠµëœ ê²ƒì€ ì•„ë‹ê¹Œ? ê¸°ì‚¬ê°€ ë‚˜ì˜¤ê³  ì–¼ë§ˆ ì§€ë‚˜ì§€ ì•Šì•„ ëŒ“ê¸€ì„ ë‚¨ê¸°ê±°ë‚˜, ê·¸ ë‹¹ì‹œ ë¶„ìœ„ê¸°ì— ë§ëŠ” ëŒ“ê¸€ì˜ ë‚´ìš©ì„ ë‚¨ê¸°ê±°ë‚˜, ì‚¬ì‹¤ë¡œ ë³´ì—¬ì§€ëŠ” ë°ì´í„°ì™€ í•¨ê»˜ ëŒ“ê¸€ì„ ì‘ì„±í•˜ê±°ë‚˜ í•˜ëŠ” ë“± ìì‹ ë§Œì˜ ì „ëµì´ ìˆì„ ê²ƒì´ë‹¤. ê·¸ëŸ¬ë‚˜ ì´ ì „ëµë“¤ì´ 100%ì˜ í™•ë¥ ë¡œ(=í•­ìƒ) í†µí•˜ì§€ëŠ” ì•Šì•˜ì„ ê²ƒì´ë‹¤. ë•Œë¡œëŠ” ì¼ì° ëŒ“ê¸€ì„ ì‘ì„±í–ˆìŒì—ë„ ë’¤ëŠ¦ê²Œ ì‘ì„±í•œ ëŒ“ê¸€ì´ í­ë°œì ì¸ ê³µê°ì„ ì´ëŒì–´ë‚´ì„œ top 10ì— ë“¤ì§€ ëª»í–ˆì„ ìˆ˜ë„ ìˆê³ , ë‹¹ì‹œì˜ ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°ì— íƒ‘ìŠ¹í•˜ëŠ” ëŒ“ê¸€ì„ ë‚¨ê²¼ìŒì—ë„ ë‹¤ë¥¸ ëŒ“ê¸€ ì¤‘ì— ë‘ë“œëŸ¬ì§€ì§€ ëª»í•´ ê³µê°ì„ ë°›ì§€ ëª»í–ˆì„ ìˆ˜ë„ ìˆë‹¤. top user ê°„ì— ì¼ë°˜ì ì¸ top 10 ì„±ê³µë¥ ì´ ì¡´ì¬í•  ê²ƒì´ê³  ì´ëŠ” normal distributionì„ ë”°ë¥¸ë‹¤ëŠ” ê°€ì„¤ì„ ë°”íƒ•ìœ¼ë¡œ &quot;top userê°€ ì‘ì„±í•œ ì „ì²´ ëŒ“ê¸€ ìˆ˜ ëŒ€ë¹„ top 10ì— ë“¤ì—ˆë˜ ëŒ“ê¸€ ìˆ˜(=top 10 ì„±ê³µë¥ )&quot;ë¥¼ ê³„ì‚°í•´ë³´ì•˜ë‹¤. ì •ì¹˜ top users userId top comment # total comment # top 10 ì„±ê³µë¥  (%) user 1 369 386 95.60 user 2 339 380 89.21 user 3 269 289 93.08 user 4 178 610 29.18 user 5 178 1090 16.33 user 6 175 424 41.27 user 7 174 818 21.27 user 8 155 316 49.05 user 9 143 950 15.05 user 10 141 583 24.19 ê²½ì œ top users userId top comment # total comment # top 10 ì„±ê³µë¥  (%) user 11 289 1185 24.39 user 12 226 2935 7.70 user 13 219 1656 13.22 user 14 183 1636 11.19 user 15 173 1378 12.55 user 16 161 989 16.28 user 17 160 654 24.46 user 18 157 2589 6.06 user 19 139 1514 9.18 user 20 127 742 17.12 ì‚¬íšŒ top users userId top comment # total comment # top 10 ì„±ê³µë¥  (%) user 21 366 953 38.41 user 22 308 1636 18.83 user 23 271 935 28.98 user 24 241 1254 19.22 user 25 233 1656 14.07 user 26 204 328 62.20 user 27 191 719 26.56 user 28 168 625 26.88 user 29 149 1190 12.52 user 30 148 1489 9.94 ë¬¸í™” top users userId top comment # total comment # top 10 ì„±ê³µë¥  (%) user 31 373 1636 22.80 user 32 367 935 39.25 user 33 301 1417 21.24 user 34 243 890 27.30 user 35 220 1656 13.29 user 36 188 1943 9.68 user 37 178 3245 5.49 user 38 172 2738 6.28 user 39 164 200 82.00 user 40 151 719 21.00 IT top users userId top comment # total comment # top 10 ì„±ê³µë¥  (%) user 41 714 3123 22.86 user 42 572 3886 14.72 user 43 442 2287 19.33 user 44 399 1468 27.18 user 45 231 810 28.52 user 46 234 3010 7.77 user 47 275 1622 16.95 user 48 317 1493 21.23 user 49 346 2349 14.73 user 50 364 1185 30.72 ì„¸ê³„ top users userId top comment # total comment # top 10 ì„±ê³µë¥  (%) user 51 237 1636 14.49 user 52 214 1432 14.94 user 53 145 615 23.58 user 54 148 1709 8.66 user 55 155 611 25.37 user 56 156 1076 14.50 user 57 162 864 18.75 user 58 165 2778 5.94 user 59 165 1254 13.16 user 60 175 575 30.43 top userì˜ top 10 ì„±ê³µë¥ ì„ í™•ë¥  ë³€ìˆ˜ Xë¼ê³  í–ˆì„ ë•Œì˜ histogramê³¼ ëª¨ë“  ìœ ì €ê°€ ì „ëµì„ ë°”íƒ•ìœ¼ë¡œ í™œë™í•˜ëŠ” ê·¸ë£¹ì´ë¼ê³  ê°€ì •í–ˆì„ ë•Œ Gaussian distributionìœ¼ë¡œ ì¶”ì •í•œ í™•ë¥  ë¶„í¬ì´ë‹¤. (Gaussian Mixture Modelë¡œ distribution fittingí•œ ê²°ê³¼ëŠ” Appendix A ì°¸ê³ ) ì •ì¹˜ ì„¹ì…˜ì—ì„œë§Œ ìœ ì¼í•˜ê²Œ ratio &gt; 90% ì¸ top user(user 1, user 3)ê°€ ì¡´ì¬í–ˆìœ¼ë©° ì´ë“¤ì˜ top 10 ì „ëµ ì„±ê³µë¥ ì€ ë‹¤ë¥¸ top user ëŒ€ë¹„ ë°œìƒí•˜ê¸° ì–´ë ¤ìš¸ ì •ë„ë¡œ (0.0053%, 0.0079%) ë†’ë‹¤ê³  í•´ì„í•  ìˆ˜ ìˆë‹¤. ìˆ«ì ì´ë©´ì˜ íŒ¨í„´ì„ ë³´ê¸° ìœ„í•´ ì „ì²´ ì •ì¹˜ë©´ ê¸°ì‚¬ë“¤ì˜ ëŒ“ê¸€ ìˆ˜ì™€ user 1, user 3ì˜ ì „ì²´ ëŒ“ê¸€ ìˆ˜, top 10 ë‚´ì— ë“  ëŒ“ê¸€ ìˆ˜ë¥¼ ê·¸ë˜í”„ë¡œ ì‹œê°í™” í•´ë³´ì•˜ë‹¤. c.f. 2016.3 ~ 2018.5 ê¹Œì§€ êµµì§í•œ ì´ìŠˆë“¤[1] [2] [3] ì´ì„¸ëŒ vs. ì•ŒíŒŒê³  (2016.3) ì˜¥ì‹œ (2016.4) ìµœìˆœì‹¤ íƒœë¸”ë¦¿ pc (2016.10) ë°•ê·¼í˜œ íƒ„í•µ ì†Œì¶”ì•ˆ (2016.12) ì‚¬ë“œë°°ì¹˜ / ë°•ê·¼í˜œ ìˆ˜ê° / ì„¸ì›”í˜¸ ì¸ì–‘(2017.3) 19ëŒ€ ëŒ€í†µë ¹ ì„ ê±° (ë¬¸ì¬ì¸ ë‹¹ì„ ) (2017.5) ì´ëŒ€ëª©ë™ ì‹ ìƒì•„ ì‚¬ë§ (2017.12) í‰ì°½ ë™ê³„ ì˜¬ë¦¼í”½ (2018.2) ì´ëª…ë°• ìˆ˜ê° (2018.3) ë“œë£¨í‚¹ (2018.4) ë‚¨ë¶1ì°¨ì •ìƒíšŒë‹´ @íŒë¬¸ì  (2018.4) ë‚¨ë¶2ì°¨ì •ìƒíšŒë‹´ (2018.5) user 1 (ratio: 96%) íšŒìƒ‰ lineì´ ì •ì¹˜ë©´ ê¸°ì‚¬ ëŒ“ê¸€, íŒŒë€ìƒ‰ lineì´ ì‘ì„±ìê°€ ì“´ ì „ì²´ ëŒ“ê¸€ ìˆ˜, ì´ˆë¡ìƒ‰ lineì´ ì‘ì„±ìê°€ ì“´ ëŒ“ê¸€ ì¤‘ top 10 ë‚´ì— ë“¤ì—ˆë˜ ëŒ“ê¸€ ìˆ˜ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. user 1ì´ ì£¼ë¡œ í™œë™í–ˆë˜ ì‹œê¸°ëŠ”, ìµœìˆœì‹¤ íƒœë¸”ë¦¿ pc ì‚¬ê±´, ë°•ê·¼í˜œ íƒ„í•µ ë° 19ëŒ€ ëŒ€í†µë ¹ ì„ ê±°, í‰ì°½ ë™ê³„ì˜¬ë¦¼í”½ ë° MB ë‹¤ìŠ¤ ì‚¬ê±´ê³¼ ë§ë¬¼ë ¤ ìˆì—ˆë‹¤. ëŒ“ê¸€ ë‚´ìš©ì„ ì‹œê¸° ë³„ë¡œ ëœ¯ì–´ë³´ë©´, ë‹¤ìŒê³¼ ê°™ë‹¤. title article date user top comments æœ´ëŒ€í†µë ¹, â€˜29ì¼ê¹Œì§€ ëŒ€ë©´ì¡°ì‚¬â€™ æª¢ ìš”ì²­ì— ì‚¬í˜ì§¸ ë¬µë¬µë¶€ë‹µ 2016-11-25 15:12:00 ëŒ€í†µë ¹ì¸ ìê°€ ìì‹ ì˜ ê´€í• í•˜ì— ìˆëŠ” ê²€ì°°ì„ ë¶€ì •í•œë‹¤ë©´ ê³§ êµ­ê°€ë„ ë¶€ì •í•˜ê² ë‹¤ëŠ” ì˜ë¯¸ë‹¤. ì´ëŸ° ëŒ€í†µë ¹ì€ ë”ì´ìƒ ëŒ€í•œë¯¼êµ­ ëŒ€í†µë ¹ì´ ì•„ë‹ˆë‹¤. ì°¨ì€íƒ ë³€í˜¸ì¸ â€œì°¨ì”¨, ìµœìˆœì‹¤ ì§€ì‹œë¡œ ê¹€ê¸°ì¶˜ ì‹¤ì¥ ê³µê´€ì„œ ë©´ë‹´â€ 2016-11-27 16:04:00 ê¹€ê¸°ì¶˜ì˜ ì§„ë‘ì§€íœ˜í•˜ì— ë°•ê·¼í˜œ ì •ê¶Œì˜ ëª¨ë“  ë¶ˆë²•ë“¤ì´ ìí–‰ë˜ì—ˆë‹¤. ì •ë§ ì•…ë§ˆê°™ì€ ì¸ê°„ì´ë‹¤. ë³€í˜¸ì¸ â€œì°¨ì€íƒ, å´” ì§€ì‹œë¡œ ê¹€ê¸°ì¶˜ ë§Œë‚˜â€¦ìš°ë³‘ìš° ì¥ëª¨ì™€ ê³¨í”„ë„â€(ì¢…í•©) 2016-11-27 16:46:00 ê¹€ê¸°ì¶˜ì˜ ì§„ë‘ì§€íœ˜í•˜ì— ë°•ê·¼í˜œ ì •ê¶Œì˜ ë¶ˆë²•ë“¤ì´ ìí–‰ë˜ì—ˆë‹¤. êµ¬ì†ìˆ˜ì‚¬í•´ì„œ ê°ì˜¥ì—ì„œ ëª»ë‚˜ì˜¤ê²Œ ë§Œë“¤ì–´ì•¼ í•œë‹¤. ê³µì‘ì •ì¹˜ë¶€í„° ê³µì•ˆíƒ„ì•• ì •ê²½ìœ ì°©ì˜ ì£„ë¥¼ ë¬¼ì–´ì•¼ í•œë‹¤. ì²­ë¬¸íšŒì¥ë„ ì§€ë°°í•œ â€˜ì´›ë¶ˆë¯¼ì‹¬â€™â€¦èˆ‡é‡ â€˜ì¬ë²Œ ë´ì£¼ê¸°â€™ ì—†ì—ˆë‹¤ 2016-12-06 12:34:00 ë‡Œë¬¼ì´ì—ˆë‹¤ëŠ” ì§„ìˆ ì„ ì´ëŒì–´ë‚´ê¸°ì—ëŠ” í˜ë“¤ê²ƒ ê°™ë‹¤. ì§€ë“¤ì´ ê°ì˜¥ê°ˆ ì¼ì´ë‹ˆê¹Œâ€¦ ê°•ìš”ì£„ëŠ” í™•ì‹¤í• ë“¯â€¦ ì¬ë²Œ ì´ìˆ˜ë“¤ â€œì²­ì™€ëŒ€ ê±°ì ˆ ì–´ë ¤ì›Œâ€â€¦í•˜ë‚˜ê°™ì´ ëŒ€ê°€ì„± ë¶€ì¸ 2016-12-06 12:45:00 ë‡Œë¬¼ì´ì—ˆë‹¤ëŠ” ì§„ìˆ ì„ ì´ëŒì–´ë‚´ê¸°ì—ëŠ” í˜ë“¤ê²ƒ ê°™ë‹¤. ì§€ë“¤ì´ ê°ì˜¥ê°ˆ ì¼ì´ë‹ˆê¹Œâ€¦ ê°•ìš”ì£„ëŠ” í™•ì‹¤í• ë“¯â€¦ ë°•í•œì²  å‰ì†Œì¥ í•œí‘œ, â€˜ìºìŠ¤íŒ…ë³´íŠ¸â€™ ë ë»”í•œ ì•„ìŠ¬ì•„ìŠ¬ ìƒí™© ë‚˜ì˜¬ê¹Œ 2017-03-04 08:00:00 íƒ„í•µ ê¸°ê°ì— í‘œ ë˜ì§€ë©´ ê·¸ê²Œ íŒì‚¬ëƒ? ì¬íŒì •ì—ì„œ ê¶¤ë³€ì„ ëŠ˜ì–´ë†“ì€ ë°•ì¸¡ ëŒ€ë¦¬ì¸ë“¤ì˜ ì•ˆí•˜ë¬´ì¸ì— ì†ì„ ë“¤ì–´ì¤€ë‹¤ë©´ íŒì‚¬ì´ê¸°ë¥¼ í¬ê¸°í•˜ê³  ë°•ê·¼í˜œ ë¶€ì—­ì— ë™ì°¸í•˜ê² ë‹¤ëŠ” ì„ ì–¸ì¼ ë¿ì´ë‹¤. 85ì‹œê°„ ì¬íŒ, ì†ê¸°ë¡ 3000ìª½â€¦íƒ„í•µì‹¬íŒ ì´ë²ˆì£¼ ê²°ë¡ ë‚ ê¹Œ 2017-03-05 09:00:00 íƒ„í•µ ê¸°ê°ì— í‘œ ë˜ì§€ë©´ ê·¸ê²Œ íŒì‚¬ëƒ? ì¬íŒì •ì—ì„œ ê¶¤ë³€ì„ ëŠ˜ì–´ë†“ì€ ë°•ì¸¡ ëŒ€ë¦¬ì¸ë“¤ì˜ ì•ˆí•˜ë¬´ì¸ì— ì†ì„ ë“¤ì–´ì¤€ë‹¤ë©´ íŒì‚¬ì´ê¸°ë¥¼ í¬ê¸°í•˜ê³  ë°•ê·¼í˜œ ë¶€ì—­ì— ë™ì°¸í•˜ê² ë‹¤ëŠ” ì„ ì–¸ì¼ ë¿ì´ë‹¤. [ë¦¬ì–¼ë¯¸í„°] ë‹¤ì æ–‡ 42.6% vs å®‰ 37.2%â€¦ì–‘ì æ–‡ 47.6% vs å®‰ 43.3% 2017-04-10 09:15:00 ì—¬ë¡ ëª°ì´ì— í”ë“¤ë¦´ êµ­ë©´ì´ ì•„ë‹ˆë‹¤. ë¬´ì˜ì˜ ë¿”ì²˜ëŸ¼ ë‚˜ì•„ê°€ë©´ ì•¼í•©ì€ í©ì–´ì§€ê³  êµ³ê±´í•¨ì´ ìŠ¹ë¦¬í•  ê²ƒì´ë‹¤. æ–‡ â€œê¹€ë¶€ê²¸ ë™ì§€ ë¯¸ì•ˆí•˜ë‹¤â€¦ê¼­ êµ­ë¯¼í†µí•© í•´ë‚´ê² ë‹¤â€ 2017-04-22 08:01:00 ê¹€ë¶€ê²¸ì˜ ì§„ì‹¬ì´ ëŠê»´ì§€ê³  ê·¸ë¥¼ ìœ„ë¡œí•˜ê³  ëœ»ì„ ê°™ì´ í•˜ëŠ” ë¬¸ì¬ì¸ì˜ ì§„ì‹¬ë„ ëŠê»´ì§„ë‹¤. ë‚¨ìë“¤ì—ê²Œ ì´ëŸ° ë™ì§€ì• ëŠ” ì£½ìŒë„ ë¶ˆì‚¬í•˜ê²Œ ë§Œë“œëŠ” ë§ˆë ¥ê³¼ë„ ê¹‰ë‹¤. ì¡°~ì˜¤íƒ€!!! æ–‡ ëŒ€í†µë ¹ â€œë‚´ê²Œ ë°˜ëŒ€í•˜ë¼â€ íŒŒê²©ì  ìˆ˜ì„íšŒì˜ ì‹œë™(ìƒë³´) 2017-05-25 12:56:00 ìš”ìƒˆ ëŒ€í†µë ¹ì˜ í–‰ë™ê³¼ ì§€ì‹œì‚¬í•­ì„ ë³´ë©´ ì •ë§ ì¤€ë¹„ëœ ê²¸ì†í•œ ì‚¬ëŒì´ë€ê²Œ ì§„ì†”í•˜ê²Œ ëŠê»´ì§„ë‹¤. ëŒ€í•œë¯¼êµ­ êµ­ë¯¼ì¸ê²Œ ìë‘ìŠ¤ëŸ½ê³  í–‰ë³µí•´ì§„ë‹¤. æ–‡ëŒ€í†µë ¹ â€œì‚¬ë“œ ì„ì‹œë°°ì¹˜, í˜„ì¬ ì •ë¶€ê°€ ì·¨í•  ìˆ˜ ìˆëŠ” ìµœì„ ì˜ ì¡°ì¹˜â€(ì¢…í•©) 2017-09-08 21:13:00 êµ­ê°€ì˜ ì§€ë„ìëŠ” ìì‹ ì˜ êµ³ì€ ì‹ ë…ê¹Œì§€ë„ êµ­ê°€ì™€ êµ­ë¯¼ì„ ìœ„í•´ ì ì‹œ ì ‘ì–´ì•¼í•  ìš©ê¸°ê°€ í•„ìš”í•  ë•Œê°€ìˆë‹¤. ê·¸ ì§€ë„ìë¼ê³  ì™œ ìì‹ ì˜ ì‹ ë…ì„ êº¾ìŒì— ìê´´ê°ê³¼ ê³ ë¯¼ì´ ì—†ê² ëŠ”ê°€? ê·¸ëŠ” ìì‹ ì„ ì§€ì§€í•˜ëŠ” ì‚¬ëŒë“¤ë§Œì˜ ì§€ë„ìê°€ ì•„ë‹ˆë¼ ëŒ€í•œë¯¼êµ­ì˜ ì§€ë„ìì´ê¸° ë•Œë¬¸ì´ë‹¤. ê·¸ì˜ ê³ ë‡Œì°¬ ê²°ë‹¨ì„ ìœ„ë¡œí•˜ë©° ì§€ì¼œë³´ê³  í˜ì„ ì‹¤ì–´ì£¼ê³  ì‹¶ë‹¤. èˆ‡ â€œì•ˆì² ìˆ˜, ë‚˜ë¼ë‹¤ìš´ ë‚˜ë¼ ë§Œë“œëŠ” ì¼ í„í›¼ ë§ë¼â€ 2017-11-04 16:10:00 ëª…ë²„ê¸° êµ¬í•˜ê¸°ì— í˜ˆì•ˆì´ ëœ ëª…ë°”ê¸° ì•„ë°”íƒ€!!! ê¹€ì •ì€ ìœ„ì›ì¥ â€œì´ë¥¸ ì‹œì¼ë‚´ ë§Œë‚  ìš©ì˜â€â€¦ë¬¸ ëŒ€í†µë ¹ì— ë°©ë¶ ìš”ì²­(ì¢…í•©) 2018-02-10 15:56:00 ë‚¨ë¶ ì •ìƒíšŒë‹´ì• ì„œ í—ˆì‹¬íƒ„íšŒí•˜ê²Œ ëª¨ë“  í•  ë§ ë‹¤í•´ì„œ ê¸°í•„ì½” í•œë°˜ë„ ë¹„í•µí™”ì™€ í‰í™”ë¥¼ ì´ë£¨ì–´ì•¼ í•œë‹¤. [í˜„ì¥ì˜ìƒ] ë°©ë¯¸ íŠ¹ì‚¬ë‹¨, íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ ë©´ë‹´ ê²°ê³¼ ë°œí‘œ 2018-03-09 09:11:00 í•œë°˜ë„ í‰í™”ê°€ ì„¸ê³„ í‰í™”ë‹¤. ì´ëŸ° í‰í™” ëª¨ë“œê°€ ì–¼ë§ˆë§Œì¸ê°€â€¦ ê°™ì€ ë‚´ìš©ì˜ ëŒ“ê¸€ì´ top ì— ì˜¤ë¥¸ ê²ƒë„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. ë‹¤ë¥¸ ì„¹ì…˜ì— ê°™ì€ ëŒ“ê¸€ì„ ë‚¨ê¸°ê³ ë„ topì— ì˜¤ë¥¸ ì ë„ ìˆë‹¤. (ì•„ë˜ í‘œ ì°¸ê³ ) title section article date top user comments [í˜„ì¥ì˜ìƒ] ë°•ê·¼í˜œ å‰ ëŒ€í†µë ¹ ë²•ì›ìœ¼ë¡œ ì¶œë°œ society 2017-03-30 10:18:00 ìµœê³ ì˜ ë³´ì•ˆê³¼ ê²½í˜¸ë¥¼ ì² ì €íˆ ë°›ì„ ìˆ˜ ìˆëŠ” êµ¬ì¹˜ì†Œë¥¼ ê±°ì³ êµë„ì†Œë¡œ ì§í–‰í•˜ë©´ ë‚˜ë¼ë„ ì•ˆì •ë˜ê³  êµ­ë¯¼ë“¤ë„ í‰ì•ˆí•˜ê³  ë°•ê·¼í˜œ ìì‹ ë„ ì–¸ë¡ ì˜ ê°ì‹œë¡œë¶€í„° ë²—ì–´ë‚ ìˆ˜ ìˆë‹¤. êµ¬ì† ê°ˆë¦¼ê¸¸ì— ì„  ë°•ê·¼í˜œ â€˜ì›…ë³€ ëŒ€ì‹  ì¹¨ë¬µâ€™ ì„ íƒ politics 2017-03-30 10:22:00 ìµœê³ ì˜ ë³´ì•ˆê³¼ ê²½í˜¸ë¥¼ ì² ì €íˆ ë°›ì„ ìˆ˜ ìˆëŠ” êµ¬ì¹˜ì†Œë¥¼ ê±°ì³ êµë„ì†Œë¡œ ì§í–‰í•˜ë©´ ë‚˜ë¼ë„ ì•ˆì •ë˜ê³  êµ­ë¯¼ë“¤ë„ í‰ì•ˆí•˜ê³  ë°•ê·¼í˜œ ìì‹ ë„ ì–¸ë¡ ì˜ ê°ì‹œë¡œë¶€í„° ë²—ì–´ë‚ ìˆ˜ ìˆë‹¤. user 3 (ratio: 93%) user 3 ì˜ ì£¼ í™œë™ ì‹œê¸°ëŠ” ì‚¬ë“œë°°ì¹˜, í‰ì°½ ë™ê³„ì˜¬ë¦¼í”½ ë° ë¶ë¯¸íšŒë‹´ê³¼ ë§ë¬¼ë ¤ìˆì—ˆë‹¤. ëŒ“ê¸€ì„ ìì„¸íˆ ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤. title article date user top comments ì •ìƒíšŒë‹´ ëŒë°œ ë³€ìˆ˜ëŠ” â€˜ì‚¬ë“œâ€™â€¦ì²­ â€œëª¨ë“  ê°€ëŠ¥ì„± ì¤€ë¹„â€ 2017-06-25 20:20:00 êµ­ìµê³¼êµ­ê°€ì•ˆë³´ê°€ìµœìš°ì„ ì…ë‹ˆë‹¤~~~~ ì†¡ì˜ë¬´ â€œì‚¬ë“œ, ë¹„ì¤€ ì•„ë‹Œ êµ­íšŒ ê²€ì¦â€¦ê³ ì•¡ì—°ë´‰Â·ìŒì£¼ìš´ì „ ì†¡êµ¬â€(ì¢…í•©) 2017-06-28 12:18:00 ì´ìœ ë¯¸ë…¹ì·¨ë¡ì—ë§›ì§±êµ¬ì¹˜ê³ ë†€ì•„ë‚œì–¸ë¡ ì€Ã— ì´ìœ ë¯¸-ì´ì¤€ì„œ ì¤‘ í•œ ëª…ì€ ê±°ì§“ë§â€¦ìœ—ì„  ìˆ˜ì‚¬ ë¶ˆê°€í”¼ 2017-06-28 20:52:00 ì´ìœ ë¯¸ë…¹ì·¨ë¡ì—ë§›ì¥êµ¬ì¹˜ê³ ë†€ì•„ë‚œì–¸ë¡ ì€~~~~??? è», ì†¡ì˜ë¬´ ì¸ì‚¬ì²­ë¬¸íšŒì„œ ê³µê°œëœ â€˜êµ°ì‚¬ê¸°ë°€ ìœ ì¶œâ€™ ì¡°ì‚¬ ì°©ìˆ˜ 2017-06-29 12:24:00 ììœ ë‹¹ë†ˆë“¤ë‹µë‹¤ë„ë‘‘ë†ˆë“¤ æ–‡ëŒ€í†µë ¹, ë‚´ì¼ íŠ¸ëŸ¼í”„ì™€ ë§Œë‚œë‹¤â€¦ì·¨ì„ í›„ ì²« éŸ“ç¾ì •ìƒíšŒë‹´ 2017-06-29 13:54:00 êµ­ìµê³¼êµ­ê°€ì•ˆë³´ê°€ìµœìš°ì„ ì…ë‹ˆë‹¤ë¶€ë””ì¢‹ì€ê²°ê³¼ìˆìœ¼ì‹œê¸¸~ [ë‹¨ë…] â€˜ì œë³´ ì¡°ì‘â€™ ìˆ˜ì‚¬ë§ ì¢í˜€ì˜¤ì å®‰ ë…ëŒ€í•œ ì´ì¤€ì„œâ€¦ì™œ? 2017-06-29 20:19:00 ì² ìˆ˜ì•¼~ ê¹œë¹µê°ˆì‹œê°„ì´ë‹¤ê°€ì˜¤ë„¤~~~~ íŠ¸ëŸ¼í”„, æ–‡ëŒ€í†µë ¹ ë¶€ë¶€ì— ë°±ì•…ê´€ ì‚¬ì ê³µê°„ â€˜íŠ¸ë¦¬í‹° ë£¸â€™ ê¹œì§ê³µê°œ(ì¢…í•©) 2017-06-30 13:23:00 ë¬¸ì¬ì¸ëŒ€í†µë ¹ë‹˜~ ë©‹ì €ë¶€ëŸ¬ìš”~â™¡â™¡â™¡ í•œë°˜ë„ ì´ìŠˆì„œ â€˜ì£¼ë„ê¶Œâ€™ í™•ë³´ ì„±ê³¼â€¦í•œë¯¸FTA ì¬í˜‘ìƒ â€˜ìˆ™ì œâ€™(ì¢…í•©) 2017-07-01 10:05:00 êµ­ìµê³¼êµ­ê°€ì•ˆë³´ê°€ìµœìš°ì„ ì…ë‹ˆë‹¤ë¶€ë””ì¢‹ì€ê²°ê³¼ìˆìœ¼ì‹œê¸¸~~~~~~~~â™¡â™¡ ë‚¨ë¶ â€œ4ì›”ë§ ì •ìƒíšŒë‹´ íŒë¬¸ì ì„œ ê°œìµœâ€â€¦íŠ¹ì‚¬ë‹¨ ë°œí‘œ(ì¢…í•©) 2018-03-06 20:24:00 ì´ê²Œ ì‹¤í™”ë‚˜ã…¡ ã…¡ã…¡ã…¡ã…¡ ë¬¸ ëŒ€í†µë ¹ â€œì„œìš¸Â·í‰ì–‘Â·íŒë¬¸ì  ì¤‘ åŒ—ì´ íŒë¬¸ì  ì •ìƒíšŒë‹´ ì„ íƒâ€ 2018-03-07 15:28:00 ë¬¸í†µ ì§€ì§€ í•©ë‹ˆë‹¤ ë¬¸ ëŒ€í†µë ¹ â€œêµ­ì™¸ ëŒ€ë¶ ë¹„ë°€ì ‘ì´‰ ì—†ì–´â€¦ì €ìª½ì— ë†€ì•„ë‚˜ëŠ” ê²ƒ ì•„ëƒâ€ 2018-03-07 16:53:00 ë¬¸ ëŒ€í†µ ë ¹ë‹˜ ì§€ì§€ í•©ë‹ˆë‹¤ æ–‡ëŒ€í†µë ¹ â€œë¶í•µëª©í‘œëŠ” ë¹„í•µí™”â€¦ì œì¬ì™„í™”, ì§€ê¸ˆì€ ë¶ˆê°€ëŠ¥â€(ì¢…í•©) 2018-03-07 17:16:00 ë¬¸ëŒ€í†µë ¹ë‹˜ ì§€ì§€í•©ë‹ˆë‹¤ [í˜„ì¥ì˜ìƒ] ë°©ë¯¸ íŠ¹ì‚¬ë‹¨, íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ ë©´ë‹´ ê²°ê³¼ ë°œí‘œ 2018-03-09 09:11:00 ì´ê²Œ ì‹¤í™”ëƒã…¡ã…¡ã…¡ã…¡ Conclusions ì–´ë·°ì €ë¥¼ íƒ€ì¸ì˜ ìƒê°ì— ì˜í–¥ì„ ë¯¸ì¹˜ê³  ë¹„ì •ìƒì ì¸ í–‰íƒœë¥¼ ë³´ì´ëŠ” ì‚¬ìš©ìë¡œ ì •ì˜í•˜ì˜€ê³ , ì´ ê¸°ì¤€ì— ë”°ë¼ ì–´ë·°ì €ë¡œ ì˜ì‹¬ë˜ëŠ” ì‚¬ìš©ìë¥¼ ì°¾ì•„ë‚´ê³ ì í•˜ì˜€ë‹¤. ìˆœê³µê° ê¸°ì¤€, ëŒ“ê¸€ì´ 10ìœ„ê¶Œ ë‚´ì— ë“¤ì—ˆë˜ íšŸìˆ˜ê°€ ë§ì•˜ë˜ ì‘ì„±ì ì¤‘ì—ì„œ ì‘ì„±í•œ ëŒ“ê¸€ ìˆ˜ ëŒ€ë¹„ top 10 ëŒ“ê¸€ ìˆ˜ì˜ ë¹„ìœ¨ì´ ì¼ë°˜ì ì´ì§€ ì•Šì€ ì‘ì„±ì ê°œì¸ì ìœ¼ë¡œ, **1.**ê³¼ **2.**ì˜ ê¸°ì¤€ì— ë“œëŠ” ì‚¬ìš©ìëŠ” user 1, user 3 ë¼ëŠ” ìƒê°ì´ë‹¤. ì‘ì„±í•œ ì „ì²´ ëŒ“ê¸€ ìˆ˜ëŠ” ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì— ë¹„í•´ ì ì€ í¸ì´ì—ˆì§€ë§Œ top ëŒ“ê¸€ì— ë“¤ì—ˆë˜ ë¹„ìœ¨ì€ ê°€ì¥ ë†’ì•˜ê³ , ê·¸ ìˆ˜ì¹˜ê°€ ì¼ë°˜ì ì´ì§€ëŠ” ì•Šì•˜ë‹¤. ì–´ë·°ì €ë¥¼ ì°¾ê³ ì ì‹œì‘í•œ ë¶„ì„ì´ì—ˆì§€ë§Œ ë°ì´í„°ë¥¼ ì‚´í´ë³´ë©´ì„œ ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ì´ ê°€ì§€ëŠ” ë‹¨ì¼í•˜ê³  ê³µê°œëœ ranking systemì´ ì–¼ë§ˆë‚˜ ìœ„í—˜í•œì§€ë¥¼ ì˜¤íˆë ¤ ì¸ì‹í•˜ê²Œ ë˜ì—ˆë‹¤. ë¶„ì„í•œ ê¸°ê°„ì—ì„œ ì¤‘ë³µ ì œê±°í•œ ê¸°ì‚¬ì˜ ìˆ˜ëŠ” ì´ 100,780ê°œ ì˜€ê³ , ë§Œì•½ top 10 ëŒ“ê¸€ì˜ ì‘ì„±ìê°€ ëª¨ë‘ ë‹¤ë¥¸ ì‚¬ìš©ìì˜€ë‹¤ë©´ 1,007,800ëª…ì´ ê°ìì˜ ì˜ê²¬ì„ ê°œì‹œí–ˆì„ ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ì‹¤ì œ ê·¸ ê¸°ê°„ì— ì§‘ê³„ëœ uniqueí•œ ì‘ì„±ìëŠ” ì´ 308,731 ëª…ì— ë¶ˆê³¼í–ˆë‹¤. ê²Œë‹¤ê°€ ì¤‘ë³µ ëŒ“ê¸€ê¹Œì§€ í¬í•¨í•˜ë©´, ê·¸ ë‹¤ì–‘ì„±ì€ ì¡°ê¸ˆ ë” ë–¨ì–´ì§„ë‹¤. ì´ ê°™ì€ ë©´ì—ì„œ ë„¤ì´ë²„ ë‰´ìŠ¤ ëŒ“ê¸€ì€ ë‹¤ì–‘ì„±ì„ ì¶©ë¶„íˆ ìˆ˜ìš©í•˜ê³  ìˆì§€ ëª»í•˜ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. â€œí”Œë«í¼ì´ê¸° ë•Œë¬¸ì— ê·¸ëŸ´ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ?â€ ì‹¶ì§€ë§Œ í˜ì´ìŠ¤ë¶ì´ë‚˜ ìœ íŠœë¸Œ, ë ˆë”§ê°™ì€ ë‹¤ë¥¸ í”Œë«í¼ì—ì„œì˜ ëŒ“ê¸€ì„ ë³´ë©´ ë¬´ì‘ì • í˜¸ê°ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤. ì´ í”Œë«í¼ë“¤ì˜ ê¸°ì¤€ì´ ë¬¸ì œê°€ ì—†ë‹¤ëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤. í•˜ì§€ë§Œ ë„¤ì´ë²„ ë‰´ìŠ¤ ë³´ë‹¤ ë‹¤ì–‘í•œ ê¸°ì¤€ìœ¼ë¡œ ëŒ“ê¸€ì„ ì •ë ¬ì‹œí‚¤ê³  ìˆìœ¼ë©° (ìµœì‹ ìˆœ, ì˜¤ë˜ëœ ìˆœ, ê³µê°ì„ ë§ì´ ë°›ì€ ìˆœ, relevance ìˆœ, í˜¸ê° + voteì˜ í¬ê¸° ë“±) ì´ë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì˜ê²¬ì´ ì‰½ê²Œ ë…¸ì¶œë  ìˆ˜ ìˆëŠ” í™˜ê²½ì„ ì¡°ì„±í•˜ì˜€ë‹¤ëŠ” ì ì—ì„œëŠ” ì¢€ ë” ë†’ì€ ì ìˆ˜ë¥¼ ì£¼ê³  ì‹¶ë‹¤. ê·¸ë˜ì„œ ì„¸ ë²ˆì§¸ ê¸€ì€, ê°„ë‹¨í•˜ì§€ë§Œ ë‹¤ë¥¸ ì •ë ¬ ê¸°ì¤€ì„ ì ìš©í–ˆì„ ë•Œ ë°œê²¬ë˜ëŠ” ìƒˆë¡œìš´ ëŒ“ê¸€ì— ëŒ€í•´ì„œ ë‹¤ë¤„ ë³¼ ì˜ˆì •ì´ë‹¤. í”„ë¡œì íŠ¸ ì´ˆì°½ê¸°ì—, ê°™ì´ ì‘ì—…ì„ ì§„í–‰í–ˆë˜ ì¬ëª…ë‹˜ì´ ëŒë ¤ë³¸ ê²°ê³¼ê°€ ìˆëŠ”ë° ì´ ê²ƒë„ ì¡°ê¸ˆ ë‹¤ë“¬ì–´ì„œ ì˜¬ë¦¬ë©´ ì¬ë°Œì„ ê²ƒ ê°™ë‹¤! 3íƒ„ì€â€¦ íœ´ê°€(@Norway) ë‹¤ë…€ì˜¤ê³  ë‚˜ì„œ ì‘ì—…í•´ë³¼ê¹Œ ì‹¶ë‹¤. To be continuedâ€¦ Appendix A: Gaussian Mixture Model Fitting GMMì˜ n_components ìµœì  ê°œìˆ˜ë¥¼ êµ¬í•˜ê¸° ìœ„í•´ silhouette scoreë¥¼ ê³„ì‚°í•˜ì˜€ë‹¤. scoreê°€ ê°€ì¥ ë†’ì€ n_components=2 ì´ë¯€ë¡œ 2ê°œì˜ gaussianì„ ê°€ì •í•˜ì—¬ fitting í•´ë³´ë©´ ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ë‹¤. userId cluster 1 prob cluster 2 prob ratio (%) user 1 2.27E-16 1 95.60 user 3 2.56E-15 1 93.08 user 2 9.31E-14 1 89.21 user 39 4.96E-11 1 82.00 user 6 8.11E-01 0.188898 41.27 user 9 1.00E+00 0.000219 15.05 References 1.https://ko.wikipedia.org/wiki/2016ë…„_ëŒ€í•œë¯¼êµ­ â†©2.https://ko.wikipedia.org/wiki/2017ë…„_ëŒ€í•œë¯¼êµ­ â†©3.https://ko.wikipedia.org/wiki/2018ë…„_ëŒ€í•œë¯¼êµ­ â†©","link":"/2019/08/03/Naver-News-Comments-Analysis-(2)/"},{"title":"Pandas Dataframeì˜ ë‹¤ì–‘í•œ iteration ë°©ë²• ë¹„êµ","text":"pandasëŠ” ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ì‚¬ëŒë“¤ì´ë¼ë©´ ëˆ„êµ¬ë‚˜ ì“¸ ìˆ˜ ë°–ì— ì—†ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë¼ì´ë¸ŒëŸ¬ë¦¬ì´ë‹¤. table í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê¸°ì— í¸ë¦¬í•˜ì§€ë§Œ ì˜¤í”ˆì†ŒìŠ¤ë¼ëŠ” íŠ¹ì§•ê³¼ ë‹¤ì–‘í•œ ê¸°ëŠ¥ ì§€ì› ë•Œë¬¸ì— ì†ë„ ë©´ì—ì„œëŠ” ìµœì í™”ë˜ì–´ ìˆì§€ ì•Šì€ í¸ì´ë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” pandasì˜ ì—¬ëŸ¬ ê¸°ëŠ¥ ì¤‘ì—ì„œ iterationí•˜ëŠ” ì—¬ëŸ¬ ë°©ë²•ì„ ì†ë„ì™€ ì‚¬ìš©ì„± ì¸¡ë©´ì—ì„œ ë¹„êµí•´ë³¸ ë‚´ìš©ì„ ì•„ì£¼ ê°„ë‹¨í•˜ê²Œ ì •ë¦¬í•´ ë³´ì•˜ë‹¤. Summary rank method time iterrows ëŒ€ë¹„ ì†ë„ 1 itertuples 7.7ms x8.1 2 at / iat 15.8ms x4 3 loc / iloc 24.6ms x2.5 4 iterrows 62.7ms x1 ë²ˆì™¸ values 7.1ms x8.8 ë²ˆì™¸ apply + to_dict 9.91 ms x6.3 Introduction ì‹¤í—˜ì— ì‚¬ìš©í•œ ë°ì´í„°ëŠ” ì•„ë˜ì™€ ê°™ì´ id, text, title ì •ë³´ë¡œ ì´ë£¨ì–´ì§„ ìœ„í‚¤í”¼ë””ì•„ë¥¼ ì²˜ë¦¬í•œ table í˜•ì‹ì˜ ë°ì´í„°ì´ë‹¤. textëŠ” ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œë¥¼ ì¼ì • ê¸¸ì´ ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ ê°€ê³µí•œ ë¬¸ì¥ë“¤ì´ê³ , titleì€ í•´ë‹¹ ë¬¸ì¥ì´ ì†í•œ ìœ„í‚¤í”¼ë””ì•„ ë¬¸ì„œì˜ ì œëª©ì„ ì˜ë¯¸í•œë‹¤. idëŠ” ê° ë¬¸ì¥ë“¤ì˜ ê³ ìœ  ë²ˆí˜¸ì´ë‹¤. ë°ì´í„°ì˜ row ë³„ë¡œ iterationì„ í•˜ë©´ì„œ ì²˜ë¦¬í•  ë‚´ìš©ì€ 1) ì•„ë˜ì˜ cut_textë¥¼ í†µí•´ textì˜ ê¸¸ì´ë¥¼ ì¤„ì´ê³ , 2) table ì˜ ë‚´ìš©ì„ list_of_dict í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì´ë‹¤. def cut_text(text, max_len: int = 100): return ' '.join(text.split()[:max_len]) ì‹¤í—˜í•  í•¨ìˆ˜ëŠ” í¬ê²Œ iterrows, loc/iloc, at/iat, itertuples, ê·¸ë¦¬ê³  ì†ë„ ë©´ì—ì„œëŠ” ì¥ì ì´ ìˆìœ¼ë‚˜ ì•½ê°„ì˜ ë‹¨ì ì´ ìˆëŠ” values, ê·¸ë¦¬ê³  ì´ë²ˆ task ì— overfitting ëœ apply + to_dict ê°€ ìˆë‹¤. í•˜ë‚˜í•˜ë‚˜ ì‚´í´ë³´ë„ë¡ í•˜ì! iterrows ë§ì´ ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ì´ì§€ë§Œ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šë‹¤. %%timeitresult = []for i, row in data.iterrows(): short_text = cut_text(row['text']) instance = { 'id': row['id'], 'text': short_text, 'title': row['title'] } result.append(instance) 62.7 ms Â± 729 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each) loc / iloc iterrows ë‹¤ìŒìœ¼ë¡œ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë°©ì‹ì´ë‹¤. iterrowsì— ë¹„í•´ 2.5ë°° ì •ë„ ë¹ ë¥¸ ì†ë„ë¥¼ ë³´ì¸ë‹¤. %%timeitresult = []for idx in data.index: short_text = cut_text(data.loc[idx, 'text']) instance = { 'id': data.loc[idx, 'id'], 'text': short_text, 'title': data.loc[idx, 'title'] } result.append(instance) 24.6 ms Â± 235 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each) :warning: ë‹¤ë§Œ, locì„ ì˜ëª» ì“°ê²Œ ë˜ë©´ iterrowsë¥¼ ì¼ì„ ë•Œë³´ë‹¤ë„ ë” ì˜¤ëœ ì‹œê°„ì´ ì†Œìš”ëœë‹¤. %%timeitresult = []for idx in data.index: short_text = cut_text(data.loc[idx]['text']) # diff instance = { 'id': data.loc[idx]['id'], 'text': short_text, 'title': data.loc[idx]['title'] } result.append(instance) 261 ms Â± 1.12 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each) :warning: ë¯¸ë¦¬ rowë¥¼ ë°›ìœ¼ë©´ ì¡°ê¸ˆ ë” ë¹¨ë¼ì§€ì§€ë§Œ, ê·¸ëŸ¼ì—ë„ iterrowsëŒ€ë¹„ ëŠë¦¬ë‹¤. %%timeitresult = []for idx in data.index: row = data.loc[idx] short_text = cut_text(row['text']) # diff instance = { 'id': row['id'], 'text': short_text, 'title': row['title'] } result.append(instance) 99.4 ms Â± 904 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each) at / iat loc / iloc ê³¼ ìœ ì‚¬í•˜ì§€ë§Œ, íŠ¹ì • columnê³¼ rowì— í•´ë‹¹í•˜ëŠ” ê°’ì„ ë°›ê³  ì‹¶ì„ ë•Œ ì‚¬ìš©í•œë‹¤. at í•¨ìˆ˜ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…ì€ pandas ê³µì‹ ë¬¸ì„œì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤. iterrowsì— ë¹„í•´ 4ë°° ì •ë„ ë¹ ë¥¸ ì†ë„ë¥¼ ë³´ì¸ë‹¤. %%timeitresult = []for idx in data.index: short_text = cut_text(data.at[idx, 'text']) instance = { 'id': data.at[idx, 'id'], 'text': short_text, 'title': data.at[idx, 'title'] } result.append(instance) 15.8 ms Â± 49.6 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each) itertuples iterrowsì™€ ìœ ì‚¬í•˜ì§€ë§Œ, Seriesê°€ returnë˜ëŠ” iterrowsì™€ëŠ” ë‹¤ë¥´ê²Œ NamedTupleì´ return ëœë‹¤. columnì— ëŒ€ì‘ë˜ëŠ” ê°’ì— ì ‘ê·¼í•˜ê¸°ë„ ì‰½ê³ , ì†ë„ë„ 8ë°° ì´ìƒ ë¹ ë¥´ë‹¤. %%timeitresult = []for row in data.itertuples(): short_text = cut_text(row.text) instance = { 'id': row.id, 'text': short_text, 'title': row.title } result.append(instance) 7.7 ms Â± 21.9 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each) values ì—¬ê¸°ì„œë¶€í„°ëŠ” ë²ˆì™¸ ëŠë‚Œì¸ë°, valuesëŠ” ì†ë„ê°€ ê°€ì¥ ë¹ ë¥´ë‹¤ëŠ” ì¥ì ì´ ìˆì§€ë§Œ columnì— ëŒ€ì‘ë˜ëŠ” ê°’ì„ ë¶ˆëŸ¬ì˜¬ ë•Œ ë¶ˆí¸í•œ ì ì´ ìˆë‹¤. ì´ ì ì„ ê°ì•ˆí•´ì„œ ì¨ë„ ë¬´ê´€í•˜ë‹¤ë©´ ê°€ì¥ ì¢‹ì€ ì„ íƒì´ ë  ê²ƒ ê°™ë‹¤. %%timeitresult = []for value in data.values: short_text = cut_text(value[1]) instance = { 'id': value[0], 'text': short_text, 'title': value[2] } result.append(instance) 7.1 ms Â± 43.8 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each) apply + to_dict for ë¬¸ ì•ˆì—ì„œ ì²˜ë¦¬í•  ë‚´ìš©ì´ ë³µì¡í•˜ì§€ ì•Šì€ ì´ë²ˆ íƒœìŠ¤í¬ê°™ì€ ê²½ìš°ì— ì“°ê¸° ì í•©í•œ ë°©ì‹ì´ë‹¤. ìƒˆë¡œìš´ dataframe í˜¹ì€ ìƒˆë¡œìš´ columnì„ ìƒì„±í•´ì•¼ í•´ì„œ ë©”ëª¨ë¦¬ ì¸¡ë©´ì—ì„œ ì˜¤ëŠ” ë‹¨ì ì€ ìˆì§€ë§Œ, ì½”ë“œê°€ ì§§ê³  ê¹”ë”í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤. %%timeitresult = data.copy()result['text'] = result['text'].apply(lambda x: cut_text(x))result = result.to_dict(orient='records') 9.91 ms Â± 19.6 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each) References https://inmoonlight.github.io/notebooks/html/2021-02-04-pandas-dataframe-iterations.html https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.at.html https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.itertuples.html","link":"/2021/02/04/Pandas-Dataframe-iterations/"},{"title":"Positional Encoding in NLP","text":"Positional encoding í˜¹ì€ position encodingì€ ëª¨ë¸ êµ¬ì¡°ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ sequential informationì„ ì–»ì§€ ëª»í•˜ëŠ” ê²½ìš°ì— ëŒ€í•´ ì •ë³´ë¥¼ ê°•ì œí•˜ëŠ” ë°©ì‹ì´ë‹¤. ë³´í†µ sequential dataë¥¼ Recurrent Neural Network (RNN) ì™¸ì˜ ë‹¤ë¥¸ ëª¨ë¸ë¡œ ë‹¤ë£¨ê³  ì‹¶ì„ ë•Œ ë§ì´ ì‚¬ìš©ëœë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” Convolutional Neural Network (CNN), End-to-End Memory Network (MemN2N), Transformerì—ì„œ sentence embeddingì„ ìœ„í•´ ì‚¬ìš©ëœ positional encodingì— ëŒ€í•´ ì†Œê°œí•˜ë ¤ê³  í•œë‹¤. Introduction ì¼ë°˜ì ìœ¼ë¡œ NLP ëª¨ë¸ì€ ê° ë¬¸ì¥ì„ êµ¬ì„±í•˜ëŠ” tokenì„ one-hot vectorê°€ ì•„ë‹Œ distributed vectorë¡œ í‘œí˜„í•œë‹¤. ê·¸ ì´ìœ ëŠ” distributed representationì´ 1) ë¹„ìŠ·í•œ ì˜ë¯¸ì§€ë§Œ ë‹¤ë¥¸ lexical formì„ ê°€ì§„ tokenì„ ë” ì˜ í‘œí˜„í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ê³ , 2) embedding dimensionì„ ê°ì†Œì‹œí‚¬ ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤. ë¬¸ì¥ì˜ embeddingì€ ë¬¸ì¥ì„ ì´ë£¨ëŠ” ê° tokenì˜ embeddingì„ ì¡°í•©í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì–»ì–´ì§„ë‹¤. ì´ ë•Œ positionì— ëŒ€í•œ ì •ë³´ê°€ ì—†ë‹¤ë©´ ëª¨ë¸ì€ handful of chocolateê³¼ chocolate of handfulì„ ê°™ì€ ì˜ë¯¸ë¡œ ì¸ì‹í•˜ê²Œ ëœë‹¤. RNNì€ ëª¨ë¸ êµ¬ì¡° ìì²´ì— time informationì´ ë…¹ì•„ì ¸ ìˆë‹¤. ê·¸ë˜ì„œ handful --&gt; of --&gt; chocolate ì˜ ìˆœì„œê°€ ë‹´ê¸´ sentence embeddingì„ ìì—°ìŠ¤ëŸ½ê²Œ ì–»ì„ ìˆ˜ ìˆë‹¤. ë°˜ë©´ CNNì´ë‚˜ Attention ê¸°ë°˜ì˜ TransformerëŠ” ìˆœì„œì— ëŒ€í•œ ì •ë³´ë¥¼ ê°•ì œí•´ì•¼ í•˜ê³ , ì´ ë•Œ positional encodingì´ ì‚¬ìš©ëœë‹¤. Positional encoding (PE) ì€ token embedding vectorì— ê³±í•´ì§€ëŠ” ì •ë³´ë¡œ, sentenceì—ì„œ í•´ë‹¹ tokenì´ ì–´ë””ì— ìœ„ì¹˜í•´ ìˆëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. Jê°œì˜ token \\(t_j \\in \\mathbb{R}^d\\)ìœ¼ë¡œ êµ¬ì„±ëœ sentence \\(s = [t_1, t_2, â€¦, t_J]\\)ê°€ ìˆë‹¤ê³  í•˜ì. PE \\(\\in \\mathbb{R}^{J \\times d}\\) ì˜ row \\(j\\)ë§ˆë‹¤ ë‹¤ë¥¸ ê°’ì„ ê°€ì§€ë„ë¡ í•˜ì—¬ ë¬¸ì¥ ë§¨ ì²˜ìŒì˜ handfulê³¼ ë§¨ ë’¤ì˜ handfulì„ ë‹¤ë¥´ê²Œ ì¸ì‹í•˜ë„ë¡ í•œë‹¤. PEë¥¼ êµ¬ì„±í•˜ëŠ” ë°©ì‹ì—ëŠ” í¬ê²Œ ë‘ ì¢…ë¥˜ê°€ ìˆë‹¤. í•˜ë‚˜ëŠ” í•™ìŠµê¸°ë°˜, ë‹¤ë¥¸ í•˜ë‚˜ëŠ” positionê³¼ dimensionì„ ì…ë ¥ìœ¼ë¡œ í•œ í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ëŠ” ë°©ë²•ì´ë‹¤. Learned Positional Embeddings í•™ìŠµê¸°ë°˜ì˜ PEë¥¼ êµ¬ì„±í•˜ëŠ” ë°©ì‹ì€ Convolutional Sequence to Sequence Learning (ConvS2S)[1]ì—ì„œ ì‚¬ìš©ë˜ì—ˆë‹¤. í‰ê·  0, í‘œì¤€í¸ì°¨ 0.1ì„ ë”°ë¥´ëŠ” normal distributionìœ¼ë¡œ initializeë˜ê³  í•™ìŠµì„ í†µí•´ position ì •ë³´ë¥¼ ë°°ìš°ê¸¸ ê¸°ëŒ€í•œë‹¤. PEë¥¼ encoderì™€ decoder ëª¨ë‘ì— ì‚¬ìš©í•œ ê²½ìš°, encoderì—ë§Œ ì‚¬ìš©í•œ ê²½ìš°, decoderì—ë§Œ ì‚¬ìš©í•œ ê²½ìš°, ì•„ì˜ˆ ì‚¬ìš©í•˜ì§€ ì•Šì€ ê²½ìš°ë¡œ ë‚˜ëˆ„ì–´ ë²ˆì—­ taskì— ì‹¤í—˜í•´ë³´ì•˜ì„ ë•Œì˜ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. BLEUë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ì„í•´ë³´ë©´ encoderì—ì„œì˜ PEì—­í• ì´ decoderë³´ë‹¤ ì¡°ê¸ˆ ë” ì¤‘ìš”í•˜ë‹¤. PEë¥¼ ì•„ì˜ˆ ì“°ì§€ ì•Šì„ ë•Œì˜ ì ìˆ˜ê°€ ê°€ì¥ ë‚®ì§€ë§Œ ì ìˆ˜ ì°¨ì´ë¥¼ ìƒê°í•´ë³´ë©´ ëª¨ë¸ ì„±ëŠ¥ì—ëŠ” í¬ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ”ë‹¤ê³  í•´ì„í•´ ë³¼ ìˆ˜ ìˆë‹¤. í•™ìŠµ ê¸°ë°˜ì´ë¯€ë¡œ í•™ìŠµ ì‹œ ë‹¤ë£¨ì§€ ì•Šì•˜ë˜ ê¸¸ì´ì˜ ë¬¸ì¥ì´ ì…ë ¥ìœ¼ë¡œ ë“¤ì–´ì˜¨ ê²½ìš°, ì™¸ì‚½ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.[5] Function-based Positional Encoding í•¨ìˆ˜ ê¸°ë°˜ì˜ PEëŠ” ë¬¸ì¥ì—ì„œ ëª‡ ë²ˆì§¸ì— ìœ„ì¹˜í•œ í† í°ì¸ì§€, í† í°ì˜ embedding dimensionì´ ë¬´ì—‡ì¸ì§€ë¥¼ ì •í•´ì£¼ë©´ ê°’ì´ ì •í•´ì§„ë‹¤. ì´ ë•Œ, ë‹¤ë¥¸ ìœ„ì¹˜ì˜ ì •ë³´ê°€ ê°™ì€ ê°’ìœ¼ë¡œ mappingë˜ì§€ ì•Šì•„ì•¼ í•œë‹¤. ì–´ë–»ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆì„ê¹Œ? The Intuition 0ë¶€í„° 15ê¹Œì§€ì˜ ìˆ«ìë¥¼ 2ì§„ë²•ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë³´ì. ë‹¤ë¥¸ ìƒ‰ìœ¼ë¡œ êµ¬ë¶„ì§€ì–´ í‘œí˜„í•œ 2ì§„ìˆ˜ì˜ ìë¦¬ìˆ˜ë§ˆë‹¤ ë‹¤ë¥¸ ì£¼ê¸°ë¥¼ ê°€ì§€ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ë¶‰ì€ìƒ‰ì€ ì£¼ê¸°ê°€ 1ì´ê³ , ë…¸ë€ìƒ‰ì€ ì£¼ê¸°ê°€ 2, ì´ˆë¡ìƒ‰ì€ ì£¼ê¸°ê°€ 4, íŒŒë€ìƒ‰ì€ ì£¼ê¸°ê°€ 8ì´ë‹¤. ìœ„ ì˜ˆì‹œì—ì„œì˜ ìë¦¬ìˆ˜ë¥¼ embedding dimensionì´ë¼ê³  ìƒê°í•´ë³´ë©´ PEì—ë„ ê°™ì€ ì›ë¦¬ë¥¼ í™•ì¥ì‹œì¼œë³¼ ìˆ˜ ìˆë‹¤. In MemN2N End-to-End Memory Network (MemN2N)[4]ì—ì„œëŠ” ì•„ë˜ì˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í–ˆë‹¤. \\[PE_{k j}=(1- \\frac{j}{J})-\\frac{k}{d}(1- \\frac{2j}{J})\\] \\[j \\in {1, â€¦, J}\\] \\[k \\in {1, â€¦, D}\\] ì„ì˜ì˜ ë¬¸ì¥ *â€œThe same representation is used for questions, memory inputs and memory outputs.â€*ì— ì ìš©ë˜ëŠ” PEë¥¼ ì‹œê°í™”í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.[5] ì—¬ê¸°ì„œëŠ” dimensionì— ê´€ê³„ì—†ì´ ê°™ì€ ì£¼ê¸°ë¥¼ ê°€ì§€ì§€ë§Œ ì‹œì‘ê°’ì´ ì „ë¶€ ë‹¤ë¥´ë‹¤. ê²°ê³¼ì ìœ¼ë¡œëŠ” positionë§ˆë‹¤ ë‹¤ë¥¸ vectorë¥¼ ê³±í•˜ê²Œ ë˜ì–´ position ì •ë³´ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆë‹¤. ë‹¤ë¥¸ ë¬¸ì¥ ê¸¸ì´ë¥¼ ê°€ì§€ëŠ” ê²½ìš°ì— ëŒ€í•´ì„œ ì ìš©í•´ë³´ë©´ ì–´ë–¨ê¹Œ? ì´ë²ˆì—ëŠ” *â€œWe therefore propose a second representation that encodes the position of words within the sentence.â€*ì— ëŒ€í•´ ì‹œê°í•´ë³´ì•˜ë‹¤.[5] positionì´ ëŠ˜ì–´ë‚œë§Œí¼ position encoding ê°’ì˜ ë³€í™”ë„ê°€ ì¤„ì—ˆë‹¤. JëŠ” ë¬¸ì¥ë§ˆë‹¤ ë‹¬ë¼ì§€ë¯€ë¡œ ì²«ë²ˆì§¸, ë‘ë²ˆì§¸ì˜ ì ˆëŒ€ì ì¸ ìœ„ì¹˜ë³´ë‹¤ëŠ” ê° ìˆœì„œë¥¼ êµ¬ë¶„ì§“ê¸° ìœ„í•œ ëª©ì ì— ì¹˜ì¤‘í•˜ì˜€ë‹¤. ConvS2Sì—ì„œì™€ëŠ” ë‹¬ë¦¬ MemN2Nì—ì„œ PEì˜ íš¨ê³¼ëŠ” ê½¤ë‚˜ ì»¸ë˜ ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤. In Transformer Attention is all you need[5]ì—ì„œ ì‚¬ìš©ëœ PEëŠ” ì£¼ê¸°í•¨ìˆ˜ë¡œ ìœ ëª…í•œ sin í•¨ìˆ˜ì™€ cos í•¨ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œë‹¤. (a.k.a, sinusoidal functions) \\[ \\begin{aligned} P E_{(\\text {pos, 2k} )} &amp;=\\sin \\left(\\text {pos} / 10000^{2 k / d}\\right) \\\\ P E_{(\\text {pos,2k+1})} &amp;=\\cos \\left(\\text {pos} / 10000^{2 k / d}\\right) \\end{aligned} \\] ì ì‹œ ê³ ë“±í•™êµ ë•Œ ë°°ìš´ ìˆ˜í•™ì„ ë– ì˜¬ë ¤ë³´ì. \\(sin(ax + b)\\) ì˜ ì£¼ê¸°ëŠ” \\(\\frac{2\\pi}{|a|}\\) ì´ë‹¤. ë”°ë¼ì„œ PEì˜ íŠ¹ì • position vector ê°’ì˜ ì£¼ê¸°ëŠ” \\(2\\pi \\cdot 10000^{2 k / d}\\) ì™€ ê°™ë‹¤. MemN2Nì—ì„œì˜ PEì™€ëŠ” ë‹¬ë¦¬, position vectorì˜ ì£¼ê¸°ê°€ vectorì˜ dimensionë§ˆë‹¤ ë³€í™”í•œë‹¤. ì „ì²´ ë²¡í„° í¬ê¸°(\\(d\\))ê°€ 128ì´ë¼ê³  ê°€ì •í•  ë•Œ, \\(k\\)ê°€ ì‘ì„ìˆ˜ë¡ ì£¼ê¸°ê°€ ì§§ê³  \\(k\\)ê°€ í´ìˆ˜ë¡ ì£¼ê¸°ë„ ê¸¸ì–´ì§„ë‹¤. (ì•„ë˜ ê·¸ë¦¼ ì°¸ê³ ) ì™œ Transformerì—ì„œëŠ” MemN2Nê³¼ ë‹¤ë¥´ê²Œ sinusoidal í•¨ìˆ˜ë¥¼ ì¼ì„ê¹Œ? ë…¼ë¬¸ì—ì„œ ê·¸ ì´ìœ ë¥¼ ì§§ê²Œ ê¸°ìˆ í•˜ê³  ìˆë‹¤. We chose this function because we hypothesized it would allow the model to easily learn to attend by relative positions, since for any fixed offset \\(k\\), \\(P E_{pos+k}\\) can be represented as a linear function of \\(P E_{pos}\\). sinusodial í•¨ìˆ˜ì˜ íŠ¹ì§•ì„ ì´ìš©í•´ ì²«ë²ˆì§¸, ë‘ë²ˆì§¸ë§ˆë‹¤ ê°™ì€ position ì •ë³´ë¥¼ ì£¼ë©´ì„œë„ \\(n + k\\)ë²ˆì§¸ vectorê°€ \\(n\\)ë²ˆì§¸ vectorì™€ ê´€ê³„ê°€ ìˆì„ ë•Œ ì´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆëŠ” ì—¬ì§€ë¥¼ ë‚¨ê²¨ì£¼ê¸° ìœ„í•¨ì´ë‹¤. (ì°¸ê³ ë¡œ ì´ì— ëŒ€í•œ ìˆ˜í•™ì ì¸ ì¦ëª…ì€ ì´ articleì— ê¸°ìˆ ë˜ì–´ ìˆë‹¤.) ë˜í•œ PE vector ê°„ì˜ distanceëŠ” ëŒ€ì¹­ì ì´ê³  ê±°ë¦¬ì— ë”°ë¼ ì¼ì •í•œ ë¹„ìœ¨ë¡œ ê°ì†Œí•œë‹¤. Transformerì˜ self-attention ì—°ì‚°ì—ì„œ ë¹›ì„ ë°œí•˜ëŠ” íŠ¹ì§•ì´ë‹¤. Conclusions PEëŠ” í¬ê²Œ í•™ìŠµì„ í†µí•´ ì •í•´ì§ˆ ìˆ˜ ìˆê³  ë¯¸ë¦¬ ì§€ì •í•œ í•¨ìˆ˜ë¡œ ì •í•´ì§ˆ ìˆ˜ë„ ìˆë‹¤. í•™ìŠµì„ í†µí•œ ë°©ì‹ì€ í•™ìŠµì‹œ ë³´ì§€ ì•Šì•˜ë˜ ìƒˆë¡œìš´ ê¸¸ì´ê°€ ë“±ì¥í–ˆì„ ë•Œ ì™¸ì‚½ì´ ë¶ˆê°€ëŠ¥í•˜ì§€ë§Œ í•¨ìˆ˜ ê¸°ë°˜ì˜ PEëŠ” ê°€ëŠ¥í•˜ë‹¤. í•¨ìˆ˜ë„ ì–´ë–¤ í•¨ìˆ˜ë¥¼ ì“°ëŠëƒì— ë”°ë¼ ì¢…ë¥˜ê°€ êµ¬ë¶„ë˜ëŠ”ë°, ì ˆëŒ€ì ì¸ ìœ„ì¹˜ì— ë”°ë¼ ê°™ì€ ê°’ì„ ê°€ì§€ë©´ì„œë„ ìƒëŒ€ì  ìœ„ì¹˜ì˜ ê´€ê³„ë„ í•™ìŠµí•  ìˆ˜ ìˆëŠ” \\(sin\\)ê³¼ \\(cos\\) ê¸°ë°˜ì˜ í•¨ìˆ˜ê°€ ê°€ì¥ ì¢‹ì€ ë°©ë²•ì´ë¼ê³  ìƒê°ëœë‹¤. References 1.https://arxiv.org/abs/1705.03122 â†©2.https://kazemnejad.com/blog/transformer_architecture_positional_encoding/ â†©3.https://arxiv.org/abs/1503.08895 â†©4.https://github.com/inmoonlight/notebooks/blob/master/notebooks/2020-01-26-MemN2N-Position-Encoding.ipynb â†©5.https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf â†©","link":"/2020/01/26/Positional-Encoding/"},{"title":"PyTorchì˜ view, transpose, reshape í•¨ìˆ˜ì˜ ì°¨ì´ì  ì´í•´í•˜ê¸°","text":"ìµœê·¼ì— pytorchë¡œ ê°„ë‹¨í•œ ëª¨ë“ˆì„ ì¬êµ¬í˜„í•˜ë‹¤ê°€ lossì™€ dev scoreê°€ ì›ë˜ êµ¬í˜„ëœ ê²°ê³¼ì™€ ë‹¬ë¼ì„œ ì˜ì•„í•´í•˜ë˜ ì°°ë‚˜, tensor ì°¨ì›ì„ ë³€ê²½í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜ë„í•˜ì§€ ì•Šì€ ë°©í–¥ìœ¼ë¡œ êµ¬í˜„ëœ ê²ƒì„ í™•ì¸í•˜ê²Œ ë˜ì—ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ ì´ìœ ëŠ” transpose ì™€ view ì˜ ê¸°ëŠ¥ì„ í—·ê°ˆë ¤í–ˆê¸° ë•Œë¬¸ì´ì—ˆë‹¤. ë‘ í•¨ìˆ˜ì˜ ì°¨ì´ëŠ” contiguous ë¥¼ ì´í•´í•´ì•¼ ì•Œ ìˆ˜ ìˆëŠ” ë‚´ìš©ì´ì—ˆê³ , í˜¹ì‹œ ì´ ê°œë…ì´ í—·ê°ˆë¦¬ëŠ” ì‚¬ëŒë“¤ì„ ìœ„í•´ ê°„ë‹¨í•œ ì˜ˆì‹œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë¦¬í•´ë³´ì•˜ë‹¤. contiguous ë€ matrix ì˜ ëˆˆì— ë³´ì´ëŠ” (advertised) ìˆœì°¨ì ì¸ shape information ê³¼ ì‹¤ì œë¡œ matrix ì˜ ê° ë°ì´í„°ê°€ ì €ì¥ëœ ìœ„ì¹˜ê°€ ê°™ì€ì§€ì˜ ì—¬ë¶€ì´ë‹¤. ì•„ë˜ì˜ ì˜ˆì‹œì—ì„œ t ëŠ” contiguous í•˜ë‹¤. ì™œëƒí•˜ë©´ t[0][0][0] â†’ t[0][0][1] â†’ t[0][1][0] â€¦ ì˜ ë°ì´í„° í¬ì¸í„° ìœ„ì¹˜ (0 â†’ 1 â†’ 2 â€¦ ) ë˜í•œ ì—°ì†ì ì´ê¸° ë•Œë¬¸ì´ë‹¤. ì•„ì§ ì´í•´ê°€ ë˜ì§€ ì•Šì•„ë„ ê´œì°®ë‹¤. ì˜ˆì‹œë¥¼ ì¢€ ë” ë³´ì! t = torch.tensor([[[0, 1], [2, 3], [4, 5]], \\ [[6, 7], [8, 9], [10, 11]], \\ [[12, 13], [14, 15], [16, 17]], \\ [[18, 19], [20, 21], [22, 23]]]) # (4, 3, 2) print(t) >foldedtensor([[[ 0, 1], [ 2, 3], [ 4, 5]], [[ 6, 7], [ 8, 9], [10, 11]], [[12, 13], [14, 15], [16, 17]], [[18, 19], [20, 21], [22, 23]]]) view view ë¥¼ í†µí•´ t ë¼ëŠ” tensorì˜ shapeë¥¼ ë³€ê²½ì‹œì¼œë³´ì•˜ë‹¤. tv = t.view(4, 2, 3) print(tv) >foldedtensor([[[ 0, 1, 2], [ 3, 4, 5]], [[ 6, 7, 8], [ 9, 10, 11]], [[12, 13, 14], [15, 16, 17]], [[18, 19, 20], [21, 22, 23]]]) shapeì´ (4, 2, 3) ìœ¼ë¡œ ì˜ ë°”ë€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  tv[0][0][0] â†’ tv[0][0][1] â†’ tv[0][0][2] â€¦ ì˜ ë°ì´í„° í¬ì¸í„° ìœ„ì¹˜ (0 â†’ 1 â†’ 2 â€¦ ) ë˜í•œ ì—°ì†ì ì´ê¸° ë•Œë¬¸ì— tv ëŠ” contiguous í•˜ë‹¤. tv.is_contiguous()---True ë°ì´í„°ì˜ tensor index ìˆœì„œëŒ€ë¡œ tensorë¥¼ flatten ì‹œì¼œì£¼ëŠ” í•¨ìˆ˜ë¥¼ í†µí•´ t ì™€ tv ë¥¼ ë¹„êµí•˜ë©´ ë™ì¼í•˜ê²Œ ë‚˜ì˜¤ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. t.flatten() == tv.flatten()---tensor([True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]) ë˜í•œ t ì™€ tv ì˜ ë°ì´í„°ëŠ” pointer ê°’ì´ ë™ì¼í•˜ì—¬ í•œ ìª½ì˜ tensor data ë¥¼ ìˆ˜ì •í•˜ë©´ ë‹¤ë¥¸ ìª½ì˜ ê°’ë„ ë™ì‹œì— ë³€ê²½ëœë‹¤. t.storage().data_ptr() == tv.storage().data_ptr() # data pointer ê°’ì´ ì¼ì¹˜í•¨---True # Modifying view tensor changes base tensor as well.t[0][0][0] = 99tv[0][0][0]---tensor(99) transpose transpose ë¥¼ í†µí•´ t ë¼ëŠ” í…ì„œì˜ shapeì„ ë³€ê²½ì‹œì¼œë³´ì•˜ë‹¤. shapeì€ tvì™€ ë™ì¼í•˜ë‚˜, êµ¬ì„±ì´ ì¡°ê¸ˆ ë‹¤ë¥¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì°¸ê³ ë¡œ, ë³´í†µ (batch_size, hidden_dim, input_dim) ì„ (batch_size, input_dim, hidden_dim) ìœ¼ë¡œ ë°”ê¿”ì£¼ëŠ” ì‘ì—…ì„ í•  ë•Œì— transpose ë¥¼ ì‚¬ìš©í•œë‹¤. tt = t.transpose(2, 1) # (4, 2, 3) print(tt) >foldedtensor([[[ 0, 2, 4], [ 1, 3, 5]], [[ 6, 8, 10], [ 7, 9, 11]], [[12, 14, 16], [13, 15, 17]], [[18, 20, 22], [19, 21, 23]]]) ì•ì„  ì˜ˆì‹œì—ì„œ t ì˜ ë°ì´í„° í¬ì¸í„°ëŠ” 0 â†’ 1 â†’ 2 â€¦ ìˆœì„œëŒ€ë¡œ ì €ì¥ëœ ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆë‹¤. tì™€ tv ëª¨ë‘ ë°ì´í„° í¬ì¸í„°ì˜ ë¬¼ë¦¬ì  ìˆœì„œì™€ shape ìƒì—ì„œì˜ ë°ì´í„° ìˆœì„œê°€ ê°™ì•˜ê¸° ë•Œë¬¸ì— contiguous í–ˆë‹¤. í•˜ì§€ë§Œ tt ì˜ ê²½ìš° 0 â†’ 1 â†’ 2 â€¦ â‰  tt[0][0][0] â†’ tt[0][0][1] â†’ tt[0][0][2] â€¦ ì´ê¸° ë•Œë¬¸ì— contiguous í•˜ì§€ ì•Šë‹¤. tt.is_contiguous()---False tt ë¥¼ flatten ì‹œí‚¤ë©´ ë¬¼ë¦¬ì  ìˆœì„œ (0 â†’ 1 â†’ 2 â€¦ ) ì™€ shape ìƒì˜ ìˆœì„œê°€ ë‹¤ë¥¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. tt.flatten()---tensor([ 0, 2, 4, 1, 3, 5, 6, 8, 10, 7, 9, 11, 12, 14, 16, 13, 15, 17, 18, 20, 22, 19, 21, 23]) contiguous ê·¸ë ‡ë‹¤ë©´ ê°•ì œë¡œ ë¬¼ë¦¬ì  ìœ„ì¹˜ë¥¼ ì—°ì†ì ìœ¼ë¡œ ë§Œë“¤ì–´ë²„ë¦¬ë©´ ì–´ë–»ê²Œ ë ê¹Œ? ê²‰ë³´ê¸°ì—ëŠ” tt ì™€ ë³„ ì°¨ì´ê°€ ì—†ì–´ë³´ì¸ë‹¤. tt.contiguous() == tt---tensor([[[True, True, True], [True, True, True]], [[True, True, True], [True, True, True]], [[True, True, True], [True, True, True]], [[True, True, True], [True, True, True]]]) í•˜ì§€ë§Œ ê° ë°ì´í„° í¬ì¸í„°ë¥¼ ë¹„êµí•˜ë©´ tt.contiguous() ëŠ” 0 â†’ 2 â†’ 4 â€¦ ì´ê³  tt ëŠ” 0 â†’ 1 â†’ 2 ì´ê¸° ë•Œë¬¸ì— ì•„ë˜ì˜ ê°’ì´ Falseê°€ ë‚˜ì˜¤ëŠ” ê²ƒì„ ì˜ˆìƒí•´ë³¼ ìˆ˜ ìˆë‹¤. tt.contiguous().storage().data_ptr() == tt.storage().data_ptr()---False reshape contiguous ê°œë…ì„ ì´í•´í–ˆë‹¤ë©´, reshape ê³¼ view í•¨ìˆ˜ì˜ ì°¨ì´ë„ ì•Œ ìˆ˜ ìˆë‹¤. ì‰½ê²Œ ì–˜ê¸°í•˜ë©´ reshape() == contiguous().view() ì™€ ê°™ë‹¤. view ëŠ” contiguous í•˜ì§€ ì•Šì€ tensor ì— ëŒ€í•´ì„œëŠ” ì ìš©í•  ìˆ˜ ì—†ë‹¤. tt.view(4, 3, 2) # tt.shape() == (4, 2, 3)---------------------------------------------------------------------------RuntimeError Traceback (most recent call last)&lt;ipython-input-89-785954c0ff12&gt; in &lt;module&gt;----&gt; 1 tt.view(4, 3, 2) # tt.shape() == (4, 2, 3)RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead. tt.contiguous().view(4, 3, 2)---tensor([[[ 0, 2], [ 4, 1], [ 3, 5]], [[ 6, 8], [10, 7], [ 9, 11]], [[12, 14], [16, 13], [15, 17]], [[18, 20], [22, 19], [21, 23]]]) í•˜ì§€ë§Œ reshape ì€ ê°•ì œë¡œ tensorë¥¼ contiguous í•˜ê²Œ ë§Œë“¤ë©´ì„œ shapeì„ ë³€ê²½í•˜ê¸° ë•Œë¬¸ì— ê°€ëŠ¥í•˜ë‹¤. tt.reshape(4, 3, 2)---tensor([[[ 0, 2], [ 4, 1], [ 3, 5]], [[ 6, 8], [10, 7], [ 9, 11]], [[12, 14], [16, 13], [15, 17]], [[18, 20], [22, 19], [21, 23]]]) tt.reshape(4, 3, 2).is_contiguous()---True Summary view : tensor ì— ì €ì¥ëœ ë°ì´í„°ì˜ ë¬¼ë¦¬ì  ìœ„ì¹˜ ìˆœì„œì™€ index ìˆœì„œê°€ ì¼ì¹˜í•  ë•Œ (contiguous) shapeì„ ì¬êµ¬ì„±í•œë‹¤. ì´ ë•Œë¬¸ì— í•­ìƒ contiguous í•˜ë‹¤ëŠ” ì„±ì§ˆì´ ë³´ìœ ëœë‹¤. transpose : tensor ì— ì €ì¥ëœ ë°ì´í„°ì˜ ë¬¼ë¦¬ì  ìœ„ì¹˜ ìˆœì„œì™€ ìƒê´€ì—†ì´ ìˆ˜í•™ì  ì˜ë¯¸ì˜ transposeë¥¼ ìˆ˜í–‰í•œë‹¤. ì¦‰, ë¬¼ë¦¬ì  ìœ„ì¹˜ì™€ transposeê°€ ìˆ˜í–‰ëœ tensor ì˜ index ìˆœì„œëŠ” ê°™ë‹¤ëŠ” ë³´ì¥ì´ ì—†ìœ¼ë¯€ë¡œ í•­ìƒ contiguous í•˜ì§€ ì•Šë‹¤. reshape : tensor ì— ì €ì¥ëœ ë°ì´í„°ì˜ ë¬¼ë¦¬ì  ìœ„ì¹˜ ìˆœì„œì™€ index ìˆœì„œê°€ ì¼ì¹˜í•˜ì§€ ì•Šì•„ë„ shapeì„ ì¬êµ¬ì„±í•œ ì´í›„ì— ê°•ì œë¡œ ì¼ì¹˜ì‹œí‚¨ë‹¤. ì´ ë•Œë¬¸ì— í•­ìƒ contiguous í•˜ë‹¤ëŠ” ì„±ì§ˆì´ ë³´ìœ ëœë‹¤. References https://inmoonlight.github.io/notebooks/html/2021-03-03-PyTorch-view-transpose-reshape.html https://discuss.pytorch.org/t/contigious-vs-non-contigious-tensor/30107/2","link":"/2021/03/03/PyTorch-view-transpose-reshape/"},{"title":"PyTorchì˜ IterableDatasetì„ ì‚¬ìš©í•´ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°","text":"PyTorch 1.2 ì´ìƒë¶€í„° torch.utils.data ì—ì„œëŠ” í¬ê²Œ map-style dataset (torch.utils.data.Dataset) ê³¼ iterable dataset (torch.utils.data.IterableDataset) ì˜ ë‘ ì¢…ë¥˜ì˜ ë°ì´í„° í´ë˜ìŠ¤ë¥¼ ì§€ì›í•˜ê³  ìˆë‹¤. ë°ì´í„° ì‚¬ì´ì¦ˆê°€ í´ ë•ŒëŠ” IterableDataset ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ì€ë°, Dataset ê³¼ëŠ” ë”œë¦¬ ì•„ì§ ê°œë°œë˜ì–´ì•¼ í•  ê¸°ëŠ¥ì´ ë” í•„ìš”í•œ í´ë˜ìŠ¤ë¼ì„œ ì‚¬ìš©í•  ë•Œì— ìœ ì˜í•  ì ì´ ìˆì–´ ì •ë¦¬í•´ë³´ê²Œ ë˜ì—ˆë‹¤. Map-style Dataset 1.2 ì´í•˜ ë²„ì „ì—ì„œ ì‚¬ìš©ë˜ë˜ map-style datasetì€ memoryì— ëª¨ë“  ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•  ìˆ˜ ìˆì„ ë•Œ ì‚¬ìš©í•˜ëŠ” ê°€ì¥ ì¼ë°˜ì ì¸ dataset type ì´ë‹¤. custom dataset classë¥¼ ìƒì„±í•˜ê³ ì í•  ë•Œ torch.utils.data.Dataset ì„ ìƒì†ë°›ì•„ __len__ , __getitem__ ì„ êµ¬í˜„í•˜ë©´ ëœë‹¤. from torch.utils.data import Datasetclass MyMapDataset(Dataset): def __init__(self, data): self.data = data def __len__(self): return len(self.data) def __getitem__(self, index): return self.data['text'][index] Iterable Dataset í•˜ì§€ë§Œ í•™ìŠµ ë°ì´í„°ê°€ ë©”ëª¨ë¦¬ì— ë‹¤ ì˜¬ë¼ê°€ì§€ ì•ŠëŠ” ê²½ìš°ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ë‹¤ì–‘í•œ ë°©ë²• ì¤‘ì— í•˜ë‚˜ë¡œ, torch.utils.data.IterableDataset ì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì´ ìˆë‹¤. Map-style Datasetê³¼ ë¹„ìŠ·í•˜ê²Œ torch.utils.data.IterableDataset ì„ ìƒì†ë°›ì•„ì„œ custom dataset classë¥¼ ìƒì„±í•˜ê³ , __iter__ ë¥¼ ì„ ì–¸í•˜ë©´ ëœë‹¤. from torch.utils.data import IterableDatasetclass MyIterableDataset(IterableDataset): def __init__(self, data_path): self.data_path = data_path def __iter__(self): iter_csv = pd.read_csv(self.data_path, sep='\\t', iterator=True, chunksize=1) for line in iter_csv: line = line['text'].item() yield line Datasetì´ batch dataë¥¼ ìƒì„±í•  ë•Œ map_dataset[index]ë¥¼ ì‚¬ìš©í•œë‹¤ë©´, IterableDatasetì€ next(iterable_dataset) ì„ ì‚¬ìš©í•œë‹¤. ì´ ë•Œë¬¸ì— DataLoaderë¥¼ í†µí•´ IterableDatasetì„ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ sampler ì˜µì…˜ì˜ ì‚¬ìš©ì´ ì–´ë µë‹¤. ê·¸ë˜ì„œ random suffling ì„ í•˜ê³  ì‹¶ë‹¤ë©´ ë¯¸ë¦¬ ë°ì´í„°ì…‹ì„ shuffling í•œ ì´í›„ì— ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒì´ ì¢‹ë‹¤. Going Parallel PyTorch ê³µì‹ë¬¸ì„œì— ë”°ë¥´ë©´ IterableDatasetì„ num_workers &gt; 0ì˜ ì¡°ê±´ì—ì„œ ì‚¬ìš©í•  ë•Œ íŠ¹ë³„íˆ ë‹¤ìŒì„ ìœ ë…í•  ê²ƒì„ ì œì•ˆí•˜ê³  ìˆë‹¤. When num_workers &gt; 0, each worker process will have a different copy of the dataset object, so it is often desired to configure each copy independently to avoid having duplicate data returned from the workers. get_worker_info(), when called in a worker process, returns information about the worker. It can be used in either the datasetâ€™s __iter__() method or the DataLoader â€˜s worker_init_fn option to modify each copyâ€™s behavior. ìœ„ì˜ ë¬¸ì¥ì„ ì´í•´í•˜ë ¤ë©´ num_workers ì— ëŒ€í•œ ì´í•´ì™€, num_workers &gt; 0 ì¼ ë•Œ IterDataset ì—ì„œ ì–´ë–¤ í˜„ìƒì´ ì¼ì–´ë‚˜ëŠ”ì§€ ì•Œì•„ì•¼í•œë‹¤. num_workersëŠ” ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì˜¬ ë•Œ ì‚¬ìš©í•  subprocessì˜ ê°œìˆ˜ì´ë‹¤. num_workers == 0 ì€ main processì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ëª¨ë¸ì— passí•˜ëŠ” ì‘ì—…ì„ ëª¨ë‘ ìˆ˜í–‰í•œë‹¤ëŠ” ëœ»ì´ë©°, num_workers == 2ëŠ” subprocess 2ê°œì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  main processì—ì„œëŠ” subprocessì—ì„œ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ë¥¼ modelì— passí•˜ëŠ” ì—­í• ë§Œ ë‹´ë‹¹í•œë‹¤. ë”°ë¼ì„œ num_workers &gt; 0 ì¼ ë•Œ data loadingì—ì„œì˜ ë³‘ëª©ì´ ì¤„ì–´ë“¤ë©° gpu utilization ì„ 100% ê°€ê¹Œì´ ëŒì–´ì˜¬ë¦´ ìˆ˜ ìˆë‹¤. ê·¸ëŸ¼, num_workers &gt; 0 ì¼ ë•Œ ì–´ë–¤ í˜„ìƒì´ ë°œìƒí•˜ëŠ”ì§€ ì‚´í´ë³´ì. Map-Style Dataset from torch.utils.data import DataLoader, Dataset, IterableDatasetimport timeclass MyMapDataset(Dataset): def __init__(self, data): self.data = data def __len__(self): return len(self.data) def __getitem__(self, index): worker = torch.utils.data.get_worker_info() worker_id = worker.id if worker is not None else -1 start = time.time() time.sleep(0.1) end = time.time() return self.data[index], worker_id, start, enddata = range(16)map_dataset = MyMapDataset(data) num_workers == 0 ì¸ ê²½ìš° loader = DataLoader(map_dataset, batch_size=4, num_workers=0)for d in loader: batch, worker_ids, starts, ends = d print(batch, worker_ids)-----tensor([0, 1, 2, 3]) tensor([-1, -1, -1, -1])tensor([4, 5, 6, 7]) tensor([-1, -1, -1, -1])tensor([ 8, 9, 10, 11]) tensor([-1, -1, -1, -1])tensor([12, 13, 14, 15]) tensor([-1, -1, -1, -1]) num_workers == 2 ì¸ ê²½ìš° loader = DataLoader(map_dataset, batch_size=4, num_workers=2)for d in loader: batch, worker_ids, starts, ends = d print(batch, worker_ids)-----tensor([0, 1, 2, 3]) tensor([0, 0, 0, 0])tensor([4, 5, 6, 7]) tensor([1, 1, 1, 1])tensor([ 8, 9, 10, 11]) tensor([0, 0, 0, 0])tensor([12, 13, 14, 15]) tensor([1, 1, 1, 1]) ì˜ë„í•œëŒ€ë¡œ, subprocess ë³„ë¡œ ì„œë¡œ ë‹¤ë¥¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. Iterable Dataset from torch.utils.data import DataLoader, Dataset, IterableDatasetimport timeclass MyIterableDataset(IterableDataset): def __init__(self, data): self.data = data def __iter__(self): for x in self.data: worker = torch.utils.data.get_worker_info() worker_id = worker.id if worker is not None else -1 start = time.time() time.sleep(0.1) end = time.time() yield x, worker_id, start, enddata = range(16)iterable_dataset = MyIterableDataset(data) num_workers == 0 loader = DataLoader(iterable_dataset, batch_size=4, num_workers=0)for d in loader: batch, worker_ids, starts, ends = d print(batch, worker_ids)-----tensor([0, 1, 2, 3]) tensor([-1, -1, -1, -1])tensor([4, 5, 6, 7]) tensor([-1, -1, -1, -1])tensor([ 8, 9, 10, 11]) tensor([-1, -1, -1, -1])tensor([12, 13, 14, 15]) tensor([-1, -1, -1, -1]) num_workers == 2 loader = DataLoader(iterable_dataset, batch_size=4, num_workers=2)for d in loader: batch, worker_ids, starts, ends = d print(batch, worker_ids)----tensor([0, 1, 2, 3]) tensor([0, 0, 0, 0])tensor([0, 1, 2, 3]) tensor([1, 1, 1, 1])tensor([4, 5, 6, 7]) tensor([0, 0, 0, 0])tensor([4, 5, 6, 7]) tensor([1, 1, 1, 1])tensor([ 8, 9, 10, 11]) tensor([0, 0, 0, 0])tensor([ 8, 9, 10, 11]) tensor([1, 1, 1, 1])tensor([12, 13, 14, 15]) tensor([0, 0, 0, 0])tensor([12, 13, 14, 15]) tensor([1, 1, 1, 1]) âš ï¸ worker 0ê³¼ worker 1ì—ì„œ ê°™ì€ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ê³  ìˆë‹¤. ì´ ì ì´ ê³µì‹ë¬¸ì„œì—ì„œ ì§€ì í•˜ê³  ìˆëŠ” ë‚´ìš©ì´ë‹¤. ê° ì›Œì»¤ë³„ë¡œ ê°™ì€ __iter__()ë¥¼ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— ê°™ì€ ë°ì´í„°ë¥¼ ë¡œë”©í•˜ê²Œ ëœë‹¤. ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ì„œëŠ” worker_init_fn ì—ì„œ ì§ì ‘ ì›Œì»¤ ë³„ ë°ì´í„°ë¥¼ ì¬ë¶„ë°° ì‹œì¼œì¤˜ì•¼ í•œë‹¤. def worker_init_fn(_): worker_info = torch.utils.data.get_worker_info() dataset = worker_info.dataset worker_id = worker_info.id split_size = len(dataset.data) // worker_info.num_workers dataset.data = dataset.data[worker_id * split_size: (worker_id + 1) * split_size] loader = DataLoader(iterable_dataset, batch_size=4, num_workers=2, worker_init_fn=worker_init_fn)for d in loader: batch, worker_ids, starts, ends = d print(batch, worker_ids)-----tensor([0, 1, 2, 3]) tensor([0, 0, 0, 0])tensor([ 8, 9, 10, 11]) tensor([1, 1, 1, 1])tensor([4, 5, 6, 7]) tensor([0, 0, 0, 0])tensor([12, 13, 14, 15]) tensor([1, 1, 1, 1]) worker_init_fn ì„ í†µí•´ ë¶„ë°°ì‹œì¼œì¤€ ê²°ê³¼ worker 0ê³¼ worker 1 ì—ì„œ ë‹¤ë¥¸ ë°ì´í„°ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤ ğŸ™‚ Conclusions IterableDataset ì€ ë°ì´í„°ê°€ ë©”ëª¨ë¦¬ì— ì˜¬ë¼ê°€ì§€ ì•Šì„ë§Œí¼ í´ ë•Œ ì‚¬ìš©í•˜ë©´ ì¢‹ë‹¤. Datasetê³¼ ë‹¤ë¥´ê²Œ __iter__()ë¥¼ ì„ ì–¸í•´ì„œ ë°ì´í„°ë¥¼ ë¶€ë¥¸ë‹¤. í•˜ì§€ë§Œ ì´ íŠ¹ì§• ë•Œë¬¸ì— Sampler ì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤. ë˜í•œ num_workers &gt; 0 ì¸ ì„¸íŒ…ì—ì„œëŠ” ê° ì›Œì»¤ì—ì„œ ë‹¤ë¥¸ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë„ë¡ worker_init_fnì„ ì„ ì–¸í•´ì•¼ í•œë‹¤. References How to Build a Streaming DataLoader with PyTorch | by David MacLeod | Speechmatics | Medium https://inmoonlight.github.io/notebooks/html/2021-02-21-PyTorch-Dataset.html torch.utils.data â€” PyTorch 1.7.1 documentation","link":"/2021/02/21/PyTorch-IterableDataset/"},{"title":"ë‚˜, ë‹¤ì‹œ ì“°ëŠ” ìê¸°ì†Œê°œì„œ","text":"ë§¤ë‹¬ ì—¬ëŠ” ì—°ìš¸ë¦¼ ëª¨ì„ì´ì§€ë§Œ íŠ¹íˆë‚˜ ì§€ë‚œ ë‹¬ì— í–ˆë˜ ê°€ì¹˜ ì›Œí¬ìƒµì€ ë‚´ê²Œ ë§ì€ ê³ ë¯¼ì„ ë‚¨ê²¨ì¤€ ì‹œê°„ì´ì—ˆë‹¤. 200ì—¬ ê°œì˜ ê°€ì¹˜ë“¤ ì¤‘, ë‚´ê°€ ì¤‘ìš”í•˜ê²Œ ì—¬ê¸°ëŠ” ê°€ì¹˜ë¥¼ ì„ íƒí•˜ëŠ” ê³¼ì • ì†ì—ì„œ ì¢…ì°©ì ì´ ìƒê°ë³´ë‹¤ ëª…í™•í•˜ë‹¤ëŠ” ì¸ìƒì„ ë°›ì•˜ëŠ”ë°, ê·¸ ì§€ì ì„ í–¥í•´ ë‚˜ëŠ” ì œëŒ€ë¡œ ê°€ê³  ìˆëŠ” ê²ƒì¸ì§€ì— ëŒ€í•œ ì˜ë¬¸ì´ ìƒê²¼ê¸° ë•Œë¬¸ì´ì—ˆë‹¤. ë‚´ê°€ ê³¨ëë˜ ê°€ì¹˜ëŠ” ê³µí—Œ, ëŠ¥ë ¥, ë¦¬ë”ì‹­, ì´íƒ€ì£¼ì˜, ì§€í˜œì˜€ê³ , ì§€í˜œë¡œìš°ë©´ì„œë„ ëŠ¥ë ¥ìˆëŠ” ì‚¬íšŒì  ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê¸°ì—…ê°€ë¡œ ìš”ì•½ë˜ì—ˆë‹¤. ë°˜ë©´, ë‚´ê°€ ì§€ê¸ˆ ë°œ ë”›ê³  ìˆëŠ” í˜„ì¬ëŠ” ë°ì´í„° ë¶„ì„ê°€ì´ì ëª¨ì„ ê¸°íšìë¡œ ê°„ëµí•˜ê²Œ ì†Œê°œí•´ ë³¼ ìˆ˜ ìˆì—ˆë‹¤. ì´ ìë¦¬ì—ì„œ ì–´ë–»ê²Œ ì‚¬íšŒì  ê¸°ì—…ê°€ë¡œ ë‚˜ì•„ê°ˆ ìˆ˜ ìˆì„ì§€, ì™œ í˜„ì¬ì˜ ê·¸ ì¼ì„ í•˜ê³  ìˆê³ , ë‚´ê°€ í’€ê³  ì‹¶ì€ ì‚¬íšŒì  ë¬¸ì œì™€ ì–´ë–»ê²Œ ì—°ê´€ë˜ëŠ”ì§€ ë“±ì„ ë‹¤ì‹œ í•œ ë²ˆ í˜„ì¬ì˜ ë‚˜ì—ê²Œ ë¬¼ì–´ì•¼ í•  ë•Œê°€ ì™”ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ê·¸ë˜ì„œ ê°„ëµí•˜ê²Œ ë‚˜ë¥¼ ì†Œê°œí•´ë³´ëŠ” ë¬¸ì¥ì„ ì ì–´ë³´ì•˜ë‹¤. ì €ëŠ” íŒŒíŒŒê³ ë¼ëŠ” ì¸ê³µì§€ëŠ¥ ë²ˆì—­ ì„œë¹„ìŠ¤ë¥¼ í•¨ê»˜ ë§Œë“¤ì–´ë‚˜ê°€ê³  ìˆëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì—”ì§€ë‹ˆì–´ì…ë‹ˆë‹¤. ëŒ€í•™ì— ì…í•™í–ˆì„ ë•Œì˜ ì „ê³µì€ í™”í•™ìƒë¬¼ê³µí•™ìœ¼ë¡œ í˜„ì¬ í•˜ê³  ìˆëŠ” ì¼ê³¼ í° ê´€ë ¨ì´ ì—†ëŠ” ì „ê³µì´ì—ˆìŠµë‹ˆë‹¤. ì‚¬ëŒë“¤ì€ ì €ë§ˆë‹¤ì˜ ê°€ì¹˜ì™€ ì¶”êµ¬í•˜ëŠ” ë°”ê°€ ìˆê³ , ì´ë¥¼ ìµœëŒ€í•œìœ¼ë¡œ ë°œí˜„í•  ìˆ˜ ìˆëŠ” ì‚¬íšŒë¥¼ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤. 'ë‚ ë¦¬ë‹¤â€™ë¼ëŠ”, ë” ë§ì€ ì‚¬ëŒë“¤ì´ ìê¸°ì´í•´ë¥¼ í•  ìˆ˜ ìˆëŠ” ëª¨ì„ì„ ê¸°íší•˜ëŠ” ë‹¨ì²´ì—ì„œ 'ì—°ìš¸ë¦¼â€™ì´ë¼ëŠ” ëª¨ì„ì„ ê¸°íší•˜ê³  ìš´ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì œ ì‚¶ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„ì—ì„œëŠ” ì†Œëª¨ì ì¸ ê²½ìŸì´ ì—†ê³ , ë‹¤ì–‘í•œ ì¥ì ì„ ì¸ì •í•˜ëŠ” ì‹œìŠ¤í…œì„ ë§Œë“¤ê³  ì‹¶ë‹¤ëŠ” ê¿ˆì´ ìˆìŠµë‹ˆë‹¤. í•œ ë¬¸ì¥, í•œ ë¬¸ì¥ì´ ì„œë¡œ í¬ê²Œ ì—°ê´€ì´ ë˜ì–´ ë³´ì´ì§€ëŠ” ì•ŠëŠ” í”¼ìƒì ì¸ í˜•íƒœì˜ ìê¸°ì†Œê°œì„œê°€ ë˜ì—ˆë‹¤. í•˜ì§€ë§Œ ì•„ì§ ë°œê²¬ë˜ì§€ ëª»í–ˆì„ ë¿, ì œê°ê°ì˜ ë¬¸ì¥ì„ ê´€í†µí•˜ëŠ” ë¬´ì–¸ê°€ê°€ ìˆì„ ê²ƒì´ë¼ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ê·¸ ë‹µì€ ìŠ¤ìŠ¤ë¡œì—ê²Œ ë˜ì ¸ì§„ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ê³¼ì •ì—ì„œ ì°¾ì„ ìˆ˜ ìˆê² ì§€. 'ë‚˜â€™ë¼ëŠ” ì‚¬ëŒì„ ì„¤ëª…í•´ì£¼ëŠ” ìœ¼ë‹ˆê¹Œ. ì–¸ì œë‚˜ ê·¸ë ‡ë“¯, ì¢‹ì€ ì§ˆë¬¸ì€ ì¢‹ì€ ë‹µì„ ì´ë„ëŠ” ë°©í–¥í‚¤ë‹¤. ë‹¹ì‹ ì€ ì–´ë–¤ ì‚¬ëŒì¸ê°€?","link":"/2019/07/20/Rewriting-self-introduction/"},{"title":"í•œêµ­ì–´ ì•…ì„±ëŒ“ê¸€ íƒì§€ë¥¼ ìœ„í•œ ëŒ“ê¸€ ì½”í¼ìŠ¤ êµ¬ì¶•ê¸°","text":"ì•½ 4-5ê°œì›”ë™ì•ˆ ì‚¬ì´ë“œë¡œ ì§„í–‰í–ˆë˜ í˜ì˜¤ ëŒ“ê¸€ í”„ë¡œì íŠ¸[1]ê°€ ì„±ê³µì ìœ¼ë¡œ ë§ˆë¬´ë¦¬ë˜ì—ˆë‹¤. ê°™ì€ ë¬¸ì œì˜ì‹ì„ ê°€ì§„ ì‚¬ëŒë“¤ê³¼ ì‹œì‘í•´ì„œ ê°ì í•˜ê³ ì‹¶ì—ˆë˜ ë‚´ìš©ì„ ì¡°ìœ¨í•˜ê³ , í˜ì˜¤ ëŒ“ê¸€ì´ ë¬´ì—‡ì¸ê°€ì— ëŒ€í•´ ê¹Šê²Œ ê³ ë¯¼í•´ë³´ëŠ” ê³¼ì •ë“¤ì´ ì‰½ì§„ ì•Šì•˜ì§€ë§Œ ì˜ë¯¸ìˆëŠ” í™œë™ì´ë¼ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ë˜í•œ, ì‚¬ì´ë“œë¡œ ì§„í–‰ëœ í”„ë¡œì íŠ¸ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ì›ë™ë ¥ì´ ì‚¬ë¼ì§€ì§€ ì•Šê³  ê¾¸ì¤€íˆ ì¼ì´ ì§„í–‰ë˜ì—ˆë˜ ê²ƒì€ ëª¨ë‘ êµ¬ì„±ì›ë“¤ì˜ ìƒí˜¸ë³´ì™„ì ì¸ ì—­ëŸ‰ ë•ë¶„ì´ ì•„ë‹ˆì—ˆì„ê¹Œ ì‹¶ë‹¤. ì‚¬ì‹¤ ì´ ê¸€ì„ ì“°ê²Œ ëœ ê³„ê¸°ëŠ” ë…¼ë¬¸ì—ëŠ” ì“°ì§€ ëª»í–ˆë˜ ë°ì´í„°ì— ëŒ€í•œ ì´ì•¼ê¸°ë¥¼ í•˜ê³  ì‹¶ì–´ì„œì˜€ë‹¤. ì£¼ì–´ì§„ 4ì¥ì— ë§ì€ ë‚´ìš©ì„ ë‹´ìœ¼ë ¤ë‹¤ë³´ë‹ˆ ì •ì‘ ì‘ì—…í•˜ë©´ì„œ ê³ ë ¤í–ˆë˜ ì„¸ë¶€ì‚¬í•­ì´ë‚˜ ì–´ë ¤ì› ë˜ ì , ì§€ë‚˜ê³ ë‚˜ë‹ˆ ì•„ì‰¬ì› ë˜ ë¶€ë¶„ë“¤ì— ëŒ€í•´ ì ì§„ ëª»í–ˆê¸° ë•Œë¬¸ì´ë‹¤. ì•„ë§ˆ ë°ì´í„°ì…‹ì„ í™œìš©í•˜ë ¤ê³  ìƒê°í•˜ëŠ” ì‚¬ëŒë“¤ì—ê²Œë„ ì¢‹ì€ íŒì´ ë˜ì§€ ì•Šì„ê¹Œ? ì–´ë…¸í…Œì´ì…˜ ì™œ í¸ê²¬ê³¼ í˜ì˜¤ì¸ê°€? ì–´ë…¸í…Œì´ì…˜ ê°€ì´ë“œë¼ì¸ì—ë„ ë‚˜ì™€ìˆë“¯ì´ ìš°ë¦¬ëŠ” í¬ê²Œ í¸ê²¬ê³¼ í˜ì˜¤ë¼ëŠ” ë‘ ê°€ì§€ aspectì— ëŒ€í•´ì„œ labelì„ ìˆ˜ì§‘í–ˆë‹¤. ì²˜ìŒì—ëŠ” ì„±ì— ê´€ë ¨ëœ í¸ê²¬ ë° í˜ì˜¤ì™€ ê·¸ ì™¸ì˜ í¸ê²¬ ë° í˜ì˜¤ë¡œ ë‚˜ëˆ„ì—ˆëŠ”ë°, ì´ë³´ë‹¤ëŠ” í¸ê²¬ê³¼ í˜ì˜¤ë¡œ êµ¬ë¶„í•˜ëŠ” ê²ƒì´ ë‚«ë‹¤ëŠ” íŒë‹¨ì„ í–ˆë‹¤. ê°€ì´ë“œë¼ì¸ ì‘ì„±ì„ ìœ„í•´ ëŒ“ê¸€ì„ ì§ì ‘ íƒœê¹…í•˜ë‹¤ ë³´ë‹ˆ í¸ê²¬ë§Œ ì¡´ì¬í•˜ëŠ” ëŒ“ê¸€ê³¼ í˜ì˜¤ë§Œ ì¡´ì¬í•˜ëŠ” ëŒ“ê¸€ì´ ì¡´ì¬í–ˆë‹¤. í•­ìƒ í˜ì˜¤ê°€ í¸ê²¬ìœ¼ë¡œë¶€í„° ì‹œì‘ë˜ì§€ëŠ” ì•Šì•˜ê³ , í¸ê²¬ì´ ìˆìŒì„ ë¶€ë„ëŸ¬ì›Œí•˜ì§€ ì•Šê³  ì„¸ìƒì˜ ì§„ë¦¬ì¸ ê²ƒì²˜ëŸ¼ ì´ì•¼ê¸°í•˜ëŠ” ëŒ“ê¸€ì´ ë³´ì˜€ë‹¤. í˜ì˜¤ê°€ í¸ê²¬ìœ¼ë¡œ ì‹œì‘ëœ ê²½ìš°ëŠ”, ë¬´ë¦¬í•˜ê²Œ ê°œì¸ì˜ íŠ¹ì„±ì„ ì§‘ë‹¨ì˜ íŠ¹ì„±ìœ¼ë¡œ í™•ì¥í•´ì„œ ê·¸ ì§‘ë‹¨ì— ëŒ€í•œ í˜ì˜¤ë¥¼ ê°œì¸ì—ê²Œ í‘œì¶œí•  ë•Œì˜€ë‹¤. ê·¸ë˜ì„œ ì´ ë‘˜ì˜ ê´€ê³„ë¥¼ ë°ì´í„°ë¡œ íŒŒì•…í•  ìˆ˜ ìˆë„ë¡, ë˜ í¸ê²¬ê³¼ í˜ì˜¤ë¥¼ êµ¬ë¶„ì§€ì–´ ìƒê°í•  ìˆ˜ ìˆë„ë¡ í¸ê²¬ì— ê´€ë ¨ëœ labelê³¼ í˜ì˜¤ì— ê´€ë ¨ëœ labelì„ êµ¬ë¶„ì§“ê¸°ë¡œ í–ˆë‹¤. ì–¸ì–´í•™ì— ê´€ì‹¬ìˆëŠ” ì‚¬ëŒë“¤ì´ë¼ë©´ labelì„ ë°”íƒ•ìœ¼ë¡œ ëŒ“ê¸€ì„ ë¶„ì„í•˜ëŠ” ê²ƒìœ¼ë¡œë„ ì¬ë°ŒëŠ” ì—°êµ¬ê°€ ë  ê²ƒ ê°™ë‹¤. í‘œí˜„ì˜ ììœ ì™€ í˜ì˜¤ì˜ ê²½ê³„ ì´ ë‘˜ì„ êµ¬ë¶„ì§“ëŠ” ì¢‹ì€ thresholdë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì€ ë¬´ìŠ¨ ëª©ì ìœ¼ë¡œ í™œìš©í•˜ëƒì— ë‹¬ë ¤ìˆë‹¤. ìš°ë¦¬ì˜ ëª©ì ì€ í˜ì˜¤ ëŒ“ê¸€ì˜ í”¼í•´ìê°€ ì¤„ì–´ë“¤ê¸°ë¥¼ ë°”ë¼ëŠ” ê²ƒì´ì—ˆìœ¼ë¯€ë¡œ ìµëª…ì¸ì˜ í‘œí˜„ì˜ ììœ ë³´ë‹¤ëŠ” ê¸°ì‚¬ì˜ ëŒ€ìƒì´ ë˜ëŠ” ì‚¬ëŒì˜ ê¸°ë¶„ì„ ì¢€ ë” ì‹ ê²½ì“°ê¸°ë¡œ í–ˆë‹¤. ê·¸ë˜ì„œ íƒœê¹…ì„ í•  ë•Œì— ë‹¹ì‚¬ìì˜ ì…ì¥ì—ì„œ ìƒê°í•˜ë„ë¡ ê°€ì´ë“œí–ˆë‹¤. ì–´ë…¸í…Œì´ì…˜ì´ ì–´ë ¤ì› ë˜ ëŒ“ê¸€ ì˜ˆì „ì— ë°ë·”ì‘ì—ì„œ ìˆ˜ì˜ë³µì…ê³  ìˆ˜ì¤‘ì”¬ ê¸°ì–µë‚œë‹¤ ì§„ì§œ ì„¹ì”¨í–ˆëŠ”ë° ì—°ì˜ˆì¸ì´ë¼ëŠ” ì§ì—…ì´ ê°€ì§€ëŠ” íŠ¹ìˆ˜ì„± ë•Œë¬¸ì— íŒë‹¨í•˜ê¸° ì–´ë ¤ì› ë˜ ê²½ìš°ì´ë‹¤. íŠ¹íˆ ì—¬ìì—°ì˜ˆì¸ì— ëŒ€í•´ì„œëŠ” ì™¸ëª¨ì— ëŒ€í•´ í’ˆí‰í•˜ëŠ” ëŒ“ê¸€ì´ ë§ì•˜ëŠ”ë°, ìŠ¤ìŠ¤ë¡œê°€ ì—°ì˜ˆì¸ì´ì—ˆë˜ ì ì´ ì—†ìœ¼ë‹ˆ ê°ì •ì´ì…ì„ í•´ì„œ ì´ë¥¼ ëª¨ìš•ì´ë¼ê³  ë´ì•¼í• ì§€ë„ ëª¨ë¥´ê² ê³ , ë§Œì•½ ì˜ë„ì ìœ¼ë¡œ ì™¸ëª¨ë¥¼ ë¶€ê°í•´ì„œ ìœ ëª…ì„¸ë¥¼ ì–»ì€ ê²½ìš°ë¼ë©´ ëª¨ìš•ì´ë¼ê³  ë³´ê¸°ê°€ ë” ì–´ë µë‹¤ê³  ìƒê°í–ˆë‹¤. ê²°êµ­ ê°ìì˜ íŒë‹¨ì— ë§¡ê²¨ì„œ majority votingì„ í–ˆì§€ë§Œ ì •ë§ ì–´ë ¤ì› ë˜ ì¼€ì´ìŠ¤ì˜€ë‹¤. ì‹ ì²œì§€? â€œì¼ë°˜ì ìœ¼ë¡œ ë¹„ë‚œë°›ì„ë§Œí•œ í–‰ìœ„ë¡œ ì¸í•œ í˜ì˜¤ëŠ” ì–´ë–»ê²Œ íŒë‹¨í•´ì•¼í• ê¹Œ?â€ ë¥¼ ê³ ë¯¼í•˜ê²Œ ë§Œë“  ëŒ“ê¸€ì´ì—ˆë‹¤. ì‹ ì²œì§€ êµë„ë¡œ ì¸í•´ ì½”ë¡œë‚˜ê°€ ë¹ ë¥´ê²Œ í¼ì¡Œë˜ ì‚¬ê±´ ì´í›„ë¡œ &quot;ì‹ ì²œì§€&quot;ëŠ” ë¶€ì •ì ì¸ ì´ë¯¸ì§€ë¡œ êµ³ì–´ì ¸ ë²„ë ¸ëŠ”ë°, ì´ ë§¥ë½ì„ ê³ ë ¤í•´ì„œ ìœ„ì˜ ëŒ“ê¸€ì„ í˜ì˜¤ë¼ê³  íƒœê¹…í•˜ë©´ &quot;ì‹ ì²œì§€&quot;ë¼ëŠ” ê°€ì¹˜ ì¤‘ë¦½ì ì¸ ë‹¨ì–´ê°€ í˜ì˜¤ë¡œ íƒœê¹…ë˜ê¸°ì— êµ‰ì¥íˆ ê³ ë¯¼ì´ ë§ì•˜ìŠµë‹ˆë‹¤. ì‚´ë¹ ì§„ ë§ˆë‹·ê°™ì•  ìœ„ì™€ ë¹„ìŠ·í•œ ì¼€ì´ìŠ¤ë¡œ ì´ ëŒ“ê¸€ ë˜í•œ íŒë‹¨í•˜ê¸° ë¬´ì²™ì´ë‚˜ ì–´ë ¤ì› ë‹¤ ã… ã…  offensiveë¡œ íŒë‹¨í•˜ìë‹ˆ ë§ˆë‹·ì€ ë­ê°€ ë˜ëƒëŠ”â€¦ Other biases ë¼ëŠ” label í˜„ì¬ëŠ” bias labelì´ gender bias, other biases, none ì˜ ì„¸ê°€ì§€ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ì´ë ‡ê²Œ í•  ìˆ˜ ë°–ì— ì—†ì—ˆë˜ ê°€ì¥ í° ì´ìœ ëŠ” ì˜ˆì‚° ë¬¸ì œì˜€ë‹¤ ã… ã…  ëˆì´ ë§ì•˜ë‹¤ë©´ gender ì™¸ì—ë„ ì •ì¹˜, ì§€ì—­, ì¸ì¢… ë“±ì— ëŒ€í•œ í¸ê²¬ë„ labelì„ ìˆ˜ì§‘í•  ìˆ˜ ìˆì—ˆì„í…ë° í•˜ëŠ” ì•„ì‰¬ì›€ì´â€¦ ì¸ë‹¹ 150ë§Œì› ì´ìƒì€ ë¶€ë‹´í•˜ê³  ì‹¶ì§€ ì•Šì•„ì„œ, ê·¸ë¦¬ê³  ì—°ì˜ˆ ë„ë©”ì¸ì€ ì„± í¸ê²¬ì´ ê°€ì¥ ë§ì€ ë¹„ì¤‘ì„ ì°¨ì§€í•˜ê³  ìˆì–´ì„œ ì´ëŸ° ê²°ì •ì„ í•˜ê²Œ ë˜ì—ˆë‹¤. ê·¸ëŸ¬ë‹¤ë³´ë‹ˆ others ë¼ëŠ” label ì€ ì˜¨ê°– ì¢…ë¥˜ì˜ í¸ê²¬ì´ ëª¨ë‘ ëª¨ì•„ì ¸ ìˆë‹¤. ì•„ë§ˆë„ ëª¨ë¸ì´ ê³§ì¥ others ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì€ ì‰½ì§€ ì•Šì„ ê²ƒì´ë¼ê³  ìƒê°í•œë‹¤. ì´ taskëŠ”, ë…¼ë¬¸ì— ì í˜€ìˆë“¯ì´, 2-step classification ë¬¸ì œë¥¼ í‘¸ëŠ” ë°©ì‹ì´ ë‚«ì§€ ì•Šì„ê¹Œë¼ê³  ìƒê°í•œë‹¤. ë¨¼ì € gender / no-gender ë¥¼ ì˜ˆì¸¡í•˜ê³ , ê·¸ ì´í›„ì— bias ìœ  / ë¬´ ë¥¼ ì˜ˆì¸¡í•˜ë©´ gender, others, none ì„ ì¢€ ë” ì‰½ê²Œ ì˜ˆì¸¡í•  ìˆ˜ ìˆì„ ê²ƒì´ë¼ê³  ìƒê°í•œë‹¤. ì–´ë…¸í…Œì´ì…˜ ì‘ì—… ì‹œ context ë¯¸ì œê³µ ëŒ“ê¸€ì— í¬í•¨ëœ í¸ê²¬ ë° í˜ì˜¤ë¥¼ ë”ìš± ì •í™•í•˜ê²Œ íŒë‹¨í•˜ê¸° ìœ„í•´ì„œëŠ” ëŒ“ê¸€ì´ ì‘ì„±ëœ ë‰´ìŠ¤ ê¸°ì‚¬ì— ëŒ€í•œ ì •ë³´ê°€ í•„ìš”í•˜ë‹¤. í•˜ì§€ë§Œ í˜„ì‹¤ì ì¸ ì´ìœ ë“¤ë¡œ í¬ê¸°í–ˆì—ˆë‹¤. â€œì‘ì—…ìê°€ ê¸°ì‚¬ë¥¼ ì½ì–´ì•¼ í•˜ëŠ” ë²ˆê±°ë¡œì›€ì„ ê°ìˆ˜í• ê¹Œ?â€ â€œíƒœê¹… í”Œë«í¼ì—ì„œ ì´ ê¸°ëŠ¥ì„ ì œê³µí•´ì¤„ê¹Œ?â€ â€œë‰´ìŠ¤ ê¸°ì‚¬ì˜ ë‚´ìš©ì— ëŒ€í•œ ì €ì‘ê¶Œì€ ìš°ë¦¬ì—ê²Œ ì—†ê¸° ë•Œë¬¸ì— ê³µê°œ ë°ì´í„°ì…‹ì— í¬í•¨í•  ìˆ˜ ì—†ê³ , ê·¸ëŸ´ê±°ë¼ë©´ íƒœê¹…ì„ ì»¨í…ìŠ¤íŠ¸ ì—†ì´ í•˜ëŠ”ê²Œ ì¢‹ì§€ ì•Šì„ê¹Œ?â€ ë“±ì˜ ì§ˆë¬¸ë“¤ì— ëŒ€í•´ ëª…ì¾Œí•œ ë‹µë³€ì„ ë‚´ë¦¬ì§€ ëª»í–ˆê³ , ê²°êµ­ ëŒ“ê¸€ì˜ ë‚´ìš©ë§Œ ë³´ê³  íŒë‹¨í•˜ëŠ” ë°©ì‹ì„ ê°€ì ¸ê°”ë‹¤. ì§€ë‚˜ê³ ë‚˜ë‹ˆ ì•„ì‰¬ì›€ì´ ë‚¨ëŠ” ê±´ ì–´ì©” ìˆ˜ ì—†ëŠ”ë“¯í•˜ë‹¤. Testset êµ¬ì„± í˜„ì¬ testsetì€ í•¨ê»˜ ì‘ì—…í–ˆë˜ ì €ì™€ ì¡°ì›ìµ, ì´ì¤€ë²”ì´ ì§ì ‘ ì‘ì—…í•œ ë¼ë²¨ì´ ë‹¬ë ¤ìˆë‹¤. ìš°ë¦¬ì˜ ì˜ë„ì™€ ë¶€í•©í•˜ëŠ”, ê°€ì¥ ì–´ë…¸í…Œì´ì…˜ì´ ì˜ ë˜ì—ˆë‹¤ê³  ë³´ì¥í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ì…‹ì´ë¼ê³  ë³¼ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ ì§€ë‚˜ê³ ë‚˜ë‹ˆ â€œì‹œê°„ ìˆœìœ¼ë¡œ train, validation, testsetì„ êµ¬ì„±í–ˆë‹¤ë©´ ì–´ë• ì„ê¹Œ?â€ í•˜ëŠ” ì•„ì‰¬ì›€ì´ ë‚¨ì•˜ë‹¤. ëŒ“ê¸€ì—ëŠ” ë§ì€ ì‚¬íšŒì  ë°°ê²½ì§€ì‹ì´ ë…¹ì•„ì ¸ìˆë‹¤. íŠ¹íˆ ì¸ë¬¼ì˜ ì´ë¦„ì´ ê°€ì§€ê³  ìˆëŠ” ì •ë³´ê°€ ìˆëŠ”ë°, ìš°ë¦¬ê°€ ìˆ˜ì§‘í•œ ê¸°ê°„ì—ëŠ” ìŠ¹ë¦¬ì™€ ì •ì¤€ì˜ ë“±ì˜ ì—°ì˜ˆì¸ì´ ì–½í˜€ìˆë˜ ë‹¨í†¡ë°© ì‚¬ê±´ì´ í¬í•¨ë˜ì–´ ìˆì—ˆë‹¤. ê·¸ë˜ì„œ &quot;ìŠ¹ë¦¬&quot;ê°€ í¬í•¨ëœ ëŒ“ê¸€ì€ ë¶€ì •ì ì¸ ë§¥ë½ ì†ì—ì„œ íŒë‹¨ë˜ì—ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ â€œìŠ¹ë¦¬ê°€ ë­˜ ì˜ëª»í–ˆë‹¤ê³  ë‚œë¦¬ë“¤ì¸ì§€â€¦ê·¸ëƒ¥ ìŠ¹ë¦¬ ë¶€ëŸ½ê³  ë² ì•Œê¼´ë¦° ì• ë“¤ì´ í™”ë‚œê±°ë¡œë°–ì— ì•ˆë³´ì„ã…â€ ë¼ëŠ” ëŒ“ê¸€ì—ì„œ &quot;ìŠ¹ë¦¬&quot;ë¥¼ ì œê±°í•˜ë©´ ì„±í¸ê²¬ì´ ì—†ëŠ” ê²ƒìœ¼ë¡œ íƒœê¹…ë˜ì—ˆê² ì§€ë§Œ, &quot;ìŠ¹ë¦¬&quot;ê°€ í¬í•¨ë˜ì—ˆê¸° ë•Œë¬¸ì— ì„±í¸ê²¬ì´ ì¡´ì¬í•˜ëŠ” ê²ƒìœ¼ë¡œ íƒœê¹…ëœë‹¤. Generalizationì„ ì˜ í•˜ëŠ” ëª¨ë¸ì´ ì§„ì§œ ì˜í•˜ëŠ” ëª¨ë¸ì´ë¼ê³  í–ˆì„ ë•Œ, í•™ìŠµ ë°ì´í„°ì— &quot;ìŠ¹ë¦¬&quot;ê°€ ì—†ì–´ë„ ìœ„ì˜ ëŒ“ê¸€ì— ë‹¬ë¦° ë¼ë²¨ì„ ì˜ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ íŒë³„í•  ìˆ˜ ìˆê²Œ testsetì„ êµ¬ì„±í–ˆë‹¤ë©´ ë” ì¢‹ì•˜ì„ ê²ƒ ê°™ë‹¤. KoBERT tokenization baselineìœ¼ë¡œ CharCNN, BiLSTM, BERTë¥¼ ì‚¬ìš©í•œ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ë…¼ë¬¸[2]ì— ì²¨ë¶€í–ˆë‹¤. ì—¬ëŸ¬ task ëª¨ë‘ BERTê°€ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì˜€ë‹¤. ëŒ“ê¸€ì€ ë§ì¶¤ë²•ì„ ì§€í‚¤ëŠ” ë¬¸ì¥ê³¼ëŠ” ê±°ë¦¬ê°€ ë©€ê³ , ì¤„ì„ë§, ì‹ ì¡°ì–´, ì—°ì˜ˆì¸ëª…, ê·¸ë¦¬ê³  ê·¸ ì™¸ì˜ ê³ ìœ ëª…ì‚¬ ë“±ì´ ë§ì´ ë“±ì¥í•œë‹¤. ê·¸ë˜ì„œ BERT tokenization ê²°ê³¼ë¥¼ ë³´ë©´ í•œ ê¸€ì ì”© ë¶„ë¦¬ë˜ëŠ” ê²½ìš°ê°€ ë¹ˆë²ˆí–ˆë‹¤. í˜ì§€í•´ë¼ ê°€ì„¸ì—°. í˜ì§€ê°€ ë‹µì´ë‹¤ ì•„ë‹˜ë§ê³ ì‹ ì¦ê±°ë„ì—†ì´ ìœ ì¬ì„ ì–¸ê¸‰í•˜ë…¸['â–í˜', 'ì§€', 'í•´', 'ë¼', 'â–', 'ê°€', 'ì„¸', 'ì—°', '.', 'â–í˜', 'ì§€ê°€', 'â–ë‹µ', 'ì´ë‹¤', 'â–ì•„', 'ë‹˜', 'ë§', 'ê³ ', 'ì‹', 'â–ì¦ê±°', 'ë„', 'ì—†ì´', 'â–ìœ ì¬ì„', 'â–ì–¸ê¸‰', 'í•˜', 'ë…¸'] god ë°•ì¤€í˜•ì´ ì´ ê¸°ì‚¬ë¥¼ ì‹«ì–´í•©ë‹ˆë‹¤.`['â–', 'go', 'd', 'â–ë°•', 'ì¤€', 'í˜•', 'ì´', 'â–ì´', 'â–ê¸°ì‚¬', 'ë¥¼', 'â–ì‹«ì–´', 'í•©ë‹ˆë‹¤', '.'] koBERT í•™ìŠµ ë°ì´í„°ì— ìì£¼ ë“±ì¥í–ˆë˜ ì—°ì˜ˆì¸ ì´ë¦„ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ë³´ì¡´ë˜ëŠ” ë°˜ë©´, ê·¸ë ‡ì§€ ëª»í•œ ì—°ì˜ˆì¸ì€ ì´ë¦„ì´ ìª¼ê°œì§„ë‹¤. ì¡°ê°œê°–ê³  ê°œã…ˆã„¹í•˜ëŠ” íƒœì½©ì´ë‚˜ ê°œì´ì‹¹ëŒ€ëŠ”ì¡°ìƒŒì§•ë“¤ì´ë‚˜ ã…ˆã„´ì›ƒê¹€ã…‹ã…‹ã…‹ ['â–O', 'O', 'O', 'â–ì¡°', 'ê°œ', 'ê°–', 'ê³ ', 'â–ê°œ', 'á„Œá„…', 'í•˜ëŠ”', 'â–íƒœ', 'ì½©', 'ì´ë‚˜', 'â–ê°œ', 'ì´', 'ì‹¹', 'ëŒ€', 'ëŠ”', 'ì¡°', 'ìƒŒ', 'ì§•', 'ë“¤ì´', 'ë‚˜', 'â–', 'á„Œá„‚', 'ì›ƒ', 'ê¹€', 'á„', 'á„', 'á„'] ã……ã…‚ ë”ëŸ½ê²Œ ë©”ê°ˆì–´ë¡œ ì œëª©ë½‘ëŠ”ê±° ë´ë¼['â–', 'á„‰á„‡', 'â–ë”', 'ëŸ½', 'ê²Œ', 'â–ë©”', 'ê°ˆ', 'ì–´', 'ë¡œ', 'â–ì œ', 'ëª©', 'ë½‘', 'ëŠ”', 'ê±°', 'â–ë´', 'ë¼'] â€œã…ˆã„´â€, â€œã…ˆã„¹â€, â€œã……ã…‚â€ ê°™ì€ ë‹¨ì–´ê°€ tokenizationì—ì„œëŠ” ìª¼ê°œì§€ì§€ ì•ŠëŠ”ë‹¤. ì–´ë ¤ì› ë˜ ì‘ì—…ì´ì—ˆê³ , ì™„ë²½í–ˆë‹¤ê³ ëŠ” í•  ìˆ˜ ì—†ì§€ë§Œ ì¢‹ì€ ì‹œì‘ì ì´ ë  ìˆ˜ ìˆëŠ” í”„ë¡œì íŠ¸ì˜€ë‹¤ê³ ëŠ” ìƒê°í•œë‹¤. ì´ë²ˆì— í•´ê²°í•  ìˆ˜ ì—†ì—ˆë˜ ì—¬ëŸ¬ í•œê³„ì ë“¤ì„ ê·¹ë³µí•˜ëŠ” ë‹¤ë¥¸ ì¢‹ì€ ê²°ê³¼ë“¤ì´ ë§ì´ ë‚˜ì˜¬ ìˆ˜ ìˆê¸¸ :) ì´ì œ ì§„ì§œ ë! References 1.https://github.com/kocohub/korean-hate-speech â†©2.https://arxiv.org/abs/2005.12503 â†©","link":"/2020/05/28/Retrospect-of-Constructing-Korean-HateSpeech-Dataset/"},{"title":"ìŠ¤ì¹´ì´ìºìŠ¬ì„ í†µí•´ ë³¸ ì„œìš¸ëŒ€í•™êµ í•™ìƒë“¤ì˜ ìš°ìš¸ì¦","text":"ê¸°ì‚¬ì— ë”°ë¥´ë©´, ì„œìš¸ëŒ€í•™êµ í•™ìƒë“¤ì˜ 47%ê°€ ìš°ìš¸ì¦ì„ ì•“ê³  ìˆë‹¤ê³  í•œë‹¤. ê·¸ ì›ì¸ìœ¼ë¡œ ì‚¬ìƒ ìµœì•…ì˜ ì·¨ì—…ë‚œê³¼ ê³¼ì—´ëœ í•™ì  ê²½ìŸì„ ê¼½ê³  ìˆëŠ”ë°, ì‹¤ìƒì„ ì „í˜€ ëª¨ë¥´ê³  í•˜ëŠ” ì†Œë¦¬ë‹¤. ë§Œì•½ ê·¸ ì´ìœ ë¡œ ìš°ìš¸í–ˆë”ë¼ë©´, ì§„ë¡œë¬¸ì œë‚˜ í•™ì—…ë¬¸ì œë¡œ ìƒë‹´ì†Œë¥¼ ì°¾ëŠ” í•™ìƒë“¤ì´ ì œì¼ ë§ì•„ì•¼ í•œë‹¤. ê·¸ëŸ¬ë‚˜, ê¸°ì‚¬ì—ë„ ì í˜€ìˆë“¯ì´ ì‹¬ë¦¬ìƒë‹´ì†Œë¥¼ ì°¾ëŠ” ëŒ€ë¶€ë¶„ì˜ í•™ìƒì€ â€œì •ì„œë¬¸ì œâ€ë¡œ ì–´ë ¤ì›€ì„ ê²ªê³  ìˆë‹¤. ì„œìš¸ëŒ€ í•™ìƒë“¤ì€ í™•ì‹¤íˆ íƒ€êµ í•™ìƒë“¤ì— ë¹„í•´ ì·¨ì—… ê±±ì •ì´ ëœí•˜ë‹¤. ì£¼ë³€ì—ì„œ â€œì·¨ì—…ì„ í•˜ì§€ ëª»í•  ê²ƒâ€ìœ¼ë¡œ ì—¼ë ¤í•˜ëŠ” í•™ìƒë“¤ì€ ë³´ì§€ ëª»í–ˆë‹¤. ëŒ€ì‹ , â€œë‚´ê°€ ë¬´ì—‡ì„ ì¢‹ì•„í•˜ëŠ”ì§€, ë¬´ì—‡ì„ ì˜í•  ìˆ˜ ìˆëŠ”ì§€, ë‚´ê°€ ì„ íƒí•œ ëª¨ë“  ê²ƒë“¤ì´ ê´œì°®ì€ ê²ƒì¸ì§€, ì´ë˜ë„ ë˜ëŠ” ê²ƒì¸ì§€, í‰ìƒì— ê±¸ì³ ì´ë¤„ë‚´ê³  ì‹¶ì€ ë‚´ ì‚¶ì˜ ëª©ì ì€ ë¬´ì—‡ì¸ì§€, ë‚˜ëŠ” ì–´ë–¤ ì‚¬ëŒì¸ì§€â€ë¥¼ ëª°ë¼ ë°©í™©í•˜ëŠ” í•™ìƒë“¤ì€ ë§ì•˜ë‹¤. ìš”ì¦˜ ì¸ê¸°ë¦¬ì— ë°©ì˜ ì¤‘ì¸ ë“œë¼ë§ˆ â€œìŠ¤ì¹´ì´ìºìŠ¬â€ì„ ë³¸ ì‚¬ëŒë“¤ì´ë¼ë©´, ì„œìš¸ëŒ€ìƒì˜ ì´ëŸ° ê³ ë¯¼ì— ê³µê°í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤. ì„œìš¸ëŒ€í•™êµì— ì…í•™í•œ ëŒ€ë¶€ë¶„ì˜ í•™ìƒë“¤ì€ ìŠ¤ì¹´ì´ìºìŠ¬ì˜ í•™ìƒë“¤ê³¼ ë¹„ìŠ·í•œ í•™ì°½ì‹œì ˆì„ ë³´ë‚¸ë‹¤. ìš´ ì¢‹ê²Œ ê³µë¶€ì— ì¬ëŠ¥ì„ ê°€ì§€ê³  íƒœì–´ë‚˜ì„œ í° ì–´ë ¤ì›€ì—†ì´ ì´ˆë“±í•™êµì™€ ì¤‘í•™êµ êµìœ¡ê³¼ì •ì—ì„œ ìš”êµ¬í•˜ëŠ” ë°”ë¥¼ ì¶©ì‹¤íˆ ë”°ë¼ê°€ê³ , ê³ ë“±í•™êµì— ì§„í•™í•˜ë©´ ìì—°ìŠ¤ë ˆ ì¢‹ì€ ëŒ€í•™ì— ê°€ëŠ” ê²ƒì´ ëª©í‘œê°€ ë˜ì–´ ë²„ë¦°ë‹¤. ì£¼ë³€ì—ì„œ ê´€ì‹¬ì„ ê°€ì§€ëŠ” ê²ƒì€ ëª¨ë‘ â€œì„±ì â€ì— ê´€ë ¨ëœ ê²ƒë“¤ ë¿ì´ë‹¤. ì§€ê¸ˆ ë‚´ê°€ ì·¨ì•½í•œ ê³¼ëª©ì€ ë¬´ì—‡ì¸ì§€, ì–´ë–¤ ì¸ê°•ì´, ì–´ë–¤ ì„ ìƒë‹˜ì´ ì¢‹ì€ì§€. ë¶€ëª¨ë‹˜ë„ ë‚´ê°€ ë†’ì€ ì„±ì ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ ëª¨ë“  ë°©ë©´ì—ì„œ ì„œí¬íŠ¸ë¥¼ í•´ì£¼ì‹ ë‹¤. ë§ˆì¹˜ ì¢‹ì€ ëŒ€í•™ì—ë§Œ ë“¤ì–´ê°€ë©´ ë‚˜ì˜ ì¸ìƒì—ì„œ í–‰ë³µì´ ë³´ì¥ëœ ê²ƒì²˜ëŸ¼. ê·¸ë¦¬ê³ , í•™ìƒ ìŠ¤ìŠ¤ë¡œë„ ìì‹ ì„ ê¸°ë§Œí•œë‹¤. ëŒ€í•™êµì— ì…í•™í•˜ê¸° ì „ê¹Œì§€ ì´ í•™ìƒë“¤ì—ê²ŒëŠ” í° ê³ ë¯¼ì´ë„ ê²ƒì´ ì—†ë‹¤. ëª©í‘œëŠ” í™•ì‹¤í–ˆê³ , ê·¸ ëª©í‘œë¥¼ í–¥í•´ ì¶©ì‹¤íˆ ë‹¬ë ¤ë‚˜ê°€ê³  ìˆê¸° ë•Œë¬¸ì—. ë¬¸ë“ ë– ì˜¤ë¥´ëŠ”, **â€œì™œ ë‚˜ëŠ” ì¢‹ì€ ëŒ€í•™ì— ê°€ì•¼í•˜ì§€?â€**ë¼ëŠ” ì§ˆë¬¸ì´ ê°€ì¥ í° ë°©í•´ë¬¼ì´ê³ , ê·¸ëŸ° ìƒê°ì€ ì¼ë‹¨ ì¢‹ì€ ëŒ€í•™ì— ë¶™ì€ ì´í›„ì— í•˜ëŠ” ê²ƒìœ¼ë¡œ ì—¬ê²¨ì§„ë‹¤. ê·¸ë ‡ê²Œ ì¸ìƒì˜ ì¤‘ìš”í•œ ë¬¸ì œë¥¼ ê³ ë¯¼í•˜ëŠ” ì‹œê¸°ë¥¼ ë¯¸ë£¨ê²Œ ëœë‹¤. ì„œìš¸ëŒ€í•™êµì— ì…í•™í•˜ê³  ë‚˜ì„œ ì´ë“¤ì€ ê³¼ì—° í–‰ë³µí–ˆì„ê¹Œ? ê·¸ë¦¬ê³ , ì¸ìƒì˜ ê·¼ë³¸ì ì¸ ë¬¸ì œë“¤-ì‚¶ì˜ ì´ìœ , ëª©ì , ë‚˜ì˜ ì¡´ì¬ ì´ìœ -ì´ í•´ê²°ì´ ë˜ì—ˆì„ê¹Œ? ì „í˜€ ê·¸ë ‡ì§€ ì•Šë‹¤. ëŒ€í•™êµ ì…í•™ ìì²´ê°€ ëª©ì ì´ì—ˆê¸°ì— ì´ë¥¼ ë‹¬ì„±í•œ ìˆœê°„ì—ëŠ” í–‰ë³µí–ˆê² ì§€ë§Œ, ê·¸ ì´í›„ì˜ ì‚¶ì— ëŒ€í•´ì„œëŠ” í¬ê²Œ ê³ ë¯¼í•´ë³¸ ì ì´ ì—†ì—ˆê¸° ë•Œë¬¸ì— ëŒ€í•™ ì…í•™ ì´í›„ì˜ ì‹œê°„ë“¤ì€ ì´ í•™ìƒë“¤ì—ê²Œ ë„ˆë¬´ë‚˜ í° ì§ìœ¼ë¡œ ë‹¤ê°€ì™”ì„ ê²ƒì´ë‹¤. ê³ ë“±í•™êµ ë•Œ ë‚˜ì— ëŒ€í•œ ì§„ì§€í•œ ê³ ë¯¼ì—†ì´ ì„ íƒí•œ ì „ê³µì´ ë‚˜ì™€ ë§ì§€ ì•ŠìŒì„ ê¹¨ë‹«ê¸° ì‹œì‘í•˜ê³ , ê·¸ë ‡ë‹¤ë©´ ë‚˜ì—ê²Œ ë§ëŠ” ë¯¸ë˜ëŠ” ë¬´ì—‡ì¸ì§€ë¥¼ ë¬»ê²Œ ëœë‹¤. í•˜ì§€ë§Œ ê²½í—˜ì´ ì ë‹¤ë³´ë‹ˆ ê·¸ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì°¾ëŠ” ê²ƒì´ ì–´ë µê³ , ë‹µì´ ë¬¸ë“ ë– ì˜¬ëë”ë¼ë„ í•­ìƒ ì œì¼ ì¢‹ì€ ì„ íƒì§€ë¥¼ íƒí•´ì™”ê³ , ì •ë‹µì´ ìˆëŠ” ì„ íƒì„ í•´ì™”ê¸° ë•Œë¬¸ì— â€˜ì´ë˜ë„ ë˜ëŠ”ê±¸ê¹Œ?â€™ë¼ëŠ” ìƒê°ê³¼ í•¨ê»˜ ìŠ¤ìŠ¤ë¡œ ê²°ì •ì„ ë‚´ë¦¬ì§€ ëª»í•˜ê³  ë¨¸ë¬¼ëŸ¬ìˆë‹¤. ì´ë“¤ì€ ê·¸ë™ì•ˆ ì‚´ì•„ì™”ë˜ ë°©ì‹ê³¼ ì „í˜€ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì‚´ì•„ê°€ê¸¸ ë„ì „ë°›ëŠ”ë‹¤. ê·¸ë˜ì„œ ì„œìš¸ëŒ€í•™êµ í•™ìƒë“¤ì€ ë‘ë µë‹¤. í•˜ì§€ë§Œ ê·¸ ë§ˆìŒì„ ëˆ„êµ°ê°€ì—ê²Œ ì˜ í„¸ì–´ë†“ì§€ ëª»í•œë‹¤. ë¶€ëª¨ë‹˜ì€ â€˜ìš°ë¦¬ ì•„ì´ëŠ” ìŠ¤ìŠ¤ë¡œ ì•Œì•„ì„œ ì˜ í•  ê²ƒâ€™ì´ë¼ê³  ìƒê°í•˜ê¸°ì— í„¸ì–´ë†“ì§€ ëª»í•˜ê³ , ê³ ë“±í•™êµ ì¹œêµ¬ë“¤ì€ â€˜ì„œìš¸ëŒ€ê°€ ê³ ë¯¼ì€ ë¬´ìŠ¨ ê³ ë¯¼â€™ì´ë¼ê³  ìƒê°í•˜ê¸°ì—, ê°™ì€ ëŒ€í•™êµ ì¹œêµ¬ë“¤ì€ ì†ì„ ì‰½ê²Œ í„¸ì–´ë†“ì„ë§Œí¼ ê¹Šì€ ê´€ê³„ê°€ ì•„ë‹ˆê¸°ì— ì´ëŸ° ì´ì•¼ê¸°ë¥¼ í•˜ê¸° ì–´ë µë‹¤. ë§ˆìŒ ì†ì— ë¶€ì±„ì²˜ëŸ¼ ìŒ“ì´ëŠ” ì´ì•¼ê¸°ë“¤ì´ ì–´ëŠ ìˆœê°„ ìŠ¤ìŠ¤ë¡œë¥¼ ê³ªê²Œ ë§Œë“ ë‹¤. ë‚˜ì˜ ì´ì•¼ê¸°ë¥¼ í¸ê²¬ì—†ì´ ë“¤ì–´ì¤„ ìˆ˜ ìˆëŠ” ì‚¬ëŒì„ ì›í•˜ê²Œ ëœë‹¤. ê·¸ë˜ì„œ ìƒë‹´ì†Œë¥¼ ì°¾ê²Œ ë˜ê³ , ê·¸ ê³³ì—ì„œ ì˜¤íˆë ¤ ì£¼ë³€ ì‚¬ëŒë“¤ì—ê²Œ í•˜ì§€ ëª»í–ˆë˜ ë‚˜ì˜ ê¹Šì€ ì´ì•¼ê¸°ë¥¼ í„¸ì–´ë†“ê²Œ ëœë‹¤. ê·¸ë¦¬ê³ , ê·¸ ê²ƒë§Œìœ¼ë¡œë„ ë§ˆìŒì´ ì¹˜ìœ ëœë‹¤. ë‚´ê°€ ëŠë¼ëŠ” ëª¨ë“  ê²ƒë“¤ì´ ì´ìƒí•˜ì§€ ì•Šê³ , ì§€ê¸ˆì€ ë„˜ì–´ì§€ê³  ë‹¤ì¹  ìˆ˜ ë°–ì— ì—†ëŠ” ì‹œê¸°ë¼ëŠ” ì‚¬ì‹¤ì— ìœ„ì•ˆë°›ëŠ”ë‹¤. ë‚¨ì˜ ì´ì•¼ê¸°ì²˜ëŸ¼ ì¼ì§€ë§Œ, ì•½ 70%ì •ë„ëŠ” ë‚˜ì˜ ì´ì•¼ê¸°ì´ë‹¤. ê·¸ë˜ì„œ ìš”ì¦˜ ìŠ¤ì¹´ì´ìºìŠ¬ì„ ë³´ë©´ ë§ˆìŒì´ ì•„í”„ë‹¤. ìŠ¤ì¹´ì´ìºìŠ¬ ì…ì£¼ ê°€ì¡± ì¤‘ ì–´ëŠ ëˆ„êµ¬ë„ ëŒ€í•™ ì´í›„ì˜ ì‚¶ì— ëŒ€í•´ì„œëŠ” ì´ì•¼ê¸°í•˜ì§€ ì•ŠëŠ”ë‹¤. ì–´ë–¤ ì‚¬ëŒì´ ë˜ê³  ì‹¶ì€ì§€, ë‚˜ì˜ ì£½ìŒì€ ì–´ë–»ê²Œ ê¸°ì–µë˜ê³  ì‹¶ì€ì§€, ì™œ ê·¸ ëŒ€í•™ì— ê°€ê³  ì‹¶ì€ì§€, ê·¸ ëŒ€í•™ì— ê°€ì„œ ì œì¼ í•˜ê³  ì‹¶ì€ ê²ƒì€ ë¬´ì—‡ì¸ì§€ ë“±. â€˜ì„œìš¸ì˜ëŒ€ í•©ê²©â€™ì´ë¼ëŠ” ì¦ëª…ì„œê°€ ì „ë¶€ì¸ ì„¸ìƒ. ê·¸ ì•ˆì—ì„œ ì´ë¯¸ ê³ªì„ëŒ€ë¡œ ê³ªì•„ë²„ë¦° ì˜ì¬ë¥¼ ë– ì˜¬ë ¤ë³¸ë‹¤.","link":"/2018/12/23/Skycastle/"},{"title":"Social Bias in NLP Models","text":"í•œ ìŠ¤íƒ€íŠ¸ì—…ì—ì„œ ê°œë°œí•œ ì¸ê³µì§€ëŠ¥ ì±„ìš©ì†”ë£¨ì…˜(a.k.a. AI ë©´ì ‘ê´€)ì„ ë²Œì¨ ì—¬ëŸ¬ ê¸°ì—…ì—ì„œ ì‚¬ìš©í•˜ê³  ìˆë‹¤ëŠ” ë‰´ìŠ¤ê¸°ì‚¬ë¥¼ ì ‘í•˜ê²Œ ë˜ì—ˆë‹¤. í•´ë‹¹ ê¸°ì—…ì€ &quot;ì„±ë³„ì´ë‚˜ í•™ë ¥ ë“±ì— ë”°ë¥¸ ì°¨ë³„ ë°©ì§€ì™€ ì •í™•í•œ ì—­ëŸ‰ ì¶”ì •&quot;ì„ ìœ„í•´ 5ë§Œ 2ì²œì—¬ëª…ì˜ ë°ì´í„°ë¥¼ í™•ë³´í•˜ì—¬ í•™ìŠµí–ˆë‹¤ê³  ë§í•œë‹¤. 5ë§Œ 2ì²œì—¬ëª…ì˜ ë°ì´í„°ì™€ ì°¨ë³„ ë°©ì§€ê°€ ì–´ë–¤ ê´€ë ¨ì´ ìˆëŠ”ì§€ëŠ” ëª¨ë¥´ê² ì§€ë§Œ, ë§ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•œë‹¤ëŠ” ê±¸ ë‚´ì„¸ìš°ê³  ì‹¶ì—ˆë‹¤ë©´ ëŒ€ëŸ‰ì˜ ë°ì´í„°ê°€ í¸í–¥ì„±ì„ ì¤„ì´ëŠ” ê²ƒê³¼ëŠ” ë¬´ê´€í•˜ë‹¤ê³  ë§í•˜ê³  ì‹¶ë‹¤. 5ë§Œ 2ì²œê°œë³´ë‹¤ ë” ë§ì€ ë°ì´í„°ë¡œ í•™ìŠµí•œ Language Model ë„ í¸í–¥ì„± ë¬¸ì œê°€ ìˆìœ¼ë©° ì´ ì´ìŠˆëŠ” ì•„ì§ë„ ì—°êµ¬ìë“¤ì— ì˜í•´ í™œë°œíˆ ì—°êµ¬ë˜ê³  ìˆë‹¤. Introduction 2020ë…„ 6ì›” ë§ì— ë‹¤ìŒê³¼ ê°™ì€ íŠ¸ìœ—ì´ ì˜¬ë¼ì™”ë‹¤. ì˜¤ë°”ë§ˆë¥¼ ëª¨ìì´í¬í•œ ì´ë¯¸ì§€ë¥¼ ë„£ì—ˆëŠ”ë° ë°±ì¸ì˜ íŠ¹ì§•ì„ ê°€ì§„ ì´ë¯¸ì§€ê°€ ìƒì„±ì´ ë˜ì—ˆë‹¤ëŠ” ê²ƒì´ë‹¤. ì´ íŠ¸ìœ—ì€ í˜ëŸ¬í˜ëŸ¬ Yann LeCunì˜ ê·€ì— ë“¤ì–´ê°„ë‹¤. ê·¸ë¦¬ê³  ì´ëŠ” ë‹¤ì‹œ ì¡°ê²½í˜„ êµìˆ˜ë‹˜ì„ í†µí•´ Alice Oh êµìˆ˜ë‹˜ì˜ AI &amp; Ethics íŠ¹ê°• ë°œí‘œìë£Œ[9]ì—ì„œ ì•„ë˜ì˜ ë¬¸êµ¬ì™€ í•¨ê»˜ ë‹¤ì‹œ í•œë²ˆ ì¸ìš©ëœë‹¤. Too much blame on data curation, too little blame on algorithms ì¡°ê²½í˜„ êµìˆ˜ë‹˜ì˜ ì´ì•¼ê¸°ë¥¼ ì¢€ ë” ë“¤ì–´ë³´ì. â€œë¬¼ë¡  ë°ì´í„°ë„ ë¬¸ì œê°€ ìˆì§€ë§Œ ì•Œê³ ë¦¬ì¦˜ì˜ ì˜ëª»ì´ ì „í˜€ ì—†ëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤â€ ë¼ê³  ì£¼ì¥í•œë‹¤. ì•„ë˜ì˜ ì¥í‘œì—ì„œëŠ” ML ì•Œê³ ë¦¬ì¦˜ì˜ solution spaceë¥¼ êµ¬íšë³„ë¡œ ë‚˜ëˆ„ì–´ì„œ ì´ 4ê°€ì§€ë¡œ êµ¬ë¶„í•˜ê³  ìˆë‹¤. Training solutions: í•™ìŠµ ë°ì´í„°ì…‹ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” solution space Shortcut solutions: í•™ìŠµ ë° ì£¼ì–´ì§„ í…ŒìŠ¤íŠ¸ì…‹ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” solution space Intended solutions: í•™ìŠµ ë° ì£¼ì–´ì§„ í…ŒìŠ¤íŠ¸ì…‹ê³¼ o.o.d í…ŒìŠ¤íŠ¸ì…‹ ëª¨ë‘ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì´ëŠ” solution space. ì—¬ê¸°ì•¼ë§ë¡œ ìš°ë¦¬ê°€ ì›í•˜ëŠ” ì§„ì§œ general knowledgeê°€ ìˆëŠ” space Learnable solutions: ì•Œê³ ë¦¬ì¦˜ì´ í•™ìŠµì„ í†µí•´ ë„ë‹¬í•  ìˆ˜ ìˆëŠ” solution space ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²ƒì€ intended solution spaceì™€ learnable spaceê°€ ë§Œë‚˜ëŠ” ì ì— í•™ìŠµ ëª¨ë¸ì´ ìˆ˜ë ´í•˜ê²Œ ë§Œë“œëŠ” ê²ƒì´ë‹¤. í•˜ì§€ë§Œ ì´ëŠ” ì‰½ì§€ ì•Šë‹¤. data bias ê°€ ìˆê¸° ë•Œë¬¸ì— model ì´ í•™ìŠµê³¼ì •ì—ì„œ data ë‚´ì— ì¡´ì¬í•˜ëŠ” bias ë¥¼ í•¨ìœ í•  ìˆ˜ ë°–ì— ì—†ëŠ” ê²ƒì€ ë§ì§€ë§Œ, ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  ì´ ëª¨ë“  ê²ƒì´ data bias ì˜ ì˜ëª»ë•Œë¬¸ë§Œì€ ì•„ë‹ˆë¼ëŠ” ê²ƒì´ ì¡°ê²½í˜„ êµìˆ˜ë‹˜ì´ ì´ì•¼ê¸°í•˜ê³  ì‹¶ì—ˆë˜ ë‚´ìš©ì´ë‹¤. ì•„ë˜ì˜ ì¥í‘œëŠ” random seed ë¥¼ ë°”ê¿ˆì— ë”°ë¼ learnable ëª¨ë¸ì˜ í•™ìŠµ ê²°ê³¼ê°€ ìœ„ì¹˜í•˜ëŠ” solution spaceë¥¼ ë³´ì—¬ì¤€ë‹¤. seed ë§Œ ë°”ê¾¸ì–´ë„ solution spaceê°€ ë‹¬ë¼ì§€ëŠ” ê²ƒìœ¼ë¡œ ë¯¸ë£¨ì–´ë³´ì•„, ì¶©ë¶„íˆ ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì •ì„ ì˜ tuning í•˜ë©´ ì›í•˜ëŠ” solution space ìª½ìœ¼ë¡œ í•™ìŠµí•  ì—¬ì§€ê°€ ìˆë‹¤ê³  ë³´ì—¬ì§„ë‹¤. Undesirable solution ì˜ ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œ? ì—¬ëŸ¬ ì´ìœ  ì¤‘ í•˜ë‚˜ë¡œ, shortcut solution ì¤‘ ì¼ë¶€ëŠ” ì˜ëª»ëœ correlation ì„ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì´ë¼ëŠ” ì ì´ ìˆë‹¤. â€œCorrelation does not imply Causalityâ€ ë¼ëŠ” ìœ ëª…í•œ ëª…ì œê°€ ìˆë‹¤. ëˆˆì— ë“œëŸ¬ë‚˜ëŠ” Xì™€ Y variable ì˜ ê´€ê³„ì— ëª¨ë‘ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” confounding factor Z ê°€ ìˆê³  hidden varirable ì¸ ê²½ìš° ìš°ë¦¬ëŠ” ì‹¤ì œ ì¸ê³¼ê´€ê³„ë¥¼ ë†“ì¹˜ê³  ìƒê´€ê´€ê³„ë¥¼ ì¸ê³¼ê´€ê³„ì²˜ëŸ¼ í•™ìŠµí•  ìœ„í—˜ì´ ìˆë‹¤. ê°€ì¥ ìœ ëª…í•œ ì˜ˆë¡œ, â€œì´ˆì½œë ›ì˜ ì†Œë¹„(X)ê°€ ë§ì€ ë‚˜ë¼ì—ì„œ ë…¸ë²¨ìƒ(Y)ì„ ë§ì´ ë°›ëŠ”ë‹¤.â€ ê°€ ìˆë‹¤. ì‹¤ì œë¡œëŠ” â€œê³ ë“±êµìœ¡ì— íˆ¬ìí•˜ëŠ” ë¬¼ì§ˆì , ì‹œê°„ì  ì—¬ìœ ê°€ ë§ì„ìˆ˜ë¡(Z) ì´ˆì½œë › ì†Œë¹„(X)ê°€ ë§ë‹¤.â€ ì™€ &quot;ê³ ë“±êµìœ¡ì— íˆ¬ìí•˜ëŠ” ë¬¼ì§ˆì , ì‹œê°„ì  ì—¬ìœ ê°€ ë§ì„ìˆ˜ë¡(Z) ë…¸ë²¨ìƒ(Y)ì„ ë§ì´ ë°›ëŠ”ë‹¤.&quot;ì˜ ì¸ê³¼ê´€ê³„ì—ì„œ Z variable ì„ ë¬´ì‹œí•œì±„ í•´ì„í•˜ë©´ ì˜ëª»ëœ ì •ë³´ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì¤€ë‹¤. ëª¨ë¸ë„ ë§ˆì°¬ê°€ì§€ë‹¤. í•™ìŠµì— ë…¸ì¶œë˜ëŠ” ë°ì´í„° ë¶„í¬ì—ì„œëŠ” Zê°€ ëª…ì‹œì ìœ¼ë¡œ ë³´ì´ì§€ ì•Šì„ ìˆ˜ ìˆë‹¤. ë°±ì¸ ë‚¨ì„±ì´ ìƒëŒ€ì ìœ¼ë¡œ ê²½ì œì ì¸ ì—¬ìœ ê°€ ë” ìˆì–´ì„œ ì¸í„°ë„·ì— ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ëŠ” ê²½ìš°ê°€ ë§ì•˜ê³ , ì´ ë•Œë¬¸ì— ì›¹ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„° ì¤‘ì˜ ëŒ€ë‹¤ìˆ˜ê°€ ë°±ì¸ ë‚¨ì„±ì¼ ìˆ˜ ë°–ì— ì—†ë‹¤ê³  í–ˆì„ ë•Œ, ì´ ì‚¬ì‹¤ì€ ë°ì´í„°ì˜ ë¶„í¬ë§Œ íŒŒì•…í•˜ëŠ” ëª¨ë¸ì˜ ì…ì¥ì—ì„œëŠ” í•™ìŠµí•˜ê¸° ì–´ë ¤ìš´ ì •ë³´ì¼ ìˆ˜ ìˆë‹¤. ëª¨ë“  bias ê°€ ë‚˜ì ê¹Œ? ê¼­ ê·¸ë ‡ì§€ëŠ” ì•Šë‹¤. ë•Œë¡  ìš°ë¦¬ëŠ” ëª¨ë¸ì´ inductive bias ë¥¼ í•™ìŠµí•˜ê¸¸ ë°”ë€ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, â€œë‚˜ë¹„ê°€ ì½”ë¼ë¦¬ë¥¼ í¬ì‹í•˜ì§€ ì•ŠëŠ”ë‹¤â€ ëŠ” ì •ë³´ëŠ” ëª¨ë¸ ì…ì¥ì—ì„œëŠ” í•„ìš”í•œ bias ì´ë‹¤. ê·¸ëŸ¬ë‚˜ social bias ì™€ ê°™ì€ ì¢…ë¥˜ì˜ ì •ë³´ëŠ” í•™ìŠµí•˜ì§€ ì•Šê¸°ë¥¼ ê¸°ëŒ€í•œë‹¤. NLPì—ì„œëŠ”? ì•ì—ì„œëŠ” ì´ë¯¸ì§€ë¥¼ ì˜ˆë¡œ ë“¤ì—ˆì§€ë§Œ, ì—¬ëŸ¬ ë…¼ë¬¸ì—ì„œë„ NLP ëª¨ë¸ì´ social bias ë¥¼ í•™ìŠµí•˜ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì§/ê°„ì ‘ì ì ìœ¼ë¡œ ë³´ì—¬ì£¼ê³  ìˆë‹¤. ëª¨ë¸ì´ í•™ìŠµí•œ word embedding ì„ ë¶„ì„í•´ì„œ biasë¥¼ í•™ìŠµí–ˆìŒì„ í†µí•´ ë³´ì´ê±°ë‚˜[1][2], í•™ìŠµ dataset ìì²´ì— social bias ê°€ ìˆìŒì„ ë³´ì´ê±°ë‚˜[3], bias ë¥¼ ì¸¡ì •í•˜ëŠ” taskì™€ metricì„ ì œì•ˆí•˜ì—¬ ì–¼ë§Œí¼ biasë¥¼ í•™ìŠµí–ˆëŠ”ì§€ ë¥¼ ìˆ˜ì¹˜ì ìœ¼ë¡œ í‰ê°€[2][4][5][6]í•œë‹¤. ìƒˆë¡œìš´ bias ì¸¡ì • taskë¥¼ ì œì•ˆí•  ë•Œ ìˆ˜ë°˜ë˜ëŠ” datasetì´ ìˆëŠ”ë°, ì—¬ê¸°ì—ë„ êµ¬ì¶• ë°©ì‹ì— ë”°ë¼ ë‘ê°€ì§€ ì¢…ë¥˜ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆë‹¤. í•˜ë‚˜ëŠ” templated-based dataset[4], ë‹¤ë¥¸ í•˜ë‚˜ëŠ” crowdsourced dataset[5][6] ì´ë‹¤. ëª¨ë¸ì˜ embedding space ë¶„ì„ ì´ ë°©ë²•ë¡ ì€ PLM ì´ì „, word2vec ì´ ë§ì´ ì‚¬ìš©ë˜ì—ˆë˜ ì‹œê¸°ì— ë“±ì¥í–ˆë‹¤. word2vecì„ í†µí•´ í•™ìŠµëœ ë‹¨ì–´ì˜ ê´€ê³„ë¥¼ ë¶„ì„í–ˆì„ ë•Œ social bias ê°€ ì–¼ë§ˆë‚˜ ë°˜ì˜ë˜ì—ˆëŠ”ì§€ë¥¼ íŒë‹¨í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, man - woman ~= computer programmer - homemaker ì˜ ê´€ê³„ê°€ ì„±ë¦½í•œë‹¤ë©´ ì´ ëª¨ë¸ì€ social bias ë¥¼ í•¨ìœ í•˜ê³  ìˆë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. Man is to computer programmer as woman is to homemaker? debiasing word embeddings[1]ì—ì„œëŠ” word2vecì˜ geometric biasì— ëŒ€í•´ ë¶„ì„í•˜ì˜€ë‹¤. Figure 1ì˜ ì™¼ìª½ì—ëŠ” she / he ì™€ ê°€ê¹Œì´ì— ìˆëŠ” ì§ì—… ë‹¨ì–´ ëª©ë¡ì´ ìˆë‹¤. ê·¸ë¦¬ê³  ê° ì§ì—… ë‹¨ì–´ë“¤ì„ crowd worker ì—ê²Œ female-stereotypic, male-steretotypic, neutral í•œì§€ë¥¼ ë¬¼ì—ˆì„ ë•Œì˜ ê²°ê³¼ì™€ corrleationì„ êµ¬í–ˆê³ , ê·¸ ê²°ê³¼ 0.51 ì •ë„ì˜ moderate í•œ ê²°ê³¼ê°€ ë‚˜ì™”ë‹¤. Figure 1ì˜ ì˜¤ë¥¸ìª½ì—ëŠ” she-he ì˜ ê´€ê³„ì™€ ìœ ì‚¬í•œ ë‹¨ì–´ë“¤ì˜ ê´€ê³„ ëª©ë¡ì„ ë³´ì—¬ì£¼ê³  ìˆë‹¤. ì´ ì¤‘ì—ì„œ Gender stereotypical í•œ analogyì™€ gender appropriateí•œ analogyì˜ ìˆ˜ëŸ‰ì„ ë¹„êµí•˜ì˜€ê³ , 150 ê°œì˜ ê´€ê³„ ì¤‘ 29ê°œê°€ gender stereotypical í•˜ë‹¤ê³  íŒë‹¨ë˜ì—ˆë‹¤. ë°ì´í„°ì…‹ ìì²´ì— í•¨ìœ ëœ Bias í•™ìŠµí•œ ëª¨ë¸ì„ ë¶„ì„í•˜ëŠ” ë°©ë²•ì´ ì•„ë‹Œ, í•™ìŠµí•˜ëŠ” ëŒ€ìƒì´ ë˜ëŠ” ë°ì´í„°ì…‹ ìì²´ë¥¼ model-agnostic í•˜ê²Œ ë¶„ì„í•˜ëŠ” ë°©ë²•ë„ ì œì•ˆë˜ì—ˆë‹¤. Social Bias in Elicited Natural Language Inferences[3]ì—ì„œëŠ” SNLI ë°ì´í„°ì…‹ì— ì¡´ì¬í•˜ëŠ” bias ë¥¼ PMI ì™€ Likelihood ratio test of independenceë¥¼ í†µí•´ í†µê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì˜€ë‹¤. ì•„ë˜ì˜ Table 1ì€ SNLI ë°ì´í„°ì—ì„œ gender, age, race/ethnicity/nationality ì— í•´ë‹¹í•˜ëŠ” ë‹¨ì–´ë“¤ ê°ê°ì— ëŒ€í•´ PMIê°€ ë†’ì€ ë‹¨ì–´ë“¤ì„ ë‚˜ì—´í•´ ë†“ì€ ê²ƒì´ë‹¤. woman &amp; man, girls &amp; boys, white man &amp; african american ë“± ì°¨ì´ê°€ ì—†ì–´ì•¼í•  ê°œë…ë“¤ì— ëŒ€í•´ PMI ìƒ ê°€ê¹Œìš´ ë‹¨ì–´ë“¤ì„ ë¹„êµí•´ë³´ë©´ ì°¨ì´ê°€ ìˆë‹¤. Table 2ëŠ” inference type ë³„ë¡œ gender words ë“¤ì— ëŒ€í•´ PMIê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬í•œ ê²°ê³¼ë‹¤. ë‹¹ì—°íˆ ë¹„ìŠ·í•  ìˆ˜ ë°–ì— ì—†ëŠ” ê²°ê³¼ - women &amp; woman, females - ë¥¼ ì œì™¸í•˜ê³  gender stereotypical í•œ ë‹¨ì–´ë“¤ì„ ì‚´í´ë³´ë©´ gender biasê°€ ì‚¬ë­‡ ë“œëŸ¬ë‚œë‹¤. women - chat, smile ì€ entailed ê´€ê³„ì¸ ë°˜ë©´, women - dicussing, politics ëŠ” contradiction ê´€ê³„ì—ì„œ ìì£¼ ë“±ì¥í•œë‹¤. Bias evaluation task ì•ì„œ ì†Œê°œí•œ ë‘ ë°©ë²•ì€ ëª¨ë¸ í•™ìŠµê²°ê³¼ì˜ embedding spaceì—ì„œì˜ ë‹¨ì–´ ë¶„í¬ì™€ ë°ì´í„° ìì²´ì˜ íŠ¹ì„±ì„ ì´ìš©í•œ í†µê³„í•™ì  ê´€ì ì„ í™œìš©í•˜ì˜€ë‹¤. ì´ì™€ ë‹¤ë¥´ê²Œ ëª¨ë¸ì˜ biasë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°©ë²•ìœ¼ë¡œ task based evaluation ì´ ìˆë‹¤. bias ë¥¼ íŒë‹¨í•  ìˆ˜ ìˆëŠ” task ì¦‰, datasetê³¼ metric ì„ ì„¤ê³„í•´ì„œ ì ìˆ˜ë¥¼ ë‚´ê³  ë¹„êµí•˜ëŠ” ë°©ì‹ì´ë‹¤. ì´ëŠ” ë‹¤ì‹œ, template based dataset ê³¼ crowdsource-based datasetì„ í™œìš©í•œ taskë¡œ ë‚˜ëˆ ë³¼ ìˆ˜ ìˆë‹¤. Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods[4]ì—ì„œëŠ” winograd schema ë¥¼ ë°”íƒ•ìœ¼ë¡œ biasë¥¼ ì¸¡ì •í•  ìˆ˜ ìˆëŠ” taskë¥¼ ì œì•ˆí•˜ì˜€ë‹¤. Winograd Schema[8]ë€, Terry Winograd ì˜ ì´ë¦„ì„ ë”´ schema ë¡œ, ì•„ë˜ì˜ ì˜ˆì‹œì™€ ê°™ì€ ë¬¸ì¥ í˜•ì‹ì„ ì¼ì»«ëŠ”ë‹¤. The city councilmen refused the demonstrators a permit because they [feared/advocated] violence. ì´ taskì˜ ì •ë‹µì„ ë§ì¶”ê¸° ìœ„í•´ì„ , ëŒ€ëª…ì‚¬ê°€ ë¬´ì—‡ì„ ê°€ë¦¬í‚¤ëŠ”ì§€ì— ëŒ€í•œ ì´í•´ê°€ í•„ìš”í•˜ê³ , ì´ ì´í•´ëŠ” councilmentê³¼ demonstratorì˜ ê´€ê³„ì— ëŒ€í•œ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í•œë‹¤. ì•„ë˜ì˜ ë‘ê°€ì§€ íƒ€ì…ì„ ë”°ë¥´ëŠ” ë¬¸ì¥ë“¤ì´ biasë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ìœ„í•œ datasetìœ¼ë¡œ ì œì•ˆëœë‹¤. [entity1], [entity2]ëŠ” Male í˜¹ì€ Female entity ë“¤ì´ê³ , [pronoun]ì€ he/she ì˜ ëŒ€ëª…ì‚¬ì´ë‹¤. ë¬¸ì¥ ë‚´ì—ì„œ [pronoun]ê³¼ [entity]ì˜ ê´€ê³„ë¥¼ ë³´ê³ , pro-stereotypical í•œ ê´€ê³„ë¥¼ anti-stereotypical í•œ ê´€ê³„ë³´ë‹¤ ì„ í˜¸í•œë‹¤ë©´ biasê°€ ìˆëŠ” ëª¨ë¸ë¡œ íŒë‹¨í•œë‹¤. StereoSet: Measuring stereotypical bias in pretrained language models[5] ì€ 4ê°œì˜ bias domain - gender, profession, race, religion - ì— ëŒ€í•´ì„œ crowdsource ë°©ì‹ìœ¼ë¡œ ìˆ˜ì§‘ëœ ë°ì´í„°ì™€ bias ì¸¡ì • metric ì„ ì œì•ˆí•˜ê³  ìˆë‹¤. crowdsource ë°©ì‹ì€ template ê¸°ë°˜ ë°©ì‹ ëŒ€ë¹„ real-world ì— ë” ê°€ê¹ê²Œ ë°ì´í„°ì…‹ì„ ìˆ˜ì§‘í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤. StereoSetì—ì„œëŠ” LMì´ ë°°ì›Œì•¼ í•  ì§€ì‹ê³¼ ë°°ìš°ì§€ ì•Šê¸¸ ê¸°ëŒ€í•˜ëŠ” ì§€ì‹ (social bias) ì„ êµ¬ë¶„í•´ì„œ í•™ìŠµí–ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ í…ŒìŠ¤íŠ¸í•œë‹¤. Context Association Test (CAT) ë¼ê³  ëª…ì¹­í•œ TestëŠ” Intrasentenceì™€ Intersentence ë‘ ì¢…ë¥˜ì˜ í…ŒìŠ¤íŠ¸ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. ê·¸ë¦¬ê³  ëª¨ë¸ì´ ê° testì— ëŒ€í•´ ë‹µë³€í•œ ê²°ê³¼ë¥¼ ranking problem (option 1ì„ ì„ íƒí•œ ë¹„ìœ¨ì´ option 2ë¥¼ ì„ íƒí•œ ë¹„ìœ¨ë³´ë‹¤ ë§ì•˜ëŠ”ê°€, ì ì—ˆëŠ”ê°€) ìœ¼ë¡œ pose ì‹œì¼œì„œ ìµœì¢… bias scoreë¥¼ ë‚¸ë‹¤. ì•ì„œ ì–¸ê¸‰í–ˆë“¯ì´, LMì´ ë°°ì›Œì•¼ í•  ì§€ì‹ê³¼ ë°°ìš°ì§€ ì•Šê¸¸ ê¸°ëŒ€í•˜ëŠ” ì§€ì‹ (social bias) ì„ êµ¬ë¶„í•´ì„œ í•™ìŠµí–ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê¸° ë•Œë¬¸ì— lms ì™€ ss ë¥¼ êµ¬ë¶„í•˜ì˜€ê³ , ì´ ë‘ ì ìˆ˜ë¥¼ ì¢…í•©í•´ì„œ ìµœì¢… CAT score ë¥¼ ë„ì¶œí•œë‹¤. Language Modeling Score (lms) model has to rank the meaningful association higher than meaningless associaton score: percentage of instances in which a language model prefers ideal: 100 Stereotype Score (ss) score: percentage examples in which a model prefers a stereotypical association over an anti-stereotypical association ideal: 50 Idealized CAT Score (icat) combine both lms and ss \\[icat = lms *\\frac{min(ss, 100-ss)}{50}\\] ideal: 100 (when lms: 100 and ss: 50) fully biased: 0 (when lms: 0, ss: 100 or 0) random model: 50 (when lms: 50, ss: 50) CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models[6]ì€ EMNLP 2020ì— ì–µì…‰ëœ ë…¼ë¬¸ìœ¼ë¡œ, stereosetê³¼ ë§ˆì°¬ê°€ì§€ë¡œ template ê¸°ë°˜ì´ ì•„ë‹Œ crowndsourced ë°ì´í„°ì…‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. í¬ê²Œ 9ê°€ì§€ì˜ biasì— ëŒ€í•´ ë¬¸ì¥ í•˜ë‚˜ëŠ” stereotypingí•œ ê²ƒ, ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ëœ stereotyping í•œ ê²ƒìœ¼ë¡œ êµ¬ì„±í•œë‹¤. ë‘ ë¬¸ì¥ì˜ ê±°ë¦¬ëŠ” ë§¤ìš° ê°€ê¹Œì›Œì•¼ í•œë‹¤. í‰ê°€ì˜ ê²½ìš°, ì°¨ì´ê°€ ìˆëŠ” tokenì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ token (=unmodified token)ì„ ìˆœì°¨ì ìœ¼ë¡œ masking í•´ì„œ ê°ê°ì˜ log-likelihoodë¥¼ êµ¬í•œ ë’¤ ê·¸ í•©ì„ ìµœì¢… ì ìˆ˜ë¡œ ê°€ì§„ë‹¤. Limitations on â€œBias in NLPâ€ researches Language (Technology) is Power: A Critical Survey of â€œBiasâ€ in NLP[7]ì—ì„œëŠ” ê¸°ì¡´ì˜ 146ê°œ â€œbias in NLPâ€ paperì— ëŒ€í•œ surveyë¥¼ ì§„í–‰í•˜ë©´ì„œ ì´ì „ ì—°êµ¬ë“¤ì— ëŒ€í•œ ë¹„íŒê³¼ ì´ë¥¼ ê·¹ë³µí•  ìˆ˜ ìˆëŠ” ë°©í–¥ìœ¼ë¡œì˜ ì—°êµ¬ë¥¼ ì œì•ˆí•˜ì˜€ë‹¤. ë¹„íŒì˜ í¬ì¸íŠ¸ëŠ” í¬ê²Œ 3ê°€ì§€ì´ë‹¤. &quot;bias&quot;ì˜ ì •ì˜ì— ëŒ€í•œ ë…¼ì˜ ë¶€ì¬ &quot;bias&quot;ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ë¬¸ì œì— ëŒ€í•œ ê³ ë¯¼ ë¶€ì¡± (movitations are often vague, inconsistent, and lacking in normative reasoning) ê¸°ì¡´ í•™ê³„ì—ì„œ ë…¼ì˜ë˜ê³  ìˆëŠ” &quot;bias&quot;ì™€ì˜ ì•½í•œ ì—°ê²°ì„± ì˜ˆë¥¼ ë“¤ì–´, &quot;racial bias&quot;ì— ëŒ€í•œ ë‹¤ìŒ ê¸°ì¡´ ì—°êµ¬ë“¤ì„ ì‚´í´ë³´ì. ë‹¤ë£¨ê³  ìˆëŠ” ì£¼ì œëŠ” racial bias ì§€ë§Œ ì‹¤ì œë¡œëŠ” ë³´ë‹¤ í˜‘ì†Œí•œ African-American English (AAE) ì— ëŒ€í•´ì„œ ë‹¤ë£¨ê³  ìˆë‹¤. (ê·¸ë˜ë†“ê³  ì œëª©ì— racial biasë¥¼ ì ì–´ë‘” ê²ƒì€ ë­˜ê¹Œ? Asian ì°¨ë³„ì— ëŒ€í•´ì„œëŠ”?) ê·¸ë¦¬ê³  ê°™ì€ AAEì— ëŒ€í•´ ë‹¤ìŒê³¼ ê°™ì´ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ bias ê°€ ì¡´ì¬í•œë‹¤ê³  ì£¼ì¥í•˜ê³  ìˆë‹¤. African Americanê³¼ ì—°ê´€ëœ ì´ë¦„ì€ pleasant wordsë³´ë‹¤ unpleasant wordsì— ë” ê°€ê¹Œì›€ POS tagger, Language Identification, dependency parser ì—ì„œ AAEì— ì—°ê´€ëœ termì´ í¬í•¨ë˜ëŠ” ê²½ìš° ëœ ì •í™•í•¨ toxicity detection system ì´ AAE ì™€ ì—°ê´€ëœ feature ê°€ ìˆëŠ” íŠ¸ìœ—ì„ ë” offensive í•˜ë‹¤ê³  íŒë‹¨ë‚´ë¦¬ëŠ” ê²½í–¥ì´ ìˆìŒ ê¸°ì¡´ ì—°êµ¬ë“¤ ì¤‘ ì–´ë–¤ ê²ƒë„ AAE í˜¹ì€ racial hierarchies in the USì—ì„œì˜ racial hierarchies, raciolinguistic ë¶„ì„ì„ ì–¸ê¸‰í•˜ì§€ ì•Šì•˜ë‹¤. ë˜, AAEë¥¼ ëˆ„ê°€ ì´ì•¼ê¸°í•˜ëŠ”ê°€ì— ë”°ë¼ì„œë„ bias ì—¬ë¶€ë¥¼ ë‹¤ë¥´ê²Œ íŒë‹¨í•  ìˆ˜ ìˆìœ¼ë‚˜ ì´ì— ëŒ€í•œ ê³ ë ¤ëŠ” ì—†ì´ ì˜¤ì§ text ë§Œ ë†“ê³  íŒë‹¨í•˜ì˜€ë‹¤. ì–´ë–¤ ë§¥ë½ì—ì„œ AAE ê°€ ë¬¸ì œê°€ ë  ìˆ˜ ìˆê³ , bias ë˜ì—ˆë‹¤ê³  íŒë‹¨í•  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•œ ê³ ë ¤ëŠ” ì—†ì—ˆë‹¤. ê°œì¸ì ìœ¼ë¡œë„ ë‹¨ìˆœ ë°ì´í„°/ëª¨ë¸ ê²°ê³¼ ë¶„ì„ì˜ ë°©ë²•ë¡ ì´ ì• ë§¤í•˜ë‹¤ëŠ” ìƒê°ì´ ë“ ë‹¤. biasê°€ ìˆëŠ” ë¬¸ì¥/ë‹¨ì–´ì— ëŒ€í•´ ë‹¤ë¥¸ ë¬¸ì¥/ë‹¨ì–´ì™€ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ë„ì¶œí•œë‹¤ê³  ì´ì•¼ê¸°í•˜ê³  ìˆì§€ë§Œ, ì„ì˜ì˜ íŠ¹ì„±ë“¤ì— ëŒ€í•´ì„œë„ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•´ë³´ë©´ ë˜‘ê°™ì€ ê²°ê³¼ê°€ ë‚˜ì˜¬ ê²ƒ ê°™ë‹¤. ê·¸ë¦¬ê³  Crowdsourcing ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ datasetì´ bias ê°€ ì—†ìŒì„ ë³´ì¥í•˜ëŠ” ë‚´ìš©ë„ ë¶€ì¡±í–ˆë‹¤. US ì— ì‚´ê³  ìˆëŠ” ì‚¬ëŒë“¤ì´ annotator ë¡œ ì°¸ì—¬í–ˆì§€ë§Œ ë³´ìˆ˜ì ì¸ ì£¼ì˜ ì‚¬ëŒë“¤ì´ ë” ë§ì•˜ë‹¤ê±°ë‚˜, biasì— ëŒ€í•œ ì§€ì‹ì´ ë¶€ì¡±í•œ ì‚¬ëŒë“¤ì´ ë” ë§ì•˜ë‹¤ë©´ ë¬¸ì œê°€ ë  ì—¬ì§€ê°€ ìˆë‹¤. So? ì˜¬ë°”ë¥¸ ë°©ì‹ìœ¼ë¡œ bias in NLP ì£¼ì œë¥¼ tackle í•˜ê¸° ìœ„í•´ì„œëŠ” ì–¸ì œ Biased ëª¨ë¸ì´ ë¬¸ì œë¥¼ ì¼ìœ¼í‚¤ëŠ”ì§€ë¥¼ ìš°ì„  ê³ ë¯¼í•´ë´ì•¼í•  ê²ƒ ê°™ë‹¤. Biased modelì€ ì–¸ì œ ë¬¸ì œê°€ ë ê¹Œ? (Open Question) Bias ì˜ ë²”ìœ„ê°€ ë„“ìœ¼ë¯€ë¡œ gender bias ì— êµ­í•œí•´ì„œ ìƒê°í•´ë³´ì. ë§Œì•½ gender bias detection model ì„ ê°„ë‹¨í•˜ê²Œ KcBERTë¥¼ korean-hatespeech-dataset (gender bias) taskì— finetuning[10] í•œ ê²ƒìœ¼ë¡œ ì‚¬ìš©í•œë‹¤ê³  í–ˆì„ ë•Œ, ëª¨ë¸ì´ í‹€ë¦¬ëŠ” gender-biased ì˜ˆë¬¸ì´ o.o.d test set ì—ì„œ ë§ì´ ë“±ì¥í•œë‹¤ë©´ ë¬¸ì œê°€ ë ê¹Œ? í˜¹ì€ ì •ë‹µì€ ì œëŒ€ë¡œ ë§ì¶”ì—ˆë”ë¼ë„ ì˜ëª»ëœ ë‹¨ì–´ë¥¼ queueë¡œ ë°›ì•„ì„œ ë§ì¶”ëŠ” ê²ƒì´ë¼ë©´ ë¬¸ì œì´ì§€ ì•Šì„ê¹Œ? ë¬¸ì œê°€ ëœë‹¤ë©´, ì´ ë¬¸ì œëŠ” ë¬´ì—‡ìœ¼ë¡œë¶€í„° ê¸°ì¸í• ê¹Œ? KcBERT ê°€ í•™ìŠµí•œ ë°ì´í„°ë¡œë¶€í„° ì˜¤ëŠ” ë¬¸ì œ KcBERTë¥¼ finetuning í•˜ëŠ” ë°©ë²•ìœ¼ë¡œë¶€í„° ì˜¤ëŠ” ë¬¸ì œ finetuning dataset ì˜ ë¬¸ì œ ì œì‘ ì‹œ &quot;gender bias&quot;ë¥¼ annotator ì˜ ì§ê´€ì— ë§¡ê¸°ê¸°ë³´ë‹¤ëŠ” guidelineì„ ë°”íƒ•ìœ¼ë¡œ tagging ë˜ì—ˆë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ annotatorì˜ biasë¥¼ ìµœì†Œí™”í–ˆë‹¤ê³  ë³´ì—¬ì§„ë‹¤. dataset ì´ ì‘ê¸° ë•Œë¬¸ì— real world ë¥¼ ì¶©ë¶„íˆ ë°˜ì˜í•˜ì§€ ëª»í•´ì„œ ë‚˜íƒ€ë‚˜ëŠ” ë¬¸ì œ Human-in-the-loop ìœ¼ë¡œ í’€ì–´ë³¼ ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ? static benchmark ê°€ ì‰½ê²Œ stale í•´ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ ì œì•ˆëœ DynaBench[11]ë¼ëŠ” dynamic benchmark frameworkì„ ì°¸ê³ í•˜ë©´ ì–´ë–¨ê¹Œ? DynaBenchëŠ” userë“¤ì´ íŠ¹ì • taskë¥¼ í‘¸ëŠ” ëª©ì ìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ì´ í‹€ë¦¬ëŠ” ì˜ˆë¬¸ì„ ìƒì„±í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì‹œ ëª¨ë¸ì´ í•™ìŠµí•´ì„œ ì§€ì†ì ìœ¼ë¡œ ë°œì „í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì¡Œë‹¤. ê°„ë‹¨í•˜ê²Œ í•™ìŠµì‹œí‚¨ KcBERT finetuning model ì„ í†µí•´ ì˜ˆì¸¡í•œ ê²°ê³¼ë¥¼ ë³´ì•˜ì„ ë•Œ ì£¼ì–´ì§„ testset ê³¼ ìƒê°í•´ë³¼ ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ì˜ˆë¬¸ì— ëŒ€í•´ì„œëŠ” ë‚˜ì˜ì§€ ì•Šì€ ê²°ê³¼ë¥¼ ë³´ì„ì„ í™•ì¸í•˜ì˜€ë‹¤. DynaBenchë¥¼ benchmarking í•œ ì›¹ì‚¬ì´íŠ¸ë¥¼ ë§Œë“¤ì–´ë³´ë©´ ì¬ë°ŒëŠ” ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ìˆì§€ ì•Šì„ê¹Œ? References 1.Man is to computer programmer as woman is to homemaker? debiasing word embeddings â†©2.Semantics derived automatically from language corpora contain human-like biases â†©3.Social Bias in Elicited Natural Language Inferences â†©4.Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods â†©5.StereoSet: Measuring stereotypical bias in pretrained language models â†©6.CrowS-Pairs: A Challenge Dataset for Measuring Social Biases in Masked Language Models â†©7.Language (Technology) is Power: A Critical Survey of â€œBiasâ€ in NLP â†©8.https://en.wikipedia.org/wiki/Winograd_Schema_Challenge â†©9.https://kyunghyuncho.me/social-impacts-bias-of-ai/ â†©10.https://github.com/inmoonlight/detox/tree/master â†©11.https://dynabench.org/ â†©","link":"/2020/11/14/Social-bias-in-NLP-models/"},{"title":"ë‚´ê°€ ë³´ë‚´ëŠ” ì‹œê°„ì— ë¶€ì—¬í•˜ëŠ” ë‚˜ë§Œì˜ ì˜ë¯¸","text":"ê°œì¸ì ìœ¼ë¡œ, PUBLY ë°•ì†Œë ¹ ëŒ€í‘œë‹˜ì˜ ì¸ìŠ¤íƒ€ê³„ì •ì„ ì¢‹ì•„í•œë‹¤. íŠ¹íˆ ë³¸ì¸ì´ ì½ì—ˆë˜ ì±…ì— ëŒ€í•´ ì†Œê°œí•˜ëŠ” í”¼ë“œë¥¼ ì• ì •í•œë‹¤. ê³µê°í•˜ëŠ” ë¬¸ì¥ì´ ë¹„ìŠ·í•  ë•Œê°€ ë§ê³ , ê·¸ ê¸€ì„ ì½ê³  ë‚œ ë’¤ì˜ ìƒê°ì„ ì—¿ë³´ëŠ” ì¬ë¯¸ê°€ ìˆë‹¤. ìµœê·¼, íšŒì‚¬ì— ì—°ì°¨ë¥¼ ì´í‹€ì •ë„ ë‚´ê³  ë¬´ì—‡ì„ í• ì§€ ê³ ë¯¼í•˜ë˜ ì¤‘ì— ê·¸ í”¼ë“œì— ìˆì—ˆë˜ â€œì¼í•˜ëŠ” ë§ˆìŒâ€ì´ë¼ëŠ” ì±…ì´ ë– ì˜¬ëë‹¤. â€˜ì˜³ë‹¤êµ¬ë‚˜!â€™ í•˜ê³  ì§‘ì–´ë“  ì±…ì„ ì´ì œì„œì•¼ ê±°ì˜ ë‹¤ ì½ì—ˆëŠ”ë°, ê·¸ ì¤‘ì— ë§ˆìŒì— í„± ê±¸ë ¸ë˜ ë¶€ë¶„ì„ ì†Œê°œí•˜ë ¤ê³  í•œë‹¤. ì „ë¬¸ì„±ì´ í•œ ê°€ì§€ ì´ë¦„ì˜ ì§ì—…ê³¼ ê²°ë¶€ë˜ëŠ” ê²ƒì´ë¼ë©´, íƒì›”ì„±ì€ ì¼ì„ ë°”ë¼ë³´ëŠ” ì ‘ê·¼ë²•, ë‹¤ì–‘í•œ ë¶„ì•¼ë¡œ í™•ëŒ€í•  ìˆ˜ ìˆëŠ” ì¤‘ì‹¬ ê¸°ìˆ ê³¼ ì—°ê²°ëœë‹¤. &quot;ì¤‘ì‹¬ ê¸°ìˆ &quot;ì€ ì‚¬ì‹¤ í•˜ë‚˜ì˜ ì„œì‚¬ì´ì ì´ë¦„ ë¶™ì´ê¸°ë‹¤. ê¸°ìì˜€ë‹¤ê°€ ë²ˆì—­ê°€ì´ì ì‘ê°€ë¡œ ì¼í•˜ê³ , ë˜ ë¹„ì˜ë¦¬ë‹¨ì²´ì˜ ì˜¹í˜¸ë¶€ì¥ì—ì„œ ì‚¬ì—…ë³¸ë¶€ì¥ì„ ê±°ì¹œ ê¹€í¬ê²½ ì‘ê°€ëŠ” ìì‹ ì˜ ì¤‘ì‹¬ ê¸°ìˆ ì´ â€œì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ëŠ” ê²ƒâ€ì´ë¼ê³  ë§í–ˆë‹¤. ì§ì—…ê³¼ ì§ìœ„ëŠ” ê³„ì† ë°”ë€Œì—ˆì§€ë§Œ, ì •ë³´ë¥¼ êµ¬ì¡°í™”í•˜ëŠ” ê²ƒì´ ì–¸ì œë‚˜ ìì‹ ì˜ ì¼ì´ì—ˆë‹¤ëŠ” ê²ƒì´ë‹¤. â€¦ ì „ë¬¸ì„±ì˜ í•„ìš” ì¡°ê±´ì€ ë‘ ê°€ì§€ë‹¤. í•˜ë‚˜ëŠ” â€˜ì˜¤ëœ ê¸°ê°„â€™ì„ ë³´ëƒˆë‹¤ëŠ” ê²ƒì´ê³ , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ê·¸ ì˜¤ëœ ê¸°ê°„ì´ â€˜ì‹œìŠ¤í…œì´ ì¸ì •í•˜ëŠ” ë‚´ë¶€ì—ì„œ ë³´ë‚¸ ê¸°ê°„â€™ì´ì–´ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤. â€¦ ê·¸ì— ë°˜í•´ íƒì›”ì„±ì€ ëˆ„êµ¬ì—ê²Œë‚˜ ì—´ë ¤ ìˆì§€ë§Œ, ê·¸ëŸ¼ì—ë„ ë”ìš± ê°€ì§€ê¸° ì–´ë ¤ìš´ ê²ƒì´ë‹¤. íƒì›”ì„±ì€ ë˜í•œ ìì‹ ì´ í•´ì˜¨ ì¼, í•˜ê³  ìˆëŠ” ì¼ì„ ì–´ë–»ê²Œ ë°˜ì¶”í•˜ë©° ìì‹ ë§Œì˜ ì‹œê°ìœ¼ë¡œ í•´ì„í•˜ëŠ”ê°€ì˜ ë¬¸ì œì´ê¸°ë„ í•˜ë‹¤. ê°™ì€ ì¼ì„ í•´ë„ ê·¸ ì¼ì˜ ê²½í—˜ì„ í†µí•´ ì¨ë‚´ë ¤ê°ˆ ìˆ˜ ìˆëŠ” ì´ì•¼ê¸°ëŠ” ì‚¬ëŒë§ˆë‹¤ ë‹¤ë¥´ë‹¤. ì–¼í• ë³´ì•„ íŒŒí¸ì ì´ê³  ë¶ˆì—°ì†ì ì¸ ê²½í—˜ì„ í†µí•´ì„œë„ ì¼ê´€ë˜ê³  ì˜ë¯¸ ìˆëŠ” ì´ì•¼ê¸°ë¥¼ ì¨ë‚´ë ¤ê°ˆ ìˆ˜ ìˆëŠ” ì‚¬ëŒì€ ìê¸° ê¸°ì¤€ì„ ê°€ì§€ê³  ìˆê³ , ê·¸ ê¸°ì¤€ì— ë§ì¶° ìê¸° ì¼ì˜ ê²½í—˜ì„ ìŠ¤ìŠ¤ë¡œ í•´ì„í•  ìˆ˜ ìˆëŠ” ì‚¬ëŒì´ë‹¤. ì¼í•˜ëŠ” ë§ˆìŒì „ë¬¸ì„±ì´ ì•„ë‹Œ íƒì›”ì„± ì§€ê¸ˆ ë‚˜ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì„±ê²©ì˜ ë‘ ê°€ì§€ ì¼ (íŒŒíŒŒê³ ì™€ ë‚ ë¦¬ë‹¤) ì„ ë³‘í–‰í•˜ê³  ìˆë‹¤. ë‘˜ ë‹¤ ì˜í•˜ê³  ì‹¶ì€ ë§ˆìŒì€ í¬ì§€ë§Œ ëŠ¥ë ¥ì˜ ë¶€ì¡±ìœ¼ë¡œ ì–´ëŠ ê²ƒ í•˜ë‚˜ ì œëŒ€ë¡œ í•˜ê³  ìˆì§€ ëª»í•˜ê³  ìˆì—ˆëŠ”ë°, ì¼ì— ì¹˜ì¼ ë•Œë§ˆë‹¤ â€˜í•˜ë‚˜ë§Œ í•´ë„ ë²„ê±°ìš´ë°, ë‚˜ëŠ” ì™œ ì´ë ‡ê²Œ ì‚´ê³  ìˆì§€?â€™ ë¼ëŠ” ìƒê°ì´ ë“¤ë©´ì„œ ì•„ë¬´ê²ƒë„ í•˜ê³  ì‹¶ì§€ ì•Šì€ ëŠë‚Œì´ ê°•í•˜ê²Œ ë“¤ê³¤ í–ˆë‹¤. ì—°ì°¨ë¥¼ ì¼ë˜ ê·¸ ë•Œì˜ ë‚˜ì—ê²Œ í•„ìš”í–ˆë˜ ê±´, ë‚´ê°€ ì‹œê°„ì„ íˆ¬ìí•˜ëŠ” ì¼ì— ëŒ€í•œ ë‚˜ë§Œì˜ ì˜ë¯¸ë¥¼ ë˜ì°¾ëŠ” ê²ƒì´ì—ˆë‹¤. ë‹¤í–‰íˆ íœ´ê°€ ê¸°ê°„ ë‚´ì—, ë¶ˆì™„ì „í•˜ê³  ë¯¸ì™„ì„±ì¸ í•´ì„ì¼ì§€ë¼ë„ ìƒˆë¡­ê²Œ ì˜ë¯¸ë¥¼ ë¶€ì—¬í–ˆë‹¤. ê·¸ë¦¬ê³  ê·¸ì œì„œì•¼, ë‹¤ì‹œ ì‹œì‘í•  ìˆ˜ ìˆëŠ” í˜ì„ ì–»ì„ ìˆ˜ ìˆì—ˆë‹¤. ë‚´ê°€ í•˜ê³  ìˆëŠ” ë‘ ì¼ì˜ ì¤‘ì‹¬ì—ëŠ” ì‚¬ëŒì´ ìˆì—ˆë‹¤. ë‚˜ëŠ” íƒ€ì¸ì´ í•´ê²°í•˜ê³  ì‹¶ì€ ë¬¸ì œë¥¼ ë‚˜ì˜ ë¬¸ì œë¡œ ì‰½ê²Œ íˆ¬ì˜ì‹œí‚¨ë‹¤. ëˆ„êµ°ê°€ì˜ ë¬¸ì œì™€ ì´ë¥¼ ë‘˜ëŸ¬ì¬ ìƒí™©ì„ ì´í•´í•˜ê³ , ë¬¸ì œë¥¼ í•´ê²°í•´ì„œ ê·¸ ì‚¬ëŒì„ ë§Œì¡±ì‹œí‚¬ ë•Œ í° ê¸°ì¨ì„ ëŠë‚€ë‹¤. ê·¸ë˜ì„œ ì‰½ê²Œ ë“œëŸ¬ë‚˜ì§€ ì•ŠëŠ” ë¬¸ì œ ìƒí™©ì„ ë” ì˜ ì´í•´í•˜ê³ ì ë°ì´í„° ë¶„ì„ì„ ì‹œì‘í–ˆê³ , ë‚´ê°€ í•´ê²°ì±…ì„ ì œì‹œí•  ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ëŠ” ë¬¸ì œì— ëŒ€í•´ì„œëŠ” ë” ë§ì€ ì‚¬ëŒì´ ë‚˜ì˜ í•´ê²° ë°©ì‹ì„ í†µí•´ ë„ì›€ì„ ë°›ê²Œ í•˜ê³  ì‹¶ì–´ì„œ ë‚ ë¦¬ë‹¤ì— ì†í•´ í”„ë¡œê·¸ë¨ ê¸°íšì„ í•˜ê³  ìˆë‹¤. ë‹¤ë¥¸ ì‚¬ëŒë“¤ì€ ì–´ë–¤ ë§ˆìŒìœ¼ë¡œ ìì‹ ì´ í•´ì˜¨ ì¼, í•˜ê³  ìˆëŠ” ì¼ì„ í•´ì„í•˜ê³  ìˆì„ê¹Œ? ë‚¨ì—ê²Œ ë‚˜ë¥¼ ì†Œê°œí•˜ê¸° ì‰¬ìš´ ë°©ì‹ - data manifoldì˜ geometrical insightì— ê´€ì‹¬ìˆëŠ” ë¡œë´‡ìë™í™” ì—°êµ¬ì‹¤ ëŒ€í•™ì›ìƒ, HCI ì—°êµ¬ì‹¤ ëŒ€í•™ì›ìƒ, deep metric learningì— ê´€ì‹¬ìˆëŠ” ëŒ€í•™ì›ìƒ, ì „ë™í‚¥ë³´ë“œ ì‰ì–´ë§ ìŠ¤íƒ€íŠ¸ì—… ê°œë°œì, (ì „) ì¸ì•¡í„°ìŠ¤ ì˜ì¥, ì„œìš¸ëŒ€ ìˆ˜í•™ê³¼ ë°•ì‚¬, google swe, ê±´ì¶•í•™ë„, íŒŒíŒŒê³  ê°œë°œì - ì´ ì•„ë‹Œ, ë³¸ì¸ ìŠ¤ìŠ¤ë¡œì—ê²Œ ë¶€ì—¬í•˜ëŠ” ì´ë¦„ì€ ë¬´ì—‡ì¼ê¹Œ?","link":"/2019/04/04/Through-my-times/"},{"title":"ë…¸ë¥´ì›¨ì´ì—ì„œì˜ ë‚˜í™€ë¡œ ì—¬í–‰: í”¼ì˜¤ë¥´ë“œ, ë¸Œë¼ìš´ ì¹˜ì¦ˆ","text":"ë¶ìœ ëŸ½ì€ ì˜¤ë¡œë¼ë¥¼ ë³´ê³  ì‹¶ì–´ì„œ ê²¨ìš¸ì— ê°ˆ ê³³ìœ¼ë¡œ ë‚´ì‹¬ ì •í•´ë‘ê³  ìˆì—ˆëŠ”ë°, ê·¸ëŸ¼ì—ë„ ë¶ˆêµ¬í•˜ê³  í•œ ì—¬ë¦„ì— ë…¸ë¥´ì›¨ì´ë¥¼ í–‰ì„ ì§€ë¡œ ì •í–ˆë˜ ê¹Œë‹­ì€ í”¼ì˜¤ë¥´ë“œ(Fjord) ì˜€ë‹¤. ì›…ì¥í•œ ìì—°ì„ ë³´ê¸¸ ì¢‹ì•„í•˜ëŠ” í¸ì¸ë°ë‹¤ê°€ (ì˜¤ë¡œë¼ë§Œ ë´ë„ ì•Œ ìˆ˜ ìˆë‹¤) ë¥ê³  ìŠµí•œ ì—¬ë¦„ì—ì„œ, ê·¸ë¦¬ê³  í‹€ì— ë°•íŒë“¯í•œ ë‹µë‹µí•œ ì‚¶ì—ì„œ ì ì‹œ ë²—ì–´ë‚˜ê³  ì‹¶ì—ˆë‹¤. ì¢€ ë” ì°¾ì•„ë³´ë‹ˆ ë…¸ë¥´ì›¨ì´ëŠ” í”¼ì˜¤ë¥´ë“œì˜ ì²œêµ­ì´ì—ˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ê´€ê´‘ê°ì´ ì°¾ëŠ” í”¼ì˜¤ë¥´ë“œì´ì ê°€ì¥ ê¸¸ê³  ê¹Šì€[1] ì†¡ë„¤í”¼ì˜¤ë¥´ë“œ(Sognefjord), ì˜í™” &lt;&lt;ê²¨ìš¸ì™•êµ­&gt;&gt;ì˜ ë°°ê²½ì´ì ê·¸ ì•„ë¦„ë‹¤ì›€ìœ¼ë¡œ UNESCO ì„¸ê³„ ìœ ì‚°ì— ì§€ì •ëœ ë‚´ë¡œì´í”¼ì˜¤ë¥´ë“œ(NÃ¦rÃ¸yfjord), ë² ë¥´ê²(Bergen)ì—ì„œ í”ŒëŸ¼(FlÃ¥m)ìœ¼ë¡œ ê°€ëŠ” ê¸¸ì— ì†¡ë„¤í”¼ì˜¤ë¥´ë“œë¥¼ ê±°ì³ ì§€ë‚˜ëŠ” Aurlandsfjord[2] ë“±ë“±. &quot;í”¼ì˜¤ë¥´ë“œ&quot;ê°€ ë¹™í•˜ë¡œ ë§Œë“¤ì–´ì§„ ì¢ê³  ê¹Šì€ ë§Œì„ ëœ»í•˜ë‹¤ë³´ë‹ˆ ë…¸ë¥´ì›¨ì´ ê³³ê³³ì— í”¼ì˜¤ë¥´ë“œë¡œ ëë‚˜ëŠ” ì´ë¦„ì´ ë§ì•˜ë‹¤. ë‚˜ëŠ” ì´ë²ˆ ì—¬í–‰ì—ì„œ ë² ë¥´ê²ì„ ë“¤ë¥´ì§€ ì•Šê³  í”ŒëŸ¼ì—ì„œë§Œ ë¨¸ë¬´ë¥´ê¸°ë¡œ í–ˆê¸° ë•Œë¬¸ì— Aurlandsfjordì—ì„œ ë‚´ë¡œì´í”¼ì˜¤ë¥´ë“œ(NÃ¦rÃ¸yfjord)ë¥¼ ê±°ì³ ìš´ë“œë ˆë‹¬(Undredal)ì—ì„œ ë¸Œë¼ìš´ ì¹˜ì¦ˆë¥¼ ì²´í—˜í•  ìˆ˜ ìˆëŠ” íˆ¬ì–´ë¥¼ ì‹ ì²­í–ˆë‹¤. ferry íˆ¬ì–´ì™€ëŠ” ë‹¤ë¥´ê²Œ RIB(Rigid Inflated Boat) íˆ¬ì–´ëŠ” ì•¼ìƒì˜ íˆ¬ì–´ì— ê°€ê¹Œì› ë‹¤. ë³´íŠ¸ì˜ ìš´ì „ì„ ë‹´ë‹¹í•˜ëŠ” ê°€ì´ë“œëŠ” ë•Œë•Œë¡œ ferryê°€ ê°€ë¥´ê³  ê°„ ë¬¼ê²° ìœ„ë¥¼ ì§€ë‚˜ë©° ìŠ¤ë¦´ê°ì„ ì£¼ê¸°ë„ í•˜ê³ , í”¼ì˜¤ë¥´ë“œ í˜‘ê³¡ì— ì‚¬ëŠ” ì‘ì€ ê³ ë˜ë¥¼ ë§Œë‚˜ë©´ ê·¼ì²˜ì—ì„œ êµ¬ê²½ì„ ì‹œì¼œì£¼ê¸°ë„ í–ˆë‹¤. ì´ì— ë”í•´ ê·¸ ì§€ì—­ì— ëŒ€í•œ ì¹œì ˆí•˜ê³  ìì„¸í•œ ì„¤ëª…ë„ í•¨ê»˜ ë“¤ì„ ìˆ˜ ìˆì–´ì„œ ë…¸ë¥´ì›¨ì´ê°€ ë” ê°€ê¹ê²Œ ëŠê»´ì¡Œë‹¤. í”¼ì˜¤ë¥´ë“œëŠ” ì •ë§ ì•„ë¦„ë‹¤ì› ë‹¤. íŠ¹íˆ ë‚´ë¡œì´í”¼ì˜¤ë¥´ë“œ(NÃ¦rÃ¸yfjord)ëŠ” í˜‘ê³¡ì˜ ê³¡ì„ ì´ ì„¬ì„¸í–ˆê³  ì¡°í™”ë¡œì› ë‹¤. ì•„ë¦„ë‹¤ì›€ê³¼ ì‹¤ìš©ì„±ì€ ë°˜ë¹„ë¡€í•œë‹¤ê³  ìƒê°í•´ì™”ëŠ”ë°, í”¼ì˜¤ë¥´ë“œë„ ë§ˆì°¬ê°€ì§€ì˜€ë‹¤. ë³´ê¸°ì—ëŠ” ì•„ë¦„ë‹µê³  ê²½ì´ë¡­ì§€ë§Œ, ê·¸ ê³³ì—ì„œ ì‚´ì•„ê°€ê¸° ìœ„í•´ì„œëŠ” ë¹„ì˜¥í•œ í‰ì§€ì—ì„œ ì‚´ì•„ê°€ëŠ” ì‚¬ëŒë“¤ì— ë¹„í•´ ë§ì€ ë…¸ë ¥ì´ í•„ìš”í–ˆë‹¤. íŠ¹íˆ &quot;ì‹&quot;ì„ í•´ê²°í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì–´ë ¤ìš´ ë¬¸ì œì˜€ë‹¤. ë…¸ë¥´ì›¨ì´ëŠ” ê²½ì‘í•  ìˆ˜ ìˆëŠ” í† ì§€ì˜ ë¹„ìœ¨ì´ ì‘ë‹¤. íŠ¹íˆ í”¼ì˜¤ë¥´ë“œ ê·¼ì²˜ëŠ” ê·¸ ë¹„ìœ¨ì˜ 1/10ì´ë‹¤. ì´ëŸ° ì²™ë°•í•¨ ë•ë¶„ì— ì„ìœ ì˜ ë°œê²¬ìœ¼ë¡œ ì§€ê¸ˆê³¼ ê°™ì´ ë¶€ìœ í•œ êµ­ê°€ê°€ ë˜ê¸° ì „ì—ëŠ” ë§ì€ ì‚¬ëŒë“¤ì´ ë¯¸êµ­ìœ¼ë¡œ ì´ë¯¼ì„ ê°”ë‹¤ê³  í•œë‹¤. ë‚¨ì€ ì‚¬ëŒë“¤ì€ ë†ì—…ëŒ€ì‹  ë‚™ë†ì—…ìœ¼ë¡œ ìƒê³„ë¥¼ ìœ ì§€í•´ ë‚˜ê°”ë‹¤. ì´ ê³³ì˜ ë‚™ë†ì—…ì€ ë‹¤ë¥¸ ê³³ì— ë¹„í•´ íŠ¹ì´í•œ ì ì´ ìˆì—ˆë‹¤. í•˜ë‚˜ëŠ” ì—¼ì†Œ ì¹˜ì¦ˆê°€ ì£¼ë¥¼ ì´ë£¬ë‹¤ëŠ” ì , ë‹¤ë¥¸ í•˜ë‚˜ëŠ” ë¸Œë¼ìš´ ì¹˜ì¦ˆë¼ëŠ” ë…íŠ¹í•œ ì¹˜ì¦ˆê°€ ë°œì „ë˜ì—ˆë‹¤ëŠ” ì . ì—¼ì†Œ ì¹˜ì¦ˆê°€ ì†Œ ì¹˜ì¦ˆë³´ë‹¤ ë°œë‹¬í•œ ì´ìœ ëŠ” ì—¼ì†Œê°€ ì‚°ì„ ì˜ íƒ€ê¸° ë•Œë¬¸ì´ë‹¤. ì¶”ìš´ ì§€ë°©ì´ë‹¤ ë³´ë‹ˆ ì—¬ë¦„ê³¼ ê²¨ìš¸ì— í’€ì„ ë¨¹ì„ ìˆ˜ ìˆëŠ” ë©´ì ì´ ëˆˆì— ë„ê²Œ ë‹¬ë¼ì§„ë‹¤. ëˆˆì´ ë…¹ì„ ì‹œê¸°ì—ëŠ” ê·¸ ê¸°íšŒë¥¼ ì‹­ë¶„ í™œìš©í•´ ì¢€ ë” ìœ„ì—ì„œ í’€ì„ ë¨¹ëŠ” ê²ƒì´ ì´ë“ì´ë‹¤. ë‹¤í–‰íˆ ì—¼ì†Œì˜ ì²œì ì€ ì´ ì¶”ìœ„ë¥¼ ê²¬ë””ë©° ì‚´ ìˆ˜ ì—†ì–´ì„œ ì—¼ì†Œ ë–¼ë¥¼ í’€ì–´ë‘ê¸°ë§Œ í•˜ë©´ ì•Œì•„ì„œ ì‚°ì„ ì˜¬ë¼ ì œì¼ ë§›ìˆëŠ” í’€ì„ ì•Œì•„ì„œ ëœ¯ì–´ë¨¹ê³  ì•ˆì „íˆ ë§ˆì„ë¡œ ê·€ê°€í•œë‹¤ê³  í•œë‹¤. ë¸Œë¼ìš´ ì¹˜ì¦ˆëŠ” ìš°ë¦¬ê°€ í”íˆ ì•„ëŠ” í™”ì´íŠ¸ ì¹˜ì¦ˆì˜ ì”ì—¬ë¬¼ë¡œ ë§Œë“  ë…íŠ¹í•œ ì¹˜ì¦ˆë‹¤. ì•„ë¬´ë¦¬ ë‚™ë†ì—…ì´ ë°œë‹¬í–ˆë‹¤ê³  í•˜ë”ë¼ë„ ê·¸ ì–‘ì´ ì¶©ë¶„í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì— ì‚¬ëŒë“¤ì€ ì¼ë°˜ í™”ì´íŠ¸ ì¹˜ì¦ˆë¥¼ ë§Œë“¤ê³  ë‚¨ì€ ê²ƒë„ ì‹ëŸ‰ìœ¼ë¡œ í™œìš©í•´ì•¼ í–ˆë‹¤. ì”ì—¬ë¬¼ì€ &quot;ìœ ì²­&quot;ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ê²ƒì¸ë° ì´ë¥¼ ì¶©ë¶„íˆ ì¡¸ì´ë©´ ê°ˆìƒ‰ìœ¼ë¡œ ë³€í•˜ê³  ì¹´ë¼ë©œì²˜ëŸ¼ ë‹¨ ë§›ì´ ë‚œë‹¤. ì—¬ê¸°ì— ì–¼ë§ˆ ë˜ì§€ ì•ŠëŠ” ì†Œì˜ ì –ìœ¼ë¡œ ë§Œë“  í¬ë¦¼ì„ 1:1 ë¹„ìœ¨ë¡œ ì„ì–´ì£¼ë©´ ë¸Œë¼ìš´ ì¹˜ì¦ˆê°€ ëœë‹¤. í™”ì´íŠ¸ ì¹˜ì¦ˆë¥¼ ë§Œë“¤ ë•Œ ì§€ë°©ì´ ë§ì´ ë¹ ì ¸ë‚˜ê°€ë‹¤ë³´ë‹ˆ ë¸Œë¼ìš´ ì¹˜ì¦ˆëŠ” ì§€ë°©ì´ ëœ í•¨ìœ ë˜ì–´ ìˆë‹¤. ë¸Œë¼ìš´ ì¹˜ì¦ˆëŠ” ë…¸ë¥´ì›¨ì´ì—ì„œ ë§ì´ íŒŒëŠ” í¬ë˜ì»¤ê°™ì€ ë¹µì— ë²„í„°ë¥¼ ë°œë¼ ê·¸ ìœ„ì— ì–¹ê³ , ê·¸ ì§€ë°©ì˜ ì¼ì„ ë°œë¼ë¨¹ëŠ”ë‹¤. ë§ˆíŠ¸ì—ì„œ íŒŒëŠ” ë¸Œë¼ìš´ ì¹˜ì¦ˆëŠ” ì¸ê³µì ì¸ í–¥ì´ ê°€ë¯¸ë˜ì–´ ìˆì–´ ì¢€ ë” ë‹¨ ë§›ì´ ë§ì´ ë‚œë‹¤. ë‚´ë¡œì´í”¼ì˜¤ë¥´ë“œì˜ ëì—ëŠ” êµ¬ë“œë°©ê²(Gudvangen)ì´ë¼ëŠ” ë§ˆì„ì´ ìˆì—ˆê³ , ìš´ë“œë ˆë‹¬(Undredal)ê³¼ëŠ” ë‹¬ë¦¬ ë°”ì´í‚¹ ì¡±ì˜ ì „í†µì„ ê°„ì§í•˜ê³  ìˆì—ˆë‹¤. ì§‘ì˜ ì§€ë¶•ì€ í’€ì´ ë®ì–´ì ¸ìˆì—ˆê³ [3], ì–´ë¦° ì•„ì´ë“¤ì´ (íŠ¹íˆ ë‚¨ì) ë‚¯ì„  ì´ë¥¼ ë”°ë¼ê°€ì§€ ëª»í•˜ë„ë¡ &quot;íŠ¸ë¡¤ì´ ë„ˆë¥¼ ì¡ì•„ë¨¹ëŠ”ë‹¤!&quot;ë©° ê²ì„ ì¤¬ë‹¤ê³  í•œë‹¤. ë†€ëê²Œë„ ì´ íŠ¸ë¡¤ì€ ë…¸ë¥´ì›¨ì´ì˜ ìœ ëª…í•œ ê·¹ì‘ê°€ í—¨ë¦­í¬ ì…ì„¼ì˜ ì†Œì„¤ &lt;&lt;í˜ë¥´ê·„íŠ¸&gt;&gt;ì— ì²˜ìŒìœ¼ë¡œ ë“±ì¥í–ˆë‹¤ê³  í•œë‹¤. ì£¼ì¸ê³µ í˜ë¥´ ê·„íŠ¸ê°€ ì‚° ì†ì—ì„œ íŒíƒ€ì§€ìŠ¤ëŸ¬ìš´ ì—¬ì •ì„ í•  ë•Œ ì´ˆë¡ ì˜·ì„ ì…ì€ ì—¬ìê°€ ë‚˜íƒ€ë‚˜ ê·¸ë¥¼ ìœ í˜¹í–ˆëŠ”ë° ì•Œê³ ë³´ë‹ˆ íŠ¸ë¡¤ì˜ ë”¸ì´ì—ˆë‹¤ê³  í•œë‹¤. ê·¸ ì´í›„ íŠ¸ë¡¤ì€ íŒíƒ€ì§€ ì†Œì„¤ ì†ì—ì„œ ê´´ê¸°ìŠ¤ëŸ½ê²Œ ë°œì „ë˜ê¸°ë„ í•˜ê³ , &lt;&lt;ê²¨ìš¸ì™•êµ­&gt;&gt;ì— ë“±ì¥í•˜ëŠ” íŠ¸ë¡¤ì²˜ëŸ¼ ê·€ì—¬ìš´ ëª¨ìŠµìœ¼ë¡œë„ ë°œì „í–ˆë‹¤. ìƒê°ë³´ë‹¤ ë…¸ë¥´ì›¨ì´ ì‚¬ëŒë“¤ì˜ ì…ì„¼ ì‚¬ë‘ì€ ì—„ì²­ë‚¬ë‹¤. ë¦´ë¦¬í•¨ë©”ë¥´(Lillehammer)ë¼ëŠ” ì§€ì—­ì—ì„œëŠ” ë§¤ë…„ 8ì›” ì´ˆë§ˆë‹¤ &lt;&lt;í˜ë¥´ê·„íŠ¸(Peer Gynt)&gt;&gt; í˜ìŠ¤í‹°ë²Œì„ ì—°ë‹¤. ë…¸ë¥´ì›¨ì´ì˜ ìì—°ì„ ë°°ê²½ìœ¼ë¡œ ì•¼ì™¸ì—ì„œ í•˜ëŠ” ì—°ê·¹ì´ ê°€ì¥ ì¸ê¸°ê°€ ë§ë‹¤. ê·¸ë¦¬ê·¸ì˜ &lt;&lt;í˜ë¥´ ê·„íŠ¸ ëª¨ìŒê³¡&gt;&gt;ìœ¼ë¡œë§Œ ì ‘í–ˆë˜ í˜ë¥´ ê·„íŠ¸ì˜ ì´ì•¼ê¸°ê°€ ê¶ê¸ˆí•´ì„œ, ê·¸ë¦¬ê³  ê·¸ë“¤ ê³ ìœ ì˜ ì¶•ì œê°€ ê¶ê¸ˆí•´ì„œ, ë‚˜ë„ í•œ ë²ˆ ì—°ê·¹ í‹°ì¼“ì„ êµ¬ë§¤í–ˆë‹¤. ì´ì— ëŒ€í•œ ë‚´ìš©ì€ ì–¸ì  ê°€â€¦ 1.ì ì–´ë„ ë‚˜ì˜ ê°€ì´ë“œì— ë”°ë¥´ë©´, ê°€ì¥ ê¸´ í”¼ì˜¤ë¥´ë“œëŠ” ì‚¬ì‹¤ Greenlandì— ìˆëŠ” í”¼ì˜¤ë¥´ë“œë¼ê³  í•œë‹¤. í•˜ì§€ë§Œ ì‚¬ëŒì´ ì‚´ì§€ ì•Šê¸° ë•Œë¬¸ì— ì•ˆ ì³ì¤€ë‹¤ê³ ... â†©2.í•œêµ­ì–´ë¡œ ì–´ë–»ê²Œ í‘œê¸°í•˜ëŠ” ê²ƒì´ ì˜³ì€ì§€ ëª°ë¼ ì˜ì–´ë¡œ ë‚¨ê²¨ë‘ì—ˆë‹¤. â†©3.ë‚˜ì˜ ê°€ì´ë“œì— ë”°ë¥´ë©´, í’€ì„ ë®ì€ ì´ìœ ëŠ” ì§€ë¶•ì„ ë” ë‹¨ë‹¨íˆ ì—®ê¸° ìœ„í•¨ê³¼ ì•„ë¦„ë‹¤ì›€(?!) ë•Œë¬¸ì´ë¼ê³  í•œë‹¤. â†©","link":"/2019/08/09/Travel-to-Norway-fjord-brown-cheese/"},{"title":"ë¹›ì˜ ê³¼ê±°","text":"ìƒˆí•´ë¥¼ ë§ì´í•˜ìë§ˆì ì‘ë…„ì˜ ëª©í‘œì™€ ê¸°ëŒ€ì—ëŠ” ì—†ë˜ ì¼ì´ ì¼ì–´ë‚¬ë‹¤. ì˜¤ëœë§Œì— ëµŒ ë¶„ê»˜ ì€í¬ê²½ ì‘ê°€ë‹˜ì˜ &quot;ë¹›ì˜ ê³¼ê±°&quot;ë¼ëŠ” ì±…ì„ ì„ ë¬¼ë°›ì€ ê²ƒì´ë‹¤. ê·¸ ë™ì•ˆ ì½ì—ˆë˜ í…ìŠ¤íŠ¸ë¼ê³ ëŠ” ì˜¤ì§ ë…¼ë¬¸ì´ì—ˆê¸°ì— ì„ ë¬¼ë°›ìë§ˆì ë“¤ì—ˆë˜ ìƒê°ì€ â€œì•„, ë‚´ê°€ ê³¼ì—° ì±…ì„ ì½ì„ ìˆ˜ ìˆì„ê¹Œ?â€ ì˜€ë‹¤. ê·¸ ì™€ì¤‘ì— ì‘ê°€ë‹˜ì˜ ì„±í•¨ì´ ëˆˆì— ë„ì—ˆë‹¤. ì€í¬ê²½ ì‘ê°€ë‹˜â€¦ ì™œ ì´ë ‡ê²Œ ìµìˆ™í•œ ì´ë¦„ì¸ê°€ í–ˆë”ë‹ˆ ê°œì¸ì ìœ¼ë¡œ ì¡´ê²½í•˜ê³  í ëª¨í•˜ëŠ” ì–¸ë‹ˆë¡œë¶€í„° ì¶”ì²œë°›ì•˜ë˜ ì‘ê°€ë‹˜ì´ì—ˆë‹¤ëŠ” ê²ƒì´ ë– ì˜¬ëë‹¤. ë‹¨ì§€ ì´ ì‘ì€ ì´ìœ ë§Œìœ¼ë¡œ ì˜¤ëœë§Œì— ì ‘í•˜ëŠ” ì†Œì„¤ì˜ ë²½ì´ ë‚®ì•„ì§€ëŠ” ëŠë‚Œì´ì—ˆë‹¤. ì´ ì±…ì„ ì½ì„ ìš´ëª…ì´ì—ˆë˜ ê²ƒì¸ì§€, ë§ˆì¹¨ ë‹¤ìŒ ë‚ ì€ ì£¼ë§ì´ì—ˆê³  ë¯¸ìš©ì‹¤ì— ì˜¤ëœë§Œì— ê°€ê¸° ìœ„í•´ ì˜ˆì•½ì„ ì¡ì•„ë‘ì—ˆë‹¤. ìë¦¬ì— ì•‰ìë§ˆì ì±…ì„ í¼ì³ë“¤ì—ˆë‹¤. ê·¸ë¦¬ê³  ë‹¨ìˆ¨ì— ê·¸ ì†Œì„¤ì˜ ì„¸ê³„ì— ëª°ì…í•˜ê²Œ ë˜ì—ˆë‹¤. ë‚´ìš© ì†Œê°œ ê·¸ë˜ë„ ê³µê°œì ì¸ ê³³ì— ì“°ëŠ” ê¸€ì´ë‹ˆë§Œí¼, ì ì–´ë„ ì´ ê¸€ì— ì–´ì©Œë‹¤ ì ‘ê·¼í•˜ê²Œ ëœ ëˆ„êµ°ê°€ë¥¼ ìœ„í•´ ì¤„ê±°ë¦¬ë¥¼ ì ì–´ë‘ì–´ì•¼ í•  ê²ƒ ê°™ë‹¤. ì£¼ì¸ê³µ 'ë‚˜â€™ëŠ” 2017ë…„ í˜„ì¬, ë‚¨í¸ì„ ì‚¬ë³„í•œ ë²ˆì—­ì¼ì„ í•˜ë©´ì„œ ì‚´ì•„ê°€ëŠ” í‰ë²”í•œ ì£¼ë¶€ë‹¤. 1977ë…„ ëŒ€í•™ìƒ ì‹œì ˆ ê¸°ìˆ™ì‚¬ì—ì„œ ì²˜ìŒìœ¼ë¡œ ì¸ì—°ì„ ë§ºì€ 'ì¹œêµ¬â€™ì™€ ëŠì–´ì§ˆë“¯ ëŠì–´ì§€ì§€ ì•ŠëŠ” ê´€ê³„ê°€ ì´ì–´ì§€ê³  ê·¸ 'ì¹œêµ¬â€™ì™€ëŠ” ê·¸ë ‡ê²Œ ì¹œí•˜ì§€ëŠ” ì•Šì§€ë§Œ ê³„ì† ì—°ë½ì„ í•˜ë©° ì§€ë‚¸ë‹¤. ì´ 'ì¹œêµ¬â€™ëŠ” ì†Œì„¤ê°€ë‹¤. ì‘ê°€ê°€ ê¿ˆì´ì—ˆë˜ ì ì€ ì—†ì—ˆì§€ë§Œ ì—¬ëŸ¬ ì§ì—…ì„ ê±°ì³ ì—¬ê¸°ì— ì´ë¥´ë €ë‹¤. ê·¸ë¦¬ê³  ë³¸ê²©ì ì¸ ì´ì•¼ê¸°ëŠ” ê·¸ ì¹œêµ¬ì˜ ì±…ì„ ì½ëŠ” ê²ƒìœ¼ë¡œ ì‹œì‘ëœë‹¤. ì±…ì€ í•¨ê»˜ ê¸°ì–µì„ ê³µìœ í•˜ê³  ìˆëŠ” ëŒ€í•™ìƒ ì‹œì ˆì„ ë°°ê²½ìœ¼ë¡œ í•œë‹¤. ì±…ì˜ êµ¬ì„± í•œ í¸ì˜ ì˜í™”ì™€ ê°™ì€ êµ¬ì„±ì´ì—ˆë‹¤. 1977ë…„ê³¼ 2017ë…„ì„ ì˜¤ê°€ë©° ì´ì•¼ê¸°ê°€ ì§„í–‰ëœë‹¤. ì²˜ìŒì—ëŠ” &quot;í”í•œ êµ¬ì„±&quot;ì´ë¼ê³  ìƒê°í–ˆì§€ë§Œ ì½ì–´ë‚˜ê°€ë‹¤ë³´ë‹ˆ ì‹œê°„ì„ ì˜¤ê°€ì§€ ì•Šìœ¼ë©´ ë¶ˆê°€ëŠ¥í–ˆì„ ì´ì•¼ê¸°ì˜€ë‹¤. '2017ë…„ì˜ ë‚˜â€™ê°€ ìˆì—ˆê¸° ë•Œë¬¸ì— '1977ë…„ì˜ ë‚˜â€™ì˜ ì–´ë¦¬ìˆ™í–ˆë˜ ë¶€ë¶„ì„ ì–´ë¥¸ì˜ ì‹œì ì—ì„œ ëŒì´ì¼œ ë³¼ ìˆ˜ ìˆì—ˆê³ , '1977ë…„ì˜ ë‚˜â€™ê°€ ìˆì—ˆê¸° ë•Œë¬¸ì— ì–´ë ¸ì„ ì‹œì ˆì˜ ë‚˜ì˜ ì‹œì ì—ì„œ ì–´ë¦¬ìˆ™í–ˆì„ ìˆ˜ ë°–ì— ì—†ì—ˆë˜ ì¼ì„ ì„¤ë“ë ¥ìˆê²Œ ì „ë‹¬í•  ìˆ˜ ìˆì—ˆë‹¤. ê·¸ë¦¬ê³  1977ë…„ì€ ì§€ê¸ˆê³¼ëŠ” ë‹¬ë¦¬ ë” ë³´ìˆ˜ì ì¸ ì‹œëŒ€ì˜€ë‹¤. '1977ë…„ì˜ ë‚˜â€™ëŠ” ê·¸ ì‹œëŒ€ë¥¼ 'ì—¬ëŒ€ìƒâ€™ì˜ ì‹œì ì—ì„œ ë¤ë¤í•˜ê²Œ ì´ì•¼ê¸°í•œë‹¤. '2017ë…„ì˜ ë‚˜â€™ì˜€ë‹¤ë©´ ì‹œë‹ˆì»¬í•œ í†¤ì´ ë¬»ì–´ë‚  ìˆ˜ ë°–ì— ì—†ì§€ ì•Šì•˜ì„ê¹Œ? ë§ˆìŒì— ë‹¿ì•˜ë˜ êµ¬ì ˆ íšŒì‚¬ì˜ ê´€ë¡€ì— ë”°ë¼ ì—¬ì„± ê¸°í˜¼ìì—ê²Œ ì£¼ì–´ì§€ëŠ” ê³„ì•½ì§ ì „í™˜ ì„œë¥˜ë¥¼ ë‚´ ì±…ìƒ ìœ„ì— ê°–ë‹¤ ë†“ì€ ê²ƒë„ ê·¸ë…€ì˜€ë‹¤. - p.9 ë§ˆìŒì— ë‹¿ì•˜ë˜ êµ¬ì ˆì´ë¼ê³  í–ˆì§€, ê·¸ êµ¬ì ˆì´ ê°ë™ì ì¼ ê²ƒì´ë¼ëŠ” ì´ì•¼ê¸°ëŠ” í•˜ì§€ ì•Šì•˜ë‹¤ :P â€˜ì •ë§ ì´ë¬ë‹¤ê³ ?â€™ ë¼ëŠ” ë†€ë¼ì›€ ë•Œë¬¸ì— ë°”ë¡œ í˜•ê´‘íœì„ ë“¤ì´ë°€ì—ˆë‹¤. ë‚˜ëŠ” ì´ëŸ° ëŒ€ìš°ê°€ ë‹¹ì—°í–ˆì—ˆë˜ ì‹œì ˆì„ ìƒìƒì¡°ì°¨ í•  ìˆ˜ ì—†ë‹¤. ëŠì–´ì§„ ê±´ ì•„ë‹ˆì§€ë§Œ ë°€ì°©ë  ì¼ë„ ì—†ëŠ”, ê°„ê²©ì´ ë¶ˆê·œì¹™í•œ ì ì„  ê°™ì€ ê´€ê³„ì˜€ë‹¤. - p.11 'ë‚˜â€™ì™€ 'ì¹œêµ¬â€™ì˜ ê´€ê³„ë¥¼ ì´ì•¼ê¸°í•˜ëŠ” ë¬¸ì¥ì´ë‹¤. ëŒ€í•™ì„ ì¡¸ì—…í•˜ê³  ì‚¬íšŒìƒí™œì„ í•˜ëŠ” ì‚¬ëŒë“¤ì´ë¼ë©´ ëˆ„êµ¬ë‚˜ ê³µê°í•  ìˆ˜ ìˆëŠ” ê´€ê³„ì¼ ê²ƒì´ë‹¤. ì–´ë–»ê²Œ ì´ë ‡ê²Œ í‘œí˜„í•  ìˆ˜ ìˆì„ê¹Œ ì‹¶ì–´ì„œ ë°‘ì¤„ì„ ê·¸ì—ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê·¸ë…€ì—ê²ŒëŠ” ì‚¬ëŒì„ ëŒ€í•  ë•Œ ë¯¸ë¬˜í•œ ê¶Œë ¥ê´€ê³„ë¥¼ ë§Œë“œëŠ” ìŠµì„±ì´ ìˆì—ˆë‹¤. ëŠì„ì—†ì´ ìì‹ ì„ ì¤‘ì‹¬ìœ¼ë¡œ ëŒì•„ê°€ëŠ” ê´€ê³„ì˜ ìì¥ì„ ë§Œë“¤ì–´ë‚´ê³  ìš°ì›”ê°ê³¼ í”¼í•´ ì˜ì‹ì„ ë²ˆê°ˆì•„ ì¨ê°€ë©° ê·¸ê²ƒì„ ì •ë‹¹í™”í–ˆë‹¤. ê±°ê¸°ì—ëŠ” ì¦ì¸ì´ í•„ìš”í–ˆë‹¤. ê²°êµ­ ë‚˜ë¡œ í•˜ì—¬ê¸ˆ ìœ„ì„±ì²˜ëŸ¼ ê·¸ë…€ì˜ ê¶¤ë„ë¥¼ ë”°ë¼ ëŒë©° ê·¸ë…€ë¼ëŠ” ì¼ë°©ì ì´ê³  ë³€ë•ìŠ¤ëŸ¬ìš´ ê´‘ì›ì„ ë°˜ì‚¬í•˜ë„ë¡ ë§Œë“¤ì–´ ë²„ë¦¬ëŠ” ê²ƒì´ë‹¤. ë‚˜ëŠ” ë‚˜ëŒ€ë¡œ ì†Œì‹¬í•¨ê³¼ ìê¸° í•©ë¦¬í™”ì˜ ì¡°í•©ì¸ ì–´ì •ì©¡í•œ ì˜¨ê²€í•¨ ë’¤ì— ìˆ¨ì–´ ê·¸ë…€ì˜ ê·¸ëŸ° íƒœë„ë¥¼ ìˆœìˆœíˆ ë°›ì•„ë“¤ì´ê³¤ í–ˆë‹¤. ì—´ì •ì€ ë‹¨í˜¸í•œ êµ¬ì„ì´ ìˆì–´ì„œ ê¸ˆì„¸ êº¾ì´ì§€ë§Œ ì¹œê·¼í•¨ì€ ì–´ëŠ ì •ë„ ì•ˆì´í•œ ê°ì •ì´ë¼ì„œ ì‚¬ì†Œí•œ ê¸°ì–µì˜ ê³µìœ ë§Œìœ¼ë¡œë„ ì‰½ê²Œ í™˜ê¸°ë˜ì—ˆë‹¤. - p.12 'ë‚˜â€™ì™€ 'ì¹œêµ¬â€™ì˜ ê´€ê³„ë¥¼ ë¬˜ì‚¬í•œ ë‚´ìš©ì´ë‹¤. ë‘˜ ì‚¬ì´ì˜ ë¯¸ë¬˜í•œ ê¶Œë ¥ê´€ê³„ì™€ ê·¸ ì†ì—ì„œ ìš°ì›”ê°ì„ ëŠë¼ëŠ” ì¹œêµ¬, ê·¸ë¦¬ê³  ê·¸ ê²ƒì´ ëŠê»´ì§€ì§€ë§Œ í¬ê²Œ ë™ìš”í•˜ì§€ ì•Šê³  ìˆœì¢…ì ì¸ 'ë‚˜â€™ì˜ ëª¨ìŠµì´ ì°¸ìœ¼ë¡œ ì„¸ë ¨ë˜ê²Œ í‘œí˜„ë˜ì—ˆë‹¤. &quot;ìì‹ ì„ ì¤‘ì‹¬ìœ¼ë¡œ ëŒì•„ê°€ëŠ” ê´€ê³„ì˜ ìì¥&quot;ê³¼ â€œì†Œì‹¬í•¨ê³¼ ìê¸° í•©ë¦¬í™”ì˜ ì¡°í•©ì¸ ì–´ì •ì©¡í•œ ì˜¨ê±´í•¨â€. ë¶€ë¶„ì ìœ¼ë¡œë‚˜ë§ˆ ëª¨ë²”ìƒ í‰ë‚´ë¥¼ ë‚´ì„œ ê·¸ ì‹œìŠ¤í…œì— ìˆœì¢…í–ˆê³  ê·¸ ëŒ€ê°€ë¡œ ì„œìš¸ì˜ í•œ ì—¬ìëŒ€í•™ì— í•©ê²©í•˜ì—¬ ê³ í–¥ê³¼ ë¶€ëª¨ë¡œë¶€í„° ë²—ì–´ë‚  ìˆ˜ ìˆì—ˆë‹¤. - p.27 ì •ë§ ë‚˜ì˜ ì´ì•¼ê¸°ì˜€ë‹¤. ê³ ë“±í•™ìƒ ì‹œì ˆì˜ ë‚˜ë„ ì´ ì±…ì˜ í™”ìì²˜ëŸ¼ ì†Œì‹¬í–ˆë‹¤. ì‹œìŠ¤í…œì„ ê±°ìŠ¤ë¥¼ í˜ê³¼ ë°°ì§±ì´ ì—†ì—ˆê¸° ë•Œë¬¸ì— ê·¸ ì•ˆì—ì„œ ë‚´ê°€ í•  ìˆ˜ ìˆëŠ” ìµœëŒ€í•œì˜ ë°˜í•­ì„ í–ˆë‹¤. ê·¸ ê³³ì—ì„œ ë²—ì–´ë‚˜ê³  ì‹œìŠ¤í…œì„ ë°”ê¿€ í˜ì„ ê°–ê¸° ìœ„í•´ ì¢‹ì€ ëŒ€í•™ì„ ê°€ëŠ” ê²ƒ. ë¶„ëª… ì´ ê²ƒì€ 1977ë…„ì˜ ë¬¸ì¥ì¼í…ë°, ì–´ì§¸ì„œ 2010ë…„ì—ë„ ë˜‘ê°™ì€ ëª¨ìŠµì´ì—ˆë˜ê±¸ê¹Œ. ê·¸ ë•Œê¹Œì§€ ë‹¤ë¦„ì´ë€ ê±¸ ì „í˜€ ê²ªì–´ë³´ì§€ ëª»í–ˆëƒê³  ë¬»ëŠ”ë‹¤ë©´ ê·¸ë ‡ì§€ëŠ” ì•Šë‹¤. 12ë…„ê°„ì´ë‚˜ ì¤‘ë‹¨ ì—†ì´ ì§€ê¸‹ì§€ê¸‹í–ˆë˜ ì´ˆì¤‘ë“±í•™êµ ìƒí™œ ì†ì—ì„œë„ íƒ€ì¸ê³¼ ë¶€ë”ªí ê¸°íšŒëŠ” ì–¼ë§ˆë“ ì§€ ìˆì—ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë‚´ê°€ ê·¸ ì‹œì ˆ ê²ªì—†ë˜ ê²ƒì€ ë‹¤ë¦„ì´ë¼ê¸°ë³´ë‹¤ ìˆ˜ì§ì ì¸ ìœ„ê³„ì™€ ì‹œë¹„ì˜€ë‹¤. ê·¸ë•Œê·¸ë•Œ ì ìš©ë˜ëŠ” ì¼ê´€ì„± ì—†ëŠ” ê·œìœ¨ì´ ìˆì—ˆê³ , ì—†ìœ¼ë©´ êµì‚¬ë‚˜ ë°˜ì¥ì´ë‚˜ í˜ì„¼ ì• ë“¤ì´ ë§Œë“¤ì—ˆë‹¤. ë‚¨ê³¼ ë‹¤ë¥¸ ê²ƒì´ ê·¸ëŒ€ë¡œ ê²°ê²©ì‚¬ìœ ê°€ ë˜ëŠ” ë‹¨ì²´ ìƒí™œì—ì„œ ë‚´ê°€ ëˆ„êµ°ì§€ ë”°ìœ„ë¥¼ ê³ ë¯¼í•  ê¸°íšŒëŠ” ì•„ë¬´ì—ê²Œë„ ì£¼ì–´ì§€ì§€ ì•Šì•˜ë‹¤. -p. 27 ì´ í˜ì´ì§€ ì†ì˜ ë§ì€ ë¬¸ì¥ì—ì„œ ë¨¸ë¬¼ë €ë‹¤. ë‚˜ë„ ì±…ì˜ ì£¼ì¸ê³µì²˜ëŸ¼ ê³ ë“±í•™êµë¥¼ íƒˆì¶œí•˜ê³  ëŒ€í•™êµì— í•©ê²©ì„ í•˜ìë§ˆì ê¸°ìˆ™ì‚¬ ìƒí™œì„ í–ˆë‹¤. 6ëª…ì´ì„œ í•¨ê»˜ ì‚¬ëŠ” ë°©ì´ì—ˆê³  í•œ ë°©ì€ ë‘ ëª…ì´ í•¨ê»˜ ì¼ë‹¤. í•©ê²©ê³¼ ì…í•™ì´ë¼ëŠ” ë“¤ëœ¬ ë§ˆìŒë„ ì ì‹œ, ë‚˜ì™€ â€˜ë‹¤ë¥¸â€™ ëˆ„êµ°ê°€ì™€ ì‹œê°„ê³¼ ì¥ì†Œë¥¼ ê³µìœ í•˜ëŠ” ê²ƒì˜ ì–´ë ¤ì›€ì´ í¬ê²Œ ë‹¤ê°€ì™”ì—ˆë‹¤. ê·¸ ë•ŒëŠ” ì´ìœ ë¥¼ ëª°ëì§€ë§Œ ì—¬ê¸°ì— ì„œìˆ ëœ ê²ƒì²˜ëŸ¼, ë‚´ê°€ ê³ ë“±í•™êµ ì‹œì ˆê¹Œì§€ ê²½í—˜í–ˆë˜ ì‚¶ ì†ì—ì„œ ì§„ì •í•œ 'ë‹¤ë¦„â€™ì— ëŒ€í•´ ì´í•´í•˜ëŠ” ì‹œê°„ì€ ì „í˜€ ì—†ì—ˆê¸° ë•Œë¬¸ì´ì—ˆë˜ ê²ƒì€ ì•„ë‹ˆì—ˆì„ê¹Œ. í˜¼ìë¼ëŠ” ê±´ ì–´ë–¤ ê³µê°„ì„ í˜¼ì ì°¨ì§€í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼ íƒ€ì¸ì˜ ì‹œì„ ì—ì„œ ë²—ì–´ë‚˜ ìµëª…ìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ì‹œê°„ì„ ëœ»í•˜ëŠ” ê±°ì˜€ë‹¤. -p. 84 ë‹¨ í•œ ë²ˆë„ í˜¼ì ë³´ë‚´ëŠ” ì‹œê°„ì„ ì´ë ‡ê²Œ ì •ì˜í•´ë³´ì§€ ì•Šì•˜ì—ˆë‹¤. ì‚¬ëŒë“¤ ì†ì— ìˆìœ¼ë©´ì„œë„ í˜¼ìë¼ê³  ëŠë¼ëŠ” ì´ìœ ëŠ” ê·¸ ë“¤ì—ê²Œ ë‚œ ì² ì €íˆ 'ìµëª…â€™ì˜ ëˆ„êµ°ê°€ì´ê¸° ë•Œë¬¸ì´ë‹¤. ì´ ê¸€ì„ ì½ì€ ì´í›„, ì§€í•˜ì² ì— ìˆì„ ë•Œë§ˆë‹¤ ê´œíˆ í”¼ì‹ë˜ê²Œ ëœë‹¤. ë‚˜ëŠ” ë‚´ ì•ì˜ ë¬¸ì„ ì—´ì§€ ëª»í•˜ê³  ë²ˆë²ˆì´ ê³¼ê±°ì˜ ë‚˜ë¡œ êµ´ëŸ¬ë–¨ì–´ì§€ê³¤ í–ˆë‹¤. -p. 86 ì™œ ìê¾¸ ë‚˜ì˜ ëŒ€í•™ìƒí™œì´ ë– ì˜¤ë¥´ëŠ” ê²ƒì¼ê¹Œ. 1977ë…„ì´ë“ , 2011ë…„ì´ë“  ì²­ì¶˜ì˜ ê³ ë¯¼ì€ ë¹„ìŠ·í–ˆë‹¤. ê·¸ë¦¬ê³  ì—¬ê¸°ì— ì ì§„ ì•Šì•˜ì§€ë§Œ í–‰ë³µì˜ ìˆœê°„ë„ ë¹„ìŠ·í–ˆë‹¤. ì‚¬ëŒì„ ë‘˜ëŸ¬ì‹¼ ì •ì¹˜ì , ì‚¬íšŒì , ê²½ì œì , ê¸°ìˆ ì  ìƒí™©ì€ ë„ˆë¬´ë‚˜ë„ ë‹¬ë¼ì¡Œì§€ë§Œ ì‚¬ëŒì€ ê²°êµ­ ë˜‘ê°™ì•˜ë‹¤. ë‚˜ë¥¼ í–‰ë³µí•˜ê²Œ ë§Œë“œëŠ” ì„ íƒê³¼ í–‰ë³µì„ ëŠë¼ëŠ” ë°©ë²•ë§Œ ë‹¬ë¼ì¡Œë‹¤. ì²«ì¸ìƒ ì—­ì‹œ ë‘ë²ˆì§¸ì™€ í¬ê²Œ ë‹¤ë¥´ì§€ ì•Šì•˜ë‹¤. -p. 287 ì´ ë¬¸ì¥ì€ ë°˜ë“œì‹œ ë‘ë²ˆ ì½ì–´ì•¼ í•œë‹¤. ë¬´ì‹¬ê²°ì— ë„˜ê¸°ë©´ í‰ë²”í•œ ë¬¸ì¥ì´ì§€ë§Œ ì „í˜€ ê·¸ë ‡ì§€ ì•Šë‹¤. ì–´ë–»ê²Œ ì²«ì¸ìƒì´ ë‘ë²ˆì§¸ ì¸ìƒ ì´í›„ì— ëŠê»´ì§ˆ ìˆ˜ ìˆë‹¨ ë§ì¸ê°€?! ì´ ë¬¸ì¥ì€ ì²«ë²ˆì§¸ ë§Œë‚¨ì„ ê¸°ì–µí•˜ì§€ ëª»í•œ ì±„ë¡œ ë‘ë²ˆì§¸ ë§Œë‚¨ì„ ì²«ë²ˆì§¸ë¼ê³  ìƒê°í–ˆê¸° ë•Œë¬¸ì— ê°€ëŠ¥í–ˆë‹¤. ì‘ê°€ë‹˜ì˜ ì¬ì¹˜ì— ë¹µ- í„°ì¡Œë‹¤. ê°œì¸ì ì¸ ê°ìƒ ì‘ê°€ë‹˜ì˜ ë¬¸ì²´ì™€ ì‚¶ì—ì„œ ëŠë¼ëŠ” ê°ê°ì— ëª¨ë‘ ê³µëª…í•  ìˆ˜ ìˆì—ˆë‹¤. ë‚´ê°€ ëŠê¼ˆë˜ &quot;ê·¸ ê°ì •&quot;ì„ ê±°ë¶€ê°ì—†ì´ ì¬ì¹˜ìˆê³  í•œí¸ìœ¼ë¡œëŠ” ë‚ ì¹´ë¡œìš´ ë¬¸ì¥ìœ¼ë¡œ êµ°ë”ë”ê¸° ì—†ì´ í‘œí˜„í•œë‹¤. êµ°ë”ë”ê¸° ì—†ìŒì€ ìì¹«í•˜ë©´ 82ë…„ìƒ ê¹€ì§€ì˜ì²˜ëŸ¼ ì–´ë–¤ ë©”ì‹œì§€ë¥¼ í’ˆì„ ìˆ˜ ìˆëŠ” ë°°ê²½ì˜ ì†Œì„¤ì„ ë‹´ë°±í•˜ê²Œ ë§Œë“ ë‹¤. ì±…ì„ ì½ìœ¼ë©´ì„œ ë‚˜ëŠ” 1977ë…„ì„ ê´€ì°°í•˜ê³  ìˆì§€ ì•Šì•˜ë‹¤. ê·¸ ì‹œëŒ€ ì†ì— ë¨¸ë¬¼ëŸ¬ ìˆìœ¼ë©° ì†Œì„¤ ì†ì˜ &quot;ë‚˜&quot;ê°€ ê²ªì–´ë‚˜ê°€ëŠ” ê°ì •ì— ê³µê°í•˜ê¸° ìœ„í•´ ì‹œëŒ€ì  ë°°ê²½ì„ ì´í•´í•˜ë ¤ê³  í–ˆë‹¤. ë‚´ê°€ 77ë…„ëŒ€ì— ë¶€ìë¡œ ì‚´ì•˜ë”ë¼ë©´, ë˜‘ë˜‘í•œ ë‚¨ìì˜€ë‹¤ë©´, ë˜‘ë˜‘í•œ ì—¬ìì˜€ë‹¤ë©´, ì†Œì‹¬í•œ ë‚¨ìì˜€ë‹¤ë©´, ì ê·¹ì ì¸ ì—¬ìì˜€ë‹¤ë©´ ì–´ë• ì„ê¹Œ. ë‚˜ì˜ ê¸°ì§ˆê³¼ ë‚˜ì˜ ì£¼ì–´ì§„ í™˜ê²½ì— ì˜í•´ 2020ë…„, ì§€ê¸ˆì˜ ë‚˜ì™€ ë‹¤ë¥¸ ëª¨ìŠµì´ì—ˆê² ì§€. ì±… ì†ì—ì„œ ì‚¬íšŒê°€ ë‚¨ìì—ê²Œ ë¶€ì—¬í•˜ëŠ” ëª¨ìŠµì€ ëŠ¥ë ¥ìˆê³  ê°€ì¡±ì„ ì±…ì„ì§€ê³  ì´ëŒì–´ë‚˜ê°€ëŠ” ê°€ë¶€ì¥ì ì¸ ê²ƒì´ì—ˆë‹¤. ë°˜ëŒ€ë¡œ ì—¬ì„±ì€ ìì›ì´ ë¶€ì¡±í•˜ë‹¤ë©´ ì–¸ì œë“  ê°€ì¥ ë¨¼ì € í¬ê¸°ë¥¼ ê°•ìš”ë°›ì€ ëŒ€ìƒì´ì—ˆê³  ë‚¨ìì˜ ë‚´ì¡°ë¥¼ ìœ„í•œ ëª¨ìŠµì„ ìš”êµ¬ë°›ì•˜ë‹¤. ë¶ˆí˜„ë“¯ ë³´ìˆ˜ì ì¸ í• ë¨¸ë‹ˆì™€ ë³´ìˆ˜ì ì¸ ì§‘ì•ˆì—ì„œ ê°€ì¡±ì˜ ê¸°ëŒ€ë¥¼ í•œëª¸ì— ë°›ì•˜ë˜ ì•„ë²„ì§€ê°€, ê·¸ë¦¬ê³  ì´ ë³´ìˆ˜ì ì¸ ì§‘ì•ˆìœ¼ë¡œ ì‹œì§‘ì™€ì„œ ë§ì€ ê²ƒì„ í¬ê¸°í–ˆë˜ ì–´ë¨¸ë‹ˆê°€ ë– ì˜¬ëë‹¤. ë…¼ë¬¸ê³¼ëŠ” ë‹¤ë¥´ê²Œ ì†Œì„¤ì€ &quot;ê·¸ë˜ì„œ ì•ìœ¼ë¡œ ë¬´ì—‡ì„ í•˜ë©´ ì¢‹ì„ê¹Œ?&quot;ì— ëŒ€í•œ ìƒê°ì„ ë‚¨ê¸°ê¸°ë³´ë‹¤ëŠ” ë‚´ê°€ ê²½í—˜í–ˆì§€ë§Œ ì˜ì‹í•˜ì§€ ì•Šì•˜ë˜ íšŒìƒ‰ ì§€ëŒ€ ì†ì˜ ê°ì •ê³¼ ê¸°ì–µì„ ì¬êµ¬ì„±í•˜ê³  ìƒˆë¡­ê²Œ ì˜ë¯¸ë¥¼ ë¶™ì—¬ì¤€ë‹¤. ê·¸ë˜ì„œ ê³¼ê±° ì†ìœ¼ë¡œ íƒí—˜í•˜ëŠ” ê¸°ë¶„ì´ ë“¤ì—ˆê³  íŠ¹íˆë‚˜ ëŒ€í•™ìƒ ì‹œì ˆì´ ë§ì´ ë– ì˜¬ëë‹¤. 2020ë…„ì€ ë‚´ê°€ í•œêµ­ë‚˜ì´ë¡œ 30ëŒ€ê°€ ëœ í•´ì´ê¸°ë„ í•˜ë‹¤. ê°œì¸ì ìœ¼ë¡œëŠ” 20ëŒ€ì˜ ë‚˜ë¥¼ ëŒì´ì¼œë³´ê¸°ì— ë„ˆë¬´ë‚˜ë„ ì¢‹ì•˜ë˜ ì±…ì´ì—ˆë‹¤. ê·¸ ë•Œ ë¬´ì—‡ì„ ì–´ë–»ê²Œ í•´ì•¼í• ì§€ ëª°ëë˜, ë‚˜ë§Œì˜ ë‹¤ë¦„ì€ ì¸ì§€í•˜ì§€ ëª»í•˜ê³  ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì´ ë‘ë µê¸°ë§Œ í–ˆë˜ ë‚´ê°€ ì§€ê¸ˆì€ ì´ë ‡ê²Œ ë‹¬ë¼ì¡Œêµ¬ë‚˜. ì§œì‹ ë§ì´ ì»¸êµ¬ë‚˜. ìˆ˜ê³ í–ˆë‹¤.","link":"/2020/01/07/The-past-of-the-light-by-Eun-hee-kyung/"},{"title":"With Little Power Comes Great Responsibility","text":"ìš”ì¦˜ ë“±ì¥í•˜ëŠ” NLP model í˜ì´í¼ë“¤ì€ ì£¼ë¡œ GLUE ë²¤ì¹˜ë§ˆí¬ì— ì„±ëŠ¥ì„ report í•˜ë©´ì„œ ì•„ì£¼ ë¯¸ì„¸í•œ ì„±ëŠ¥ ê°œì„ ì„ ê·¼ê±°ë¡œ &quot;ìš°ë¦¬ ë°©ë²•ë¡ ì€ íš¨ê³¼ì ì´ì—ˆë‹¤!&quot;ë¥¼ ì£¼ì¥í•˜ê³  ìˆë‹¤. ê³¼ì—° ì´ ê²°ê³¼ê°€ ì‹¤ì œë¡œ ê·¸ ëª¨ë¸ì´ ë” ë‚˜ì€ ëª¨ë¸ì„ì„ ì£¼ì¥í•  ìˆ˜ ìˆì„ë§Œí¼ ê·¼ê±°ê°€ íƒ„íƒ„í• ê¹Œ? ì´ë²ˆì— ì†Œê°œí•˜ëŠ” ë…¼ë¬¸ì—ì„œëŠ” NLP researchì—ì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ ê°œì„ ì„ ì£¼ì¥í•˜ëŠ” ì‹¤í—˜ ê²°ê³¼ì— ëŒ€í•´ ê·¸ ê²°ê³¼ê°€ &quot;ì •ë§ ìœ ì˜ë¯¸í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ ê°œì„ ì„ ë³´ì¥í•  ìˆ˜ ìˆëŠ”ê°€?&quot;ì— ëŒ€í•´ ë¶„ì„í•œë‹¤. ë”ë¶ˆì–´, ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•´ ë°œê²¬ëœ ë¬¸ì œì ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ overview ê¹Œì§€ ì œì•ˆí•˜ê³  ìˆë‹¤. TMI ì°¸ê³ ë¡œ ì´ ë…¼ë¬¸ì˜ ì œëª©ì€ Spidermanì˜ ìœ ëª…í•œ ëŒ€ì‚¬ì—ì„œ ìœ ë˜í–ˆë‹¤. ì œëª©ì—ì„œë¶€í„° ëŠê»´ì§€ëŠ” í˜„ ì‹œëŒ€ì˜ NLP model evaluationì— ëŒ€í•œ ê°•í•œ ë¶€ì •ì ì¸ ë‰˜ì–‘ìŠ¤ëŠ” ë…¼ë¬¸ì˜ êµì‹ ì €ìê°€ Dan Jurafsky ì´ê¸°ì— ê°€ëŠ¥í•˜ì§€ ì•Šì•˜ì„ê¹Œ ì‹¶ë‹¤. Introduction ë³¸ê²©ì ì¸ ë¶„ì„ ë°©ë²•ë¡  ì†Œê°œì— ì•ì„œ ì•ìœ¼ë¡œ ë“±ì¥í•˜ê²Œ ë  ìš©ì–´ì— ëŒ€í•´ ê°„ë‹¨í•˜ê²Œ ì§šê³  ë„˜ì–´ê°€ë ¤ê³  í•œë‹¤. Power Power ë€, ìƒ˜í”Œ ë°ì´í„°ì—ì„œ ê´€ì¸¡í•œ ê²°ê³¼ê°€ true distribution ë°ì´í„°ì— ëŒ€í•´ì„œë„ ì ìš©ë  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•œ í™•ë¥ ë¡œ, &quot;í†µê³„ì  ìœ ì˜ë¯¸í•¨&quot;ê³¼ëŠ” ê´€ë ¨ì€ ìˆìœ¼ë‚˜, ë‹¤ë¥¸ metricì´ë‹¤. ë’¤ì—ì„œ ì–¸ê¸‰í•˜ê² ì§€ë§Œ, PowerëŠ” r ë²ˆì˜ ë°˜ë³µìˆ˜í–‰ ë™ì•ˆ í†µê³„ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ê°€ ëª‡ë²ˆ ë“±ì¥í–ˆëŠ”ê°€ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¸¡ì •ëœë‹¤. Type-S error sign ì— ëŒ€í•œ ì—ëŸ¬. ì‰¬ìš´ ì˜ˆë¥¼ ë“¤ë©´, ì‹¤ì œë¡œ ëª¨ë¸ Aê°€ ëª¨ë¸ Bì— ë¹„í•´ ì„±ëŠ¥ì´ ì¢‹ì€ë° ì‹¤í—˜ ê²°ê³¼ëŠ” ë°˜ëŒ€ë¡œ ë‚˜ì˜¤ëŠ” ê²½ìš°ì— í•´ë‹¹í•œë‹¤. Type-M error Magnitudeì— ëŒ€í•œ ì—ëŸ¬. ì˜ˆë¥¼ ë“¤ì–´, ì‹¤ì œ ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì˜ ì°¨ì´ê°€ ì ì€ë° ê´€ì¸¡ëœ ê²°ê³¼ì— ë”°ë¥´ë©´ ì˜ˆì¸¡ê°’ì˜ ì°¨ì´ê°€ í° ê²½ìš°ì— í•´ë‹¹í•œë‹¤. MDE (minimum detectable effect) size ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ ì°¨ì´(effect)ë¥¼ ë³´ì¥í•  ìˆ˜ ìˆëŠ” ìµœì†Œ ë°ì´í„° ì‚¬ì´ì¦ˆ. ì´ ë…¼ë¬¸ì—ì„œ ìœ ì˜ë¯¸í•œ effectëŠ” 80% Powerë¥¼ ì˜ë¯¸í•œë‹¤. ë§Œì•½ í…ŒìŠ¤íŠ¸ì…‹ì˜ ì‚¬ì´ì¦ˆê°€ ì‘ìœ¼ë©´ MDEëŠ” ì»¤ì§„ë‹¤. ì´ ìš©ì–´ë“¤ì„ í™œìš©í•´ì„œ ë‹¤ì‹œ ë³¸ ë…¼ë¬¸ì˜ contributionì„ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. NLP ì»¤ë®¤ë‹ˆí‹°ì—ì„œì˜ ì‹¤í—˜ ê²°ê³¼ì— ëŒ€í•œ Powerë¥¼ ê³ ë ¤í•˜ì§€ ì•ŠëŠ” ì‹¤í—˜ ì„¸íŒ…ê³¼ ê²°ê³¼ report ë•Œë¬¸ì— statistical noiseì™€ ìœ ì˜ë¯¸í•œ ëª¨ë¸ì˜ ì„±ëŠ¥ í–¥ìƒì„ êµ¬ë¶„í•˜ê¸° ì–´ë µë‹¤. Underpowered resultëŠ” ì‹¤í—˜ ê²°ê³¼ë¥¼ ê³¼ì¥í•˜ê±°ë‚˜, ì‹¤ì œ íš¨ê³¼ë¥¼ ë°˜ëŒ€ë¡œ í•´ì„í•  ìˆ˜ ìˆëŠ” ì—¬ì§€ê°€ ìˆë‹¤. ë„ˆë¬´ ì ì€ ìƒ˜í”Œì— ëŒ€í•´ì„œëŠ” ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ íŒë‹¨í•˜ê¸° ì–´ë µê³ , ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì´ëŠ” ê²½ìš°ì´ë”ë¼ë„ ìƒ˜í”Œ ìˆ˜ê°€ ì ì„ìˆ˜ë¡ ê·¸ íš¨ê³¼ë¥¼ ê³¼ì¥í•´ì„œ í‰ê°€í•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ëª¨ë¸ì„ í‰ê°€í•  ë•Œì— ì£¼ì–´ì§„ ì¡°ê±´ë“¤ - í…ŒìŠ¤íŠ¸ì…‹ì˜ í¬ê¸°, í‰ê°€ì ì¸ì›ìˆ˜ ë“± - ì— ëŒ€í•´ ê²°ê³¼ê°€ ìœ ì˜ë¯¸í•¨ì„ ë³´ì¥í•˜ëŠ”ì§€ ìƒê°í•´ ë³¼ í•„ìš”ê°€ ìˆë‹¤. ì´ë¥¼ ìœ„í•´ ê¸°ì¡´ì˜ í‰ê°€ frameworkì— ëŒ€í•œ Power Analysis ê°€ í•„ìš”í•˜ê³ , ë™ì‹œì— ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ ê°œì„ ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆëŠ” ì¡°ê±´ì— ëŒ€í•´ì„œë„ ë…¼ì˜ë  í•„ìš”ê°€ ìˆë‹¤. ë¨¼ì €, NLP ì—ì„œì˜ Power Analysisì— ëŒ€í•´ ì•Œì•„ë³´ì. Power Analysis for NLP NLPì˜ taskì˜ í‰ê°€ formatì€ ê·¸ë™ì•ˆ ë‹¤ë¥¸ ê³¼í•™ì  ë°©ë²•ë¡ ì—ì„œ ì ìš©ë˜ëŠ” Power Analysisë¥¼ ìˆ˜í–‰í•˜ê¸°ì— ì í•©í•˜ì§€ ì•Šë‹¤. NLP í‰ê°€ì˜ ëª¨ë“  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì»¤ë²„í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì— ì €ìë“¤ì€ ìµœëŒ€í•œ ì¼ë°˜í™” ê°€ëŠ¥í•œ simluation ê¸°ë°˜ì˜ power analysisë¥¼ ì œì•ˆí•œë‹¤. ì €ìë“¤ì´ ì œì•ˆí•˜ëŠ” Power Analysis ì•Œê³ ë¦¬ì¦˜ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. Simulationì„ í•˜ê¸° ìœ„í•´ì„œëŠ” íŠ¹ì • parameterë“¤ì´ ìš”êµ¬ëœë‹¤. ì €ìë“¤ì€ ì´ 6ê°œì˜ parameterë¥¼ ì œì•ˆí•˜ê³  ê°ê°ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. \\(n\\): í‰ê°€ì— ì‚¬ìš©ë˜ëŠ” ë°ì´í„°ì˜ ê°œìˆ˜ \\(e*\\): ê´€ì‹¬ìˆëŠ” í‰ê°€ ìˆ˜ì¹˜ (e.g., \\(\\Delta_{acc}\\) ë“±) \\(h\\): ê´€ë ¨ìˆëŠ” ë‹¤ë¥¸ ìˆ˜ì¹˜ (e.g., variance ë“±) \\(T\\): ìœ ì˜ë¯¸ì„±ì„ íŒë‹¨í•  ìˆ˜ ìˆëŠ” statistical test \\(\\alpha\\): ìœ ì˜ë¯¸ì„±ì„ íŒë‹¨í•  ìˆ˜ ìˆëŠ” threshold \\(r\\): ë°˜ë³µ ìˆ˜í–‰ íšŸìˆ˜ ì•Œê³ ë¦¬ì¦˜ì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•˜ë©´, ì´ rë²ˆì˜ ì‹¤í—˜ì— ëŒ€í•´ n ê°œì˜ ë°ì´í„°ì— ëŒ€í•œ í‰ê°€ ê²°ê³¼ë¥¼ ìƒì„±í•˜ê³  ì´ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ significance testë¥¼ ìˆ˜í–‰í•´ì„œ p-value ë¥¼ ì–»ëŠ”ë‹¤. ìµœì¢…ì ìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ê²°ê³¼ (p-valueê°€ íŠ¹ì • threshold ì´í•˜ì¸ ê²½ìš°)ì˜ íšŸìˆ˜ê°€ rë²ˆ ì¤‘ ëª‡ë²ˆì¸ì§€ë¥¼ ë°”íƒ•ìœ¼ë¡œ power ë¥¼ ê³„ì‚°í•œë‹¤. ì•„ë˜ëŠ” ìœ„ ì•Œê³ ë¦¬ì¦˜ì„ ë°”íƒ•ìœ¼ë¡œ power analysisë¥¼ ìˆ˜í–‰í•œ ì˜ˆì‹œì´ë‹¤. ì œì¼ ì™¼ìª½ì˜ ì´ë¯¸ì§€ëŠ” ì‹¤ì œ ì •ë‹µìœ¼ë¡œ, Bëª¨ë¸ì´ Aëª¨ë¸ì— ë¹„í•´ 65% ì •ë„ ì„ í˜¸ë˜ëŠ” ê²ƒì„ ë‚˜íƒ€ë‚¸ë‹¤. ë‘ ëª¨ë¸ì˜ ì„ í˜¸ë„ê°€ ê°™ìŒ(50%)ì„ ê¸°ì¤€ìœ¼ë¡œ ì•½ 15% ì •ë„ ë” ì„ í˜¸ëœë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. ê°€ìš´ë° ì´ë¯¸ì§€ëŠ” \\(r\\)=10, \\(n\\)=100ì¸ ê´€ì¸¡ ê²°ê³¼ì´ë‹¤. ìƒ˜í”Œ ìˆ˜ê°€ ë§ê¸° ë•Œë¬¸ì— 10ë²ˆì˜ trial ì¤‘, ìœ ì˜ë¯¸í•˜ê²Œ Bëª¨ë¸ì´ Aëª¨ë¸ë³´ë‹¤ ì„ í˜¸ë˜ëŠ” ê²½ìš°ê°€ 8ë²ˆìœ¼ë¡œ powerëŠ” 80%ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ë°˜ë©´ ìƒ˜í”Œ ìˆ˜ê°€ ì ì€ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ëŠ” ìœ ì˜ë¯¸í•œ trialì€ 3ë²ˆìœ¼ë¡œ powerëŠ” 30%ë¼ê³  íŒë‹¨ëœë‹¤. ë˜í•œ ìƒ˜í”Œ ìˆ˜ê°€ ë§ì€ ê²½ìš°ì— ìœ ì˜ë¯¸í•œ ê²°ê³¼ì˜ í‰ê· (B ëª¨ë¸ì´ ì„ í˜¸ë˜ëŠ” ì •ë„)ê³¼ null hypothesis(50%)ì˜ ì°¨ì´ê°€ ì‹¤ì œ ë¶„í¬ì˜ ì°¨ì´ì™€ ìœ ì‚¬í•˜ë‹¤ (íŒŒë€ìƒ‰ ë¼ì¸ê³¼ ê²€ì€ìƒ‰ ë¼ì¸ì˜ ì°¨ì´). ìƒ˜í”Œ ìˆ˜ê°€ ì ì€ ê²½ìš°, ê·¸ ì°¨ì´ê°€ ê³¼ì¥ëœë‹¤ (Type-M error). ì´ì œ ìœ„ì˜ Power Analysisê°€ ì—¬ëŸ¬ NLP í‰ê°€ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì–´ë–»ê²Œ ìˆ˜í–‰ë˜ëŠ”ì§€ì— ëŒ€í•œ ì˜ˆì‹œë¥¼ ë³´ì—¬ì¤€ë‹¤. í¬ê²Œ classfication taskì™€ generation task, ê·¸ë¦¬ê³  human evaluation ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë³´ì—¬ì£¼ëŠ”ë°, ì´ ê¸€ì—ì„œëŠ” ê·¸ ì¤‘ classification taskì™€ human evaluationì— ëŒ€í•´ì„œ ì¤‘ì ì ìœ¼ë¡œ ë‹¤ë¤„ë³´ê³ ì í•œë‹¤. Classification Task Classification Taskë¥¼ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ë“¤ì˜ Accuracy ì°¨ì´ê°€ ìœ ì˜ë¯¸í•œì§€ë¥¼ íŒë‹¨í•œë‹¤. ìœ„ì˜ Power Analysis ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ê¸° ìœ„í•´ì„œ í•„ìš”í•œ parameterë¥¼ ì†Œê°œí•œë‹¤. \\(n\\): 100, 500, â€¦ \\(T\\) (Significance test) classification ê²°ê³¼ì˜ ìœ ì˜ë¯¸ì„±ì„ í™•ì¸í•˜ëŠ” statistical testë¡œ ê°€ì¥ ë§ì´ ì“°ì´ê³  ìˆëŠ” ê²ƒì€ McNemarâ€™s testë¡œ ëª¨ë¸ ê°„ì˜ ë¶ˆì¼ì¹˜í•˜ëŠ” ì •ë„ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‘ ëª¨ë¸ì˜ ì°¨ì´ì— ëŒ€í•œ ìœ ì˜ì„±ì„ ê²€ì¦í•œë‹¤. \\[\\chi^2 = \\frac{(p_{10} - p_{01})^2}{p_{10} + p_{01}}\\] \\(e*\\) (ê´€ì‹¬ìˆëŠ” í‰ê°€ ìˆ˜ì¹˜) ëª¨ë¸ì˜ accuracy ì°¨ì´ (\\(\\Delta_{acc}\\))ì™€ ë‘ ëª¨ë¸ì´ ê°™ì€ ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•  í™•ë¥  (\\(P_a\\)) ì„ ì œì•ˆí•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ëª¨ë¸ Aê°€ baselineê³¼ ë¹„êµí–ˆì„ ë•Œ 0.02 ë§Œí¼ì˜ accuracy ì°¨ì´ë¥¼ ë³´ì´ê³ , 90%ì˜ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì¼ì¹˜í•œë‹¤ê³  í•˜ì. ì´ëŠ” ë‹¤ì‹œ ë§í•´ 10%ì˜ ê²°ê³¼ëŠ” ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì´ë©°, 2%ë¼ëŠ” ì„±ëŠ¥ ì°¨ì´ì— ë”°ë¼ì„œ 6%ëŠ” ëª¨ë¸ Aê°€ ë§ê³ , 4%ëŠ” baselineì˜ ê²°ê³¼ê°€ ë§ì„ ê²ƒì´ë‹¤. with-little-power-table-4.png \\(\\alpha\\): 0.05 ìœ„ì˜ íŒŒë¼ë¯¸í„°ì—ì„œ \\(n\\)ì„ 100ë¶€í„° 5000ê¹Œì§€ ëŠ˜ë¦¬ë©´ì„œ ì‹¤í—˜í•œ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ë‘ ëª¨ë¸ì´ ê°™ì€ ê²°ê³¼ë¥¼ ì˜ˆì¸¡í•  í™•ë¥  (\\(P_a\\)) ì´ ë‚®ì„ìˆ˜ë¡ ë‘ ëª¨ë¸ì˜ ì„±ëŠ¥ì°¨ì´(\\(\\Delta_{acc}\\))ê°€ ì ê²Œ ë‚˜ëŠ” ê²½ìš°ëŠ” ìƒì‹ì ìœ¼ë¡œ ë°œìƒí•˜ê¸° ì–´ë µë‹¤. \\(n\\)ì´ 5000ìœ¼ë¡œ ë§ì€ ê²½ìš°ì—ë„ 80% Powerë¥¼ ì–»ëŠ” ì‹œì ì˜ (\\(\\Delta_{acc}\\))ëŠ” \\(P_a\\)ê°€ ë†’ì„ ë•Œê°€ ë” ë‚®ë‹¤. \\(n\\)ì´ ì‘ì€ ê²½ìš°ì—ëŠ” ë”ë”ìš± ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ì°¨ì´ë¥¼ ì£¼ì¥í•˜ê¸° ìœ„í•´ í•„ìš”í•œ ì„±ëŠ¥ í­ì´ ì¦ê°€í•œë‹¤. Assessing power in the literature ìœ„ì˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒì˜ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ í•  ìˆ˜ ìˆë‹¤. ì£¼ì–´ì§„ í…ŒìŠ¤íŠ¸ì…‹ì— ëŒ€í•œ baseline ëŒ€ë¹„ ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ ì°¨ì´ëŠ” ì–´ëŠ ì •ë„ì¼ê¹Œ? GLUEì™€ SQuAD 2.0 ì— ëŒ€í•´ ê²°ê³¼ë¥¼ reportí•œ ëª¨ë¸ë“¤ì˜ baseline ëŒ€ë¹„ í‰ê·  accuracy ì°¨ì´ (\\(|\\Delta_{acc}|\\)) ë¥¼ êµ¬í•œë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„ í˜•íšŒê·€ ë°©ì‹ì„ í†µí•´ êµ¬í•´ì§„ \\(P_a\\)ë¥¼ ë„ì¶œí•˜ë©°, ë„ì¶œëœ ë‘ ê°’ê³¼ í…ŒìŠ¤íŠ¸ì…‹ì˜ ì‚¬ì´ì¦ˆë¥¼ ë°”íƒ•ìœ¼ë¡œ 80% powerë¥¼ ë§Œì¡±(MDE; minimum detectable effect)í•˜ëŠ” \\(\\Delta_{acc}\\)ë¥¼ êµ¬í•œë‹¤. Est. MDE ë³´ë‹¤ \\(|\\Delta_{acc}|\\)ì´ ë‚®ì€ taskë“¤(WNLI, MRPC, SST-2)ì€ ì„±ëŠ¥ ê°œì„ ì„ ì£¼ì¥í•˜ëŠ” ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì´ ì‹¤ì œë¡œ ê·¸ taskë¥¼ ë” ì˜í•œë‹¤ê³  ë§í•  ìˆ˜ ì—†ë‹¤. í‰ê·  ê°’ì´ë¯€ë¡œ, ë§Œì•½ ì–´ë–¤ ëª¨ë¸ì´ Est. MDE ë³´ë‹¤ ë†’ì€ ì„±ëŠ¥ ê°œì„ ì„ ë³´ì—¬ì£¼ì—ˆë‹¤ê³  í•˜ë”ë¼ë„ ë°ì´í„°ì…‹ì˜ í¬ê¸°ê°€ ì‘ê¸° ë•Œë¬¸ì— Type-M errorë¥¼ ì˜ì‹¬í•˜ê²Œ ëœë‹¤. ì €ìë“¤ì€ ì´ ë¶„ì„ ê²°ê³¼ë¥¼ ë‘ê³  ë‹¤ìŒê³¼ ê°™ì´ ê°•í•˜ê²Œ ì£¼ì¥í•˜ê³  ìˆë‹¤. (íŒ¨ê¸°ë¬´ì—‡) In extreme cases, such as MRPC and SST-2, it is worth considering whether it is time to retire these datasets as the basis for model comparison. Likert-Scale Human Evaluations ëŒ€í™”ì™€ ê°™ì€ NLG íƒœìŠ¤í¬ì—ì„œëŠ” ì ì ˆí•œ evaluation metric ì´ ë¶€ì¬í•˜ê¸° ë•Œë¬¸ì— ì£¼ë¡œ Human evaluation ê²°ê³¼ë¥¼ reportí•œë‹¤. Human evaluation ê²°ê³¼ë„ ë‹¤ì–‘í•˜ê²Œ measureë˜ëŠ”ë° ì—¬ê¸°ì„œëŠ” ê·¸ ì¤‘ì—ì„œ Likert-scale ë¡œ reportí•˜ëŠ” ê²½ìš°ì— ëŒ€í•´ì„œ power analysisë¥¼ ìˆ˜í–‰í•˜ì˜€ë‹¤. Meta-analysis Power Analysisì— ì•ì„œ ë…¼ë¬¸ì—ì„œ ìˆ˜í–‰í•œ Human evaluationì— ëŒ€í•´ ê°„ë‹¨í•œ í†µê³„ëŸ‰ì„ ì •ë¦¬í•˜ì˜€ë‹¤. ë†€ëê²Œë„ 69%ì˜ ë…¼ë¬¸ì—ì„œ 100ê°œ ë¯¸ë§Œì˜ í…ŒìŠ¤íŠ¸ì…‹ì„ ì‚¬ìš©í–ˆê³ , 18%ë§Œì´ 200ê°œ ì´ìƒì˜ í…ŒìŠ¤íŠ¸ì…‹ì„ ì‚¬ìš©í–ˆë‹¤. ë˜í•œ 34%ì˜ ë…¼ë¬¸ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê±´ë‹¹ rating ìˆ˜ë¥¼ ì œê³µí•˜ì§€ ì•Šì•˜ê³ , 28%ì˜ ë…¼ë¬¸ì—ì„œ ì „ì²´ ì–´ë…¸í…Œì´í„° ìˆ˜ë¥¼ ê³µê°œí•˜ì§€ ì•Šì•˜ë‹¤. 57%ì˜ ì‹¤í—˜ì—ì„œ ì•„ì´í…œ ë‹¹ 3ëª…ì˜ ì–´ë…¸í…Œì´í„°ë¥¼ ë‘ì—ˆë‹¤. ì •ë¦¬í•˜ë©´, typical í•œ ì„±ëŠ¥ í‰ê°€ ì‹œë‚˜ë¦¬ì˜¤ëŠ” 3ëª…ì˜ ì‘ì—…ìê°€ 100ê°œì˜ ê²°ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ê²ƒì´ë‹¤. Power analysis for human Likert ratings Power analysisë¥¼ ìœ„í•´ì„œëŠ” ì•ì„œ ì–¸ê¸‰í•œ simulationì„ ìˆ˜í–‰í•´ì•¼ í•œë‹¤. ì—¬ê¸°ì—ëŠ” ì‘ì—…ìì˜ í¸ì°¨, ì‘ì—…ì ìˆ˜, í‰ê°€í•œ ë¬¸ì¥ ìˆ˜ ë“±ì˜ ì •ë³´ê°€ í•„ìš”í•˜ë‹¤. ì´ parametersë¥¼ ë„ì¶œí•˜ê¸° ìœ„í•´ ì €ìë“¤ì€ ê¸°ì¡´ ë…¼ë¬¸ì—ì„œ reportí•œ ì„±ëŠ¥ í‰ê°€ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ hierarchical mixed effects modelì„ ì‚¬ìš©í•œë‹¤. ê·¸ë¦¬ê³  ë„ì¶œëœ parameterë¥¼ ë°”íƒ•ìœ¼ë¡œ power analysisë¥¼ ìˆ˜í–‰í•´ì„œ ì•„ë˜ì˜ ê·¸ë˜í”„ë¥¼ ì–»ëŠ”ë‹¤. ì´ ê·¸ë˜í”„ë¥¼ í†µí•´ ì¶©ë¶„í•œ powerë¥¼ ê°€ì§„ ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•´ ëª‡ëª…ì˜ ì–´ë…¸í…Œì´í„°ì™€ ëª‡ê°œì˜ í‰ê°€ ì¸ìŠ¤í„´ìŠ¤ê°€ í•„ìš”í•œê°€? ì— ëŒ€í•œ ë‹µì„ ì•Œ ìˆ˜ ìˆë‹¤. ë¶„ì„ ê²°ê³¼ë¥¼ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤. ëŒ€ë¶€ë¶„ì˜ human evaluationì€ underpowered ì¼ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. ê°€ì¥ í”í•œ í‰ê°€ ë°©ì‹ì€ 3ëª…ì˜ ì–´ë…¸í…Œì´í„°ì—ê²Œ 100ê°œì˜ ë°ì´í„°ë¥¼ í‰ê°€ì‹œí‚¤ëŠ” ê²ƒì´ë‹¤. ë³´ìˆ˜ì ìœ¼ë¡œ ì‘ì—…ìë“¤ì˜ í¸ì°¨ê°€ í¬ë‹¤ê³  í•œë‹¤ë©´ ìœ ì˜ë¯¸í•œ ì°¨ì´ë¥¼ ë³´ì´ëŠ” ì ìˆ˜ì°¨ì´ëŠ” [0,1]ë¡œ normalize ì‹œì¼°ì„ ë•Œ 0.2 ì´ìƒì´ì–´ì•¼ í•œë‹¤. ì¼ë°˜ì ì¸ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì‘ì—…ìë“¤ì˜ í¸ì°¨ê°€ ì ë”ë¼ë„, ì‘ì€ ì„±ëŠ¥ ì°¨ì´ë¥¼ ìœ ì˜ë¯¸í•˜ë‹¤ê³  ì¸ì§€í•˜ê¸°ì—ëŠ” ë¶€ì¡±í•˜ë‹¤ ì¼ë°˜ì ì¸ ì‹œë‚˜ë¦¬ì˜¤(3ëª…ì˜ ì–´ë…¸í…Œì´í„°, 100ê°œì˜ ë°ì´í„°)ì—ì„œ ì‘ì—…ìë“¤ì˜ í¸ì°¨ê°€ ì‘ë‹¤ê³  ê°€ì •í•˜ë”ë¼ë„ 0.1 ì´ìƒì˜ ì ìˆ˜ì°¨ì´ì—¬ì•¼ ìœ ì˜ë¯¸í•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. 10ëª…ì˜ ì‘ì—…ìë“¤ì´ 500ê°œì˜ ë°ì´í„°ì— í‰ê°€ë¥¼ í•œë‹¤ê³  í•  ë•Œì—ì•¼ 0.05 ì •ë„ì˜ ì°¨ì´ë§Œìœ¼ë¡œë„ ìœ ì˜ë¯¸í•˜ë‹¤ê³  ì´ì•¼ê¸°í•  ìˆ˜ ìˆë‹¤. ëŒ€ë¶€ë¶„ì˜ human evaluationì€ ì œëŒ€ë¡œ ê²°ê³¼ë¥¼ reportí•˜ì§€ ì•ŠëŠ”ë‹¤. ì¦‰, í‰ê°€ì˜ ë””í…Œì¼ì´ ë¹ ì ¸ìˆë‹¤. ê·¸ëŸ¬ë‚˜ (ì•ˆíƒ€ê¹ê²Œë„) ëŒ€ë¶€ë¶„ì˜ ì„±ëŠ¥ ê²°ê³¼ì—ì„œ ìœ„ì˜ ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šì•„ ì• ì´ˆì— í‰ê°€ì˜ ìœ ì˜ë¯¸í•¨ì„ ì œëŒ€ë¡œ íŒë‹¨í•˜ì§€ ëª»í•œë‹¤. Overall Recommendations baseline ê²°ê³¼ì™€ ë¹„êµí•˜ê¸° ì „ì— power analysis ê°€ ì„ í–‰ë˜ì–´ì•¼ í•œë‹¤. Underpowered ì‹¤í—˜ì€ ê°œì„ ë˜ì—ˆë‹¤ê³  ì£¼ì¥í•˜ë©´ ì•ˆëœë‹¤. ìƒˆë¡œìš´ ë°ì´í„°ì…‹ê³¼ shared taskì—ì„œ ê²°ì •í•˜ëŠ” ë°ì´í„°ì…‹ ì‚¬ì´ì¦ˆëŠ” MDEë¥¼ ê³ ë ¤í•´ì„œ ê²°ì •ë˜ì–´ì•¼ í•œë‹¤. GLUE taskì—ì„œ ì„±ëŠ¥ ê°œì„ ì˜ ìœ ì˜ë¯¸í•¨ì„ íŒë‹¨í•  ìˆ˜ ì—†ëŠ” MRPC, SST-2ì˜ taskëŠ” í‰ê°€ ëŒ€ìƒì—ì„œ ë¹ ì§€ê±°ë‚˜ í…ŒìŠ¤íŠ¸ì…‹ì„ í™•ì¥ì‹œì¼œì•¼ í•œë‹¤. Power analysisë¥¼ ìœ„í•´ fine-tuned modelì˜ checkpointê°€ ê³µê°œë˜ì–´ì•¼ í•œë‹¤. Anonymized human evaluation ê²°ê³¼ê°€ ê³µìœ ë˜ì–´ì•¼ í•˜ê³ , human evalutationì„ ìˆ˜í–‰í•¨ì— ì•ì„œ ì ì ˆí•œ sample sizeë¥¼ ë„ì¶œí•˜ê¸° ìœ„í•œ power analysisê°€ í•„ìš”í•˜ë‹¤. References https://arxiv.org/abs/2010.06595","link":"/2020/12/13/With-little-power-comes-great-responsibiltiy/"},{"title":"ì—°ìš¸ë¦¼ ì´ì•¼ê¸°","text":"ì—°ìš¸ë¦¼ì˜ ì—°ì€, ì´ì•¼ê¸°í•  ì—°ì´ë‹¤. ì´ì•¼ê¸°ì˜ í˜ì„ ë¯¿ê¸°ì— ë‚˜ì˜¬ ìˆ˜ ìˆì—ˆë˜ ê¸°íšì´ë‹¤. ìš°ë¦¬, ë‚ ë¦¬ë‹¤: ë‚˜ë¥¼ ì•Œë¦¬ë‹¤ íŒ€ì€ ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ì‚¬ëŒë“¤ì€ ë³¸ì—°ì˜ ìƒ‰ì„ ê°€ì§€ê³  ìˆë‹¤ê³  ë¯¿ê³  ìˆë‹¤. ì§€ê¸ˆ ì´ ìˆœê°„ì—ë„ ì‚¬ëŒë“¤ì€ ê°ìì˜ ë°©ì‹ìœ¼ë¡œ í˜„ìƒì„ ì¸ì‹í•˜ê³ , ì´í•´í•˜ê³ , ëŠë¼ê³  ìˆë‹¤. ê·¸ë¦¬ê³  ë‚˜ë§Œì´ ê²½í—˜í•˜ëŠ” íŠ¹ë³„í•œ ì‹œê°„ì„ ë³´ë‚¸ë‹¤. ê·¸ ì†ì—ì„œ ìš°ë¦¬ëŠ” ê°ìì˜ ê°€ì¹˜ê´€ê³¼ ê°ìì˜ ê³ ë¯¼ì„ ê°€ì§€ê²Œ ëœë‹¤. í‰ì†Œì— ì´ëŸ° ê°œì¸ì ì¸ ìƒê°ë“¤ì€ ìˆ˜ë©´ ìœ„ë¡œ ì˜ ë“œëŸ¬ë‚˜ì§€ ì•ŠëŠ”ë‹¤. ê°€ì¹˜ê´€ì„ ê°€ê° ì—†ì´ ì´ì•¼ê¸°í•˜ê¸°ì—” ì‚¬íšŒì—ì„œ ìˆ˜ìš© ê°€ëŠ¥í•œ ë²”ìœ„ê°€ ì œí•œì ì´ê³ , ê³ ë¯¼ì„ ìˆ¨ê¹€ì—†ì´ ì´ì•¼ê¸°í•˜ê¸°ì—” ë‚˜ì˜ ê³ ë¯¼ì„ ì§„ì‹¬ìœ¼ë¡œ ê·€ ê¸°ìš¸ì—¬ì¤„ ì‚¬ëŒì´ ë¶€ì¡±í•˜ë‹¤. ê·¸ë˜ì„œ ì—°ìš¸ë¦¼ì´ ê¸°íšë˜ì—ˆë‹¤. ì—°ìš¸ë¦¼ì˜ ì—°(è®Œ)ì€ ì´ì•¼ê¸°í•  ì—°ì´ê³ , ìš¸ë¦¼ì€ ë‹¤ì–‘í•œ ì‚¬ëŒë“¤ì˜ ì´ì•¼ê¸°ê°€ ê³µëª…í•˜ëŠ” ìˆœê°„ì„ ë‹´ì€ ë‹¨ì–´ì´ë‹¤. ì—°(è®Œ) ì´ì•¼ê¸°ë¥¼ í†µí•´ ê°ìì˜ ìƒ‰ì´ ë“œëŸ¬ë‚œë‹¤. ë‹¤ë¥¸ ì‚¬ëŒë“¤ì—ê²Œ ë‚´ê°€ ê°€ì§„ ìƒê°ê³¼ ê³ ë¯¼ì„ ì „ë‹¬í•˜ëŠ” ê³¼ì •ì—ì„œ ì¶”ìƒì ì¸ í˜•íƒœë¡œ ë‚¨ì•„ìˆë˜ ê²½í—˜ì´ ë‚˜ë§Œì˜ ì–¸ì–´ë¡œ ëšœë ·í•˜ê²Œ ë¬˜ì‚¬ëœë‹¤. ê·¸ë•Œ ë‚˜ëŠ” ì™œ ê·¸ëŸ° ìƒê°ì„ í•˜ê²Œ ë˜ì—ˆëŠ”ì§€, ë‚˜ëŠ” ì™œ ê·¸ë ‡ê²Œ ë°–ì— í•  ìˆ˜ ì—†ì—ˆëŠ”ì§€ë¥¼ ì´ì•¼ê¸°í•¨ìœ¼ë¡œì¨ ê·¸ë•Œì˜ ë‚˜ì™€ ê·¸ë•Œì˜ ìƒí™©ì„ ì´í•´í•œë‹¤. ìš¸ë¦¼ ì´ì•¼ê¸°ëŠ”, ê·¸ê²ƒì„ ì§„ì‹¬ìœ¼ë¡œ ë“¤ì–´ì£¼ëŠ” ì‚¬ëŒë“¤ì´ ìˆì„ ë•Œ í˜ì„ ê°€ì§„ë‹¤. ë‚˜ì˜ ê°€ì¹˜ê´€ê³¼ íƒ€ì¸ì˜ ê°€ì¹˜ê´€ì´ ë§Œë‚˜ ì„œë¡œì˜ ê°€ì¹˜ê´€ì— ì˜í–¥ì„ ì¤Œìœ¼ë¡œì¨ í™•ì¥ë˜ê³ , ë‚´ê°€ ê°€ì§„ ê³ ë¯¼ì„ ë‹¤ë¥¸ ì‚¬ëŒì˜ ì‹œì„ ì—ì„œ ë°”ë¼ë´„ìœ¼ë¡œì¨ ìƒˆë¡­ê²Œ ë‚˜ì˜ ê³ ë¯¼ì„ ë°”ë¼ë³´ëŠ” ì‹œê°ì„ ì œê³µë°›ì„ë¿ë”ëŸ¬, ë‚˜ë¥¼ ì´í•´í•´ì£¼ê³  í¸ê²¬ ì—†ì´ ë°›ì•„ì£¼ê¸° ë•Œë¬¸ì— ìœ„ë¡œë°›ëŠ”ë‹¤. ê·¸ë˜ì„œ ë‚˜ì˜ ì´ì•¼ê¸°ëŠ” ë‹¤ì‹œê¸ˆ ìƒˆë¡œìš´ ì˜ë¯¸ë¥¼ ê°€ì§„ ì±„ë¡œ ë‚˜ì—ê²Œ ë‹¤ê°€ì˜¨ë‹¤. ì´ì•¼ê¸°ì™€ ì´ì•¼ê¸°ê°€ ë§Œë‚˜ ê³µëª…í•˜ëŠ” ìˆœê°„ì„ ë§Œë“¤ì–´ê°€ê³  ì‹¶ë‹¤. ëª¨ë“  ì´ì•¼ê¸°ëŠ” ì €ë§ˆë‹¤ì˜ ê°€ì¹˜ê°€ ìˆê³ , ë‚˜ëˆŒìˆ˜ë¡ ë” í° í˜ì„ ë°œíœ˜í•  ìˆ˜ ìˆë‹¤.","link":"/2019/04/01/Yeonullim/"},{"title":"Zero to One (ì œë¡œíˆ¬ì›)","text":"ì œë¡œíˆ¬ì›. í•´ì„í•˜ë©´ 0ì—ì„œ 1. ì¦‰, ë¬´ì—ì„œ ìœ ë¥¼ ì°½ì¡°í•œë‹¤ëŠ” ì˜ë¯¸ë‹¤. ì±…ì˜ ì œëª©ì— ê±¸ë§ê²Œ ì£¼ë³€ì— ìŠ¤íƒ€íŠ¸ì—…ì— ë‹¤ë‹ˆëŠ” ë¶„ë“¤ì—ê²Œ ìì£¼ ì¶”ì²œë°›ì•˜ë˜ ì±…ì´ë‹¤. ë‚´ìš© ì†Œê°œ ìŠ¤íƒ€íŠ¸ì—…ì´ ì„±ê³µí•˜ê¸° ìœ„í•œ ì¡°ê±´ì— ëŒ€í•´ ì´ì•¼ê¸°í•˜ê³  ìˆë‹¤. í”íˆë“¤ &quot;ì‹œì¥ìš°ìœ„ë¥¼ ì í•´ì„œ ê²½ìŸì—ì„œ ìŠ¹ë¦¬í•œ ìŠ¤íƒ€íŠ¸ì—…&quot;ì„ ì„±ê³µí•œ ìŠ¤íƒ€íŠ¸ì—…ì´ë¼ê³  ìƒê°í•œë‹¤. í•˜ì§€ë§Œ ì €ìëŠ” í•  ìˆ˜ ìˆë‹¤ë©´ ê²½ìŸì€ í”¼í• ìˆ˜ë¡ ì¢‹ë‹¤ê³  ë§í•œë‹¤. ê²½ìŸ ë•Œë¬¸ì— ë¼ì´ë²Œ íšŒì‚¬ë¥¼ ì‚¬ìš©ìë³´ë‹¤ ë” ì‹ ê²½ì“°ê²Œ ë˜ë©´ ë” ì´ìƒ ì„œë¹„ìŠ¤ê°€ ì‚¬ìš©ìë¥¼ í–¥í•˜ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì €ìì—ê²Œ ê²½ìŸì´ë€, ì•„ë¬´ë„ ì´ìœ¤ì„ ì–»ì§€ ëª»í•˜ê³  ì˜ë¯¸ ìˆê²Œ ì°¨ë³„í™” ë˜ëŠ” ë¶€ë¶„ë„ ì—†ì´ ìƒì¡´ì„ ìœ„í•´ ì‹¸ìš°ëŠ” ê²ƒì´ë‹¤. ê·¸ë ‡ë‹¤ë©´ ì €ìëŠ” ì„±ê³µí•˜ëŠ” ìŠ¤íƒ€íŠ¸ì—…ì„ ì–´ë–¤ ê¸°ì—…ìœ¼ë¡œ ìƒê°í•˜ê³  ìˆì„ê¹Œ? ì•„ë˜ì˜ ê¸€ì— ê·¸ ë‹µì´ ìˆë‹¤. ëª¨ë“  ê¸°ì—…ì€ ë‚¨ë“¤ì´ í•  ìˆ˜ ì—†ëŠ” ê²ƒì„ í•´ë‚´ëŠ” ë§Œí¼, ë”± ê·¸ë§Œí¼ë§Œ ì„±ê³µí•  ìˆ˜ ìˆë‹¤. ì°½ì¡°ì  ë…ì ì´ë€, ìƒˆë¡œìš´ ì œí’ˆì„ ë§Œë“¤ì–´ì„œ ëª¨ë“  ì‚¬ëŒì—ê²Œ í˜œíƒì„ ì£¼ëŠ” ë™ì‹œì— ê·¸ ì œí’ˆì„ ë§Œë“  ì‚¬ëŒì€ ì§€ì† ê°€ëŠ¥í•œ ì´ìœ¤ì„ ì–»ëŠ” ê²ƒì´ë‹¤. í–‰ë³µí•œ ê¸°ì—…ë“¤ì€ ë‹¤ë“¤ ì„œë¡œ ë‹¤ë¥´ë‹¤. ë‹¤ë“¤ ë…íŠ¹í•œ ë¬¸ì œë¥¼ í•´ê²°í•´ ë…ì ì„ êµ¬ì¶•í–ˆê¸° ë•Œë¬¸ì´ë‹¤. ë°˜ë©´ì— ì‹¤íŒ¨í•œ ê¸°ì—…ë“¤ì€ í•œê²°ê°™ë‹¤. ê²½ìŸì„ ë²—ì–´ë‚˜ì§€ ëª»í•œ ê²ƒì´ë‹¤. ë§ˆìŒì— ë‹¿ì•˜ë˜ êµ¬ì ˆ ëŒ€í•™ìƒë“¤ì€ ëª‡ëª‡ ì „ê³µ ë¶„ì•¼ì—ì„œëŠ” ê³ ë„ì˜ ì „ë¬¸ì  ê¸°ìˆ ì„ ìŠµë“í•˜ê¸°ë„ í•˜ì§€ë§Œ, ì •ì‘ ê·¸ ëŠ¥ë ¥ìœ¼ë¡œ ë” ë„“ì€ ì„¸ìƒì—ì„œ ë¬´ì—‡ì„ í•  ìˆ˜ ìˆëŠ”ì§€ì— ê´€í•´ì„œëŠ” ì•„ë¬´ê²ƒë„ ë°°ìš°ì§€ ëª»í•œë‹¤. ì±…ì˜ ì£¼ì œì™€ëŠ” ìƒê´€ì—†ì§€ë§Œ, ì´ ë¬¸ì¥ì— ê³µê°í•˜ì§€ ì•Šì„ ìˆ˜ ì—†ì—ˆë‹¤. êµìœ¡ì´ ì‚¬íšŒë¥¼ ì«“ì•„ê°€ì§€ ëª»í•˜ëŠ” ê²ƒì€ ë¯¸êµ­ì´ë‚˜ í•œêµ­ì´ë‚˜ ë‹¤ë¥¼ ë°” ì—†ë‹¤ëŠ” ì‚¬ì‹¤ì´ ì¸ìƒê¹Šì—ˆë‹¤. ì§€ì†ì ì¸ ê°€ì¹˜ë¥¼ ì°½ì¶œí•˜ê³  ë˜ ë³´ìœ í•˜ê³  ì‹¶ë‹¤ë©´, ì°¨ë³„í™”ë˜ì§€ ì•ŠëŠ” ì œí’ˆìœ¼ë¡œ íšŒì‚¬ë¥¼ ì°¨ë¦¬ì§€ ë§ˆë¼. ì—°ìš¸ë¦¼ì„ ëŸ°ì¹­í–ˆì„ ë•Œì˜ ê²½í—˜ì´ ë– ì˜¬ëë‹¤. ì‚¬ìš©ìì—ê²Œ ì£¼ê³  ì‹¶ì€ ê°€ì¹˜ê°€ ìˆì—ˆì§€ë§Œ, ë‚˜ì™€ ë¹„ìŠ·í•œ ìƒê°ìœ¼ë¡œ ì´ë¯¸ ì‚¬ëŒë“¤ì—ê²Œ ê°€ì¹˜ë¥¼ ì „íŒŒí•˜ê³  ìˆëŠ” ê¸°ì—…ì´ ì–´ëŸ¿ìˆì—ˆë‹¤. ì•„ì´ë””ì–´ê°€ ë¹„ìŠ·í•˜ë”ë¼ë„, ë‚¨ë“¤ê³¼ ë‹¤ë¥´ê²Œ êµ¬í˜„í–ˆë‹¤ë©´ ì°¨ë³„í™”ëœ ì œí’ˆì´ë¼ê³  ë¶€ë¥¼ ìˆ˜ ìˆì—ˆê² ì§€ë§Œ ê·¸ëŸ¬ê¸°ê°€ ì‰½ì§€ ì•Šì•˜ê³  ëë‚´ ê²½ìŸ ì†ì—ì„œ ë’¤ì³ì¡Œë‹¤. ì‚¬ì‹¤ ê°€ë²¼ìš´ ë™ì•„ë¦¬ ê°™ì€ ëŠë‚Œì´ì—ˆê¸° ë•Œë¬¸ì— ë‚˜ì˜ì§€ ì•Šì€ ê²½í—˜ì´ë¼ê³  ìƒê°ë˜ì§€ë§Œ, ë‹¤ìŒì— ë¬´ì—‡ì¸ê°€ ì‹œì‘í•˜ê²Œ ëœë‹¤ë©´ (ì‚¬ì—…ì´ë“  í”„ë¡œì íŠ¸ì´ë“ ) ì°¨ë³„ì„±ì„ ì—¼ë‘ì— ë‘ì–´ì•¼ê² ë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ì‹ ìƒê¸°ì—…ì—ê²Œ ì™„ë²½í•œ í‘œì  ì‹œì¥ì€ ê²½ìŸìê°€ ì—†ê±°ë‚˜ ì•„ì£¼ ì ìœ¼ë©´ì„œë„ íŠ¹ì •í•œ ì‚¬ëŒë“¤ì´ ì ì€ ê·œëª¨ë¡œ ëª¨ì—¬ ìˆëŠ” ì‹œì¥ì´ë‹¤. í‹ˆìƒˆì‹œì¥ì„ ë§Œë“¤ì–´ë‚´ ì§€ë°°í•˜ê²Œ ë˜ì—ˆë‹¤ë©´, ê´€ë ¨ ìˆëŠ” ì¢€ ë” ë„“ì€ ì‹œì¥ìœ¼ë¡œ ì„œì„œíˆ ì‚¬ì—…ì„ í™•ì¥í•´ì•¼ í•œë‹¤. ì´ ì£¼ì¥ì€ ì˜ê²¬ì´ ë‹¤ë¥¼ ìˆ˜ ìˆë‹¤ê³  ìƒê°í•œë‹¤. ì»¨ì„¤íŒ… íšŒì‚¬ì—ì„œ ì¼í•´ë³¸ ê²½í—˜ì´ ìˆëŠ” ì‚¬ëŒì´ë¼ë©´, ì‹ ì‚¬ì—… ì œì•ˆì„ í•  ë•Œì˜ ë…¼ë¦¬ì™€ ì ˆëŒ€ì ìœ¼ë¡œ ë°˜ëŒ€ë˜ëŠ” ë‚´ìš©ì´ë¼ëŠ” ê²ƒì„ ì•Œ ê²ƒì´ë‹¤. â€œì‹œì¥ì˜ ê·œëª¨ê°€ í¬ê³ , ê·¸ ì‹œì¥ì˜ ê²½ìŸìƒëŒ€ê°€ ëˆ„êµ¬ì´ë©° ìš°ë¦¬ëŠ” ê·¸ ì•ˆì—ì„œ ì–´ë–¤ í¬ì§€ì…”ë‹ì´ê¸° ë•Œë¬¸ì— ì‹œì¥ì˜ n% ë¥¼ ì°¨ì§€í•  ìˆ˜ ìˆë‹¤.â€ ë¼ëŠ” ë…¼ë¦¬ë¡œ ì´ ì‹ ì‚¬ì—…ì˜ ê°€ëŠ¥ì„±ì„ íƒ€ì§„í•˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì´ë‹¤. ê·¸ëŸ° ë©´ì—ì„œ ì´ ë¬¸ì¥ì€ ì‹ ì„ í–ˆê³ , ì œë¡œíˆ¬ì›ì´ë¼ëŠ” ì œëª©ì— ê±¸ë§ëŠ” ì£¼ì¥ì´ë¼ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ì–´ë ¤ìš´ ì¼ì€ ì„±ì·¨í•  ìˆ˜ ìˆì§€ë§Œ, ë¶ˆê°€ëŠ¥í•œ ì¼ì€ ì„±ì·¨í•  ìˆ˜ ì—†ë‹¤ ê°€ëŠ¥ì„±ì— ëŒ€í•´ì„œ ìƒê°í•´ë³´ê²Œ ë§Œë“  ê¸€ê·€ë‹¤. ì•„ë¬´ë„ í•˜ì§€ ì•Šê³  ìˆëŠ” ì¤‘ìš”í•œ ì¼ì„ ì™œ ìš°ë¦¬ê°€ í•˜ê³  ìˆëŠ”ì§€ ì„¤ëª…í•  ìˆ˜ ìˆì–´ì•¼ í•œë‹¤. ìƒˆë¡œìš´ í”„ë¡œì íŠ¸, í˜¹ì€ ì‚¬ì—…ì„ í•œë‹¤ë©´ ìŠ¤ìŠ¤ë¡œì—ê²Œ ë¬¼ì–´ë´ì•¼ í•˜ëŠ” ì§ˆë¬¸ì´ë¼ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤. ì™œ ì´ ë¬¸ì œì¸ì§€, ì™œ ìš°ë¦¬ì˜ í•´ê²°ì±…ì´ì–´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•´ ë‚˜ë¶€í„° ë‚©ë“ì‹œí‚¤ì§€ ëª»í•œë‹¤ë©´ ëˆ„êµ¬ë¥¼ ì„¤ë“í•  ìˆ˜ ìˆì„ê¹Œ? ì‚¬íšŒë¥¼ ìœ„í•´ì„œ ì •ë§ë¡œ ì¢‹ì€ ì¼ì€ ë­”ê°€ ë‚¨ë“¤ê³¼ â€˜ë‹¤ë¥¸â€™ ì¼ì„ í•˜ëŠ” ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  ê·¸ë ‡ê²Œ í•˜ëŠ” ê²ƒì´ì•¼ë§ë¡œ ê¸°ì—…ì´ ìƒˆë¡œìš´ ì‹œì¥ì„ ë…ì í•´ ì´ìœ¤ì„ ë§Œë“œëŠ” ë°©ë²•ì´ê¸°ë„ í•˜ë‹¤. ìµœê³ ì˜ í”„ë¡œì íŠ¸ëŠ” ë‹¤ë“¤ ë– ë“¤ì–´ëŒ€ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ë‚¨ë“¤ì—ê²Œ ê°„ê³¼ë˜ê³  ìˆì„ ê°€ëŠ¥ì„±ì´ í¬ë‹¤. ê°€ì¥ ë¤ë²¼ë³¼ ë§Œí•œ ë¬¸ì œëŠ” ì•„ë¬´ë„ í•´ê²°í•´ë³´ë ¤ê³  í•˜ì§€ì¡°ì°¨ ì•ŠëŠ” ë¬¸ì œì¼ ë•Œê°€ ë§ë‹¤. ë…ì ê¸°ìˆ ì€ ê°€ì¥ ê°€ê¹Œìš´ ëŒ€ì²´ ê¸°ìˆ ë³´ë‹¤ ì¤‘ìš”í•œ ë¶€ë¶„ì—ì„œ â€˜10ë°°â€™ëŠ” ë” ë›°ì–´ë‚˜ì•¼ ì§„ì •í•œ ë…ì ì  ìš°ìœ„ë¥¼ í™•ë³´í•  ìˆ˜ ìˆë‹¤. ì•„ë¬´ë„ í•´ê²°í•´ë³´ë ¤ê³  í•˜ì§€ ì•ŠëŠ” ë¬¸ì œëŠ” ë¶ˆê°€ëŠ¥í•œ ë¬¸ì œì´ê±°ë‚˜, ì–´ë ¤ìš´ ì¼ì¼ ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  ì–´ë ¤ìš´ ì¼ì„ í’€ ìˆ˜ ìˆëŠ” ê¸°ì—…ì¼ìˆ˜ë¡ ë” ë›°ì–´ë‚œ ì—­ëŸ‰ì„ ë³´ìœ í•  ê²ƒì´ê³ , ë‚¨ë“¤ì´ ì‰½ê²Œ ì ‘ê·¼í•˜ì§€ ëª»í•˜ëŠ” ë…ì ì  ìš°ìœ„ì— ê°€ê¹Œìš´ í¬ì§€ì…˜ì— ìˆì§€ ì•Šì„ê¹Œ? ê°œì¸ì ì¸ ê°ìƒ í”íˆ ìƒê°í•˜ëŠ” ì„±ê³µí•˜ëŠ” ì‚¬ì—…ì— ëŒ€í•œ ì¡°ê±´ì˜ í‹€ì—ì„œ ë¹ ì ¸ë‚˜ì˜¤ê²Œ ë§Œë“  ì±…ì´ì—ˆë‹¤. ëˆ„êµ¬ë‚˜ ìƒê°í•  ìˆ˜ ìˆëŠ” ë¬¸ì œì™€, ëˆ„êµ¬ë‚˜ í’€ ìˆ˜ ìˆëŠ” í•´ê²°ì±…ì´ë¼ë©´ ê·¸ë³´ë‹¤ ìœ„í—˜í•œ ìŠ¤íƒ€íŠ¸ì—…ì€ ì—†ì„ ê²ƒ ê°™ë‹¤. &quot;ëˆ„êµ¬ë‚˜ ê³µê°í•˜ëŠ” í¬ê³  ì–´ë ¤ìš´ ë¬¸ì œ&quot;ì— ëŒ€í•´ &quot;ë‚˜ë§Œì˜ í•´ê²°ì±…&quot;ì„ ê°€ì§ˆ ìˆ˜ ìˆëŠ” ì‚¬ëŒì´ê³  ì‹¶ë‹¤.","link":"/2020/07/20/Zero-to-one-by-peter/"}],"tags":[{"name":"essay","slug":"essay","link":"/tags/essay/"},{"name":"ML","slug":"ML","link":"/tags/ML/"},{"name":"NLP","slug":"NLP","link":"/tags/NLP/"},{"name":"quantum","slug":"quantum","link":"/tags/quantum/"},{"name":"quantum computing","slug":"quantum-computing","link":"/tags/quantum-computing/"},{"name":"dataset","slug":"dataset","link":"/tags/dataset/"},{"name":"paper","slug":"paper","link":"/tags/paper/"},{"name":"LM","slug":"LM","link":"/tags/LM/"},{"name":"Google","slug":"Google","link":"/tags/Google/"},{"name":"BERT","slug":"BERT","link":"/tags/BERT/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"mentoring","slug":"mentoring","link":"/tags/mentoring/"},{"name":"book","slug":"book","link":"/tags/book/"},{"name":"data analysis","slug":"data-analysis","link":"/tags/data-analysis/"},{"name":"news comments","slug":"news-comments","link":"/tags/news-comments/"},{"name":"social good","slug":"social-good","link":"/tags/social-good/"},{"name":"pandas","slug":"pandas","link":"/tags/pandas/"},{"name":"pytorch","slug":"pytorch","link":"/tags/pytorch/"},{"name":"hate speech","slug":"hate-speech","link":"/tags/hate-speech/"},{"name":"bias","slug":"bias","link":"/tags/bias/"},{"name":"travel","slug":"travel","link":"/tags/travel/"},{"name":"norway","slug":"norway","link":"/tags/norway/"},{"name":"evaluation","slug":"evaluation","link":"/tags/evaluation/"}],"categories":[{"name":"Essay","slug":"Essay","link":"/categories/Essay/"},{"name":"ML","slug":"ML","link":"/categories/ML/"},{"name":"Paper","slug":"Paper","link":"/categories/Paper/"},{"name":"NLP","slug":"ML/NLP","link":"/categories/ML/NLP/"},{"name":"Quantum Computing","slug":"ML/Quantum-Computing","link":"/categories/ML/Quantum-Computing/"},{"name":"Ops","slug":"Ops","link":"/categories/Ops/"},{"name":"Git","slug":"Ops/Git","link":"/categories/Ops/Git/"},{"name":"Book","slug":"Book","link":"/categories/Book/"},{"name":"Data Analysis","slug":"ML/Data-Analysis","link":"/categories/ML/Data-Analysis/"},{"name":"PyTorch","slug":"ML/PyTorch","link":"/categories/ML/PyTorch/"}]}