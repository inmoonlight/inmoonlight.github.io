<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (a.k.a. T5) - Space Moon</title><meta description="최근 NLP task에서 좋은 성능을 보이는 모델은 대량의 monolingual corpus를 통해 unsupervised pre-training을 한 LM을 task에 맞게 supervised fine-tuning을 하는 transfer learning에 기반하고 있다. 같은 transfer learning framework 안에서도 다양한 모델이 존재한"><meta property="og:type" content="blog"><meta property="og:title" content="Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (a.k.a. T5)"><meta property="og:url" content="https://inmoonlight.github.io/2020/08/29/Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/"><meta property="og:site_name" content="Space Moon"><meta property="og:description" content="최근 NLP task에서 좋은 성능을 보이는 모델은 대량의 monolingual corpus를 통해 unsupervised pre-training을 한 LM을 task에 맞게 supervised fine-tuning을 하는 transfer learning에 기반하고 있다. 같은 transfer learning framework 안에서도 다양한 모델이 존재한"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s1600/image3.gif?style=centerme"><meta property="og:image" content="https://1.bp.blogspot.com/-89OY3FjN0N0/XlQl4PEYGsI/AAAAAAAAFW4/knj8HFuo48cUFlwCHuU5feQ7yxfsewcAwCLcBGAsYHQ/s1600/image2.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-architecture-variants.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-attention-variants.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-architecture-results.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-flowchart-unsupervised-objectives.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-high-level-result.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-strategy-result.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-corruption-result.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-span-length-result.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-dataset-result.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-datasize-result.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-finetuning-result.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-multitask-result.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-combination-result.png?style=centerme"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/t5-scaling-result.png?style=centerme"><meta property="article:published_time" content="2020-08-29T08:00:00.000Z"><meta property="article:modified_time" content="2023-11-02T02:50:49.144Z"><meta property="article:author" content="Jihyung Moon"><meta property="article:tag" content="ML"><meta property="article:tag" content="NLP"><meta property="article:tag" content="paper"><meta property="article:tag" content="LM"><meta property="article:tag" content="Google"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s1600/image3.gif?style=centerme"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://inmoonlight.github.io/2020/08/29/Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/"},"headline":"Space Moon","image":[],"datePublished":"2020-08-29T08:00:00.000Z","dateModified":"2023-11-02T02:50:49.144Z","author":{"@type":"Person","name":"Jihyung Moon"},"description":"최근 NLP task에서 좋은 성능을 보이는 모델은 대량의 monolingual corpus를 통해 unsupervised pre-training을 한 LM을 task에 맞게 supervised fine-tuning을 하는 transfer learning에 기반하고 있다. 같은 transfer learning framework 안에서도 다양한 모델이 존재한"}</script><link rel="canonical" href="https://inmoonlight.github.io/2020/08/29/Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/"><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-131297969-1" async></script><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-131297969-1');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><link rel="alternate" href="/feed.xml" title="Space Moon" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/space_moon.png" alt="Space Moon" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/inmoonlight"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-9-tablet is-9-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" datetime="2020-08-29T08:00:00.000Z" title="2020-08-29T08:00:00.000Z">2020-08-29</time><span class="level-item"><a class="link-muted" href="/categories/Paper/">Paper</a></span><span class="level-item">16 minutes read (About 2349 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (a.k.a. T5)</h1><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><!-- hexo-inject:begin --><!-- hexo-inject:end -->최근 NLP task에서 좋은 성능을 보이는 모델은 대량의 monolingual
corpus를 통해 unsupervised pre-training을 한 LM을 task에 맞게 supervised
fine-tuning을 하는 transfer learning에 기반하고 있다. 같은 transfer
learning framework 안에서도 다양한 모델이 존재한다. 우리가 아는 모델만
하더라도 BERT, GPT, ELMO 등이 있고, GLUE benchmark에 대해서 테스트한
점수가 있다.</p>
<p>하지만 과연 점수가 더 높다고 더 좋은 모델이라고 할 수 있을까? 우리가
모델이라고 부르는 것 안에는 학습 방식 외에도 학습에 사용한 데이터셋,
optimizer, 모델의 크기 등 많은 내용이 함축되어 있다. 그래서 각 모델의
아이디어 중 과연 <strong>"어떤 특징이 좋은 모델 성능을 내는데에 도움이
되었을까?"</strong>라고 묻는다면 쉽게 대답하기 어렵다.</p>
<p>이 논문에서 소개하는 Text-to-Text Transfer Transformer (T5) 는 그
답을 찾기 위해 고안한 framework이다. <a id="more"></a></p>
<h2 id="transfer-learning-framework-text-to-text-transfer-transformer-t5">Transfer
learning framework: Text-to-Text Transfer Transformer (T5)</h2>
<p>T5는 모든 task를 transformer의 building block으로 하는 seq2seq
framework 이다 (주의! encoder-decoder 와는 다르다. sequence X가 입력되면
sequence Y가 출력되는 것일 뿐). 다양한 downstream tasks (question
answering, document summarization, semtiment classification, machine
translation, etc) 를 하나의 모델 안에서 해결해야 서로 다른 transfer
learning 방식의 효과를 공정하게 비교할 수 있기 때문에 이와 같은 unified
framework 가 제안되었다. 분석하고 싶은 내용과 무관한 특징들 -- 사용한
데이터, tokenizer, vocab size, learning rate 등 -- 은 task에 상관없이
고정된다.</p>
<p><img src="https://1.bp.blogspot.com/-o4oiOExxq1s/Xk26XPC3haI/AAAAAAAAFU8/NBlvOWB84L0PTYy9TzZBaLf6fwPGJTR0QCLcBGAsYHQ/s1600/image3.gif?style=centerme" alt="T5의 학습 framework. output이 text sentence이든, class이든, score이든 모두 text-to-text framework로 학습하는 것을 볼 수 있다. <br> source: https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html" width="80%"></p>
<p><img src="https://1.bp.blogspot.com/-89OY3FjN0N0/XlQl4PEYGsI/AAAAAAAAFW4/knj8HFuo48cUFlwCHuU5feQ7yxfsewcAwCLcBGAsYHQ/s1600/image2.png?style=centerme" alt="T5의 transfer learning schema. Pre-training과 Fine-tuning step으로 구분되어 있으며 기본적인 text-to-text framework는 그대로 고수한다. <br> source: https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html" width="80%"></p>
<h2 id="pre-training-dataset-colossal-clean-crawled-corpus-c4">Pre-training
dataset: Colossal Clean Crawled Corpus (C4)</h2>
<p>Transfer learning framework에 사용되는 pre-trained model은 어떤
종류의 corpus를 사용했는지, 얼만큼의 corpus를 사용했는지에 따라서도
특징이 달라진다. 이에 대한 실험을 위해 논문에서는 common crawl로 수집한
아주 많은 양의 데이터를 소개한다.</p>
<p>양에 따른 모델 성능을 비교하기 위해 우선 기존의 Wikipedia corpus 보다
2배 이상 큰 사이즈의 데이터를 crawling 한다. 인터넷에서 crawling한
문서는 보통 매우 지저분하다. 이런 지저분한 데이터를 학습에 바로 사용하게
되면 side effect 가 있을 수 있기 때문에 중복 제거, 미완성 문장 제거,
공격적이거나 bias가 있는 문장 제거 등의 cleansing process를 거치고
깔끔한 데이터를 남긴다. 이 데이터셋의 이름이 Colossal Clean Crawled
Corpus (C4) 이다. 여러 필터링을 거쳤음에도 Wikipedia corpus 크기의 2배
이상이라고 한다.</p>
<p><a href="https://www.tensorflow.org/datasets/catalog/c4" rel="external nofollow noopener noreferrer" target="_blank">TF
dastasets</a>에서 다운로드 가능하다.</p>
<h2 id="main-contributions-of-the-paper">Main Contributions of the
paper</h2>
<p>앞서 소개했듯이, 이 논문에서 풀고 싶은 질문은 "다양한 NLP transfer
learning framework 중에서 어떤 feature가 좋은 성능을 내는데에 도움이
될까?"이다. 따라서 조금씩 training schema를 달리해가며 여러 downstream
task의 성능을 비교해야 한다.</p>
<p>이 논문에서는 크게 1) <a href="#pre-training-architecture">Pre-training architecture</a> 2) <a href="#pre-training-objective">Pre-training objective</a> 3) <a href="#pre-training-dataset">Pre-training dataset</a> 4) <a href="#pre-training-datasize">Pre-training datasize</a> 5) <a href="#training-strategy">Training strategy</a> 6) <a href="#scaling-strategy">Scaling strategy</a>를 주목하고 있다. 그리고
중요한 Disclaimer로, <strong><em>여기서 소개하는 architecture와
objective는 GPT, ELMO 등의 구현을 아주 정확하게 replicate 하고 있지
않다</em></strong>고 언급한다. 어느 정도 이 모델들의 구조에 motivate된
내용이 보이지만 정확하게 같지는 않다.</p>
<h3 id="pre-training-architecture">Pre-training architecture</h3>
<h4 id="encoder-decoder-baseline-vs.-language-model-vs.-prefix-lm">Encoder-Decoder
(Baseline) vs. Language Model vs. Prefix LM</h4>
<p>크게 세가지 모델 구조를 실험하였다. Encoder-Decoder에서 Encoder는
fully-visible attention을 적용하였고 decoder만 causal attention을
적용하였다. LM은 전부 causal attention이며, 이는 uni-directional하게
정보를 습득하는 것을 나타낸다. PrefixLM의 경우 encoder-decoder 와 유사한
것으로 보인다. input인 x에 대해서는 bi-directional하게 정보를 습득하고
y만 causal attention이 적용된다.</p>
<p><img src="/assets/images/t5-architecture-variants.png?style=centerme" width="50%" alt="모든 모델의 입력과 출력은 text와 text이다. building block은 transformer이며, block과 block을 연결하는 attention의 방식이 <br> 아래 그림의 Fully-visible, Causal, Causal with prefix 중에 해당하는 것을 볼 수 있다.">
<img src="/assets/images/t5-attention-variants.png?style=centerme" width="60%"></p>
<p><strong>Q. 어떤 Pre-training model architecture 가 가장
효과적일까?</strong></p>
<p><img src="/assets/images/t5-architecture-results.png?style=centerme" width="90%"></p>
<p>Encoder-Decoder architecture가 가장 효과적이었다. LM의 성능이 가장
좋지 않았는데, 이를 통해 bi-directional context를 input으로 넣어주는
것이 효과적이라는 사실을 알 수 있다.</p>
<h3 id="pre-training-objective">Pre-training objective</h3>
<p>아래 이미지에서 확인할 수 있듯, 크게 네단계로 나누어서 생각해볼 수
있다: 1) High-level approaches 2) Corruption strategies 3) Corruption
rate 4) Corrupted span length</p>
<p><img src="/assets/images/t5-flowchart-unsupervised-objectives.png?style=centerme" width="60%"></p>
<h4 id="high-level-approaches">High-level approaches</h4>
<p>세가지 방식을 비교한다. Prefix language modeling 은 문장의 앞부분을
context로 제공하는 방식, BERT-style 은 Masked-LM (MLM) 방식, 그리고
Deshuffling 은 문장의 token을 뒤섞고 원 문장을 맞추는 방식이다.</p>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Objective</th>
<th>Inputs</th>
<th>Targets</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Prefix language modeling</td>
<td>Thank you for inviting</td>
<td>me to your party last week .</td>
</tr>
<tr class="even">
<td>BERT-style</td>
<td>Thank you &lt;M&gt; &lt;M&gt; me to your party apple week.</td>
<td>(original text)</td>
</tr>
<tr class="odd">
<td>Deshuffling</td>
<td>party me for your to . last fun you inviting week Thank</td>
<td>(original text)</td>
</tr>
</tbody>
</table>
<p><strong>Q. 어떤 High-level approach 가 가장 효과적일까?</strong></p>
<p><img src="/assets/images/t5-high-level-result.png?style=centerme" width="80%"></p>
<p>위의 표의 결과에 따르면 BERT-style (MLM) objective 가 가장 좋은
성능을 보인다.</p>
<h4 id="corruption-strategies">Corruption strategies</h4>
<p>이번에는 High-level approaches 중 가장 좋은 성능을 보인 BERT-style
approach 에 대해서 적용해 볼 수 있는 다양한 corruption strategies 에
따라 실험한다. 총 세가지 전략이 있다. 모두 i.i.d. 로 masking을 하는 것은
동일하지만, token 단위로 masking 하는 방식이 있고 (i.i.d. noise, mask
tokens) span 단위로 masking 해서 예측하는 문장은 입력에서 masking된
부분을 예측하고 아닌 부분을 masked token으로 예측하는 방식 (i.i.d.
noise, replace spans (a.k.a. Denoising, Baseline)), 그리고 원문에서
token을 제외하고 제외된 부분을 예측하는 방식 (i.i.d. noise, drop tokens)
이 있다.</p>
<table>
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Objective</th>
<th>Inputs</th>
<th>Targets</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>i.i.d. noise, mask tokens</td>
<td>Thank you &lt;M&gt; &lt;M&gt; me to your party &lt;M&gt; week.</td>
<td>(original text)</td>
</tr>
<tr class="even">
<td>i.i.d. noise, replace spans (a.k.a, Denoising, Baseline)</td>
<td>Thank you &lt;X&gt; me to your party &lt;Y&gt; week.</td>
<td>&lt;X&gt; for inviting &lt;Y&gt; last &lt;Z&gt;</td>
</tr>
<tr class="odd">
<td>i.i.d. noise, drop tokens</td>
<td>Thank you me to your party week.</td>
<td>for inviting last</td>
</tr>
</tbody>
</table>
<p><strong>Q. BERT-style approach의 다양한 corruption strategy 중 무엇이
가장 효과적일까?</strong></p>
<p><img src="/assets/images/t5-strategy-result.png?style=centerme" width="80%" alt="별표시가 baseline을 의미한다"></p>
<p>위의 표에 따르면 Denoising 방식이 가장 좋은 성능을 낸다.</p>
<h4 id="corruption-rate">Corruption rate</h4>
<p>마찬가지로 위에서 가장 성능이 좋았던 Denoising 방식에서 corruption
rate을 10%, 15%, 25%, 50%로 다르게하며 살펴본다.</p>
<p><strong>Q. 원 문장의 얼만큼을 corrupt 하는 것이 가장
좋을까?</strong></p>
<p><img src="/assets/images/t5-corruption-result.png?style=centerme" width="80%"></p>
<p>표에 따르면 15%가 적당하다는 결론이 나온다.</p>
<h4 id="random-spans">Random spans</h4>
<p>15% 정도 denoising 방식으로 corrupt 할 때 평균적인 span의 길이를
다르게 조정해볼 수 있다. Baseline으로 사용한 i.i.d.와 2, 3, 5, 10 의
길이를 비교할 수 있다.</p>
<p><strong>Q. corrupt할 때 가장 적정한 평균 span 길이는
몇일까?</strong></p>
<p><img src="/assets/images/t5-span-length-result.png?style=centerme" width="80%"></p>
<p>표에 따르면 i.i.d 에 따라 corrupt하는 것이 가장 효과적이다.</p>
<h3 id="pre-training-dataset">Pre-training Dataset</h3>
<p>Pre-training 모델의 성능은 데이터셋에 따라 달라질 수 있다. 이를
실험하기 위해 논문에서 수집한 C4와 C4, unfiltered 그리고 다른 특징을
가진 데이터셋으로 pre-training 한 후 task 마다의 성능을 비교하였다.
결과는 C4를 쓰는 것이 가장 좋았다.</p>
<p><img src="/assets/images/t5-dataset-result.png?style=centerme" width="80%" alt="TBC는 Toronto Book Corpus의 약자"></p>
<h3 id="pre-training-datasize">Pre-training datasize</h3>
<p>GLUE benchmark의 상위권 모델은 보통 pre-training에 사용한 datasize가
크며 모델의 사이즈도 굉장히 크다. T5는 다행히도 모델의 capacity가 큰
편이라 데이터 사이즈를 조절해가며 실험을 할 수 있었고, C4 전체를
사용했을 때 가장 성능이 좋았다. 다시 말해, 아직 모델의 capacity 가 더
크다고 이해할 수 있다.</p>
<p><img src="/assets/images/t5-datasize-result.png?style=centerme" width="80%"></p>
<h3 id="training-strategy">Training strategy</h3>
<p>Transfer learning 은 Training strategy에 따라서도 성능이 달라질 수
있다. Training strategy는 Fine-tuning, Multi-task learning 방식으로
나뉘며 이를 어떻게 조합하는지 또한 전략에 포함되었다.</p>
<h4 id="fine-tuning-methods">Fine-tuning methods</h4>
<p>Fine-tuning 은 모든 파라미터를 사용했을 때 가장 성능이 좋다.
<img src="/assets/images/t5-finetuning-result.png?style=centerme" width="80%"></p>
<h4 id="multi-task-learning-pre-training">Multi-task learning
(pre-training)</h4>
<p>T5 의 task는 다양한데, 과연 각 task를 얼만큼 학습시키는 것이 좋을지에
대한 실험이다. Equal 의 경우 task dataset의 사이즈에 상관없이 같은 수의
문장을 학습시키는 방식이다. K threshold 를 사용한 경우, 기본적으로
task의 문장 사이즈만큼 샘플링하되, K 이상의 데이터는 K 만큼만 학습에
활용한다.</p>
<p>결과는 sampling 하지 않는 것이 가장 좋다.
<img src="/assets/images/t5-multitask-result.png?style=centerme" width="80%"></p>
<h4 id="combining-fine-tuning-and-multi-task-learning">Combining
fine-tuning and multi-task learning</h4>
<p>위에서 소개한 다양한 방식을 조합하여 실험하였고, multi-task
pre-training과 fine-tuning 조합이 가장 좋은 성능을 보였다.
<img src="/assets/images/t5-combination-result.png?style=centerme" width="80%"></p>
<h3 id="scaling-strategy">Scaling strategy</h3>
<p>scale-up 할 수 있는 hyperparameter의 값을 조절해가며 실험하였다.
training steps, batch size, model size 를 조절한 결과, model size 를
키우고 training steps 을 늘린 경우에 가장 좋은 성능을 보였다.</p>
<p><img src="/assets/images/t5-scaling-result.png?style=centerme" width="80%"></p>
<h2 id="conclusions">Conclusions</h2>
<p>위의 여러 실험들의 결과를 종합하면, <strong>1) Encoder-Decoder
architecture 2) Span prediction objective 3) C4 dataset 4) Multi-task
pre-training 5) Bigger models trained longer</strong> 의 구조로 학습할
때 가장 좋은 transfer learning 효과를 얻을 수 있다.</p>
<h2 id="references">References</h2>
<p>[1] https://youtu.be/eKqWC577WlI <br> [2]
https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html</p>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/ML/">ML</a><a class="link-muted mr-2" rel="tag" href="/tags/NLP/">NLP</a><a class="link-muted mr-2" rel="tag" href="/tags/paper/">paper</a><a class="link-muted mr-2" rel="tag" href="/tags/LM/">LM</a><a class="link-muted mr-2" rel="tag" href="/tags/Google/">Google</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/11/14/Social-bias-in-NLP-models/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Social Bias in NLP Models</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/07/20/Zero-to-one-by-peter/"><span class="level-item">Zero to One (제로투원)</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://inmoonlight.github.io/2020/08/29/Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/';
            this.page.identifier = '2020/08/29/Exploring-the-Limits-of-Transfer-Learning-with-a-Unified-Text-to-Text-Transformer/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'inmoonlight' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#transfer-learning-framework-text-to-text-transfer-transformer-t5"><span class="mr-2">1</span><span>Transfer
learning framework: Text-to-Text Transfer Transformer (T5)</span></a></li><li><a class="is-flex" href="#pre-training-dataset-colossal-clean-crawled-corpus-c4"><span class="mr-2">2</span><span>Pre-training
dataset: Colossal Clean Crawled Corpus (C4)</span></a></li><li><a class="is-flex" href="#main-contributions-of-the-paper"><span class="mr-2">3</span><span>Main Contributions of the
paper</span></a><ul class="menu-list"><li><a class="is-flex" href="#pre-training-architecture"><span class="mr-2">3.1</span><span>Pre-training architecture</span></a><ul class="menu-list"><li><a class="is-flex" href="#encoder-decoder-baseline-vs.-language-model-vs.-prefix-lm"><span class="mr-2">3.1.1</span><span>Encoder-Decoder
(Baseline) vs. Language Model vs. Prefix LM</span></a></li></ul></li><li><a class="is-flex" href="#pre-training-objective"><span class="mr-2">3.2</span><span>Pre-training objective</span></a><ul class="menu-list"><li><a class="is-flex" href="#high-level-approaches"><span class="mr-2">3.2.1</span><span>High-level approaches</span></a></li><li><a class="is-flex" href="#corruption-strategies"><span class="mr-2">3.2.2</span><span>Corruption strategies</span></a></li><li><a class="is-flex" href="#corruption-rate"><span class="mr-2">3.2.3</span><span>Corruption rate</span></a></li><li><a class="is-flex" href="#random-spans"><span class="mr-2">3.2.4</span><span>Random spans</span></a></li></ul></li><li><a class="is-flex" href="#pre-training-dataset"><span class="mr-2">3.3</span><span>Pre-training Dataset</span></a></li><li><a class="is-flex" href="#pre-training-datasize"><span class="mr-2">3.4</span><span>Pre-training datasize</span></a></li><li><a class="is-flex" href="#training-strategy"><span class="mr-2">3.5</span><span>Training strategy</span></a><ul class="menu-list"><li><a class="is-flex" href="#fine-tuning-methods"><span class="mr-2">3.5.1</span><span>Fine-tuning methods</span></a></li><li><a class="is-flex" href="#multi-task-learning-pre-training"><span class="mr-2">3.5.2</span><span>Multi-task learning
(pre-training)</span></a></li><li><a class="is-flex" href="#combining-fine-tuning-and-multi-task-learning"><span class="mr-2">3.5.3</span><span>Combining
fine-tuning and multi-task learning</span></a></li></ul></li><li><a class="is-flex" href="#scaling-strategy"><span class="mr-2">3.6</span><span>Scaling strategy</span></a></li></ul></li><li><a class="is-flex" href="#conclusions"><span class="mr-2">4</span><span>Conclusions</span></a></li><li><a class="is-flex" href="#references"><span class="mr-2">5</span><span>References</span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Book/"><span class="level-start"><span class="level-item">Book</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Essay/"><span class="level-start"><span class="level-item">Essay</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">12</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/ML/Data-Analysis/"><span class="level-start"><span class="level-item">Data Analysis</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/ML/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/ML/PyTorch/"><span class="level-start"><span class="level-item">PyTorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/ML/Quantum-Computing/"><span class="level-start"><span class="level-item">Quantum Computing</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Ops/"><span class="level-start"><span class="level-item">Ops</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Ops/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Paper/"><span class="level-start"><span class="level-item">Paper</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time datetime="2021-07-10T16:03:00.000Z">2021-07-11</time></p><p class="title is-6"><a class="link-muted" href="/2021/07/11/Git-merge-strategy/">Git의 다양한 머지 전략 비교 - 우리 팀은 어떤 전략을 도입해야 할까?</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Ops/">Ops</a> / <a class="link-muted" href="/categories/Ops/Git/">Git</a></p></div></article><article class="media"><div class="media-content size-small"><p><time datetime="2021-03-02T19:22:00.000Z">2021-03-03</time></p><p class="title is-6"><a class="link-muted" href="/2021/03/03/PyTorch-view-transpose-reshape/">PyTorch의 view, transpose, reshape 함수의 차이점 이해하기</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/ML/">ML</a> / <a class="link-muted" href="/categories/ML/PyTorch/">PyTorch</a></p></div></article><article class="media"><div class="media-content size-small"><p><time datetime="2021-02-21T14:22:00.000Z">2021-02-21</time></p><p class="title is-6"><a class="link-muted" href="/2021/02/21/PyTorch-IterableDataset/">PyTorch의 IterableDataset을 사용해서 데이터 불러오기</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/ML/">ML</a> / <a class="link-muted" href="/categories/ML/PyTorch/">PyTorch</a></p></div></article><article class="media"><div class="media-content size-small"><p><time datetime="2021-02-04T05:22:00.000Z">2021-02-04</time></p><p class="title is-6"><a class="link-muted" href="/2021/02/04/Pandas-Dataframe-iterations/">Pandas Dataframe의 다양한 iteration 방법 비교</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/ML/">ML</a></p></div></article><article class="media"><a class="media-left" href="/2021/01/10/Adieu-2020-and-happy-new-year/"><p class="image is-64x64"><img class="thumbnail" src="/assets/images/2020-2021.jpg" alt="2020년을 정리하고, 2021년을 맞이하는 글"></p></a><div class="media-content size-small"><p><time datetime="2021-01-10T12:13:00.000Z">2021-01-10</time></p><p class="title is-6"><a class="link-muted" href="/2021/01/10/Adieu-2020-and-happy-new-year/">2020년을 정리하고, 2021년을 맞이하는 글</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Essay/">Essay</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/space_moon.png" alt="Space Moon" height="28"></a><p class="size-small"><span>&copy; 2024 Jihyung Moon</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://inmoonlight.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>