<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.1"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Positional Encoding in NLP - Space Moon</title><meta description="Positional encoding 혹은 position encoding은 모델 구조에서 자연스럽게 sequential information을 얻지 못하는 경우에 대해 정보를 강제하는 방식이다. 보통 sequential data를 Recurrent Neural Network (RNN) 외의 다른 모델로 다루고 싶을 때 많이 사용된다. 이번 글에서는 Conv"><meta property="og:type" content="blog"><meta property="og:title" content="Positional Encoding in NLP"><meta property="og:url" content="https://inmoonlight.github.io/2020/01/26/Positional-Encoding/"><meta property="og:site_name" content="Space Moon"><meta property="og:description" content="Positional encoding 혹은 position encoding은 모델 구조에서 자연스럽게 sequential information을 얻지 못하는 경우에 대해 정보를 강제하는 방식이다. 보통 sequential data를 Recurrent Neural Network (RNN) 외의 다른 모델로 다루고 싶을 때 많이 사용된다. 이번 글에서는 Conv"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://inmoonlight.github.io/assets/images/positional_encoding.png"><meta property="article:published_time" content="2020-01-26T08:00:00.000Z"><meta property="article:modified_time" content="2023-11-02T02:50:49.147Z"><meta property="article:author" content="Jihyung Moon"><meta property="article:tag" content="ML"><meta property="article:tag" content="NLP"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/assets/images/positional_encoding.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://inmoonlight.github.io/2020/01/26/Positional-Encoding/"},"headline":"Space Moon","image":["https://inmoonlight.github.io/assets/images/positional_encoding.png"],"datePublished":"2020-01-26T08:00:00.000Z","dateModified":"2023-11-02T02:50:49.147Z","author":{"@type":"Person","name":"Jihyung Moon"},"description":"Positional encoding 혹은 position encoding은 모델 구조에서 자연스럽게 sequential information을 얻지 못하는 경우에 대해 정보를 강제하는 방식이다. 보통 sequential data를 Recurrent Neural Network (RNN) 외의 다른 모델로 다루고 싶을 때 많이 사용된다. 이번 글에서는 Conv"}</script><link rel="canonical" href="https://inmoonlight.github.io/2020/01/26/Positional-Encoding/"><link rel="icon" href="/img/favicon.ico"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-131297969-1" async></script><script><!-- hexo-inject:begin --><!-- hexo-inject:end -->window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-131297969-1');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><link rel="alternate" href="/feed.xml" title="Space Moon" type="application/atom+xml"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/space_moon.png" alt="Space Moon" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="external nofollow noopener noreferrer" title="Download on GitHub" href="https://github.com/inmoonlight"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-9-tablet is-9-desktop is-9-widescreen"><div class="card"><div class="card-image"><span class="image is-7by3"><img class="thumbnail" src="/assets/images/positional_encoding.png" alt="Positional Encoding in NLP"></span></div><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" datetime="2020-01-26T08:00:00.000Z" title="2020-01-26T08:00:00.000Z">2020-01-26</time><span class="level-item"><a class="link-muted" href="/categories/ML/">ML</a><span> / </span><a class="link-muted" href="/categories/ML/NLP/">NLP</a></span><span class="level-item">12 minutes read (About 1860 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">Positional Encoding in NLP</h1><div class="content"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><!-- hexo-inject:begin --><!-- hexo-inject:end -->Positional encoding 혹은 position encoding은 모델 구조에서 자연스럽게
sequential information을 얻지 못하는 경우에 대해 정보를 강제하는
방식이다. 보통 sequential data를 Recurrent Neural Network (RNN) 외의
다른 모델로 다루고 싶을 때 많이 사용된다. 이번 글에서는 Convolutional
Neural Network (CNN), End-to-End Memory Network (MemN2N),
Transformer에서 sentence embedding을 위해 사용된 positional encoding에
대해 소개하려고 한다. <a id="more"></a></p>
<h2 id="introduction">Introduction</h2>
<p>일반적으로 NLP 모델은 각 문장을 구성하는 token을 one-hot vector가
아닌 distributed vector로 표현한다. 그 이유는 distributed
representation이 1) 비슷한 의미지만 다른 lexical form을 가진 token을 더
잘 표현할 수 있기 때문이고, 2) embedding dimension을 감소시킬 수 있기
때문이다.</p>
<p>문장의 embedding은 문장을 이루는 각 token의 embedding을 조합하는
방식으로 얻어진다. 이 때 position에 대한 정보가 없다면 모델은
<code>handful of chocolate</code>과 <code>chocolate of handful</code>을
같은 의미로 인식하게 된다. RNN은 모델 구조 자체에 time information이
녹아져 있다. 그래서 <code>handful --&gt; of --&gt; chocolate</code> 의
순서가 담긴 sentence embedding을 자연스럽게 얻을 수 있다. 반면 CNN이나
Attention 기반의 Transformer는 순서에 대한 정보를 강제해야 하고, 이 때
positional encoding이 사용된다.</p>
<p>Positional encoding (PE) 은 token embedding vector에 곱해지는 정보로,
sentence에서 해당 token이 어디에 위치해 있는지를 나타낸다. J개의 token
\(t_j \in \mathbb{R}^d\)으로 구성된 sentence \(s = [t_1, t_2, ...,
t_J]\)가 있다고 하자. PE \(\in \mathbb{R}^{J \times d}\) 의 row
\(j\)마다 다른 값을 가지도록 하여 문장 맨 처음의 <code>handful</code>과
맨 뒤의 <code>handful</code>을 다르게 인식하도록 한다.</p>
<p>PE를 구성하는 방식에는 크게 두 종류가 있다. 하나는 학습기반, 다른
하나는 position과 dimension을 입력으로 한 함수를 이용하는 방법이다.</p>
<h2 id="learned-positional-embeddings">Learned Positional
Embeddings</h2>
<p>학습기반의 PE를 구성하는 방식은 Convolutional Sequence to Sequence
Learning (ConvS2S)<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[https://arxiv.org/abs/1705.03122](https://arxiv.org/abs/1705.03122)
">[1]</span></a></sup>에서 사용되었다. 평균 0, 표준편차 0.1을 따르는
normal distribution으로 initialize되고 학습을 통해 position 정보를
배우길 기대한다.</p>
<p>PE를 encoder와 decoder 모두에 사용한 경우, encoder에만 사용한 경우,
decoder에만 사용한 경우, 아예 사용하지 않은 경우로 나누어 번역 task에
실험해보았을 때의 결과는 다음과 같다.</p>
<p><img src="/assets/images/learned_pe_table.png?style=centerme" width="50%"></p>
<p>BLEU를 기준으로 분석해보면 encoder에서의 PE역할이 decoder보다 조금 더
중요하다. PE를 아예 쓰지 않을 때의 점수가 가장 낮지만 점수 차이를
생각해보면 모델 성능에는 크게 영향을 미치지 않는다고 해석해 볼 수
있다.</p>
<p>학습 기반이므로 학습 시 다루지 않았던 길이의 문장이 입력으로 들어온
경우, 외삽이 불가능하다는 단점이
있다.<sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)">[5]</span></a></sup></p>
<h2 id="function-based-positional-encoding">Function-based Positional
Encoding</h2>
<p>함수 기반의 PE는 문장에서 몇 번째에 위치한 토큰인지, 토큰의 embedding
dimension이 무엇인지를 정해주면 값이 정해진다. 이 때, 다른 위치의 정보가
같은 값으로 mapping되지 않아야 한다. 어떻게 구현할 수 있을까?</p>
<h3 id="the-intuition">The Intuition</h3>
<p>0부터 15까지의 숫자를 2진법으로 나타내보자.</p>
<p><img src="/assets/images/PE_intuition.png?style=centerme" width="55%"></p>
<p>다른 색으로 구분지어 표현한 2진수의 자리수마다 다른 주기를 가지는
것을 볼 수 있다. 붉은색은 주기가 1이고, 노란색은 주기가 2, 초록색은
주기가 4, 파란색은 주기가 8이다.</p>
<p>위 예시에서의 자리수를 embedding dimension이라고 생각해보면 PE에도
같은 원리를 확장시켜볼 수 있다.</p>
<h3 id="in-memn2n">In MemN2N</h3>
<p>End-to-End Memory Network
(MemN2N)<sup id="fnref:4"><a href="#fn:4" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[https://github.com/inmoonlight/notebooks/blob/master/notebooks/2020-01-26-MemN2N-Position-Encoding.ipynb](https://github.com/inmoonlight/notebooks/blob/master/notebooks/2020-01-26-MemN2N-Position-Encoding.ipynb)
">[4]</span></a></sup>에서는 아래의 함수를 사용했다.</p>
<p>\[PE_{k j}=(1- \frac{j}{J})-\frac{k}{d}(1- \frac{2j}{J})\]</p>
<p>\[j \in {1, ..., J}\]</p>
<p>\[k \in {1, ..., D}\]</p>
<p>임의의 문장 <em>"The same representation is used for questions,
memory inputs and memory outputs."</em>에 적용되는 PE를 시각화해보면
다음과 같다.<sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)">[5]</span></a></sup></p>
<p><img src="/assets/images/PE_example_1.png?style=centerme" width="90%"></p>
<p>여기서는 dimension에 관계없이 같은 주기를 가지지만 시작값이 전부
다르다. 결과적으로는 position마다 다른 vector를 곱하게 되어 position
정보를 전달할 수 있다.</p>
<p>다른 문장 길이를 가지는 경우에 대해서 적용해보면 어떨까? 이번에는
<em>"We therefore propose a second representation that encodes the
position of words within the sentence."</em>에 대해
시각해보았다.<sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)">[5]</span></a></sup></p>
<p><img src="/assets/images/PE_example_2.png?style=centerme" width="90%"></p>
<p>position이 늘어난만큼 position encoding 값의 변화도가 줄었다. J는
문장마다 달라지므로 첫번째, 두번째의 절대적인 위치보다는 각 순서를
구분짓기 위한 목적에 치중하였다.</p>
<p>ConvS2S에서와는 달리 MemN2N에서 PE의 효과는 꽤나 컸던 것으로
보인다.</p>
<p><img src="/assets/images/MemN2N_PE.png?style=centerme" width="90%"></p>
<h3 id="in-transformer">In Transformer</h3>
<p>Attention is all you
need<sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top hint--error hint--medium hint--rounded hint--bounce" aria-label="[https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf](https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf)">[5]</span></a></sup>에서
사용된 PE는 <strong>주기</strong>함수로 유명한 sin 함수와 cos 함수를
기반으로 한다. (a.k.a, sinusoidal functions)</p>
<p>\[ \begin{aligned} P E_{(\text {pos, 2k} )} &amp;=\sin \left(\text
{pos} / 10000^{2 k / d}\right) \\ P E_{(\text {pos,2k+1})} &amp;=\cos
\left(\text {pos} / 10000^{2 k / d}\right) \end{aligned} \]</p>
<p>잠시 고등학교 때 배운 수학을 떠올려보자. \(sin(ax + b)\) 의 주기는
\(\frac{2\pi}{|a|}\) 이다. 따라서 PE의 특정 position vector 값의 주기는
\(2\pi \cdot 10000^{2 k / d}\) 와 같다.</p>
<p>MemN2N에서의 PE와는 달리, position vector의 주기가 vector의
dimension마다 변화한다. 전체 벡터 크기(\(d\))가 128이라고 가정할 때,
\(k\)가 작을수록 주기가 짧고 \(k\)가 클수록 주기도 길어진다. (아래 그림
참고)</p>
<p><img src="/assets/images/positional_encoding.png?style=centerme" width="85%" alt="Image credit: https://kazemnejad.com/blog/transformer_architecture_positional_encoding"></p>
<p>왜 Transformer에서는 MemN2N과 다르게 sinusoidal 함수를 썼을까?
논문에서 그 이유를 짧게 기술하고 있다.</p>
<blockquote>
<p>We chose this function because we hypothesized it would allow the
model to easily learn to attend by relative positions, since for any
fixed offset \(k\), \(P E_{pos+k}\) can be represented as a linear
function of \(P E_{pos}\).</p>
</blockquote>
<p>sinusodial 함수의 특징을 이용해 첫번째, 두번째마다 같은 position
정보를 주면서도 \(n + k\)번째 vector가 \(n\)번째 vector와 관계가 있을 때
이를 학습할 수 있는 여지를 남겨주기 위함이다. (참고로 이에 대한 수학적인
증명은 <a href="https://timodenk.com/blog/linear-relationships-in-the-transformers-positional-encoding/" rel="external nofollow noopener noreferrer" target="_blank">이
article</a>에 기술되어 있다.)</p>
<p>또한 PE vector 간의 distance는 대칭적이고 거리에 따라 일정한 비율로
감소한다. Transformer의 self-attention 연산에서 빛을 발하는
특징이다.</p>
<p><img src="/assets/images/PE_pros_1.png?style=centerme" width="50%" alt="Image credit: https://kazemnejad.com/blog/transformer_architecture_positional_encoding"></p>
<h2 id="conclusions">Conclusions</h2>
<p>PE는 크게 학습을 통해 정해질 수 있고 미리 지정한 함수로 정해질 수도
있다. 학습을 통한 방식은 학습시 보지 않았던 새로운 길이가 등장했을 때
외삽이 불가능하지만 함수 기반의 PE는 가능하다. 함수도 어떤 함수를
쓰느냐에 따라 종류가 구분되는데, 절대적인 위치에 따라 같은 값을
가지면서도 상대적 위치의 관계도 학습할 수 있는 \(sin\)과 \(cos\) 기반의
함수가 가장 좋은 방법이라고 생각된다.</p>
<h2 id="references">References</h2>
<div id="footnotes">
<hr>
<div id="footnotelist">
<ol style="list-style: none; padding-left: 0; margin-left: 40px">
<li id="fn:1">
<span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a href="https://arxiv.org/abs/1705.03122" rel="external nofollow noopener noreferrer" target="_blank">https://arxiv.org/abs/1705.03122</a><a href="#fnref:1" rev="footnote">
↩︎</a></span>
</li>
<li id="fn:2">
<span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/" rel="external nofollow noopener noreferrer" target="_blank">https://kazemnejad.com/blog/transformer_architecture_positional_encoding/</a><a href="#fnref:2" rev="footnote">
↩︎</a></span>
</li>
<li id="fn:3">
<span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a href="https://arxiv.org/abs/1503.08895" rel="external nofollow noopener noreferrer" target="_blank">https://arxiv.org/abs/1503.08895</a><a href="#fnref:3" rev="footnote">
↩︎</a></span>
</li>
<li id="fn:4">
<span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">4.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a href="https://github.com/inmoonlight/notebooks/blob/master/notebooks/2020-01-26-MemN2N-Position-Encoding.ipynb" rel="external nofollow noopener noreferrer" target="_blank">https://github.com/inmoonlight/notebooks/blob/master/notebooks/2020-01-26-MemN2N-Position-Encoding.ipynb</a><a href="#fnref:4" rev="footnote">
↩︎</a></span>
</li>
<li id="fn:5">
<span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">5.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;"><a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf" rel="external nofollow noopener noreferrer" target="_blank">https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf</a><a href="#fnref:5" rev="footnote">
↩︎</a></span>
</li>
</ol>
</div>
</div>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/ML/">ML</a><a class="link-muted mr-2" rel="tag" href="/tags/NLP/">NLP</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/01/27/Attention-in-NLP/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Attention in NLP</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/01/07/The-past-of-the-light-by-Eun-hee-kyung/"><span class="level-item">빛의 과거</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://inmoonlight.github.io/2020/01/26/Positional-Encoding/';
            this.page.identifier = '2020/01/26/Positional-Encoding/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'inmoonlight' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="is-flex" href="#introduction"><span class="mr-2">1</span><span>Introduction</span></a></li><li><a class="is-flex" href="#learned-positional-embeddings"><span class="mr-2">2</span><span>Learned Positional
Embeddings</span></a></li><li><a class="is-flex" href="#function-based-positional-encoding"><span class="mr-2">3</span><span>Function-based Positional
Encoding</span></a><ul class="menu-list"><li><a class="is-flex" href="#the-intuition"><span class="mr-2">3.1</span><span>The Intuition</span></a></li><li><a class="is-flex" href="#in-memn2n"><span class="mr-2">3.2</span><span>In MemN2N</span></a></li><li><a class="is-flex" href="#in-transformer"><span class="mr-2">3.3</span><span>In Transformer</span></a></li></ul></li><li><a class="is-flex" href="#conclusions"><span class="mr-2">4</span><span>Conclusions</span></a></li><li><a class="is-flex" href="#references"><span class="mr-2">5</span><span>References</span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Book/"><span class="level-start"><span class="level-item">Book</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Essay/"><span class="level-start"><span class="level-item">Essay</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/ML/"><span class="level-start"><span class="level-item">ML</span></span><span class="level-end"><span class="level-item tag">12</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/ML/Data-Analysis/"><span class="level-start"><span class="level-item">Data Analysis</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/ML/NLP/"><span class="level-start"><span class="level-item">NLP</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/ML/PyTorch/"><span class="level-start"><span class="level-item">PyTorch</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/ML/Quantum-Computing/"><span class="level-start"><span class="level-item">Quantum Computing</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Ops/"><span class="level-start"><span class="level-item">Ops</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Ops/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Paper/"><span class="level-start"><span class="level-item">Paper</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Startup/"><span class="level-start"><span class="level-item">Startup</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time datetime="2024-01-13T12:13:00.000Z">2024-01-13</time></p><p class="title is-6"><a class="link-muted" href="/2024/01/13/Lessons-learned-in-my-first-2-years-as-a-startup-founder/">Lessons learned in my first 2 years as a startup founder</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Startup/">Startup</a></p></div></article><article class="media"><div class="media-content size-small"><p><time datetime="2021-07-10T16:03:00.000Z">2021-07-11</time></p><p class="title is-6"><a class="link-muted" href="/2021/07/11/Git-merge-strategy/">Git의 다양한 머지 전략 비교 - 우리 팀은 어떤 전략을 도입해야 할까?</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/Ops/">Ops</a> / <a class="link-muted" href="/categories/Ops/Git/">Git</a></p></div></article><article class="media"><div class="media-content size-small"><p><time datetime="2021-03-02T19:22:00.000Z">2021-03-03</time></p><p class="title is-6"><a class="link-muted" href="/2021/03/03/PyTorch-view-transpose-reshape/">PyTorch의 view, transpose, reshape 함수의 차이점 이해하기</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/ML/">ML</a> / <a class="link-muted" href="/categories/ML/PyTorch/">PyTorch</a></p></div></article><article class="media"><div class="media-content size-small"><p><time datetime="2021-02-21T14:22:00.000Z">2021-02-21</time></p><p class="title is-6"><a class="link-muted" href="/2021/02/21/PyTorch-IterableDataset/">PyTorch의 IterableDataset을 사용해서 데이터 불러오기</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/ML/">ML</a> / <a class="link-muted" href="/categories/ML/PyTorch/">PyTorch</a></p></div></article><article class="media"><div class="media-content size-small"><p><time datetime="2021-02-04T05:22:00.000Z">2021-02-04</time></p><p class="title is-6"><a class="link-muted" href="/2021/02/04/Pandas-Dataframe-iterations/">Pandas Dataframe의 다양한 iteration 방법 비교</a></p><p class="is-uppercase"><a class="link-muted" href="/categories/ML/">ML</a></p></div></article></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/space_moon.png" alt="Space Moon" height="28"></a><p class="size-small"><span>&copy; 2024 Jihyung Moon</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="external nofollow noopener noreferrer">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="external nofollow noopener noreferrer">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="external nofollow noopener noreferrer" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://inmoonlight.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/mhchem.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><!-- hexo-inject:begin --><!-- hexo-inject:end --></body></html>