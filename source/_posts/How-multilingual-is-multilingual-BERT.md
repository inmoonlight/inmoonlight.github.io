---
title: "How multilingual is Multilingual BERT?"
layout: post
date: 2020-06-20 17:00
tags:
- ML
- NLP
- paper
- review
- BERT
categories: 
- Review
- Paper
toc: true
widgets:
   - type: toc
     position: left
   - type: categories
     position: left
   - type: recent_posts
     position: left
---

"How multilingual is Multilingual BERT?"[^1] ëŠ” ACL 2019 ì— ì–µì…‰ëœ ë…¼ë¬¸ìœ¼ë¡œ, Telmo Pires ê°€ Google AI Residency í”„ë¡œê·¸ë¨ ì¤‘ì— ì‘ì„±í•˜ì˜€ë‹¤. Unbabel ì—ì„œ Autumatic Post-Editing (APE) ìª½ ì—°êµ¬ë¥¼ ì§„í–‰í–ˆì—ˆë˜ ì—°êµ¬ìì˜€ê³ , ê·¸ë˜ì„œ multilingual BERTì— ëŒ€í•´ ë¶„ì„í•œ ë…¼ë¬¸ì„ ì“´ ê²ƒì´ ì•„ë‹ê¹Œ?
<!--more-->


## Abstract
In this paper, we show that Multilingual BERT (`M-BERT`), released by Devlin et al. (2018) as a single language model pre-trained from monolingual corpora in 104 languages, is **surprisingly good at zero-shot cross-lingual model transfer**, in which task-specific annotations in one language are used to fine-tune the model for evaluation in another language. To understand why, we present a large number of probing experiments, showing that **transfer is possible even to languages in different scripts**, that **transfer works best between typologically similar languages**, that monolingual corpora can train models for code-switching, and that the model can find translation pairs. From these results, we can conclude that `M-BERT` does create multilingual representations, but that these representations exhibit systematic deficiencies affecting certain language pairs.


## Motivation
Pretrained LM ì´ ë‹¤ì–‘í•œ NLP downstream task ì—ì„œ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ì—ˆë‹¤. Pretrained LMì˜ probing ì—°êµ¬ë“¤ì€ ëª¨ë¸ì´ í•™ìŠµí•œ representation ì´ syntactic and named entity ì—ì„œ íŠ¹íˆ ìœ ìš©í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ë³´ì—¬ì£¼ì—ˆì§€ë§Œ, ì´ ì—°êµ¬ë“¤ì€ ì˜ì–´ì— ëŒ€í•´ì„œë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ ì§„í–‰ë˜ì–´ ì™”ë‹¤. (2019 ë…„ 6ì›” ê¸°ì¤€) (ì°¸ê³ ë¡œ, BERT ëŠ” 2018ë…„ 11ì›”ì— ì²« release) 



## Main Idea
ì˜ì–´ì— ëŒ€í•´ì„œ Pretrained LMì´ ê°€ì§€ê³  ìˆëŠ” ì •ë³´, ê·¸ ì¤‘ì—ì„œë„ syntactic and named entity information ì´ ì–¸ì–´ì— ìƒê´€ì—†ì´ ì˜ generalize ë˜ëŠ”ì§€ ë¶„ì„
- Main task: NER, POS
- Main method: Zero-shot cross-lingual transfer (Multilingual BERT ëª¨ë¸ì„ í•œ ì–¸ì–´ì— ëŒ€í•´ finetuning ì‹œí‚¤ê³ , ë‹¤ë¥¸ ì–¸ì–´ì— ëŒ€í•´ ê°™ì€ taskì˜ ì„±ëŠ¥ì„ í‰ê°€)



## Main Findings
* ì•„ë˜ ë‚´ìš©ìœ¼ë¡œ í•™ìŠµí•œ Multilingual BERT (`M-BERT`) ëŠ” NERê³¼ POS task ì— ëŒ€í•´ cross-lingual transfer ability ê°€ ì¢‹ë‹¤.
    - language identifier ì—†ì´ 
    - ìœ„í‚¤í”¼ë””ì•„ì˜ ë¬¸ì„œë¡œ í•™ìŠµ (140 ê°œ ì–¸ì–´)
    - w/ shared word piece vocab

- ëª¨ë“  ì–¸ì–´ìŒì— ëŒ€í•´ zero-shot transfer ê°€ ì˜ ëœ ê²ƒì€ ì•„ë‹ˆì—ˆëŠ”ë° ê·¸ë ‡ë‹¤ë©´ ì™œ ì´ëŸ° ì°¨ì´ê°€ ë°œìƒí• ê¹Œ?
    - finetuning ì–¸ì–´ì™€ evaluation ì–¸ì–´ì˜ vocab overlap ë•Œë¬¸ì€ ì•„ë‹˜
    - ì˜¤íˆë ¤ ì–¸ì–´ì˜ typological íŠ¹ì§• ë•Œë¬¸
      - typological íŠ¹ì§•ë„ ì—¬ëŸ¬ ì¢…ë¥˜ê°€ ìˆëŠ”ë° (ì—¬ê¸°ì„œëŠ” subject/object/verb order, adjective/noun orderì— ëŒ€í•´ì„œë§Œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤Œ), ê·¸ ì¤‘ **SVO order** ì— ê°€ì¥ í° ì˜í–¥ì„ ë°›ìŒ
    - transfer í•˜ê¸° ìœ„í•œ ì–¸ì–´ì— ëŒ€í•´ í•™ìŠµí•œ ì ì´ ìˆì„ ë•Œ transfer ê°€ëŠ¥
    - `M-BERT` ì˜ ì¤‘ê°„ layer (8/12) ì—ì„œ  cross-lingual information ì´ ë†’ìŒ


## Detailed Experiments and Results

Main Question: ë¬´ì—‡ì´ `M-BERT`ì˜ zero-shot cross-lingual transferabilityë¥¼ ë§Œë“¤ì–´ë‚´ëŠ”ê°€?


### Preliminaries
#### NER task
  - dataset: [CoNLL-2002](https://www.clips.uantwerpen.be/conll2002/ner/), [2003 dataset](https://www.clips.uantwerpen.be/conll2003/ner/), Google in-house dataset
    - There are four types of phrases: person names (`PER`), organizations (`ORG`), locations (`LOC`) and miscellaneous names (`MISC`)
  - lang: `nl`, `es` (2002) / `en`, `de` (2003) ì´ 4ê°œ + in-house dataset with 16 languages (Arabic, Bengali, Czech, German, English, Spanish, French, Hindi, Indonesian, Italian, Japanese, Korean, Portuguese, Russian, Turkish, and Chinese)
  - example (`en`)
     - NER tagged plain text: 
```
[PER Wolff ] , currently a journalist in [LOC Argentina ] , played with [PER Del Bosque ] in the final years of the seventies in [ORG Real Madrid ] .
```
     - NER data:
```
        Wolff B-PER
            , O
    currently O
            a O
   journalist O
           in O
    Argentina B-LOC
            , O
       played O
         with O
          Del B-PER
       Bosque I-PER
           in O
          the O
        final O
        years O
           of O
          the O
    seventies O
           in O
         Real B-ORG
       Madrid I-ORG
            . O
```

#### POS task
- dataset: Universal Dependencies (UD) data (Universal dependencies v1: A multilingual treebank collection, Nivre, 2019) for 41 languages
  - Arabic, Bulgarian, Catalan, Czech, Danish, German, Greek, English, Spanish, Estonian, Basque, Persian, Finnish, French, Galician, Hebrew, Hindi, Croatian, Hungarian, Indonesian, Italian, Japanese, Korean, Latvian, Marathi, Dutch, Norwegian (Bokmaal and Nynorsk), Polish, Portuguese (European and Brazilian), Romanian, Russian, Slovak, Slovenian, Swedish, Tamil, Telugu, Turkish, Urdu, and Chinese
- evaluation set: Multilingual Parsing from Raw Text to Universal Dependencies, Zemman et al. 2017 (CoNLL 2017 shared Task)
  - [example (`ko`)](https://raw.githubusercontent.com/UniversalDependencies/UD_Korean-PUD):
```
# sent_id = n01007012
# text = ì´ ë¶€ë¶„ì—ì„œ ê²Œì„ê³¼ ìš°ë¦¬ ì¼ìƒ ìƒí™œ ì‚¬ì´ì˜ ìœ ì‚¬ì ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# text_en = There are parallels to draw here between games and our everyday lives.
# translit = .i .bu.bun.e.seo .ge.im.gwa .u.ri .il.sang .saeng.hwal .sa.i.yi .yu.sa.jeom.eul .chaj.eul .su .iss.seub.ni.da.
1	ì´	_	DET	DT	_	2	det	_	Translit=.i|LTranslit=_
2	ë¶€ë¶„ì—ì„œ	ë¶€ë¶„	NOUN	NN+CM	Case=Advb|Polite=Form	9	advmod	_	MSeg=ë¶€ë¶„-ì—ì„œ|Translit=.bu.bun.e.seo|LTranslit=.bu.bun
3	ê²Œì„ê³¼	ê²Œì„	NOUN	NN+CP	Polite=Form	7	compound	_	MSeg=ê²Œì„-ê³¼|Translit=.ge.im.gwa|LTranslit=.ge.im
4	ìš°ë¦¬	_	PRON	PRP	Person=1	6	compound	_	Translit=.u.ri|LTranslit=_
5	ì¼ìƒ	_	NOUN	NN	_	6	compound	_	Translit=.il.sang|LTranslit=_
6	ìƒí™œ	_	NOUN	NN	_	3	conj	_	Translit=.saeng.hwal|LTranslit=_
7	ì‚¬ì´ì˜	ì‚¬ì´	NOUN	NN+CM	Case=Gen|Polite=Form	8	nmod:poss	_	MSeg=ì‚¬ì´-ì˜|Translit=.sa.i.yi|LTranslit=.sa.i
8	ìœ ì‚¬ì ì„	ìœ ì‚¬ì 	NOUN	NN+CM	Case=Acc|Polite=Form	9	obj	_	MSeg=ìœ ì‚¬ì -ì„|Translit=.yu.sa.jeom.eul|LTranslit=.yu.sa.jeom
9	ì°¾ì„	_	VERB	VV	Form=Adn	10	acl:relcl	_	Translit=.chaj.eul|LTranslit=_
10	ìˆ˜	_	NOUN	NNB	_	11	nsubj	_	Translit=.su|LTranslit=_
11	ìˆìŠµë‹ˆë‹¤	_	ADJ	JJ	Mood=Ind|VerbForm=Fin	0	root	_	SpaceAfter=No|Translit=.iss.seub.ni.da|LTranslit=_
12	.	.	PUNCT	.	_	11	punct	_	Translit=.|LTranslit=_
```

#### Code-switching (CS) and Transliterate (Tlit) task
- Code-switching: ì—¬ëŸ¬ ì–¸ì–´ê°€ í•œ ë¬¸ì¥ì— ë“±ì¥í•˜ëŠ” ê²½ìš°
  - ex)  `I thought à¤®à¥Œà¤¸à¤® different à¤¹à¥‹à¤—à¤¾ à¤¬à¤¸ fog à¤¹à¥ˆ`
- Tlit: ìŒì°¨ í‘œê¸°
  - ex) `I thought mosam different hoga bas fog hy`

---

### `M-BERT` ì˜ cross-lingual transferability ëŠ” vocab overlap ë•Œë¬¸ì¼ê¹Œ? â†’ NO
- vocab overlap: fine-tuning dataset (train) ì˜ word piece ì™€ evaluation dataset (test) ì˜ word piece ê°„ì˜ overlap
  $$overlap = \frac{| E_{train} âˆ© E_{eval} |}{| E_{train} âˆª E_{eval}|}$$
- ê²€ì¦ ë°©ì‹:
  - NER task ì¤‘ 16ê°œì˜ ì–¸ì–´ì— ëŒ€í•œ in-house ë°ì´í„°ì…‹ìœ¼ë¡œ ê°€ëŠ¥í•œ ì–¸ì–´ìŒ (16 * 15 = 240 ê°œ) ì— ëŒ€í•´ overlapì„ êµ¬í•˜ê³ , trasfer score (F1) ë¥¼ report 
  - _**(ê²°ê³¼) `M-BERT`ëŠ” vocab overlap ê³¼ ë¬´ê´€í•˜ê²Œ generally ì„±ëŠ¥ì´ ì¢‹ë‹¤. vocab overlap ì´ 0ì¸ ì–¸ì–´ìŒì— ëŒ€í•´ì„œë„ ìµœì†Œ 40%ì˜ F1 score ë¥¼ ë³´ì¸ë‹¤. ë°˜ë©´ EN-BERT ëŠ” vocab overlap ì— êµ‰ì¥íˆ ë§ì´ ì˜í–¥ì„ ë°›ëŠ”ë‹¤.**_
<img src="https://user-images.githubusercontent.com/24843996/85154700-bfbc9d00-b292-11ea-8f7b-f25ca48b965b.png" width=90% alt="credit) http://www.dhgarrette.com/papers/pires_multilingual_bert_acl2019_slides.pdf">

---

### `M-BERT`ì˜ cross-lingual transferability ëŠ” ì–¸ì–´ì˜ typological íŠ¹ì§• ë•Œë¬¸ì¼ê¹Œ? â†’ YES
- ê·¼ê±°: POS accuracy of `ur` â†’ `hi` (91%) while `en`â†’ `ja` (49.4%) (ë‘˜ ë‹¤ ë‹¤ë¥¸ script ë¥¼ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ìŒ, a.k.a vocab overlap ~= 0)
- typological features[^2]
<img src="https://user-images.githubusercontent.com/24843996/85156077-8553ff80-b294-11ea-8a8d-5478762d6b43.png?style=centerme" width=85% alt="typological features">
<br>

- _**(ê²°ê³¼) ê³µí†µëœ typological feature ì˜ ê°œìˆ˜ê°€ ë§ì„ìˆ˜ë¡ transferabiltiy í–¥ìƒ**_
<img src="https://user-images.githubusercontent.com/24843996/85156248-c3e9ba00-b294-11ea-8ca1-b3e74ea88860.png?style=centerme" width="45%">

- _**(ê²°ê³¼) ì—¬ëŸ¬ typological features ì¤‘ì—ì„œ SOV order ì™€ AN orderì˜ ì˜í–¥ì„ ë¹„êµí–ˆì„ ë•Œ ì „ìê°€ ë” ì˜í–¥ì´ í¼**_
<img src="https://user-images.githubusercontent.com/24843996/85156350-ea0f5a00-b294-11ea-862f-64ab5e3166f3.png?style=centerme" width="50%">


### `M-BERT`ì˜ cross-lingual transferability ëŠ” CS í˜¹ì€ Tlit ê¹Œì§€ ì ìš©ë  ìˆ˜ ìˆì„ê¹Œ? â†’ CS (YES) / Tlit (NO)
- CS ì‹¤í—˜ ëª©ì : Generalizing to code-switching is similar to other cross-lingual transfer scenarios, but would beneï¬t to an even larger degree from a shared multilingual representation.
- Tlit ì‹¤í—˜ ëª©ì : Generalizing to transliterated text is similar to other cross-script transfer experiments, but has the additional caveat that _`M-BERT` was not pre-trained on text that looks like the target_.
- **_(ê²°ê³¼) `M-BERT`ëŠ” CS text ì— ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì„ (90.56% â‡’ 86.59%). í•˜ì§€ë§Œ Tlit ì€ ì´ëŸ¬í•œ ì¢…ë¥˜ì˜ ë°ì´í„°ì— í•™ìŠµë˜ì§€ ì•Šê³ ì„œëŠ” trasferabilityë¥¼ ê¸°ëŒ€í•˜ê¸° ì–´ë ¤ì›€ (85.64% â‡’ 50.41%)_**
<img src="https://user-images.githubusercontent.com/24843996/85159242-34dea100-b298-11ea-9922-3b1acc66ef7b.png?style=centerme" width=60% alt="credit) https://www.youtube.com/watch?v=ZGZy_GrFkAY">

### 4. `M-BERT`ì˜ feature space
- WMT16 ë³‘ë ¬ ì½”í¼ìŠ¤ë¥¼ ì‚¬ìš©í•´ì„œ ì–¸ì–´ìŒ ê°„ì˜ NN accuracy ì¸¡ì •
- **_(ê²°ê³¼) ì¤‘ê°„ layerì—ì„œ linguistic informationì„ ê³µìœ í•˜ê³  ì´ëŠ” ì–¸ì–´ì— ê´€ê³„ì—†ì´ ë¹„ìŠ·í•˜ê²Œ ë‚˜íƒ€ë‚¨_**
<img src="https://user-images.githubusercontent.com/24843996/85160445-7ae83480-b299-11ea-8ff2-3209922e78e7.png?style=centerme" width=45%>


## My Thoughts on the Results
### vocab overlap ì‹¤í—˜ì—ì„œ `EN-BERT`ì™€ì˜ ë¹„êµëŠ” ì •ë‹¹í•œê°€?
- ì œ ì¶”ì¸¡ìœ¼ë¡œëŠ”, vocab overlap ì‹¤í—˜ì—ì„œ `M-BERT` ë§Œì„ ë³´ì•˜ì„ ë•Œ, ì´ ê²½í–¥ì„±ì´ overlapì— ì˜í–¥ì„ ë°›ëŠ” ê²ƒì¸ì§€ ì•„ë‹Œì§€ íŒë‹¨í•˜ê¸° ì–´ë ¤ì› ê¸° ë•Œë¬¸ì— ìƒëŒ€ ë¹„êµë¥¼ í• ë§Œí•œ ê²°ê³¼ê°€ í•„ìš”í•´ì„œ EN-BERTì˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ ë„£ì€ ê²ƒ ê°™ë‹¤.
  - ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ corr ì„ ë³´ë©´ ì–´ëŠ ì •ë„ ìœ ì˜ë¯¸í•´ ë³´ì´ëŠ” ì–‘ì˜ ìƒê´€ê´€ê³„ê°€ ë‚˜ì˜¬ ê²ƒ ê°™ê³ , ê·¸ë ‡ë‹¤ë©´ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ê³  í•´ì„í•´ì•¼í•  ìˆ˜ë„ ìˆì§€ë§Œ,
  - vocab overlapì´ 0ì„ì—ë„ 40%ì˜ ì„±ëŠ¥ì„ ë³´ì´ë¯€ë¡œ ì˜í–¥ì„ ë°›ëŠ”ë‹¤ê³  í•˜ê¸°ë„ ì• ë§¤í•œ ìƒí™©ì´ ì•„ë‹ˆì—ˆì„ê¹Œ?
<img src="https://user-images.githubusercontent.com/24843996/85162060-ac61ff80-b29b-11ea-90a2-7e497a5196a9.png?style=centerme" width=70%>

- ê·¸ë ‡ì§€ë§Œ EN-BERTì™€ì˜ ë¹„êµê°€ ì •ë‹¹í•˜ë‹¤ê³  ìƒê°í•˜ê¸´ ì–´ë ¤ìš´ ê²ƒ ê°™ë‹¤.
  - NER ì˜ˆì¸¡ task ëŠ” sent -> model (either `M-BERT` or EN-BERT) -> last activation -> add.layer -> NER prediciton ë¡œ ì§„í–‰ë˜ëŠ”ë°, sent ê°€ ì˜ì–´ê°€ ì•„ë‹Œ ê²½ìš° tok ë‹¨ê³„ì—ì„œë¶€í„° `unk`ìœ¼ë¡œ ì¸ì‹ë  ê°€ëŠ¥ì„±ì´ ë†’ê¸° ë•Œë¬¸ì— transferëŠ” ê³ ì‚¬í•˜ê³  fine-tuningë„ ì–´ë ¤ìš¸ ìˆ˜ ìˆë‹¤. ì´ ë•Œë¬¸ì— ë…¼ë¬¸ì—ì„œ EN-BERTì™€ XLMì„ ë¹„êµí•˜ëŠ”ë°, Indo-european ì¸ (`de`, `nl`, `es`) ì— ëŒ€í•´ì„œë§Œ ë‚˜ì™€ìˆë‹¤. (Table 3)
  - ì˜ì–´ì™€ alphabet ì´ ë¹„ìŠ·í•˜ë©´, unk ì´ ë‚˜ì˜¤ì§€ ì•Šì„ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ê³  ìƒê°í•´ì„œ ìœ„ì˜ ê²°ê³¼ê°€ EN-BERTë¡œ ì–»ì–´ì§„ ê²ƒì— ëŒ€í•´ í¬ê²Œ ê±°ë¶€ê°ì´ ë“¤ì§€ ì•Šì•˜ê³ , ì˜¤íˆë ¤ CJK ì— ëŒ€í•´ì„œ ë³´ì˜€ì–´ì•¼ í•˜ëŠ” ê²ƒ ì•„ë‹Œê°€ í•˜ëŠ” ì˜ì‹¬ì´ ë“¤ì—ˆë‹¤.
  - ê·¸ë˜ì„œ ğŸ¤— ë¡œ ê°„ë‹¨í•˜ê²Œ tokenize ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì•˜ë‹¤.
  - sent ê°€ `es` ì¸ ê²½ìš°
    - sent: Por su parte , el Abogado General de Victoria , Rob Hulls , indicÃ³ que no hay nadie que controle que las informaciones contenidas en CrimeNet son veraces .
    - `M-BERT` tok: Por su parte , el Ab ##oga ##do General de Victoria , Rob Hull ##s , ind ##ic ##Ã³ que no hay nadie que controle que las informa ##ciones conte ##nida ##s en Crime ##Net son vera ##ces .
    - EN-BERT tok: Po ##r su part ##e , el A ##bo ##gado General de Victoria , Rob Hull ##s , in ##dic ##Ã³ que no hay na ##die que control ##e que las inform ##ac ##ione ##s con ##ten ##idas en Crime ##Net son ve ##race ##s .
  - sent ê°€ `ko` ì¸ ê²½ìš°
     - sent: ì–¸ì–´(è¨€èª)ì— ëŒ€í•œ ì •ì˜ëŠ” ì—¬ëŸ¬ê°€ì§€ ì‹œë„ê°€ ìˆì—ˆë‹¤.
     - `M-BERT` tok: ì–¸ ##ì–´ ( è¨€ èª ) ì— ëŒ€í•œ ì • ##ì˜ ##ëŠ” ì—¬ëŸ¬ ##ê°€ì§€ ì‹œ ##ë„ê°€ ìˆì—ˆë‹¤ .
     - EN-BERT tok: [UNK] ( [UNK] [UNK] ) [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] .
  - **_ìœ„ì˜ ê²°ê³¼ë¡œ ë¯¸ë£¨ì–´ë³´ì•„, vocab overlap ì´ ë‚®ìœ¼ë©´ì„œ ì„±ëŠ¥ë„ ë‚®ì•˜ë˜ ì ë“¤ì˜ ì–¸ì–´ìŒì—ëŠ” EN-BERTì—ì„œ unkì´ ë§ì´ ë‚˜ì™”ë˜ ì–¸ì–´ê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šì„ê¹Œí•˜ëŠ” ìƒê°ì´ ë“¤ì—ˆê³ , ë¹„êµê°€ ê³µì •í•˜ì§€ ì•Šë‹¤ëŠ” ìƒê°ì´ ë“¤ì—ˆë‹¤._**
 - ë˜í•œ tlit. ì„ `M-BERT` ê°€ ëª»í•˜ëŠ” ì´ìœ ë¡œ, pre-train stepì—ì„œ tlit. corpus ê°€ ì—†ì—ˆê¸° ë•Œë¬¸ì´ë¼ê³  ì–¸ê¸‰í•˜ì˜€ëŠ”ë° EN-BERT ë˜í•œ ê°™ì€ ì´ìœ ë¡œ ì„±ëŠ¥ì´ ë‚®ì„ ìˆ˜ ë°–ì— ì—†ì—ˆì„ ê²ƒì´ë¼ê³  ìƒê°.


### SOV order ê°€ ì¤‘ìš”í•œ ì ì´ì—ˆì„ê¹Œ?
- ë…¼ë¬¸ì—ì„œëŠ” ì•„ë˜ í‘œì—ì„œ SVO -> SVO (81.55) > SVO -> SOV (66.52) ë¼ëŠ” ì  ë•Œë¬¸ì— SOV order ê°€ ê°€ì¥ ì¤‘ìš”í•˜ë‹¤ê³  ì£¼ì¥í•œë‹¤.
  - í•˜ì§€ë§Œ ë°˜ëŒ€ë¡œ SOV -> SOV (64.22) > SOV -> SVO (63.98) ì˜ ì°¨ì´ê°€ ì ê²Œ ë‚˜ëŠ” ì ì€ ì„¤ëª…í•  ìˆ˜ ì—†ë‹¤.
  <img src="https://user-images.githubusercontent.com/24843996/85165966-93f4e380-b2a1-11ea-9290-8451958499e3.png?style=centerme" width=50%>

- ì œ ì¶”ì¸¡ìœ¼ë¡œëŠ”, ì˜¤íˆë ¤ ê° ê·¸ë£¹ì„ êµ¬ì„±í•˜ëŠ” ì–¸ì–´ì™€ ê·¸ ì–¸ì–´ë“¤ì´ Wikipedia ì—ì„œ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨, ì¦‰ `M-BERT` í•™ìŠµì— ì˜í–¥ì„ ë§ì´ ë¼ì¹œ ì–¸ì–´ê°€ ì¤‘ìš”í•œ ì—­í• ì„ í–ˆì„ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ë‹¤.
  - SVO languages: Bulgarian, Catalan, Czech, Danish, English, Spanish, Estonian, Finnish, French, Galician, Hebrew, Croatian, Indonesian, Italian, Latvian, Norwegian (Bokmaal and Nynorsk), Polish, Portuguese (European and Brazilian), Romanian, Russian, Slovak, Slovenian, Swedish, and Chinese.
  - SOV Languages: Basque, Farsi, Hindi, Japanese, Korean, Marathi, Tamil, Telugu, Turkish, and Urdu.
    - Urdu -> Hindi ì˜ ì„±ëŠ¥ì´ 91% ì˜€ë˜ ì ì„ ê³ ë ¤í•˜ë©´ ì´ ì¤‘ ì–´ë–¤ ì–¸ì–´ìŒì—ì„œ êµ‰ì¥íˆ ë‚®ì€ ì„±ëŠ¥ì„ ë³´ì˜€ì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒ (í‰ê· ì´ 64.22 ì´ì–´ì•¼í•˜ë¯€ë¡œ) 
    - ê·¸ë£¹ì˜ í‰ê· ì¹˜ë¥¼ ë³´ì§€ ì•Šì•˜ë‹¤ë©´ ë‹¤ë¥¸ í•´ì„ì´ ê°€ëŠ¥í–ˆì„ ìˆ˜ë„..?
- SVO order ê°€ ë¹„ìŠ·í•˜ë©´ -> transfer ê°€ ì˜ëœë‹¤! ë¼ëŠ” ì£¼ì¥ì„ í•˜ê³  ì‹¶ì—ˆë‹¤ë©´ ë¹„êµí•˜ë ¤ëŠ” ëŒ€ìƒ ì–¸ì–´ìŒë“¤ê°„ì— SVO order ë¹¼ê³ ëŠ” ì¡°ê±´ì„ ë™ì¼í•˜ê²Œ ë§Œì¡±ì‹œì¼°ì–´ì•¼ í•˜ì§€ ì•Šì„ê¹Œí•˜ëŠ” ì•„ì‰¬ì›€ì´ ë‚¨ëŠ”ë‹¤.

### Feature space
- MLMì€ ë³´í†µ ì¤‘ê°„ layer ì—ì„œ semantic í•œ ì„±ì§ˆì´ ê°€ì¥ ë‘ë“œëŸ¬ì§€ê²Œ ë‚˜íƒ€ë‚˜ëŠ” ê²ƒ ê°™ë‹¤.
  <img src="https://user-images.githubusercontent.com/24843996/85170841-ed144580-b2a8-11ea-9db9-099c019568f3.png?style=centerme" alt="credit) The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives" width=60%>

  ![credit) BERTScore: Evaluating Text Generation with BERT](https://user-images.githubusercontent.com/24843996/85170937-1208b880-b2a9-11ea-81e8-c1102286646a.png)


### ë…¼ë¬¸ì˜ ë¶„ì„ ë‚´ìš©
- ë…¼ë¬¸ì—ì„œ ë¶„ì„í•œ ê²°ë¡ ì´ ì§€ë‚˜ì¹œ ì¼ë°˜í™”ê°€ ì•„ë‹ê¹Œí•˜ëŠ” ìƒê°ë„ ë“ ë‹¤.
- ì¼ë‹¨ `M-BERT`ê°€ zero-shot transferability ê°€ ë†’ì€ ì´ìœ ëŠ” ì–´ì©Œë©´ ê°™ì€ ë‚´ìš©ì˜ Wikipedia ë¬¸ì„œë¡œ í•™ìŠµí–ˆê¸° ë•Œë¬¸ì¼ ìˆ˜ ìˆë‹¤.
  - ë§Œì•½ì— í•œêµ­ì–´ëŠ” ë™ì¼ ë‚´ìš©ì— ëŒ€í•œ ë²ˆì—­ëœ ë¬¸ì„œê°€ ì—†ëŠ” (e.g., ë„¤ì´ë²„ ë¸”ë¡œê·¸) ë¡œ í•™ìŠµí•˜ê³ , ì˜ì–´ë„ ì˜ì–´ ë‚˜ë¦„ëŒ€ë¡œì˜ ë²ˆì—­ë¬¸ì´ ì—†ëŠ” ë¬¸ì„œë¡œ í•™ìŠµëœ BERT ì˜€ë”ë¼ë„ ê°™ì€ ê²°ê³¼ê°€ ë„ì¶œë˜ì—ˆì„ì§€ëŠ” ëª¨ë¥´ê² ë‹¤.
- `M-BERT` ì˜ í•™ìŠµ ë°ì´í„°ì˜ íŠ¹ì§•ì—ì„œ ê¸°ì¸í•œ íŠ¹ì§•ì´ ì–¼ë§ˆë‚˜ ë˜ëŠ”ì§€ë„ ê¶ê¸ˆí•˜ë‹¤. ì˜¤íˆë ¤ ì—¬ê¸°ì—ì„œ ì˜í–¥ì„ ë§ì´ ë°›ì•˜ì„ ìˆ˜ë„ ìˆì„ ê²ƒ ê°™ë‹¤.

## References

[^1]: <https://www.aclweb.org/anthology/P19-1493.pdf>
[^2]: <https://www.aclweb.org/anthology/P12-1066.pdf>
