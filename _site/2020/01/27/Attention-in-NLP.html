<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    
<link rel="icon" href="/assets/images/logo.png">
    
<title>Attention in NLP | Space Moon</title>
    
 
    
<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
    
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+KR:300">

<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
    
<link href="/assets/css/screen.css" rel="stylesheet">
    
<link href="/assets/css/main.css" rel="stylesheet">
    
</head>
    

    

<body class="layout-post">

    
<!-- Begin Menu Navigation
================================================== -->
<nav class="navbar navbar-expand-lg navbar-light bg-white fixed-top mediumnavigation nav-down">
    
    <div class="container pr-0">    
    
    <!-- Begin Logo -->
    <a class="navbar-brand" href="/">
    <img src="/assets/images/logo.png" alt="Space Moon">
    </a>
    <!-- End Logo -->
  
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
    </button>
    
    
    <div class="collapse navbar-collapse" id="navbarMediumish">
       
        <!-- Begin Menu -->
        
            <ul class="navbar-nav ml-auto">
                
                
                <li class="nav-item">
                
                <a class="nav-link" href="/index.html">Blog</a>
                </li>
                
                
                <li class="nav-item">
                
                <a class="nav-link" href="/about">About</a>
                </li>
                
                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://github.com/inmoonlight/"><i class="fab fa-github"></i></a>
                </li>

                <li class="nav-item">
                <a target="_blank" class="nav-link" href="https://www.linkedin.com/in/mjihyung/"><i class="fab fa-linkedin"></i></a>
                </li>
                
                <li class="nav-item">
                <a target="_blank"  class="nav-link" href="https://twitter.com/inmoonlight_kr"><i class="fab fa-twitter"></i></a>
                </li>

                <li class="nav-item">
                <a target="_blank"  class="nav-link" href="https://www.instagram.com/jihyung.moon/"><i class="fab fa-instagram"></i></a>
                </li>

                <li class="nav-item">
                <a target="_blank"  class="nav-link" href="/feed.xml"><i class="fa fa-rss"></i></a>
                </li>
                
            </ul>		
  
        <!-- End Menu -->

    </div>
        
    </div>
</nav>
<!-- End Navigation
================================================== -->
    
<div class="site-content">   
<div class="container">
    
<!-- Site Title
================================================== -->
<!-- <div class="mainheading">
    <h1 class="sitetitle">Space Moon</h1>
    <p class="lead">
         개인적이지만 사소하지 않은 이야기를 담고 싶습니다
    </p>
</div> -->

    
    
<!-- Content
================================================== --> 
<div class="main-content">
    <!-- Begin Article
================================================== -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <!-- (1) Optimize for mobile versions: http://goo.gl/EOpFl -->
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- (1) force latest IE rendering engine: bit.ly/1c8EiC9 -->
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Attention in NLP</title>
  <meta name="description" content="  “You can’t cram the meaning of a whole %&amp;!$# sentence into a single $&amp;!#* vector!” - Raymond Mooney" />

  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  
  
  <meta property="og:site_name" content="" />
  <meta property="og:title" content="Attention in NLP"/>
  
  <meta property="og:description" content="  “You can’t cram the meaning of a whole %&amp;!$# sentence into a single $&amp;!#* vector!” - Raymond Mooney" />
  
  <meta property="og:image" content="http://localhost:4000/assets/images/attention_camera.jpg" />
  <meta property="og:url" content="http://localhost:4000/2020/01/27/Attention-in-NLP" >
  <meta property="og:type" content="blog" />
  <meta property="article:published_time" content="2020-01-27T21:00:00+09:00">

  <link rel="canonical" href="http://localhost:4000/2020/01/27/Attention-in-NLP"/>
  <link rel="shortcut icon" href="/assets/images/favicon.png" type="image/png"/>
  <link rel="stylesheet" href="//brick.a.ssl.fastly.net/Linux+Libertine:400,400i,700,700i/Open+Sans:400,400i,700,700i">
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" type="text/css" media="screen" href="/css/main.css" />
  <link rel="stylesheet" type="text/css" media="print" href="/css/print.css" />
</head>

  <body itemscope itemtype="http://schema.org/Article">
	<!-- header start -->


<!-- header end -->

	<main class="content" role="main">
	  <article class="post">
			<script type="text/javascript" async
				src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
			</script>
		
		<div class="article-image">
		  <div class="post-image-image" style="background-image: url(/assets/images/attention_camera.jpg)">
			Article Image
		  </div>
		  <div class="post-image-image2" style="background-image: url(/assets/images/attention_camera.jpg)">
			Article Image
		  </div>
		  <div class="post-meta">
			<h1 class="post-title">Attention in NLP</h1>
			<div class="cf post-meta-text">
        <time datetime="27-01-2020">Jan 27, 2020</time>
        | <span class="reading-time" title="Estimated read time">
    

    
        7 mins
    
</span> read
			  <!-- , tagged on <span class="post-tag-">, <a href="/tag/"></a></span> -->
			</div>
			<!-- <div style="text-align:center">
			  <a href="#topofpage" class="topofpage"><i class="fa fa-angle-down"></i></a>
			</div> -->
		  </div>
		</div>
		
		<section class="post-content-mediator">
		  <blockquote>
  <p>“You can’t cram the meaning of a whole %&amp;!$# sentence into a single $&amp;!#* vector!” <br />
- Raymond Mooney</p>
</blockquote>

<p>Attention은 single vector에 한 문장의 의미를 완벽하게 담을 수 없기 때문에 필요한 순간에, 필요한 정보를 사용하기 위한 방법이다.
기본적으로 <strong>query</strong> vector와 <strong>key</strong> vector의 조합으로 attention weight가 계산된다.
여기서 “조합”의 방법에는 크게 두가지가 있다.
하나는 Additive Attention으로 query vector와 key vector에 feed-forward network를 적용한 것이고,
다른 하나는 Dot-Product Attention으로 문자그대로 query vector와 key vector의 dot-product를 이용한 것이다.
이번 글에서는 각 Attention 방법들과 이들의 장단점을 소개하려고 한다.<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup></p>

<div class="breaker"></div>

<h3 id="table-of-contents">Table of Contents</h3>

<p><a href="#1-additive-attention">1. Additive Attention</a> <br />
    <a href="#11-bilinear">1.1 Bilinear</a> <br />
    <a href="#12-multi-layer-perceptron">1.2 Multi-layer Perceptron</a> <br />
<a href="#2-dot-product-attention">2. Dot-Product Attention</a> <br />
    <a href="#21-dot-product">2.1 Dot-Product</a> <br />
    <a href="#22-scaled-dot-product">2.2 Scaled Dot-Product</a> <br />
<a href="#3-conclusions">3. Conclusions</a> <br />
<a href="#references">References</a></p>

<div class="breaker"></div>

<h2 id="1-additive-attention"><a href="#table-of-contents">1. Additive Attention</a></h2>

<p>Additive Attention은 query vector와 key vector의 조합으로 attention 값을 얻을 때 단일 hidden layer를 가진 feed-forward network를 이용한다.
query vector (<script type="math/tex">q</script>) 와 key vector (<script type="math/tex">k</script>) 가 같은 dimension을 가질 필요가 없으며, dimension의 크기에 상관없이 좋은 성능을 보인다는 장점이 있다.</p>

<h3 id="11-bilinear"><a href="#table-of-contents">1.1 Bilinear</a><sup id="fnref:2"><a href="#fn:2" class="footnote">2</a></sup></h3>

<script type="math/tex; mode=display">a(\boldsymbol{q}, \boldsymbol{k})=\boldsymbol{q}^{\top} W \boldsymbol{k}</script>

<p><script type="math/tex">q</script> 와 <script type="math/tex">k</script> 에 <script type="math/tex">W</script> 를 곱하는 방법이다. 
<script type="math/tex">q</script> 를 linear transform 시킨 후, <script type="math/tex">k</script> 와 dot-product를 한 것과 같다.</p>

<h3 id="12-multi-layer-perceptron"><a href="#table-of-contents">1.2 Multi-layer Perceptron</a><sup id="fnref:3"><a href="#fn:3" class="footnote">3</a></sup></h3>

<script type="math/tex; mode=display">a(\boldsymbol{q}, \boldsymbol{k})=\boldsymbol{w}_{2}^{\top} \tanh \left(W_{1}[\boldsymbol{q} ; \boldsymbol{k}]\right)</script>

<p><script type="math/tex">q</script> 와 <script type="math/tex">k</script> 를 concat시킨 후 single hidden layer와 activation 함수로 tanh를 사용한 feed-forward network를 사용하였다. 
이 방법은 익숙할 것이다.
왜냐하면 <a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a>에서 이 attention을 이용했기 때문이다. 
아래의 오른쪽 수식에서 <script type="math/tex">a</script>는 alignment model로 위에서 언급한 feed-forward network와 같은 역할을 한다.</p>

<div style="text-align:center">
<img class="image" src="/assets/images/seq2seq_attention.png" width="60%" />
</div>
<p><br /></p>

<div class="breaker"></div>

<h2 id="2-dot-product-attention"><a href="#table-of-contents">2. Dot-Product Attention</a></h2>

<p>Dot-Product attention은 <script type="math/tex">\boldsymbol{q}^{\top} \boldsymbol{k}</script> 을 기반으로 attention weight를 구하는 방법이다.
Additive attention과는 달리 hidden layer를 곱하는 과정이 추가되지 않아서 연산 속도와 space 측면에서 효율적이다.
하지만 반드시 <script type="math/tex">q</script> 와 <script type="math/tex">k</script> 의 dimension이 같아야 한다는 제약조건이 있으며, dimension이 클 때 학습에 방해가 된다는 단점이 있다.</p>

<h3 id="21-dot-product"><a href="#table-of-contents">2.1 Dot-Product</a></h3>

<script type="math/tex; mode=display">a(\boldsymbol{q}, \boldsymbol{k})=\boldsymbol{q}^{\top} \boldsymbol{k}</script>

<p><script type="math/tex">q</script> 와 <script type="math/tex">k</script> 의 elment-wise product의 합이다.
이 연산의 특성 상, 반드시 dimension이 같아야 한다.</p>

<p>만약 <script type="math/tex">q</script> 와 <script type="math/tex">k</script> 의 각 요소가 독립적이고 평균이 0, 분산이 1 인 분포의 random variable이라면, <script type="math/tex">{q}^{\top}{k}</script> 는 평균이 0이고 분산이 dimension의 크기인 분포를 따른다. 
분산이 증가되면 dot-product에 softmax를 취했을 때 어떤 값은 굉장히 크지만 대부분의 값은 굉장히 작게 만든다.
작은 값들은 back-propagation 시 gradient도 작기 때문에 전체적으로 학습이 잘 되지 않게 만든다.
따라서 dimension이 큰 경우 성능이 좋지 않다.</p>

<h3 id="22-scaled-dot-product"><a href="#table-of-contents">2.2 Scaled Dot-Product</a><sup id="fnref:4"><a href="#fn:4" class="footnote">4</a></sup></h3>

<script type="math/tex; mode=display">a(\boldsymbol{q}, \boldsymbol{k})=\frac{\boldsymbol{q}^{\top} \boldsymbol{k}}{\sqrt{|\boldsymbol{d}|}}</script>

<p>Scaled Dot-Product는 <a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">Attention is All You Need</a> 에서 처음으로 소개된 방법이다.
Dot-Product의 dimension이 클 때 학습이 잘 되지 않는 단점을 극복하게 위해 dot-product 결과를 <script type="math/tex">q</script> 의 dimension <script type="math/tex">d</script> (<script type="math/tex">k</script> 의 dimension 이기도 하다) 의 root 값으로 나누어주었다.<sup id="fnref:5"><a href="#fn:5" class="footnote">5</a></sup></p>

<div class="breaker"></div>

<h2 id="3-conclusions"><a href="#table-of-contents">3. Conclusions</a></h2>

<p>Additive attention은 dimension에 상관없이 좋은 결과를 내고, attention을 계산하는 재료인 query vector와 key vector의 dimension에 상관없이 사용할 수 있다. 
하지만 최근의 NLP trend라고 할 수 있는, 대량의 데이터를 굉장히 큰 모델로 학습시키는 방법에는 안그래도 많은 연산량에 부담이 되는 방법이다.
그래서 계산의 부담이 적으면서 dimension이 큰 경우에 대해서도 좋은 성능을 보이는 scaled dot-product 기반의 attention이 잘 쓰이는 편이다.</p>

<div class="breaker"></div>

<h2 id="references"><a href="#table-of-contents">References</a></h2>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>전반적인 내용은 Graham Neubig의 <a href="http://phontron.com/class/nn4nlp2019/assets/slides/nn4nlp-09-attention.pdf">NN4NLP Attention 강의</a>를 참고했습니다. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:2">
      <p><a href="https://www.aclweb.org/anthology/D15-1166.pdf">Effective Approaches to Attention-based Neural Machine Translation</a> <a href="#fnref:2" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:3">
      <p><a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> <a href="#fnref:3" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:4">
      <p><a href="https://papers.nips.cc/paper/7181-attention-is-all-you-need.pdf">Attention is All You Need</a> <a href="#fnref:4" class="reversefootnote">&#8617;</a></p>
    </li>
    <li id="fn:5">
      <p>root로 나누어 준 이유는 scaled dot-product의 결과를 평균이 0, 분산이 1 인 분포로 만들기 위해서다. <a href="#fnref:5" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

		</section>
		<footer class="post-footer">
			<!-- <div class="col-md-8 p-5 align-self-center text-center"> -->
			<ul class="tag-box inline">
					  
					
						 
							<a href="/tag/machine-learning">Machine-learning </a>
						 
							<a href="/tag/nlp">Nlp </a>
						 
							<a href="/tag/attention">Attention </a>
						 
							<a href="/tag/머신러닝">머신러닝 </a>
						 
							<a href="/tag/자연어처리">자연어처리 </a>
						
					
					
			</ul>
		  <section class="share">
				
			  	
						<a class="icon-twitter" href="http://twitter.com/share?text=Attention+in+NLP&amp;url=http://localhost:4000/2020/01/27/Attention-in-NLP"
				  		onclick="window.open(this.href, 'twitter-share', 'width=550,height=255');return false;">
						<i class="fa fa-twitter"></i><span class="hidden">twitter</span>
						</a>
			 		
				
			  	
						<a class="icon-facebook" href="https://www.facebook.com/sharer.php?t=Attention+in+NLP&amp;u=http://localhost:4000/2020/01/27/Attention-in-NLP"
				  		onclick="window.open(this.href, 'facebook-share', 'width=550,height=255');return false;">
						<i class="fa fa-facebook"></i><span class="hidden">facebook</span>
						</a>
			 		
				
		  </section>
		</footer>
	  </article>
	</main>
	<script src="https://code.jquery.com/jquery-1.11.1.min.js"></script>
<script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/assets/js/index.js"></script>
<script type="text/javascript" src="/assets/js/readingTime.min.js"></script>
<script>
(function ($) {
  "use strict";
  $(document).ready(function(){

    var $window = $(window),
    $image = $('.post-image-image, .teaserimage-image');
    
      $window.on('scroll', function() {
        var top = $window.scrollTop();

        if (top < 0 || top > 1500) { return; }
        $image
          .css('transform', 'translate3d(0px, '+top/3+'px, 0px)')
          .css('opacity', 1-Math.max(top/700, 0));
      });
      $window.trigger('scroll');

      var height = $('.article-image').height();
      $('.post-content').css('padding-top', height + 'px');

      $('a[href*=#]:not([href=#])').click(function() {
        if (location.pathname.replace(/^\//,'') == this.pathname.replace(/^\//,'')
         && location.hostname == this.hostname) {
          var target = $(this.hash);
          target = target.length ? target : $('[name=' + this.hash.slice(1) +']');
          if (target.length) {
            $('html,body').animate({ scrollTop: target.offset().top }, 500);
            return false;
          }
        }
      });

  });
}(jQuery));
</script>

<!-- Google Analytics -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
   (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
   m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
   })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-131297969-1', 'auto');
ga('send', 'pageview');

</script>



  </body>
</html>
<!-- End Article
================================================== -->

  

<!-- Begin Comments
================================================== -->

	<div class="container">
		<div id="comments" class="row justify-content-center mb-5">
			<div class="col-md-10">              
				<section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
        var disqus_shortname = 'inmoonlight'; 
        var disqus_developer = 0;
        (function() {
            var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
            dsq.src = window.location.protocol + '//' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>
                
			</div>
		</div>
	</div>

<!--End Comments
================================================== -->
</div>

<!-- Bottom Alert Bar
================================================== -->
<!-- <div class="alertbar">
	<div class="container text-center">
		<span><img src="/assets/images/logo.png" alt=""> &nbsp; Never miss a <b>story</b> from us, subscribe to our newsletter</span>
        <form action="" method="post" name="mc-embedded-subscribe-form" class="wj-contact-form validate" target="_blank" novalidate>
            <div class="mc-field-group">
            <input type="email" placeholder="Email" name="EMAIL" class="required email" id="mce-EMAIL" autocomplete="on" required>
            <input type="submit" value="Subscribe" name="subscribe" class="heart">
            </div>
        </form>
	</div>
</div>     -->
    
</div><!-- /.container>
    
<!-- Categories Jumbotron
================================================== -->
<div class="jumbotron fortags">
	<div class="d-md-flex h-100">
		<div class="col-md-4 transpdark align-self-center text-center h-100">
            <div class="d-md-flex align-items-center justify-content-center h-100">
                <h2 class="d-md-block align-self-center py-1 font-weight-light">Explore <span class="d-none d-md-inline">→</span></h2>
            </div>
		</div>
		<div class="col-md-8 p-5 align-self-center text-center">
            
          
             
              <a href="/tag/멘토링">멘토링 (2)</a>
             
              <a href="/tag/mentoring">Mentoring (2)</a>
             
              <a href="/tag/essay">Essay (3)</a>
             
              <a href="/tag/에세이">에세이 (3)</a>
             
              <a href="/tag/machine-learning">Machine-learning (8)</a>
             
              <a href="/tag/book">Book (4)</a>
             
              <a href="/tag/summary">Summary (3)</a>
             
              <a href="/tag/머신러닝">머신러닝 (8)</a>
             
              <a href="/tag/책">책 (4)</a>
             
              <a href="/tag/요약">요약 (3)</a>
             
              <a href="/tag/연울림">연울림 (4)</a>
             
              <a href="/tag/데이터분석">데이터분석 (3)</a>
             
              <a href="/tag/data-analysis">Data-analysis (3)</a>
             
              <a href="/tag/사회">사회 (3)</a>
             
              <a href="/tag/society">Society (3)</a>
             
              <a href="/tag/뉴스댓글">뉴스댓글 (3)</a>
             
              <a href="/tag/news-comments">News-comments (3)</a>
             
              <a href="/tag/노르웨이">노르웨이 (1)</a>
             
              <a href="/tag/여행">여행 (1)</a>
             
              <a href="/tag/quantum-computer">Quantum-computer (1)</a>
             
              <a href="/tag/basic">Basic (1)</a>
             
              <a href="/tag/양자컴퓨터">양자컴퓨터 (1)</a>
             
              <a href="/tag/기초">기초 (1)</a>
             
              <a href="/tag/nlp">Nlp (5)</a>
             
              <a href="/tag/dataset">Dataset (1)</a>
             
              <a href="/tag/자연어처리">자연어처리 (5)</a>
             
              <a href="/tag/데이터셋">데이터셋 (1)</a>
             
              <a href="/tag/review">Review (1)</a>
             
              <a href="/tag/후기">후기 (1)</a>
             
              <a href="/tag/technique">Technique (1)</a>
             
              <a href="/tag/attention">Attention (1)</a>
             
              <a href="/tag/korean">Korean (1)</a>
             
              <a href="/tag/hate-speech">Hate-speech (1)</a>
             
              <a href="/tag/한국어">한국어 (1)</a>
             
              <a href="/tag/혐오발언">혐오발언 (1)</a>
             
              <a href="/tag/multilingual">Multilingual (1)</a>
             
              <a href="/tag/BERT">Bert (1)</a>
            
          
        

		</div>
	</div>
</div>
 


<!-- Begin Footer
================================================== -->
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                 Copyright © 2020 Space Moon 
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                <a target="_blank" href="https://www.wowthemes.net">Mediumish Theme</a> by WowThemes.net
            </div>
        </div>
    </div>
</footer>
<!-- End Footer
================================================== -->

   
</div> <!-- /.site-content>

<!-- Bootstrap core JavaScript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
    
<script src="/assets/js/jquery.min.js"></script>
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
    
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
    
<script src="/assets/js/ie10-viewport-bug-workaround.js"></script>
    
<script src="/assets/js/mediumish.js"></script>
    
<script id="dsq-count-scr" src="//inmoonlight.disqus.com/count.js"></script>
</body>
</html>
